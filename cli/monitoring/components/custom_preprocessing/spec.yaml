$schema: http://azureml/sdk-2-0/SparkComponent.json
type: spark

name: custom_preprocessor
display_name: My Custom Preprocessor
description: Filters the data based on the window provided.
version: 1.0.0
is_deterministic: true

code: ./src
entry:
  file: ./run.py

inputs:
  data_window_end:
    type: string
  data_window_start:
    type: string
  input_data:
    type: uri_folder
    mode: direct
outputs:
  preprocessed_input_data:
    type: mltable
    mode: direct
conf:
  spark.driver.cores: 1
  spark.driver.memory: 2g
  spark.executor.cores: 2
  spark.executor.memory: 2g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: True
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
  spark.synapse.library.python.env: |
    channels:
      - conda-forge
    dependencies:
      - python=3.8
      - pip:
        - scipy~=1.10.0
        - numpy~=1.21.0
        - pandas~=1.4.3
        - azureml-mlflow~=1.49.0
        - mltable~=1.3.0
        - azureml-fsspec
        - fsspec~=2023.4.0
    name: momo-base-spark
args: >-
  --data_window_end ${{inputs.data_window_end}}
  --data_window_start ${{inputs.data_window_start}}
  --input_data ${{inputs.input_data}}
  --preprocessed_input_data ${{outputs.preprocessed_input_data}}
