{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-with-data-dependency-steps.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Showcasing Dataset and PipelineParameter\n",
        "\n",
        "This notebook demonstrates how a [**FileDataset**](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.filedataset?view=azure-ml-py) or [**TabularDataset**](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py) can be parametrized with [**PipelineParameters**](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelineparameter?view=azure-ml-py) in an AML [Pipeline](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline(class)?view=azure-ml-py). By parametrizing datasets, you can dynamically run pipeline experiments with different datasets without any code change.\n",
        "\n",
        "A common use case is building a training pipeline with a sample of your training data for quick iterative development. When you're ready to test and deploy your pipeline at scale, you can pass in your full training dataset to the pipeline experiment without making any changes to your training script. \n",
        " \n",
        "To see more about how parameters work between steps, please refer [aml-pipelines-with-data-dependency-steps](https://aka.ms/pl-data-dep).\n",
        "\n",
        "* [How to create a Pipeline with a Dataset PipelineParameter](#index1)\n",
        "* [How to submit a Pipeline with a Dataset PipelineParameter](#index2)\n",
        "* [How to submit a Pipeline and change the Dataset PipelineParameter value from the sdk](#index3)\n",
        "* [How to submit a Pipeline and change the Dataset PipelineParameter value using a REST call](#index4)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Azure Machine Learning and Pipeline SDK-specific imports"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace, Experiment, Dataset\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core import Pipeline, PipelineRun\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.20.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1618509674059
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Workspace\n",
        "\n",
        "Initialize a workspace object from persisted configuration. If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure the config file is present at .\\config.json\n",
        "\n",
        "If you don't have a config.json file, go through the [configuration Notebook](https://aka.ms/pl-config) first.\n",
        "\n",
        "This sets you up with a working config file that has information on your workspace, subscription id, etc."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opendatasetspmworkspace2\n",
            "opendatasetspmrg\n",
            "eastus2\n",
            "21d8f407-c4c4-452e-87a4-e609bfb86248\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1618509683125
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an Azure ML experiment\n",
        "\n",
        "Let's create an experiment named \"showcasing-dataset\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for the run history container in the workspace.\n",
        "experiment_name = 'showcasing-dataset'\n",
        "source_directory  = '.'\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "Experiment(Name: showcasing-dataset,\nWorkspace: opendatasetspmworkspace2)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>showcasing-dataset</td><td>opendatasetspmworkspace2</td><td><a href=\"https://ml.azure.com/experiments/showcasing-dataset?wsid=/subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/opendatasetspmrg/workspaces/opendatasetspmworkspace2\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1618509686709
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create or Attach an AmlCompute cluster\n",
        "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for your AutoML run. In this tutorial, you get the default `AmlCompute` as your training compute resource."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for your cluster.\n",
        "amlcompute_cluster_name = \"cpu-cluster\"\n",
        "\n",
        "found = False\n",
        "# Check if this compute target already exists in the workspace.\n",
        "cts = ws.compute_targets\n",
        "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
        "    found = True\n",
        "    print('Found existing compute target.')\n",
        "    compute_target = cts[amlcompute_cluster_name]\n",
        "    \n",
        "if not found:\n",
        "    print('Creating a new compute target...')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", # for GPU, use \"STANDARD_NC6\"\n",
        "                                                                #vm_priority = 'lowpriority', # optional\n",
        "                                                                max_nodes = 4)\n",
        "\n",
        "    # Create the cluster.\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
        "    \n",
        "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
        "    # If no min_node_count is provided, it will use the scale settings for the cluster.\n",
        "    compute_target.wait_for_completion(show_output = True, timeout_in_minutes = 10)\n",
        "    \n",
        "     # For a more detailed view of current AmlCompute status, use get_status()."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a new compute target...\n",
            "Creating\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1618514007763
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Configuration\n",
        "\n",
        "The following steps detail how to create a [FileDataset](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.filedataset?view=azure-ml-py) and [TabularDataset](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py) from an external CSV file, and configure them to be used by a [Pipeline](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline(class)?view=azure-ml-py):\n",
        "\n",
        "1. Create a dataset from a csv file\n",
        "2. Create a [PipelineParameter](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelineparameter?view=azure-ml-py) object and set the `default_value` to the dataset. [PipelineParameter](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelineparameter?view=azure-ml-py) objects enabled arguments to be passed into Pipelines when they are resubmitted after creation. The `name` is referenced later on when we submit additional pipeline runs with different input datasets. \n",
        "3. Create a [DatasetConsumptionConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.dataset_consumption_config.datasetconsumptionconfig?view=azure-ml-py) object from the [PiepelineParameter](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelineparameter?view=azure-ml-py). The [DatasetConsumptionConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.dataset_consumption_config.datasetconsumptionconfig?view=azure-ml-py) object specifies how the dataset should be used by the remote compute where the pipeline is run. **NOTE** only [DatasetConsumptionConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.dataset_consumption_config.datasetconsumptionconfig?view=azure-ml-py) objects built on [FileDataset](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.filedataset?view=azure-ml-py) can be set `as_mount()` or `as_download()` on the remote compute."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "file_dataset = Dataset.File.from_files('https://dprepdata.blob.core.windows.net/demo/Titanic.csv')\n",
        "file_pipeline_param = PipelineParameter(name=\"file_ds_param\", default_value=file_dataset)\n",
        "file_ds_consumption = DatasetConsumptionConfig(\"file_dataset\", file_pipeline_param).as_mount()\n",
        "\n",
        "tabular_dataset = Dataset.Tabular.from_delimited_files('https://dprepdata.blob.core.windows.net/demo/Titanic.csv')\n",
        "tabular_pipeline_param = PipelineParameter(name=\"tabular_ds_param\", default_value=tabular_dataset)\n",
        "tabular_ds_consumption = DatasetConsumptionConfig(\"tabular_dataset\", tabular_pipeline_param)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "tags": [
          "datapath-remarks-sample"
        ],
        "gather": {
          "logged": 1618514352870
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will setup a training script to ingest our passed-in datasets and print their contents. **NOTE** the names of the datasets referenced inside the training script correspond to the `name` of their respective [DatasetConsumptionConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.dataset_consumption_config.datasetconsumptionconfig?view=azure-ml-py) objects we defined above."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_with_dataset.py\n",
        "from azureml.core import Run\n",
        "\n",
        "input_file_ds_path = Run.get_context().input_datasets['file_dataset']\n",
        "with open(input_file_ds_path, 'r') as f:\n",
        "    content = f.read()\n",
        "    print(content)\n",
        "\n",
        "input_tabular_ds = Run.get_context().input_datasets['tabular_dataset']\n",
        "tabular_df = input_tabular_ds.to_pandas_dataframe()\n",
        "print(tabular_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_with_dataset.py\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='index1'></a>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Pipeline with a Dataset PipelineParameter\n",
        "\n",
        "Note that the ```file_ds_consumption``` and ```tabular_ds_consumption``` are specified as both arguments and inputs to create a step."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_step = PythonScriptStep(\n",
        "    name=\"train_step\",\n",
        "    script_name=\"train_with_dataset.py\",\n",
        "    arguments=[\"--param1\", file_ds_consumption, \"--param2\", tabular_ds_consumption],\n",
        "    inputs=[file_ds_consumption, tabular_ds_consumption],\n",
        "    compute_target=compute_target,\n",
        "    source_directory=source_directory)\n",
        "\n",
        "print(\"train_step created\")\n",
        "\n",
        "pipeline = Pipeline(workspace=ws, steps=[train_step])\n",
        "print(\"pipeline with the train_step created\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_step created\n",
            "pipeline with the train_step created\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1618514385437
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='index2'></a>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit a Pipeline with a Dataset PipelineParameter\n",
        "\n",
        "Pipelines can be submitted with default values of PipelineParameters by not specifying any parameters."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline will run with default file_ds and tabular_ds\n",
        "pipeline_run = experiment.submit(pipeline)\n",
        "print(\"Pipeline is submitted for execution\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created step train_step [0f3eb083][9b51f9c9-e9e1-4bcc-8f04-9e5599fd3ffe], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 415bff50-a59c-4bc1-b92e-734e853f3a68\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/showcasing-dataset/runs/415bff50-a59c-4bc1-b92e-734e853f3a68?wsid=/subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/opendatasetspmrg/workspaces/opendatasetspmworkspace2\n",
            "Pipeline is submitted for execution\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1618514449515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(pipeline_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "851ab4db7c65458eba5ef1ac95933976"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/showcasing-dataset/runs/415bff50-a59c-4bc1-b92e-734e853f3a68?wsid=/subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/opendatasetspmrg/workspaces/opendatasetspmworkspace2\", \"run_id\": \"415bff50-a59c-4bc1-b92e-734e853f3a68\", \"run_properties\": {\"run_id\": \"415bff50-a59c-4bc1-b92e-734e853f3a68\", \"created_utc\": \"2021-04-15T19:20:45.95928Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-04-15T19:30:24.949926Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.415bff50-a59c-4bc1-b92e-734e853f3a68/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=fPL2QHPxcsh4UooGA6BkFNpeXEILwW%2BPODL9WUxleVI%3D&st=2021-04-15T20%3A11%3A21Z&se=2021-04-16T04%3A21%3A21Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.415bff50-a59c-4bc1-b92e-734e853f3a68/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=cCFA%2FooxHrwTTA8BbNAarrUhTyIm6HN4PD3NWlNJkUE%3D&st=2021-04-15T20%3A11%3A21Z&se=2021-04-16T04%3A21%3A21Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.415bff50-a59c-4bc1-b92e-734e853f3a68/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=43A6gmBEY9jEWLUSmH1%2FcHC3c%2B%2FQ70JFL5RGCZLxsSM%3D&st=2021-04-15T20%3A11%3A21Z&se=2021-04-16T04%3A21%3A21Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:09:38\"}, \"child_runs\": [{\"run_id\": \"fa5d2bed-c6da-4ceb-a97f-0c943a8c78de\", \"name\": \"train_step\", \"status\": \"Finished\", \"start_time\": \"2021-04-15T19:23:44.053792Z\", \"created_time\": \"2021-04-15T19:20:52.589012Z\", \"end_time\": \"2021-04-15T19:30:20.095547Z\", \"duration\": \"0:09:27\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-04-15T19:20:52.589012Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-04-15 19:20:52Z] Submitting 1 runs, first five are: 0f3eb083:fa5d2bed-c6da-4ceb-a97f-0c943a8c78de\\n[2021-04-15 19:30:24Z] Completing processing run id fa5d2bed-c6da-4ceb-a97f-0c943a8c78de.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"f21e246a\": {\"node_id\": \"f21e246a\", \"name\": \"file_ds_param\"}, \"1acd7771\": {\"node_id\": \"1acd7771\", \"name\": \"tabular_ds_param\"}}, \"module_nodes\": {\"0f3eb083\": {\"node_id\": \"0f3eb083\", \"name\": \"train_step\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"fa5d2bed-c6da-4ceb-a97f-0c943a8c78de\"}}, \"edges\": [{\"source_node_id\": \"f21e246a\", \"source_node_name\": \"file_ds_param\", \"source_name\": \"data\", \"target_name\": \"file_dataset\", \"dst_node_id\": \"0f3eb083\", \"dst_node_name\": \"train_step\"}, {\"source_node_id\": \"1acd7771\", \"source_node_name\": \"tabular_ds_param\", \"source_name\": \"data\", \"target_name\": \"file_dataset\", \"dst_node_id\": \"0f3eb083\", \"dst_node_name\": \"train_step\"}], \"child_runs\": [{\"run_id\": \"fa5d2bed-c6da-4ceb-a97f-0c943a8c78de\", \"name\": \"train_step\", \"status\": \"Finished\", \"start_time\": \"2021-04-15T19:23:44.053792Z\", \"created_time\": \"2021-04-15T19:20:52.589012Z\", \"end_time\": \"2021-04-15T19:30:20.095547Z\", \"duration\": \"0:09:27\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-04-15T19:20:52.589012Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.20.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1618514454521
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: 415bff50-a59c-4bc1-b92e-734e853f3a68\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/showcasing-dataset/runs/415bff50-a59c-4bc1-b92e-734e853f3a68?wsid=/subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/opendatasetspmrg/workspaces/opendatasetspmworkspace2\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: fa5d2bed-c6da-4ceb-a97f-0c943a8c78de\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/showcasing-dataset/runs/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de?wsid=/subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/opendatasetspmrg/workspaces/opendatasetspmworkspace2\n",
            "StepRun( train_step ) Status: NotStarted\n",
            "StepRun( train_step ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d.txt\n",
            "========================================================================================================================\n",
            "2021-04-15T19:23:42Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/opendatasetspmworkspace2/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/mounts/workspaceblobstore\n",
            "2021-04-15T19:23:43Z Starting output-watcher...\n",
            "2021-04-15T19:23:43Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "2021-04-15T19:25:50Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
            "2021-04-15T19:25:50Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_75dbdd65efabd34ac9f6ccab5f74b4b0\n",
            "4007a89234b4: Pulling fs layer\n",
            "5dfa26c6b9c9: Pulling fs layer\n",
            "0ba7bf18aa40: Pulling fs layer\n",
            "4c6ec688ebe3: Pulling fs layer\n",
            "574f361512d6: Pulling fs layer\n",
            "db4d1e2d7079: Pulling fs layer\n",
            "e544ee0f522d: Pulling fs layer\n",
            "c655136086be: Pulling fs layer\n",
            "2ec37f44090c: Pulling fs layer\n",
            "5fba3bd4a2c4: Pulling fs layer\n",
            "7e0ea9d0a1ab: Pulling fs layer\n",
            "da005f826951: Pulling fs layer\n",
            "f1a024a7664e: Pulling fs layer\n",
            "4cb089fddd83: Pulling fs layer\n",
            "7cfd8325b2ec: Pulling fs layer\n",
            "23efb016dfd0: Pulling fs layer\n",
            "841f0fa8d0a3: Pulling fs layer\n",
            "1d6ec8fef32b: Pulling fs layer\n",
            "4c6ec688ebe3: Waiting\n",
            "574f361512d6: Waiting\n",
            "db4d1e2d7079: Waiting\n",
            "e544ee0f522d: Waiting\n",
            "c655136086be: Waiting\n",
            "2ec37f44090c: Waiting\n",
            "5fba3bd4a2c4: Waiting\n",
            "7e0ea9d0a1ab: Waiting\n",
            "da005f826951: Waiting\n",
            "f1a024a7664e: Waiting\n",
            "4cb089fddd83: Waiting\n",
            "7cfd8325b2ec: Waiting\n",
            "23efb016dfd0: Waiting\n",
            "841f0fa8d0a3: Waiting\n",
            "1d6ec8fef32b: Waiting\n",
            "0ba7bf18aa40: Verifying Checksum\n",
            "0ba7bf18aa40: Download complete\n",
            "5dfa26c6b9c9: Verifying Checksum\n",
            "5dfa26c6b9c9: Download complete\n",
            "4c6ec688ebe3: Verifying Checksum\n",
            "4c6ec688ebe3: Download complete\n",
            "db4d1e2d7079: Verifying Checksum\n",
            "db4d1e2d7079: Download complete\n",
            "4007a89234b4: Verifying Checksum\n",
            "4007a89234b4: Download complete\n",
            "e544ee0f522d: Verifying Checksum\n",
            "e544ee0f522d: Download complete\n",
            "574f361512d6: Verifying Checksum\n",
            "574f361512d6: Download complete\n",
            "5fba3bd4a2c4: Verifying Checksum\n",
            "5fba3bd4a2c4: Download complete\n",
            "c655136086be: Verifying Checksum\n",
            "c655136086be: Download complete\n",
            "da005f826951: Verifying Checksum\n",
            "da005f826951: Download complete\n",
            "7e0ea9d0a1ab: Verifying Checksum\n",
            "7e0ea9d0a1ab: Download complete\n",
            "2ec37f44090c: Verifying Checksum\n",
            "2ec37f44090c: Download complete\n",
            "7cfd8325b2ec: Verifying Checksum\n",
            "7cfd8325b2ec: Download complete\n",
            "23efb016dfd0: Verifying Checksum\n",
            "23efb016dfd0: Download complete\n",
            "841f0fa8d0a3: Verifying Checksum\n",
            "841f0fa8d0a3: Download complete\n",
            "f1a024a7664e: Verifying Checksum\n",
            "f1a024a7664e: Download complete\n",
            "1d6ec8fef32b: Verifying Checksum\n",
            "1d6ec8fef32b: Download complete\n",
            "4cb089fddd83: Verifying Checksum\n",
            "4cb089fddd83: Download complete\n",
            "4007a89234b4: Pull complete\n",
            "5dfa26c6b9c9: Pull complete\n",
            "0ba7bf18aa40: Pull complete\n",
            "4c6ec688ebe3: Pull complete\n",
            "574f361512d6: Pull complete\n",
            "db4d1e2d7079: Pull complete\n",
            "e544ee0f522d: Pull complete\n",
            "c655136086be: Pull complete\n",
            "2ec37f44090c: Pull complete\n",
            "5fba3bd4a2c4: Pull complete\n",
            "7e0ea9d0a1ab: Pull complete\n",
            "da005f826951: Pull complete\n",
            "f1a024a7664e: Pull complete\n",
            "4cb089fddd83: Pull complete\n",
            "7cfd8325b2ec: Pull complete\n",
            "23efb016dfd0: Pull complete\n",
            "841f0fa8d0a3: Pull complete\n",
            "1d6ec8fef32b: Pull complete\n",
            "Digest: sha256:5042e7b6022a0e175950711f563a70b84f35d88cae002a569f502b498e2c89af\n",
            "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_75dbdd65efabd34ac9f6ccab5f74b4b0:latest\n",
            "viennaglobal.azurecr.io/azureml/azureml_75dbdd65efabd34ac9f6ccab5f74b4b0:latest\n",
            "2021-04-15T19:27:11Z Check if container fa5d2bed-c6da-4ceb-a97f-0c943a8c78de_sidecar already exist exited with 0, \n",
            "\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d.txt\n",
            "===============================================================================================================\n",
            "[2021-04-15T19:27:35.369250] Entering job preparation.\n",
            "[2021-04-15T19:27:36.206265] Starting job preparation.\n",
            "[2021-04-15T19:27:36.206301] Extracting the control code.\n",
            "[2021-04-15T19:27:36.235520] fetching and extracting the control code on master node.\n",
            "[2021-04-15T19:27:36.235566] Starting extract_project.\n",
            "[2021-04-15T19:27:36.235613] Starting to extract zip file.\n",
            "[2021-04-15T19:27:36.817500] Finished extracting zip file.\n",
            "[2021-04-15T19:27:36.964446] Using urllib.request Python 3.0 or later\n",
            "[2021-04-15T19:27:36.964512] Start fetching snapshots.\n",
            "[2021-04-15T19:27:36.964555] Start fetching snapshot.\n",
            "[2021-04-15T19:27:36.964573] Retrieving project from snapshot: f9952928-524a-4ee6-ab75-d2b1220af888\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 53\n",
            "[2021-04-15T19:27:38.647077] Finished fetching snapshot.\n",
            "[2021-04-15T19:27:38.647125] Finished fetching snapshots.\n",
            "[2021-04-15T19:27:38.647219] Finished extract_project.\n",
            "[2021-04-15T19:27:38.664290] Finished fetching and extracting the control code.\n",
            "[2021-04-15T19:27:38.671233] Start run_history_prep.\n",
            "[2021-04-15T19:27:38.731448] Job preparation is complete.\n",
            "[2021-04-15T19:27:38.731632] Entering Data Context Managers in Sidecar\n",
            "[2021-04-15T19:27:38.732475] Running Sidecar prep cmd...\n",
            "[2021-04-15T19:27:38.792906] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/opendatasetspmworkspace2/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/mounts/workspaceblobstore/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de\n",
            "[2021-04-15T19:27:38.793945] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
            "Enter __enter__ of DatasetContextManager\n",
            "SDK version: azureml-core==1.25.0 azureml-dataprep==2.13.2. Session id: f86384ca-c417-4059-88b5-02160107d97d. Run id: fa5d2bed-c6da-4ceb-a97f-0c943a8c78de.\n",
            "Processing 'file_dataset'.\n",
            "Processing dataset FileDataset\n",
            "{\n",
            "  \"source\": [\n",
            "    \"https://dprepdata.blob.core.windows.net/demo/Titanic.csv\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetFiles\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"c808cc42-31a9-4304-8b4f-7b4493ff1043\",\n",
            "    \"name\": null,\n",
            "    \"version\": null,\n",
            "    \"workspace\": \"Workspace.create(name='opendatasetspmworkspace2', subscription_id='21d8f407-c4c4-452e-87a4-e609bfb86248', resource_group='opendatasetspmrg')\"\n",
            "  }\n",
            "}\n",
            "Mounting file_dataset to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/opendatasetspmworkspace2/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/wd/tmpjg4fq0ru.\n",
            "Mounted file_dataset to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/opendatasetspmworkspace2/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/wd/tmpjg4fq0ru as single file.\n",
            "Exit __enter__ of DatasetContextManager\n",
            "Set Dataset file_dataset's target path to /mnt/batch/tasks/shared/LS_root/jobs/opendatasetspmworkspace2/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/wd/tmpjg4fq0ru/Titanic.csv\n",
            "[2021-04-15T19:27:49.767696] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
            "[2021-04-15T19:27:50.504292] Ran Sidecar prep cmd.\n",
            "[2021-04-15T19:27:50.504376] Running Context Managers in Sidecar complete.\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d.txt\n",
            "===============================================================================================================\n",
            "[2021-04-15T19:30:05.737875] Entering job release\n",
            "[2021-04-15T19:30:07.202367] Starting job release\n",
            "[2021-04-15T19:30:07.203116] Logging experiment finalizing status in history service.[2021-04-15T19:30:07.203339] job release stage : upload_datastore starting...\n",
            "\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 283[2021-04-15T19:30:07.204052] job release stage : start importing azureml.history._tracking in run_history_release.\n",
            "\n",
            "[2021-04-15T19:30:07.204718] job release stage : execute_job_release starting...\n",
            "[2021-04-15T19:30:07.207522] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-04-15T19:30:07.207667] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-04-15T19:30:07.270284] Entering context manager injector.\n",
            "[2021-04-15T19:30:07.304815] job release stage : send_run_telemetry starting...\n",
            "[2021-04-15T19:30:07.329519] job release stage : upload_datastore completed...\n",
            "[2021-04-15T19:30:07.360630] job release stage : execute_job_release completed...\n",
            "[2021-04-15T19:30:07.667734] get vm size and vm region successfully.\n",
            "[2021-04-15T19:30:07.703258] get compute meta data successfully.\n",
            "[2021-04-15T19:30:08.043926] post artifact meta request successfully.\n",
            "[2021-04-15T19:30:08.100694] upload compute record artifact successfully.\n",
            "[2021-04-15T19:30:08.100810] job release stage : send_run_telemetry completed...\n",
            "[2021-04-15T19:30:08.101405] Running in AzureML-Sidecar, starting to exit user context managers...\n",
            "[2021-04-15T19:30:08.101531] Running Sidecar release cmd...\n",
            "[2021-04-15T19:30:08.113026] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/opendatasetspmworkspace2/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/mounts/workspaceblobstore/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de\n",
            "Enter __exit__ of DatasetContextManager\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/opendatasetspmworkspace2/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/wd/tmpjg4fq0ru.\n",
            "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/opendatasetspmworkspace2/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/wd/tmpjg4fq0ru: Invalid argument\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/opendatasetspmworkspace2/azureml/fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/wd/tmpjg4fq0ru.\n",
            "Exit __exit__ of DatasetContextManager\n",
            "[2021-04-15T19:30:08.194683] Removing absolute paths from host...\n",
            "[2021-04-15T19:30:08.206094] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
            "[2021-04-15T19:30:08.648377] Ran Sidecar release cmd.\n",
            "[2021-04-15T19:30:08.648484] Job release is complete\n",
            "\n",
            "StepRun(train_step) Execution Summary\n",
            "======================================\n",
            "StepRun( train_step ) Status: Finished\n",
            "{'runId': 'fa5d2bed-c6da-4ceb-a97f-0c943a8c78de', 'target': 'cpu-cluster', 'status': 'Completed', 'startTimeUtc': '2021-04-15T19:23:44.053792Z', 'endTimeUtc': '2021-04-15T19:30:20.095547Z', 'properties': {'ContentSnapshotId': 'f9952928-524a-4ee6-ab75-d2b1220af888', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '9b51f9c9-e9e1-4bcc-8f04-9e5599fd3ffe', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '0f3eb083', 'azureml.pipelinerunid': '415bff50-a59c-4bc1-b92e-734e853f3a68', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'c808cc42-31a9-4304-8b4f-7b4493ff1043'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'file_dataset', 'mechanism': 'Mount'}}, {'dataset': {'id': 'cf2e6ac8-af34-4c51-a112-5465f836c313'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'tabular_dataset', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train_with_dataset.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--param1', 'DatasetConsumptionConfig:file_dataset', '--param2', 'DatasetConsumptionConfig:tabular_dataset'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-cluster', 'dataReferences': {}, 'data': {'file_dataset': {'dataLocation': {'dataset': {'id': 'c808cc42-31a9-4304-8b4f-7b4493ff1043', 'name': None, 'version': None}, 'dataPath': None}, 'mechanism': 'Mount', 'environmentVariableName': 'file_dataset', 'pathOnCompute': None, 'overwrite': False}, 'tabular_dataset': {'dataLocation': {'dataset': {'id': 'cf2e6ac8-af34-4c51-a112-5465f836c313', 'name': None, 'version': None}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'tabular_dataset', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Experiment showcasing-dataset Environment', 'version': 'Autosave_2021-04-15T19:20:59Z_790936e7', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}], 'name': 'azureml_da3e97fcb51801118b8e80207f3e01ad'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': None, 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/azureml-logs/55_azureml-execution-tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d.txt?sv=2019-02-02&sr=b&sig=JI1dcJs9wM4IqHQnkHBlR%2BrCCjCnLh7cfTIRGrO1rBU%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'azureml-logs/65_job_prep-tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/azureml-logs/65_job_prep-tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d.txt?sv=2019-02-02&sr=b&sig=yMkX2caN8iA6g6fjqZ50obyQPMST0xiz5Au8Rh1jbus%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=7fNs9TSMjNxGzvQsUIMEmF1ZzAuIj7qdW3WtG4iGWS8%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'azureml-logs/75_job_post-tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/azureml-logs/75_job_post-tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d.txt?sv=2019-02-02&sr=b&sig=mFKqy4u42I4tANhGN3uZxEBdgfGH4jMtzOCpwoIMQpg%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'azureml-logs/process_info.json': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=qNv7cH30LeYpkp%2Fq%2FrAEiR%2BVGgZFK%2Fd44tvx2x03%2FSI%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'azureml-logs/process_status.json': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=1vo1fwIOqhxAUAkSGc%2FfoYeq1aDdsBd5LbIVYmHrw54%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'logs/azureml/76_azureml.log': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/76_azureml.log?sv=2019-02-02&sr=b&sig=NfZuI8MiwGqNVLV2R5chXlT1lleFqpunZOtYybwOY7E%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=r55GFCEZESORlOEA740u0PezW3e6Ft%2FApRY0UbwTlyg%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=CK%2BfFwmOvBwnTdWhuEKX6HX8FkUcYXTzW22fBVil6GQ%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=TP0WSv85R%2FOxF1%2BhKm1CAOgy5uKTmYMGTpedNI3QSYw%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=ek3M%2BKykixGXGQvDLJeiipqDkXLOkisl%2BhwUKisoxAc%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=dxNdbTztWle%2FyY%2FExphBtPijYpvt9ELFuMvDDwJ0qIU%3D&st=2021-04-15T19%3A20%3A11Z&se=2021-04-16T03%3A30%3A11Z&sp=r', 'logs/azureml/sidecar/tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d/all.log': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/sidecar/tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d/all.log?sv=2019-02-02&sr=b&sig=FE62YXnWrG9lbUGpAXwNmioSndl2Pp%2FH35Yf4l0XJww%3D&st=2021-04-15T19%3A20%3A12Z&se=2021-04-16T03%3A30%3A12Z&sp=r', 'logs/azureml/sidecar/tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d/task.enter_contexts.log': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/sidecar/tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=N6GVWd0CXxmHUp27P2siKeyqt%2Fd9FUwWbOxGIlSp3r8%3D&st=2021-04-15T19%3A20%3A12Z&se=2021-04-16T03%3A30%3A12Z&sp=r', 'logs/azureml/sidecar/tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d/task.exit_contexts.log': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/sidecar/tvmps_f735c8e8c33ce8fc91f8ef731b5fd87c3319a2006131c60f77bf47748a3e37eb_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=lfk9%2BVcWztXDOYhjK6PEyEiPX7HG4eVKC3naFnM%2B74A%3D&st=2021-04-15T19%3A20%3A12Z&se=2021-04-16T03%3A30%3A12Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=LWxw%2B%2FVBsfT%2Fgkksx5Qqeh1Piirk%2FEyZ1AIuvqZRPvo%3D&st=2021-04-15T19%3A20%3A12Z&se=2021-04-16T03%3A30%3A12Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.fa5d2bed-c6da-4ceb-a97f-0c943a8c78de/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=9g3demt3WZVaiv3Rug7i3FC%2BqCknBovcabYIvvEezok%3D&st=2021-04-15T19%3A20%3A12Z&se=2021-04-16T03%3A30%3A12Z&sp=r'}, 'submittedBy': 'Rashaud Savage'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': '415bff50-a59c-4bc1-b92e-734e853f3a68', 'status': 'Completed', 'startTimeUtc': '2021-04-15T19:20:49.781196Z', 'endTimeUtc': '2021-04-15T19:30:24.949926Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.415bff50-a59c-4bc1-b92e-734e853f3a68/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=Y6kYcSU5j%2FzJPN%2BqWhD6hj7uuWvSzZ0tARFPh5hcDDM%3D&st=2021-04-15T19%3A10%3A54Z&se=2021-04-16T03%3A20%3A54Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.415bff50-a59c-4bc1-b92e-734e853f3a68/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=swtxJ8tYX%2FshuVvKeo0FaGUDtyf%2FrW2r2qFVkpvSboI%3D&st=2021-04-15T19%3A10%3A54Z&se=2021-04-16T03%3A20%3A54Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://opendatasetspm6562936819.blob.core.windows.net/azureml/ExperimentRun/dcid.415bff50-a59c-4bc1-b92e-734e853f3a68/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=MeCeuBYlSCj23fmgq%2FM5v9rpwVPUMU0bGBiQCNFgS68%3D&st=2021-04-15T19%3A10%3A54Z&se=2021-04-16T03%3A20%3A54Z&sp=r'}, 'submittedBy': 'Rashaud Savage'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1618515029390
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='index3'></a>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit a Pipeline with a different Dataset PipelineParameter value from the SDK\n",
        "\n",
        "The training pipeline can be reused with different input datasets by passing them in as PipelineParameters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "iris_file_ds = Dataset.File.from_files('https://raw.githubusercontent.com/Azure/MachineLearningNotebooks/'\n",
        "                                        '4e7b3784d50e81c313c62bcdf9a330194153d9cd/how-to-use-azureml/work-with-data/'\n",
        "                                        'datasets-tutorial/train-with-datasets/train-dataset/iris.csv')\n",
        "\n",
        "iris_tabular_ds = Dataset.Tabular.from_delimited_files('https://raw.githubusercontent.com/Azure/MachineLearningNotebooks/'\n",
        "                                                       '4e7b3784d50e81c313c62bcdf9a330194153d9cd/how-to-use-azureml/work-with-data/'\n",
        "                                                       'datasets-tutorial/train-with-datasets/train-dataset/iris.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run_with_params = experiment.submit(pipeline, pipeline_parameters={'file_ds_param': iris_file_ds, 'tabular_ds_param': iris_tabular_ds}) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(pipeline_run_with_params).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run_with_params.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='index4'></a>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamically Set the Dataset PipelineParameter Values using a REST Call\n",
        "\n",
        "Let's publish the pipeline we created previously, so we can generate a pipeline endpoint. We can then submit the iris datasets to the pipeline REST endpoint by passing in their IDs. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline.publish(name=\"Dataset_Pipeline\", description=\"Pipeline to test Dataset PipelineParameter\", continue_on_step_failure=True)\n",
        "published_pipeline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline.submit(ws, experiment_name=\"publishedexperiment\", pipeline_parameters={'file_ds_param': iris_file_ds, 'tabular_ds_param': iris_tabular_ds})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "import requests\n",
        "\n",
        "auth = InteractiveLoginAuthentication()\n",
        "aad_token = auth.get_authentication_header()\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "\n",
        "print(\"You can perform HTTP POST on URL {} to trigger this pipeline\".format(rest_endpoint))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the param when running the pipeline\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=aad_token, \n",
        "                         json={\"ExperimentName\": \"MyRestPipeline\",\n",
        "                               \"RunSource\": \"SDK\",\n",
        "                               \"DataSetDefinitionValueAssignments\": {\"file_ds_param\": {\"SavedDataSetReference\": {\"Id\": iris_file_ds.id}},\n",
        "                                                                     \"tabular_ds_param\": {\"SavedDataSetReference\": {\"Id\": iris_tabular_ds.id}}}\n",
        "                              }\n",
        "                        )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    response.raise_for_status()\n",
        "except Exception:    \n",
        "    raise Exception('Received bad response from the endpoint: {}\\n'\n",
        "                    'Response Code: {}\\n'\n",
        "                    'Headers: {}\\n'\n",
        "                    'Content: {}'.format(rest_endpoint, response.status_code, response.headers, response.content))\n",
        "\n",
        "run_id = response.json().get('Id')\n",
        "print('Submitted pipeline run: ', run_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline_run_via_rest = PipelineRun(ws.experiments[\"MyRestPipeline\"], run_id)\n",
        "RunDetails(published_pipeline_run_via_rest).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline_run_via_rest.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='index5'></a>"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "order_index": 13,
    "exclude_from_index": false,
    "task": "Demonstrates the use of Dataset as a PipelineParameter",
    "deployment": [
      "None"
    ],
    "authors": [
      {
        "name": "rafarmah"
      }
    ],
    "star_tag": [
      "featured"
    ],
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "compute": [
      "AML Compute"
    ],
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python36"
    },
    "tags": [
      "None"
    ],
    "datasets": [
      "Custom"
    ],
    "category": "tutorial",
    "framework": [
      "Azure ML"
    ],
    "friendly_name": "How to use Dataset as a PipelineParameter",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}