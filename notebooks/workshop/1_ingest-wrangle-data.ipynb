{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Want to *actually* do machine learning? \n",
    "## Part 1: Ingest and wrangle data\n",
    "\n",
    "*Made for Microsoft Build 2019*\n",
    "\n",
    "This is the first in a series that walks through how Azure Machine Learning service can speed up your machine learning modelling workflow so you can focus on the interesting tasks that matter. \n",
    "\n",
    "**Goal:**\n",
    "In this notebook, we'll prepare our data for regression modeling. We'll use a small sample of NYC yellow taxicab data which we've got in Azure Blob Storage. Our end goal is to wrangle the data so we can use it to predict the cost of a taxi trip. \n",
    "\n",
    "In particular, we'll showcase:\n",
    "- **Azure ML Datasets, from the Azure ML Python SDK**, which allow you to\n",
    "    - connect to Azure storage accounts where your data is, maintain data lineages, take snapshots of data for auditability and reproducibility, and version the set of transformations applied to wrangle the data.\n",
    "- (optionally) **Azure ML Data Prep SDK**, a companion toolkit to the Python SDK which allows you to\n",
    "    - wrangle data locally and at scale using the same code artifact, and prepare your data before you have an Azure subscription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "In order to run this notebook, you need:\n",
    "- A Python 3.6 notebook server with the following installed:\n",
    "    - Azure Machine Learning SDK for Python\n",
    "    - (optionally) Azure Machine Learning Data Prep SDK for Python\n",
    "- An Azure subscription, an Azure ML workspace, and sample data uploaded to an Azure Blob Storage container\n",
    "    - If not, go to our [configuration](0_configuration.ipynb) notebook to get them set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "import azureml.dataprep as dprep\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace configuration succeeded. Skip the workspace creation steps below. subscription_id = db74d2db-c6a4-4287-b984-fd05ac72cf42\n"
     ]
    }
   ],
   "source": [
    "# Retrieve an existing workspace\n",
    "#ws = Workspace.from_config()\n",
    "\n",
    "subscription_id = \"db74d2db-c6a4-4287-b984-fd05ac72cf42\"\n",
    "resource_group = \"omg_aml_testing\"\n",
    "workspace_name = \"actuallydemosung\"\n",
    "workspace_region = \"West Europe\"\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "try:\n",
    "    ws = Workspace(\n",
    "        subscription_id = subscription_id, \n",
    "        resource_group = resource_group, \n",
    "        workspace_name = workspace_name\n",
    "    )\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below. subscription_id = \"+subscription_id)\n",
    "except:\n",
    "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. [Ingest data](#Ingest-data). Reading in data and parsing file formats can be tricky and frustrating when you encounter issues since it's the first thing you need to do when you start building ML models. We'll show you how Azure ML unifies and simplifies data ingestion across all kinds of file formats.\n",
    "1. [Sample data](#Sample-data). We're often working with very large data sets, which can be unwieldy when trying to quickly iterate and wrangle. We'll show how easy it is to create a sample of your Dataset so you can experiment on that before applying to your full Dataset.\n",
    "1. [Cleanse data](#Cleanse-data). You can use your favorite open-source library to wrangle your data, or you can try out an SDK we built to help make wrangling easier regardless of your data's size.\n",
    "1. [Apply changes to full data](#Apply-changes-to-full-data). Now that you've created your data preparation script on your sampled Dataset, we'll apply that script to our full Dataset to make it ML-ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest data\n",
    "\n",
    "Datasets makes it incredibly easy to use data in Azure storage for machine learning. It handles some of the most painful parts of getting data: figuring out how to ingest your data, managing credentials, and understanding file formats.\n",
    "\n",
    "Our connection information to our Azure storage account is stored in our workpace's datastore, so we'll ask Datasets to use that information to access our data. Oftentimes, data comes stored across different files that we need to coalesce into one. In our case, we see that we have each month's data stored in a separate csv. We'll use Datasets to easily append them together with a simple globbing command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutionError",
     "evalue": "Failed to read files and get data source properties suggestions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExecutionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f4a7fb628609>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdatastore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_datastore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_read_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yellow_tripdata_2018-01.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\core\\dataset.py\u001b[0m in \u001b[0;36mauto_read_files\u001b[1;34m(path, include_path)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \"\"\"\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_read_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\data\\_dataset_client.py\u001b[0m in \u001b[0;36mauto_read_files\u001b[1;34m(path, include_path)\u001b[0m\n\u001b[0;32m    686\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mauto_read_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataprep\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdprep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[0mdataflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdprep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_read_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m         \u001b[0mfile_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_DatasetClient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_source_file_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         return _DatasetClient._get_dataset_from_dataflow(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\dataprep\\api\\readers.py\u001b[0m in \u001b[0;36mauto_read_file\u001b[1;34m(path, include_path)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;31m# File Format Detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[0mffb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_file_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m     \u001b[0mffb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mffb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dataflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minclude_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\dataprep\\api\\builders.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, fileformat_arguments)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileformat_arguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Currently only learning from the first file is supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m         \u001b[0mdatasource_properties\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_prose_file_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_properties_from_datasource_properties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasource_properties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\dataprep\\api\\builders.py\u001b[0m in \u001b[0;36m_run_prose_file_detection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m         msg_args = AnonymousDataSourceProseSuggestionsMessageArguments(\n\u001b[0;32m    248\u001b[0m             blocks=steps_to_block_datas(self._dataflow._get_steps()))\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manonymous_data_source_prose_suggestions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileformat_arguments\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFileFormatArguments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\dataprep\\api\\_aml_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(op_code, message)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mengine_api_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_environment_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msend_message_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\dataprep\\api\\engineapi\\api.py\u001b[0m in \u001b[0;36manonymous_data_source_prose_suggestions\u001b[1;34m(self, message_args)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mupdate_aml_env_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_engine_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0manonymous_data_source_prose_suggestions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtypedefinitions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAnonymousDataSourceProseSuggestionsMessageArguments\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtypedefinitions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataSourceProperties\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GetProseAnonymousDataSourcePropertiesSuggestion'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtypedefinitions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataSourceProperties\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\dataprep\\api\\engineapi\\engine.py\u001b[0m in \u001b[0;36msend_message\u001b[1;34m(self, op_code, message)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'error'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[0mraise_engine_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmessage_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\dataprep\\api\\errorhandlers.py\u001b[0m in \u001b[0;36mraise_engine_error\u001b[1;34m(error_response)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mExecutionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;34m'UnableToPreviewDataSource'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0merror_code\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mExecutionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;34m'EmptySteps'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0merror_code\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mEmptyStepsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutionError\u001b[0m: Failed to read files and get data source properties suggestions"
     ]
    }
   ],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "dataset = Dataset.auto_read_files(path=datastore.path('yellow_tripdata_2018-01.csv'))\n",
    "\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also register our Dataset to our workspace, which enables any collaborator in that workspace to access our common data artifacts. This makes it easier to work within teams by sharing the right data with the right permissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.register(\n",
    "    workspace=ws,\n",
    "    name='nyc_taxi_full',\n",
    "    description='NYC yellow taxicab data during the first half of 2018.',\n",
    "    tags={'year':'2018', 'taxi_type':'yellow', 'status':'raw'},\n",
    "    exist_ok=True,\n",
    "    update_if_exist=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.data.dataset_action_run.DatasetActionRun at 0x7f718a627b00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run on another compute to make it async\n",
    "dataset.generate_profile(compute_target='jenren-profiler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data\n",
    "\n",
    "But as we know, data rarely comes cleaned and ML-ready! Immediately, we notice that the first row contains all null values so we likely want to filter that entry out. There might also be other data quality issues that we might need to address. Rather than experimenting on our full Dataset which can take much longer, we'll start with a sampled Dataset, figure out how we need to wrangle it, then apply those transformations to our full Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:20:22</td>\n",
       "      <td>2018-01-01 00:52:51</td>\n",
       "      <td>1</td>\n",
       "      <td>10.20</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>140</td>\n",
       "      <td>257</td>\n",
       "      <td>2</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>34.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:17:04</td>\n",
       "      <td>2018-01-01 00:22:24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:24:42</td>\n",
       "      <td>2018-01-01 00:31:56</td>\n",
       "      <td>2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>170</td>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01 00:31:23</td>\n",
       "      <td>2018-01-01 00:45:38</td>\n",
       "      <td>1</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>186</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01 00:47:03</td>\n",
       "      <td>2018-01-01 01:26:24</td>\n",
       "      <td>1</td>\n",
       "      <td>9.49</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>231</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2018-01-01 00:20:22   2018-01-01 00:52:51                1   \n",
       "1         1  2018-01-01 00:17:04   2018-01-01 00:22:24                1   \n",
       "2         1  2018-01-01 00:24:42   2018-01-01 00:31:56                2   \n",
       "3         2  2018-01-01 00:31:23   2018-01-01 00:45:38                1   \n",
       "4         2  2018-01-01 00:47:03   2018-01-01 01:26:24                1   \n",
       "\n",
       "   trip_distance  RatecodeID  store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0          10.20           1               False           140           257   \n",
       "1           0.70           1               False           170           170   \n",
       "2           0.70           1               False           170           162   \n",
       "3           2.32           1               False           186           231   \n",
       "4           9.49           1               False           231           116   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2         33.5    0.5      0.5        0.00           0.0   \n",
       "1             2          5.5    0.5      0.5        0.00           0.0   \n",
       "2             2          6.0    0.5      0.5        0.00           0.0   \n",
       "3             1         11.0    0.5      0.5        3.08           0.0   \n",
       "4             1         35.0    0.5      0.5        9.08           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  \n",
       "0                    0.3         34.80  \n",
       "1                    0.3          6.80  \n",
       "2                    0.3          7.30  \n",
       "3                    0.3         15.38  \n",
       "4                    0.3         45.38  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sampled = dataset.sample(\n",
    "    sample_strategy='simple_random', \n",
    "    arguments={'probability':0.25, 'seed': 123})\n",
    "\n",
    "dataset_sampled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanse data\n",
    "\n",
    "Because we care about openness and interoperability, we made it possible for you to use the open-source libraries you already know and love. From here, you can convert your Dataset to a pandas or Spark dataframe to wrangle your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = dataset_sampled.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bonus:* We created a data preparation SDK to help you wrangle your data. With it, you can focus on writing one data wrangling script that can seamlessly transition between local, scale-up, and scale-out runtimes without needing to do costly rewrites.\n",
    "\n",
    "> You absolutely don't need to use it if you already have tools that you know and love; we're showing it here in case you'd like to try it out and realize you'd love a solution that doesn't require you to rewrite scripts when you need to scale to larger data sets. You can imagine substituting our wrangling script using the [Azure ML Data Prep SDK](https://docs.microsoft.com/en-us/python/api/overview/azure/dataprep/intro?view=azure-dataprep-py) with your own pandas, dplyr, or Spark code instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflow_sampled = dprep.read_pandas_dataframe(df_sampled, temp_folder='temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to filter out rows that seem to be completely missing, like the first row with `NA` strings in all columns. We'll then keep only the useful columns for modeling: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance</th>\n",
       "      <th>pickup_region</th>\n",
       "      <th>dropoff_region</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-08 21:13:45</td>\n",
       "      <td>4</td>\n",
       "      <td>2.90</td>\n",
       "      <td>137</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-08 21:06:43</td>\n",
       "      <td>1</td>\n",
       "      <td>2.05</td>\n",
       "      <td>164</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-08 21:32:34</td>\n",
       "      <td>1</td>\n",
       "      <td>9.03</td>\n",
       "      <td>138</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-08 21:56:39</td>\n",
       "      <td>1</td>\n",
       "      <td>1.16</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-08 21:52:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>68</td>\n",
       "      <td>246</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor     pickup_datetime  passenger_count  distance  pickup_region  \\\n",
       "0       1 2018-01-08 21:13:45                4      2.90            137   \n",
       "1       2 2018-01-08 21:06:43                1      2.05            164   \n",
       "2       2 2018-01-08 21:32:34                1      9.03            138   \n",
       "3       2 2018-01-08 21:56:39                1      1.16            238   \n",
       "4       1 2018-01-08 21:52:00                1      0.80             68   \n",
       "\n",
       "   dropoff_region  payment_type  fare_amount  \n",
       "0             142             1         13.5  \n",
       "1             239             1          9.0  \n",
       "2             238             1         27.0  \n",
       "3             151             2          7.0  \n",
       "4             246             2          5.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = dprep.ColumnSelector(term=\".*\", use_regex=True)\n",
    "drop_if_all_null = [all_columns, dprep.ColumnRelationship(dprep.ColumnRelationship.ALL)]\n",
    "useful_columns = [\n",
    "    \"fare_amount\", \"distance\", \"pickup_region\", \"dropoff_region\",\n",
    "    \"passenger_count\", \"pickup_datetime\", \"vendor\", \"payment_type\"\n",
    "]\n",
    "\n",
    "dflow_sampled = (dflow_sampled\n",
    "    .replace_na(columns=all_columns)\n",
    "    .drop_nulls(*drop_if_all_null)\n",
    "    .rename_columns(column_pairs={\n",
    "        \"VendorID\": \"vendor\",\n",
    "        \"tpep_pickup_datetime\": \"pickup_datetime\",\n",
    "        \"trip_distance\": \"distance\",\n",
    "        \"PULocationID\": \"pickup_region\",\n",
    "        \"DOLocationID\": \"dropoff_region\"\n",
    "    })\n",
    "    .keep_columns(columns=useful_columns))\n",
    "\n",
    "dflow_sampled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also notice that we have a lot of information in our `pickup_datetime` column that could be split out into multiple features, which might improve our model's performance. We'll use an intelligent transformation that attempts to split our column using example input-outputs to learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance</th>\n",
       "      <th>pickup_region</th>\n",
       "      <th>dropoff_region</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-08 21:13:45</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>21:13:45</td>\n",
       "      <td>4</td>\n",
       "      <td>2.90</td>\n",
       "      <td>137</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-08 21:06:43</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>21:06:43</td>\n",
       "      <td>1</td>\n",
       "      <td>2.05</td>\n",
       "      <td>164</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-08 21:32:34</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>21:32:34</td>\n",
       "      <td>1</td>\n",
       "      <td>9.03</td>\n",
       "      <td>138</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-08 21:56:39</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>21:56:39</td>\n",
       "      <td>1</td>\n",
       "      <td>1.16</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-08 21:52:00</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>21:52:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>68</td>\n",
       "      <td>246</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor     pickup_datetime pickup_date pickup_time  passenger_count  \\\n",
       "0       1 2018-01-08 21:13:45  2018-01-08    21:13:45                4   \n",
       "1       2 2018-01-08 21:06:43  2018-01-08    21:06:43                1   \n",
       "2       2 2018-01-08 21:32:34  2018-01-08    21:32:34                1   \n",
       "3       2 2018-01-08 21:56:39  2018-01-08    21:56:39                1   \n",
       "4       1 2018-01-08 21:52:00  2018-01-08    21:52:00                1   \n",
       "\n",
       "   distance  pickup_region  dropoff_region  payment_type  fare_amount  \n",
       "0      2.90            137             142             1         13.5  \n",
       "1      2.05            164             239             1          9.0  \n",
       "2      9.03            138             238             1         27.0  \n",
       "3      1.16            238             151             2          7.0  \n",
       "4      0.80             68             246             2          5.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflow_sampled = (dflow_sampled\n",
    "    .split_column_by_example(\n",
    "        source_column=\"pickup_datetime\",\n",
    "        example=(\"2009-01-04 02:52:00\", [\"2009-01-04\", \"02:52:00\"])\n",
    "    )\n",
    "    .rename_columns(column_pairs={\n",
    "        \"pickup_datetime_1\": \"pickup_date\",\n",
    "        \"pickup_datetime_2\": \"pickup_time\"\n",
    "    }))\n",
    "\n",
    "dflow_sampled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract more information as features to feed our ML model. For example, let's use another intelligent transform which creates a column by interpreting what day of the week a date is. We'll also continue splitting our date and time columns to get additional features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Not Missing Count</th>\n",
       "      <th>Percent Missing</th>\n",
       "      <th>Error Count</th>\n",
       "      <th>Empty Count</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>0.1% Quantile (est.)</th>\n",
       "      <th>1% Quantile (est.)</th>\n",
       "      <th>5% Quantile (est.)</th>\n",
       "      <th>25% Quantile (est.)</th>\n",
       "      <th>50% Quantile (est.)</th>\n",
       "      <th>75% Quantile (est.)</th>\n",
       "      <th>95% Quantile (est.)</th>\n",
       "      <th>99% Quantile (est.)</th>\n",
       "      <th>99.9% Quantile (est.)</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.56641</td>\n",
       "      <td>0.495813</td>\n",
       "      <td>0.24583</td>\n",
       "      <td>-0.263076</td>\n",
       "      <td>-1.90696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_year</th>\n",
       "      <td>FieldType.STRING</td>\n",
       "      <td>2001</td>\n",
       "      <td>2084</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_month</th>\n",
       "      <td>FieldType.STRING</td>\n",
       "      <td>01</td>\n",
       "      <td>12</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_monthday</th>\n",
       "      <td>FieldType.STRING</td>\n",
       "      <td>01</td>\n",
       "      <td>31</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_weekday</th>\n",
       "      <td>FieldType.STRING</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_hour</th>\n",
       "      <td>FieldType.STRING</td>\n",
       "      <td>00</td>\n",
       "      <td>23</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_minute</th>\n",
       "      <td>FieldType.STRING</td>\n",
       "      <td>00</td>\n",
       "      <td>59</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_second</th>\n",
       "      <td>FieldType.STRING</td>\n",
       "      <td>00</td>\n",
       "      <td>59</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_count</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.60003</td>\n",
       "      <td>1.24791</td>\n",
       "      <td>1.55728</td>\n",
       "      <td>2.2482</td>\n",
       "      <td>4.20344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>FieldType.DECIMAL</td>\n",
       "      <td>0</td>\n",
       "      <td>189484</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.603187</td>\n",
       "      <td>0.600428</td>\n",
       "      <td>0.956016</td>\n",
       "      <td>1.60301</td>\n",
       "      <td>2.97954</td>\n",
       "      <td>10.7442</td>\n",
       "      <td>18.9668</td>\n",
       "      <td>26.9457</td>\n",
       "      <td>2.91042</td>\n",
       "      <td>51.7372</td>\n",
       "      <td>2676.74</td>\n",
       "      <td>3643.26</td>\n",
       "      <td>1.3343e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_region</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261</td>\n",
       "      <td>4.00544</td>\n",
       "      <td>68.0177</td>\n",
       "      <td>68</td>\n",
       "      <td>115.413</td>\n",
       "      <td>161.892</td>\n",
       "      <td>233.047</td>\n",
       "      <td>260.404</td>\n",
       "      <td>264</td>\n",
       "      <td>264.017</td>\n",
       "      <td>163.349</td>\n",
       "      <td>66.5477</td>\n",
       "      <td>4428.6</td>\n",
       "      <td>-0.270174</td>\n",
       "      <td>-0.895829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_region</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262</td>\n",
       "      <td>1.13593</td>\n",
       "      <td>51.3995</td>\n",
       "      <td>50.1735</td>\n",
       "      <td>110.19</td>\n",
       "      <td>161.971</td>\n",
       "      <td>233.584</td>\n",
       "      <td>260.729</td>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>161.638</td>\n",
       "      <td>70.3801</td>\n",
       "      <td>4953.36</td>\n",
       "      <td>-0.326103</td>\n",
       "      <td>-0.949272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.84835</td>\n",
       "      <td>1.31173</td>\n",
       "      <td>0.483536</td>\n",
       "      <td>0.233807</td>\n",
       "      <td>1.14279</td>\n",
       "      <td>0.504711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>FieldType.DECIMAL</td>\n",
       "      <td>-463</td>\n",
       "      <td>234632</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.825469</td>\n",
       "      <td>4.99999</td>\n",
       "      <td>4.99997</td>\n",
       "      <td>6.49999</td>\n",
       "      <td>9.11261</td>\n",
       "      <td>14.3014</td>\n",
       "      <td>36.078</td>\n",
       "      <td>52.0147</td>\n",
       "      <td>93.24</td>\n",
       "      <td>12.8114</td>\n",
       "      <td>84.7997</td>\n",
       "      <td>7190.99</td>\n",
       "      <td>2543.79</td>\n",
       "      <td>6.64037e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ColumnProfile:\n",
       "    column_name: vendor\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 4.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 3\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 1.0\n",
       "           1%: 1.0\n",
       "           5%: 1.0\n",
       "          25%: 1.0\n",
       "          50%: 2.0\n",
       "          75%: 2.0\n",
       "          95%: 2.0\n",
       "          99%: 2.0\n",
       "        99.9%: 2.0\n",
       "\n",
       "    mean: 1.5664075244325775\n",
       "    std: 0.4958128232213052\n",
       "    variance: 0.24583035567068126\n",
       "    skewness: -0.263075540497143\n",
       "    kurtosis: -1.9069577030484934\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_year\n",
       "    type: FieldType.STRING\n",
       "\n",
       "    min: 2001\n",
       "    max: 2084\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 12\n",
       "\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_month\n",
       "    type: FieldType.STRING\n",
       "\n",
       "    min: 01\n",
       "    max: 12\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 12\n",
       "\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_monthday\n",
       "    type: FieldType.STRING\n",
       "\n",
       "    min: 01\n",
       "    max: 31\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 31\n",
       "\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_weekday\n",
       "    type: FieldType.STRING\n",
       "\n",
       "    min: Friday\n",
       "    max: Wednesday\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 7\n",
       "\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_hour\n",
       "    type: FieldType.STRING\n",
       "\n",
       "    min: 00\n",
       "    max: 23\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 24\n",
       "\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_minute\n",
       "    type: FieldType.STRING\n",
       "\n",
       "    min: 00\n",
       "    max: 59\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 60\n",
       "\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_second\n",
       "    type: FieldType.STRING\n",
       "\n",
       "    min: 00\n",
       "    max: 59\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 60\n",
       "\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: passenger_count\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 0.0\n",
       "    max: 9.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 10\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 0.0\n",
       "           1%: 1.0\n",
       "           5%: 1.0\n",
       "          25%: 1.0\n",
       "          50%: 1.0\n",
       "          75%: 2.0\n",
       "          95%: 5.0\n",
       "          99%: 6.0\n",
       "        99.9%: 6.0\n",
       "\n",
       "    mean: 1.6000294141009241\n",
       "    std: 1.2479086069335252\n",
       "    variance: 1.5572758912587714\n",
       "    skewness: 2.2482029135016237\n",
       "    kurtosis: 4.203443736437421\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: distance\n",
       "    type: FieldType.DECIMAL\n",
       "\n",
       "    min: 0.0\n",
       "    max: 189483.84\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: \n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 0.0\n",
       "           1%: 0.6031872860427718\n",
       "           5%: 0.6004281325140269\n",
       "          25%: 0.9560158807692188\n",
       "          50%: 1.6030120298422719\n",
       "          75%: 2.9795388390241033\n",
       "          95%: 10.744221979772197\n",
       "          99%: 18.966798694369153\n",
       "        99.9%: 26.945745278430945\n",
       "\n",
       "    mean: 2.9104151370926328\n",
       "    std: 51.737225439231814\n",
       "    variance: 2676.7404961498955\n",
       "    skewness: 3643.259803848533\n",
       "    kurtosis: 13342962.294174151\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_region\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 265.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 261\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 4.005439636148056\n",
       "           1%: 68.01770822670106\n",
       "           5%: 67.99995346185622\n",
       "          25%: 115.41258666490909\n",
       "          50%: 161.89152163909037\n",
       "          75%: 233.04748135781858\n",
       "          95%: 260.40383307953846\n",
       "          99%: 263.99999337232475\n",
       "        99.9%: 264.01652980857403\n",
       "\n",
       "    mean: 163.3487164037903\n",
       "    std: 66.54774763111003\n",
       "    variance: 4428.60271477391\n",
       "    skewness: -0.2701736244422988\n",
       "    kurtosis: -0.8958292531286971\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: dropoff_region\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 265.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 262\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 1.1359274626855167\n",
       "           1%: 51.39954007105725\n",
       "           5%: 50.17351568990854\n",
       "          25%: 110.19043429232673\n",
       "          50%: 161.9712194103414\n",
       "          75%: 233.58391743212252\n",
       "          95%: 260.7285908776791\n",
       "          99%: 264.0\n",
       "        99.9%: 264.9999050839458\n",
       "\n",
       "    mean: 161.6377818118957\n",
       "    std: 70.380136195183\n",
       "    variance: 4953.363570852507\n",
       "    skewness: -0.32610349279585155\n",
       "    kurtosis: -0.9492722426400788\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: payment_type\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 4.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 4\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 1.0\n",
       "           1%: 1.0\n",
       "           5%: 1.0\n",
       "          25%: 1.0\n",
       "          50%: 1.0\n",
       "          75%: 2.0\n",
       "          95%: 2.0\n",
       "          99%: 2.0\n",
       "        99.9%: 3.8483494596384715\n",
       "\n",
       "    mean: 1.3117349580359579\n",
       "    std: 0.4835361156401599\n",
       "    variance: 0.2338071751283741\n",
       "    skewness: 1.1427914242552277\n",
       "    kurtosis: 0.5047112174507209\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: fare_amount\n",
       "    type: FieldType.DECIMAL\n",
       "\n",
       "    min: -463.0\n",
       "    max: 234631.88\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: \n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 0.8254689055584856\n",
       "           1%: 4.999986829879662\n",
       "           5%: 4.9999666897617585\n",
       "          25%: 6.499994398065573\n",
       "          50%: 9.112612292926599\n",
       "          75%: 14.301440062207934\n",
       "          95%: 36.07798834749887\n",
       "          99%: 52.01465563206787\n",
       "        99.9%: 93.23996670719305\n",
       "\n",
       "    mean: 12.811404288955648\n",
       "    std: 84.79970334365854\n",
       "    variance: 7190.989687172493\n",
       "    skewness: 2543.7899746511666\n",
       "    kurtosis: 6640367.391019721"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflow_sampled = (dflow_sampled\n",
    "    # Add day of the week\n",
    "    .derive_column_by_example(\n",
    "        source_columns=\"pickup_date\",\n",
    "        new_column_name=\"pickup_weekday\",\n",
    "        example_data=[(\"2009-01-04\", \"Sunday\"), (\"2013-08-22\", \"Thursday\")]\n",
    "    )\n",
    "    # Add year, month, and day of the month\n",
    "    .split_column_by_example(\n",
    "        source_column=\"pickup_date\",\n",
    "        example=(\"2009-01-04\", [\"2009\", \"01\", \"04\"])\n",
    "    )\n",
    "    # Add hour, minute, and second\n",
    "    .split_column_by_example(\n",
    "        source_column=\"pickup_time\",\n",
    "        example=(\"02:52:58\", [\"02\", \"52\", \"58\"])\n",
    "    )\n",
    "    # Tidy our dataflow\n",
    "    .drop_columns(columns=[\n",
    "        \"pickup_datetime\", \"pickup_date\", \"pickup_time\"\n",
    "    ])\n",
    "    .rename_columns(column_pairs={\n",
    "        \"pickup_date_1\": \"pickup_year\",\n",
    "        \"pickup_date_2\": \"pickup_month\",\n",
    "        \"pickup_date_3\": \"pickup_monthday\",\n",
    "        \"pickup_time_1\": \"pickup_hour\",\n",
    "        \"pickup_time_2\": \"pickup_minute\",\n",
    "        \"pickup_time_3\": \"pickup_second\"\n",
    "    }))\n",
    "\n",
    "dflow_sampled.get_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! We've forgotten to specify the types of our columns. Doing so is important to improve our model's accuracy. Rather than doing it manually, we can let our data preparation tool infer what the column types are, then apply those changes if they look accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column types conversion candidates:\n",
       "'pickup_month': [FieldType.INTEGER],\n",
       "'pickup_weekday': [FieldType.STRING],\n",
       "'pickup_year': [FieldType.INTEGER],\n",
       "'pickup_hour': [FieldType.INTEGER],\n",
       "'passenger_count': [FieldType.INTEGER],\n",
       "'dropoff_region': [FieldType.INTEGER],\n",
       "'fare_amount': [FieldType.DECIMAL],\n",
       "'pickup_monthday': [FieldType.INTEGER],\n",
       "'pickup_second': [FieldType.INTEGER],\n",
       "'pickup_region': [FieldType.INTEGER],\n",
       "'vendor': [FieldType.INTEGER],\n",
       "'pickup_minute': [FieldType.INTEGER],\n",
       "'distance': [FieldType.DECIMAL],\n",
       "'payment_type': [FieldType.INTEGER]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_infer = dflow_sampled.builders.set_column_types()\n",
    "type_infer.learn()\n",
    "type_infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks right, so now we'll add it to our definition to persist the changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Not Missing Count</th>\n",
       "      <th>Percent Missing</th>\n",
       "      <th>Error Count</th>\n",
       "      <th>Empty Count</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>0.1% Quantile (est.)</th>\n",
       "      <th>1% Quantile (est.)</th>\n",
       "      <th>5% Quantile (est.)</th>\n",
       "      <th>25% Quantile (est.)</th>\n",
       "      <th>50% Quantile (est.)</th>\n",
       "      <th>75% Quantile (est.)</th>\n",
       "      <th>95% Quantile (est.)</th>\n",
       "      <th>99% Quantile (est.)</th>\n",
       "      <th>99.9% Quantile (est.)</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.56641</td>\n",
       "      <td>0.495813</td>\n",
       "      <td>0.24583</td>\n",
       "      <td>-0.263076</td>\n",
       "      <td>-1.90696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_year</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>2001</td>\n",
       "      <td>2084</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0442808</td>\n",
       "      <td>0.00196079</td>\n",
       "      <td>637.576</td>\n",
       "      <td>1.12983e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_month</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.79961</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.51635</td>\n",
       "      <td>1.68892</td>\n",
       "      <td>2.85246</td>\n",
       "      <td>-0.0223132</td>\n",
       "      <td>-1.23112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_monthday</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>3.41914</td>\n",
       "      <td>3.01409</td>\n",
       "      <td>8</td>\n",
       "      <td>15.1545</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>15.5539</td>\n",
       "      <td>8.68134</td>\n",
       "      <td>75.3656</td>\n",
       "      <td>0.0252804</td>\n",
       "      <td>-1.16533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_weekday</th>\n",
       "      <td>FieldType.STRING</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_hour</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5.77168</td>\n",
       "      <td>5.25264</td>\n",
       "      <td>9.20356</td>\n",
       "      <td>14.1305</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>13.7901</td>\n",
       "      <td>6.11998</td>\n",
       "      <td>37.4541</td>\n",
       "      <td>-0.467103</td>\n",
       "      <td>-0.585467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_minute</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>5.56191</td>\n",
       "      <td>5.05439</td>\n",
       "      <td>14.5235</td>\n",
       "      <td>29.6817</td>\n",
       "      <td>44.8087</td>\n",
       "      <td>56.4572</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>29.5863</td>\n",
       "      <td>17.3368</td>\n",
       "      <td>300.566</td>\n",
       "      <td>-0.00937358</td>\n",
       "      <td>-1.2089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_second</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>5.51769</td>\n",
       "      <td>5.02169</td>\n",
       "      <td>14.5727</td>\n",
       "      <td>29.5653</td>\n",
       "      <td>44.5202</td>\n",
       "      <td>56.5341</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>29.5024</td>\n",
       "      <td>17.3139</td>\n",
       "      <td>299.77</td>\n",
       "      <td>0.00020861</td>\n",
       "      <td>-1.2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_count</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.60003</td>\n",
       "      <td>1.24791</td>\n",
       "      <td>1.55728</td>\n",
       "      <td>2.2482</td>\n",
       "      <td>4.20344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>FieldType.DECIMAL</td>\n",
       "      <td>0</td>\n",
       "      <td>189484</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.603187</td>\n",
       "      <td>0.600428</td>\n",
       "      <td>0.956016</td>\n",
       "      <td>1.60301</td>\n",
       "      <td>2.97954</td>\n",
       "      <td>10.7442</td>\n",
       "      <td>18.9668</td>\n",
       "      <td>26.9457</td>\n",
       "      <td>2.91042</td>\n",
       "      <td>51.7372</td>\n",
       "      <td>2676.74</td>\n",
       "      <td>3643.26</td>\n",
       "      <td>1.3343e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_region</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261</td>\n",
       "      <td>4.00544</td>\n",
       "      <td>68.0177</td>\n",
       "      <td>68</td>\n",
       "      <td>115.413</td>\n",
       "      <td>161.892</td>\n",
       "      <td>233.047</td>\n",
       "      <td>260.404</td>\n",
       "      <td>264</td>\n",
       "      <td>264.017</td>\n",
       "      <td>163.349</td>\n",
       "      <td>66.5477</td>\n",
       "      <td>4428.6</td>\n",
       "      <td>-0.270174</td>\n",
       "      <td>-0.895829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_region</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262</td>\n",
       "      <td>1.13593</td>\n",
       "      <td>51.3995</td>\n",
       "      <td>50.1735</td>\n",
       "      <td>110.19</td>\n",
       "      <td>161.971</td>\n",
       "      <td>233.584</td>\n",
       "      <td>260.729</td>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>161.638</td>\n",
       "      <td>70.3801</td>\n",
       "      <td>4953.36</td>\n",
       "      <td>-0.326103</td>\n",
       "      <td>-0.949272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>FieldType.INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.84835</td>\n",
       "      <td>1.31173</td>\n",
       "      <td>0.483536</td>\n",
       "      <td>0.233807</td>\n",
       "      <td>1.14279</td>\n",
       "      <td>0.504711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>FieldType.DECIMAL</td>\n",
       "      <td>-463</td>\n",
       "      <td>234632</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13483329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.825469</td>\n",
       "      <td>4.99999</td>\n",
       "      <td>4.99997</td>\n",
       "      <td>6.49999</td>\n",
       "      <td>9.11261</td>\n",
       "      <td>14.3014</td>\n",
       "      <td>36.078</td>\n",
       "      <td>52.0147</td>\n",
       "      <td>93.24</td>\n",
       "      <td>12.8114</td>\n",
       "      <td>84.7997</td>\n",
       "      <td>7190.99</td>\n",
       "      <td>2543.79</td>\n",
       "      <td>6.64037e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ColumnProfile:\n",
       "    column_name: vendor\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 4.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 3\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 1.0\n",
       "           1%: 1.0\n",
       "           5%: 1.0\n",
       "          25%: 1.0\n",
       "          50%: 2.0\n",
       "          75%: 2.0\n",
       "          95%: 2.0\n",
       "          99%: 2.0\n",
       "        99.9%: 2.0\n",
       "\n",
       "    mean: 1.5664075244325775\n",
       "    std: 0.4958128232213052\n",
       "    variance: 0.24583035567068126\n",
       "    skewness: -0.263075540497143\n",
       "    kurtosis: -1.9069577030484934\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_year\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 2001.0\n",
       "    max: 2084.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 12\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 2018.0\n",
       "           1%: 2018.0\n",
       "           5%: 2018.0\n",
       "          25%: 2018.0\n",
       "          50%: 2018.0\n",
       "          75%: 2018.0\n",
       "          95%: 2018.0\n",
       "          99%: 2018.0\n",
       "        99.9%: 2018.0\n",
       "\n",
       "    mean: 2017.9999175277844\n",
       "    std: 0.04428075286225875\n",
       "    variance: 0.0019607850740484367\n",
       "    skewness: 637.5762821380305\n",
       "    kurtosis: 1129831.0757632074\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_month\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 12.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 12\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 1.0\n",
       "           1%: 1.0\n",
       "           5%: 1.0\n",
       "          25%: 2.0\n",
       "          50%: 3.7996136132227014\n",
       "          75%: 5.0\n",
       "          95%: 6.0\n",
       "          99%: 6.0\n",
       "        99.9%: 6.0\n",
       "\n",
       "    mean: 3.5163504502485994\n",
       "    std: 1.6889230819711996\n",
       "    variance: 2.852461176815095\n",
       "    skewness: -0.02231323007666511\n",
       "    kurtosis: -1.2311206716730598\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_monthday\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 31.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 31\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 1.0\n",
       "           1%: 3.4191398409686697\n",
       "           5%: 3.0140856326546914\n",
       "          25%: 8.0\n",
       "          50%: 15.15454946450136\n",
       "          75%: 23.0\n",
       "          95%: 29.0\n",
       "          99%: 31.0\n",
       "        99.9%: 31.0\n",
       "\n",
       "    mean: 15.553860845492984\n",
       "    std: 8.681339166837777\n",
       "    variance: 75.36564972967163\n",
       "    skewness: 0.025280447246868464\n",
       "    kurtosis: -1.165333887504679\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_weekday\n",
       "    type: FieldType.STRING\n",
       "\n",
       "    min: Friday\n",
       "    max: Wednesday\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 7\n",
       "\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_hour\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 0.0\n",
       "    max: 23.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 24\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 0.0\n",
       "           1%: 5.771679139818738\n",
       "           5%: 5.252640206064869\n",
       "          25%: 9.203559624716698\n",
       "          50%: 14.130465945205874\n",
       "          75%: 19.0\n",
       "          95%: 22.0\n",
       "          99%: 23.0\n",
       "        99.9%: 23.0\n",
       "\n",
       "    mean: 13.790100278647795\n",
       "    std: 6.119978596685214\n",
       "    variance: 37.45413802388512\n",
       "    skewness: -0.4671028116210545\n",
       "    kurtosis: -0.5854667319048454\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_minute\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 0.0\n",
       "    max: 59.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 60\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 0.0\n",
       "           1%: 5.561914036575268\n",
       "           5%: 5.054390444059451\n",
       "          25%: 14.523538526188501\n",
       "          50%: 29.681722311899115\n",
       "          75%: 44.80870924478124\n",
       "          95%: 56.45724303753355\n",
       "          99%: 59.0\n",
       "        99.9%: 59.0\n",
       "\n",
       "    mean: 29.586274279890407\n",
       "    std: 17.336828075590542\n",
       "    variance: 300.56560772258445\n",
       "    skewness: -0.009373580896528181\n",
       "    kurtosis: -1.2088959848948715\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_second\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 0.0\n",
       "    max: 59.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 60\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 0.0\n",
       "           1%: 5.5176864494808315\n",
       "           5%: 5.021694214876032\n",
       "          25%: 14.57266781711645\n",
       "          50%: 29.565264630481717\n",
       "          75%: 44.52018718385032\n",
       "          95%: 56.534121963776855\n",
       "          99%: 59.0\n",
       "        99.9%: 59.0\n",
       "\n",
       "    mean: 29.50238431473418\n",
       "    std: 17.31387580111178\n",
       "    variance: 299.77029525632406\n",
       "    skewness: 0.00020861009520931978\n",
       "    kurtosis: -1.200296978633076\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: passenger_count\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 0.0\n",
       "    max: 9.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 10\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 0.0\n",
       "           1%: 1.0\n",
       "           5%: 1.0\n",
       "          25%: 1.0\n",
       "          50%: 1.0\n",
       "          75%: 2.0\n",
       "          95%: 5.0\n",
       "          99%: 6.0\n",
       "        99.9%: 6.0\n",
       "\n",
       "    mean: 1.6000294141009241\n",
       "    std: 1.2479086069335252\n",
       "    variance: 1.5572758912587714\n",
       "    skewness: 2.2482029135016237\n",
       "    kurtosis: 4.203443736437421\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: distance\n",
       "    type: FieldType.DECIMAL\n",
       "\n",
       "    min: 0.0\n",
       "    max: 189483.84\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: \n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 0.0\n",
       "           1%: 0.6031872860427718\n",
       "           5%: 0.6004281325140269\n",
       "          25%: 0.9560158807692188\n",
       "          50%: 1.6030120298422719\n",
       "          75%: 2.9795388390241033\n",
       "          95%: 10.744221979772197\n",
       "          99%: 18.966798694369153\n",
       "        99.9%: 26.945745278430945\n",
       "\n",
       "    mean: 2.9104151370926328\n",
       "    std: 51.737225439231814\n",
       "    variance: 2676.7404961498955\n",
       "    skewness: 3643.259803848533\n",
       "    kurtosis: 13342962.294174151\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: pickup_region\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 265.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 261\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 4.005439636148056\n",
       "           1%: 68.01770822670106\n",
       "           5%: 67.99995346185622\n",
       "          25%: 115.41258666490909\n",
       "          50%: 161.89152163909037\n",
       "          75%: 233.04748135781858\n",
       "          95%: 260.40383307953846\n",
       "          99%: 263.99999337232475\n",
       "        99.9%: 264.01652980857403\n",
       "\n",
       "    mean: 163.3487164037903\n",
       "    std: 66.54774763111003\n",
       "    variance: 4428.60271477391\n",
       "    skewness: -0.2701736244422988\n",
       "    kurtosis: -0.8958292531286971\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: dropoff_region\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 265.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 262\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 1.1359274626855167\n",
       "           1%: 51.39954007105725\n",
       "           5%: 50.17351568990854\n",
       "          25%: 110.19043429232673\n",
       "          50%: 161.9712194103414\n",
       "          75%: 233.58391743212252\n",
       "          95%: 260.7285908776791\n",
       "          99%: 264.0\n",
       "        99.9%: 264.9999050839458\n",
       "\n",
       "    mean: 161.6377818118957\n",
       "    std: 70.380136195183\n",
       "    variance: 4953.363570852507\n",
       "    skewness: -0.32610349279585155\n",
       "    kurtosis: -0.9492722426400788\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: payment_type\n",
       "    type: FieldType.INTEGER\n",
       "\n",
       "    min: 1.0\n",
       "    max: 4.0\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: 4\n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 1.0\n",
       "           1%: 1.0\n",
       "           5%: 1.0\n",
       "          25%: 1.0\n",
       "          50%: 1.0\n",
       "          75%: 2.0\n",
       "          95%: 2.0\n",
       "          99%: 2.0\n",
       "        99.9%: 3.8483494596384715\n",
       "\n",
       "    mean: 1.3117349580359579\n",
       "    std: 0.4835361156401599\n",
       "    variance: 0.2338071751283741\n",
       "    skewness: 1.1427914242552277\n",
       "    kurtosis: 0.5047112174507209\n",
       "\n",
       "ColumnProfile:\n",
       "    column_name: fare_amount\n",
       "    type: FieldType.DECIMAL\n",
       "\n",
       "    min: -463.0\n",
       "    max: 234631.88\n",
       "    count: 13483329.0\n",
       "    missing_count: 0.0\n",
       "    not_missing_count: 13483329.0\n",
       "    percent_missing: 0.0\n",
       "    error_count: 0.0\n",
       "    empty_count: 0.0\n",
       "    unique_values: \n",
       "\n",
       "\n",
       "    Quantiles (est.):\n",
       "         0.1%: 0.8254689055584856\n",
       "           1%: 4.999986829879662\n",
       "           5%: 4.9999666897617585\n",
       "          25%: 6.499994398065573\n",
       "          50%: 9.112612292926599\n",
       "          75%: 14.301440062207934\n",
       "          95%: 36.07798834749887\n",
       "          99%: 52.01465563206787\n",
       "        99.9%: 93.23996670719305\n",
       "\n",
       "    mean: 12.811404288955648\n",
       "    std: 84.79970334365854\n",
       "    variance: 7190.989687172493\n",
       "    skewness: 2543.7899746511666\n",
       "    kurtosis: 6640367.391019721"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflow_sampled = type_infer.to_dataflow()\n",
    "dflow_sampled.get_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though Datasets comes with a highly scalable data preparation capability, you can also use languages and packages that you already know and love. Every Dataset can be converted to a pandas or Spark dataframe, but you can also run your custom Python code on Datasets. Here, we might want to leverage some numpy methods, and we can easily add these scripts to our transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflow_sampled = (dflow_sampled\n",
    "    .new_script_column(\n",
    "        new_column_name='pickup_x',\n",
    "        insert_after='cost',\n",
    "        script=\"\"\"\n",
    "def newvalue(row):\n",
    "    return np.cos(row['pickup_lat']) * np.cos(row['pickup_lng'])\n",
    "        \"\"\"\n",
    "    )\n",
    "    .new_script_column(\n",
    "        new_column_name='pickup_y',\n",
    "        insert_after='pickup_x',\n",
    "        script=\"\"\"\n",
    "def newvalue(row):\n",
    "    return np.cos(row['pickup_lat']) * np.sin(row['pickup_lng'])\n",
    "        \"\"\"\n",
    "    )\n",
    "    .new_script_column(\n",
    "        new_column_name='pickup_z',\n",
    "        insert_after='pickup_y',\n",
    "        script=\"\"\"\n",
    "def newvalue(row):\n",
    "    return np.sin(row['pickup_lat'])\n",
    "        \"\"\"\n",
    "    )\n",
    "    .new_script_column(\n",
    "        new_column_name='dropoff_x',\n",
    "        insert_after='pickup_z',\n",
    "        script=\"\"\"\n",
    "def newvalue(row):\n",
    "    return np.cos(row['dropoff_lat']) * np.cos(row['dropoff_lng'])\n",
    "        \"\"\"\n",
    "    )\n",
    "    .new_script_column(\n",
    "        new_column_name='dropoff_y',\n",
    "        insert_after='dropoff_x',\n",
    "        script=\"\"\"\n",
    "def newvalue(row):\n",
    "    return np.cos(row['dropoff_lat']) * np.sin(row['dropoff_lng'])\n",
    "        \"\"\"\n",
    "    )\n",
    "    .new_script_column(\n",
    "        new_column_name='dropoff_z',\n",
    "        insert_after='dropoff_y',\n",
    "        script=\"\"\"\n",
    "def newvalue(row):\n",
    "    return np.sin(row['dropoff_lng'])\n",
    "        \"\"\"\n",
    "    )\n",
    "    .drop_columns(columns=[\n",
    "        'pickup_lat', 'pickup_lng', 'dropoff_lat', 'dropoff_lng'\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we convert easily between pandas dataframes, you can use your favorite data visualization libraries to inspect your data as you wrangle your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-624f0d534513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdflow_sampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/azureml/dataprep/api/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_ACTIVITY_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py\u001b[0m in \u001b[0;36mto_pandas_dataframe\u001b[0;34m(self, extended_types, nulls_as_nan)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing_secrets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             self._engine_api.execute_anonymous_blocks(\n\u001b[0;32m--> 566\u001b[0;31m                 ExecuteAnonymousBlocksMessageArguments(blocks=steps_to_block_datas(dataflow_to_execute._steps)))\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mintermediate_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintermediate_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'part-*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/azureml/dataprep/api/_aml_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(op_code, message)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mengine_api_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_environment_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msend_message_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/api.py\u001b[0m in \u001b[0;36mexecute_anonymous_blocks\u001b[0;34m(self, message_args)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mupdate_aml_env_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_engine_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_anonymous_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtypedefinitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecuteAnonymousBlocksMessageArguments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Engine.ExecuteActivity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/engine.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, op_code, message)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mraise_engine_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/engine.py\u001b[0m in \u001b[0;36m_read_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'{'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_sampled = dflow_sampled.to_pandas_dataframe()\n",
    "plt.hist(df_sampled['distance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at our Dataset's summary statistics to verify whether we're ready to train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dflow_sampled.get_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By peeking at the profile, we notice that we should run two final filters to eliminate incorrectly captured data points: records should never exist where `cost` and `distance` values are 0. Let's apply our filters so we can improve our machine learning model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflow_sampled = (dflow_sampled\n",
    "    .filter(dprep.col(\"distance\") > 0)\n",
    "    .filter(dprep.col(\"fare_amount\") > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've wrangled our data into an ML-ready format, we can persist these changes by updating our Dataset's definition and verify its correctness with our profile again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled_cleaned = dflow_sampled.to_pandas_dataframe()\n",
    "dataset_sampled_cleaned = Dataset.from_pandas_dataframe(df_sampled_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't yet registered our Dataset to our Azure ML workspace. Registering the Dataset allows it to be persisted and used by any experiments and users in the workspace, making it convenient for hand-offs. We'll now register our Dataset with a few descriptive details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sampled_cleaned = dataset_sampled_cleaned.register(\n",
    "    workspace=ws,\n",
    "    name='nyc_taxi_sampled_cleaned',\n",
    "    description='Sampled NYC yellow taxicab data during 2018.',\n",
    "    tags={'year':'2018', 'status':'cleaned'},\n",
    "    exist_ok=True,\n",
    "    update_if_exist=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply changes to full data\n",
    "\n",
    "Now that we've figured out exactly how we need to prepare our data, we can generate our data preparation script by simply coalescing the transformations above into a function. We'll apply this on our full Dataset so we can use it for ML. (Though we wrote our preparation script with our Data Prep SDK, you can use whatever script using whichever library you want here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation script\n",
    "def prepare_dataframe(df):\n",
    "\n",
    "    dflow = dprep.read_pandas_dataframe(df, temp_folder='temp-full')\n",
    "\n",
    "    all_columns = dprep.ColumnSelector(term=\".*\", use_regex=True)\n",
    "    drop_if_all_null = [all_columns, dprep.ColumnRelationship(dprep.ColumnRelationship.ALL)]\n",
    "    useful_columns = [\n",
    "        \"fare_amount\", \"distance\", \"pickup_region\", \"dropoff_region\",\n",
    "        \"passenger_count\", \"pickup_datetime\", \"vendor\", \"payment_type\"\n",
    "    ]\n",
    "\n",
    "    dflow = (dflow\n",
    "    # Block 1\n",
    "        .replace_na(columns=all_columns)\n",
    "        .drop_nulls(*drop_if_all_null)\n",
    "        .rename_columns(column_pairs={\n",
    "            \"VendorID\": \"vendor\",\n",
    "            \"tpep_pickup_datetime\": \"pickup_datetime\",\n",
    "            \"trip_distance\": \"distance\",\n",
    "            \"PULocationID\": \"pickup_region\",\n",
    "            \"DOLocationID\": \"dropoff_region\"\n",
    "        })\n",
    "        .keep_columns(columns=useful_columns))\n",
    "    # Block 2\n",
    "        .split_column_by_example(\n",
    "            source_column=\"pickup_datetime\",\n",
    "            example=(\"2009-01-04 02:52:00\", [\"2009-01-04\", \"02:52:00\"])\n",
    "        )\n",
    "        .rename_columns(column_pairs={\n",
    "            \"pickup_datetime_1\": \"pickup_date\",\n",
    "            \"pickup_datetime_2\": \"pickup_time\"\n",
    "        })\n",
    "    # Block 3\n",
    "        .derive_column_by_example(\n",
    "            source_columns=\"pickup_date\",\n",
    "            new_column_name=\"pickup_weekday\",\n",
    "            example_data=[(\"2009-01-04\", \"Sunday\"), (\"2013-08-22\", \"Thursday\")]\n",
    "        )\n",
    "        .split_column_by_example(\n",
    "            source_column=\"pickup_date\",\n",
    "            example=(\"2009-01-04\", [\"2009\", \"01\", \"04\"])\n",
    "        )\n",
    "        .split_column_by_example(\n",
    "            source_column=\"pickup_time\",\n",
    "            example=(\"02:52:58\", [\"02\", \"52\", \"58\"])\n",
    "        )\n",
    "        .drop_columns(columns=[\n",
    "            \"pickup_datetime\", \"pickup_date\", \"pickup_time\"\n",
    "        ])\n",
    "        .rename_columns(column_pairs={\n",
    "            \"pickup_date_1\": \"pickup_year\",\n",
    "            \"pickup_date_2\": \"pickup_month\",\n",
    "            \"pickup_date_3\": \"pickup_monthday\",\n",
    "            \"pickup_time_1\": \"pickup_hour\",\n",
    "            \"pickup_time_2\": \"pickup_minute\",\n",
    "            \"pickup_time_3\": \"pickup_second\"\n",
    "        }))\n",
    "\n",
    "    # Block 4\n",
    "    type_infer = dflow.builders.set_column_types()\n",
    "    type_infer.learn()\n",
    "\n",
    "    dflow = type_infer.to_dataflow()\n",
    "\n",
    "    dflow = (dflow\n",
    "    # Block 5\n",
    "        .new_script_column(\n",
    "            new_column_name='pickup_x',\n",
    "            insert_after='cost',\n",
    "            script=\"\"\"\n",
    "    def newvalue(row):\n",
    "        return np.cos(row['pickup_lat']) * np.cos(row['pickup_lng'])\n",
    "            \"\"\"\n",
    "        )\n",
    "        .new_script_column(\n",
    "            new_column_name='pickup_y',\n",
    "            insert_after='pickup_x',\n",
    "            script=\"\"\"\n",
    "    def newvalue(row):\n",
    "        return np.cos(row['pickup_lat']) * np.sin(row['pickup_lng'])\n",
    "            \"\"\"\n",
    "        )\n",
    "        .new_script_column(\n",
    "            new_column_name='pickup_z',\n",
    "            insert_after='pickup_y',\n",
    "            script=\"\"\"\n",
    "    def newvalue(row):\n",
    "        return np.sin(row['pickup_lat'])\n",
    "            \"\"\"\n",
    "        )\n",
    "        .new_script_column(\n",
    "            new_column_name='dropoff_x',\n",
    "            insert_after='pickup_z',\n",
    "            script=\"\"\"\n",
    "    def newvalue(row):\n",
    "        return np.cos(row['dropoff_lat']) * np.cos(row['dropoff_lng'])\n",
    "            \"\"\"\n",
    "        )\n",
    "        .new_script_column(\n",
    "            new_column_name='dropoff_y',\n",
    "            insert_after='dropoff_x',\n",
    "            script=\"\"\"\n",
    "    def newvalue(row):\n",
    "        return np.cos(row['dropoff_lat']) * np.sin(row['dropoff_lng'])\n",
    "            \"\"\"\n",
    "        )\n",
    "        .new_script_column(\n",
    "            new_column_name='dropoff_z',\n",
    "            insert_after='dropoff_y',\n",
    "            script=\"\"\"\n",
    "    def newvalue(row):\n",
    "        return np.sin(row['dropoff_lng'])\n",
    "            \"\"\"\n",
    "        )\n",
    "        .drop_columns(columns=[\n",
    "            'pickup_lat', 'pickup_lng', 'dropoff_lat', 'dropoff_lng'\n",
    "        ])\n",
    "    # Block 6\n",
    "        .filter(dprep.col(\"distance\") > 0)\n",
    "        .filter(dprep.col(\"fare_amount\") > 0))\n",
    "\n",
    "    return dflow.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we'll convert our Dataset into a pandas dataframe so we can transform it. We'll apply our preparation script to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas_dataframe()\n",
    "df_cleaned = prepare_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll save this dataframe back as a Dataset so we can store and share it within our Azure ML workspace. This makes it easy for any collaborator with access to my workspace to use the same artifact consistently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cleaned = Dataset.from_pandas_dataframe(df_cleaned)\n",
    "dataset_cleaned = dataset_cleaned.register(\n",
    "    workspace=ws,\n",
    "    name='nyc_taxi_cleaned',\n",
    "    description='NYC yellow taxicab data during 2018.',\n",
    "    tags={'year':'2018', 'status':'cleaned'},\n",
    "    exist_ok=True,\n",
    "    update_if_exist=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our Dataset is wrangled and registered, we can use this Dataset to build our ML model. Continue to [Part 2: Build and Train Models](2_build-models.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
