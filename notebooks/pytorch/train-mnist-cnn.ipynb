{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Workspace.create(name='AzureML', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='cody-eastus-rg')"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "\n",
    "# get root of git repo\n",
    "prefix = git.Repo('.', search_parent_directories=True).working_tree_dir\n",
    "\n",
    "# training script \n",
    "script_dir = prefix+'/code/models/pytorch/mnist-cnn/'\n",
    "script_name = 'train.py'\n",
    "\n",
    "# environment file\n",
    "environment_file = prefix+'/environments/pytorch-example.yml'\n",
    "\n",
    "# azure ml settings\n",
    "environment_name = 'pytorch-iris-example'\n",
    "experiment_name = 'pytorch-mnist-example'\n",
    "compute_target = 'gpu-cluster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.optim.lr_scheduler import StepLR\n\nimport mlflow\nimport mlflow.pytorch\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.dropout1 = nn.Dropout2d(0.25)\n        self.dropout2 = nn.Dropout2d(0.5)\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.dropout1(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\n\ndef train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n            if args.dry_run:\n                break\n\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\ndef main():\n    # Training settings\n    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                        help='input batch size for training (default: 64)')\n    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n                        help='input batch size for testing (default: 1000)')\n    parser.add_argument('--epochs', type=int, default=14, metavar='N',\n                        help='number of epochs to train (default: 14)')\n    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n                        help='learning rate (default: 1.0)')\n    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n                        help='Learning rate step gamma (default: 0.7)')\n    parser.add_argument('--no-cuda', action='store_true', default=False,\n                        help='disables CUDA training')\n    parser.add_argument('--dry-run', action='store_true', default=False,\n                        help='quickly check a single pass')\n    parser.add_argument('--seed', type=int, default=1, metavar='S',\n                        help='random seed (default: 1)')\n    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                        help='how many batches to wait before logging training status')\n    args = parser.parse_args()\n    use_cuda = not args.no_cuda and torch.cuda.is_available()\n\n    # enable mlflow autologging \n    mlflow.pytorch.autolog()\n\n    torch.manual_seed(args.seed)\n\n    device = torch.device('cuda' if use_cuda else 'cpu')\n\n    kwargs = {'batch_size': args.batch_size}\n    if use_cuda:\n        kwargs.update({'num_workers': 1,\n                       'pin_memory': True,\n                       'shuffle': True},\n                     )\n\n    transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n        ])\n    dataset1 = datasets.MNIST('../data', train=True, download=True,\n                       transform=transform)\n    dataset2 = datasets.MNIST('../data', train=False,\n                       transform=transform)\n    train_loader = torch.utils.data.DataLoader(dataset1,**kwargs)\n    test_loader = torch.utils.data.DataLoader(dataset2, **kwargs)\n\n    model = Net().to(device)\n    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n\n    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n    for epoch in range(1, args.epochs + 1):\n        train(args, model, device, train_loader, optimizer, epoch)\n        test(model, device, test_loader)\n        scheduler.step()\n\nif __name__ == '__main__':\n    main()\n"
    }
   ],
   "source": [
    "print(open(script_dir+script_name).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Run(Experiment: pytorch-mnist-example,\nId: pytorch-mnist-example_1598903102_fef081a2,\nType: azureml.scriptrun,\nStatus: Starting)",
      "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>pytorch-mnist-example</td><td>pytorch-mnist-example_1598903102_fef081a2</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/experiments/pytorch-mnist-example/runs/pytorch-mnist-example_1598903102_fef081a2?wsid=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourcegroups/cody-eastus-rg/workspaces/AzureML\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from azureml.core import ScriptRunConfig, Experiment, Environment\n",
    "\n",
    "arguments = ['--epochs', 2]\n",
    "\n",
    "env = Environment.from_conda_specification(environment_name, environment_file)\n",
    "env.docker.enabled = True\n",
    "\n",
    "src = ScriptRunConfig(source_directory=script_dir, script=script_name, arguments=arguments)\n",
    "src.run_config.environment = env\n",
    "src.run_config.target = compute_target\n",
    "\n",
    "run = Experiment(ws, experiment_name).submit(src)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7915ac0cfc3c4c5cb8946d8c897c9fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sâ€¦"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/pytorch-mnist-example/runs/pytorch-mnist-example_1598903102_fef081a2?wsid=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourcegroups/cody-eastus-rg/workspaces/AzureML\", \"run_id\": \"pytorch-mnist-example_1598903102_fef081a2\", \"run_properties\": {\"run_id\": \"pytorch-mnist-example_1598903102_fef081a2\", \"created_utc\": \"2020-08-31T19:45:06.400549Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"b26d09f5-baaf-482e-8423-687344734389\", \"azureml.git.repository_uri\": \"https://github.com/azure/azureml-examples\", \"mlflow.source.git.repoURL\": \"https://github.com/azure/azureml-examples\", \"azureml.git.branch\": \"cody/updates\", \"mlflow.source.git.branch\": \"cody/updates\", \"azureml.git.commit\": \"e31e4e1ecb1b12a9eeb292965f3f80fd919f52e6\", \"mlflow.source.git.commit\": \"e31e4e1ecb1b12a9eeb292965f3f80fd919f52e6\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":1,\\\"CurrentNodeCount\\\":2}\", \"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"train.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-08-31T19:56:11.273Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_c194acdf74e95b9b1ca93f10ddb8a556295c74624bfee82d7617e74a8db27377_d.txt\": \"https://azuremlstoragef92a69eef1.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/azureml-logs/55_azureml-execution-tvmps_c194acdf74e95b9b1ca93f10ddb8a556295c74624bfee82d7617e74a8db27377_d.txt?sv=2019-02-02&sr=b&sig=lMlYlKAlX1b3tXrKt3RhqBtEsQAQMau0JZHdBVAtsiA%3D&st=2020-08-31T19%3A46%3A21Z&se=2020-09-01T03%3A56%3A21Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_c194acdf74e95b9b1ca93f10ddb8a556295c74624bfee82d7617e74a8db27377_d.txt\": \"https://azuremlstoragef92a69eef1.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/azureml-logs/65_job_prep-tvmps_c194acdf74e95b9b1ca93f10ddb8a556295c74624bfee82d7617e74a8db27377_d.txt?sv=2019-02-02&sr=b&sig=VYbOMGyK4X0ur2JZcoz4mqwTjs%2F89pikW4joNVKp44I%3D&st=2020-08-31T19%3A46%3A22Z&se=2020-09-01T03%3A56%3A22Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://azuremlstoragef92a69eef1.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=I5WP%2FSnk%2B7KG8fYwFoUZg2RTbVn4YgQHlFYaFB%2FPNnU%3D&st=2020-08-31T19%3A46%3A22Z&se=2020-09-01T03%3A56%3A22Z&sp=r\", \"azureml-logs/75_job_post-tvmps_c194acdf74e95b9b1ca93f10ddb8a556295c74624bfee82d7617e74a8db27377_d.txt\": \"https://azuremlstoragef92a69eef1.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/azureml-logs/75_job_post-tvmps_c194acdf74e95b9b1ca93f10ddb8a556295c74624bfee82d7617e74a8db27377_d.txt?sv=2019-02-02&sr=b&sig=O1KdVepTKOO8SRwL3OoJQM81PaFiWKvlxI9%2F1UGC3IA%3D&st=2020-08-31T19%3A46%3A22Z&se=2020-09-01T03%3A56%3A22Z&sp=r\", \"azureml-logs/process_info.json\": \"https://azuremlstoragef92a69eef1.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=%2BUMc7racC4L%2BrkmQyd1BlDd0Mg0zRuix9dTTYdUlliU%3D&st=2020-08-31T19%3A46%3A22Z&se=2020-09-01T03%3A56%3A22Z&sp=r\", \"azureml-logs/process_status.json\": \"https://azuremlstoragef92a69eef1.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=sRpPXm4R3vMDteDfsJEnB6WPncNyJcOy97mMK6IqOm8%3D&st=2020-08-31T19%3A46%3A22Z&se=2020-09-01T03%3A56%3A22Z&sp=r\", \"logs/azureml/127_azureml.log\": \"https://azuremlstoragef92a69eef1.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/logs/azureml/127_azureml.log?sv=2019-02-02&sr=b&sig=SruNZswqqpZgVs9TEzJPoqQ6Z0tzXpaJvjsVADWNigc%3D&st=2020-08-31T19%3A46%3A21Z&se=2020-09-01T03%3A56%3A21Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://azuremlstoragef92a69eef1.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=pvrwAh2AmwxFwfi40xVXei8WKN07A1vgwuLIn9tKuIk%3D&st=2020-08-31T19%3A46%3A22Z&se=2020-09-01T03%3A56%3A22Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://azuremlstoragef92a69eef1.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=9gvonv6sUlv3VXnfR0xA%2BJS57nti%2BKxMxEdjPEaF2gE%3D&st=2020-08-31T19%3A46%3A22Z&se=2020-09-01T03%3A56%3A22Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_c194acdf74e95b9b1ca93f10ddb8a556295c74624bfee82d7617e74a8db27377_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_c194acdf74e95b9b1ca93f10ddb8a556295c74624bfee82d7617e74a8db27377_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_c194acdf74e95b9b1ca93f10ddb8a556295c74624bfee82d7617e74a8db27377_d.txt\"], [\"logs/azureml/127_azureml.log\"]], \"run_duration\": \"0:11:04\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2020-08-31 19:46:23,448|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2020-08-31 19:46:23,448|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2020-08-31 19:46:23,454|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2020-08-31 19:46:23,455|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-08-31 19:46:23,745|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7faf565caae8> for run source azureml.scriptrun\\n2020-08-31 19:46:23,771|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-08-31 19:46:23,778|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-08-31 19:46:23,778|azureml.core.authentication|DEBUG|Time to expire 1814322.221301 seconds\\n2020-08-31 19:46:23,778|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-08-31 19:46:23,778|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-08-31 19:46:23,779|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-08-31 19:46:23,779|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-08-31 19:46:23,824|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-08-31 19:46:23,824|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-08-31 19:46:23,825|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-08-31 19:46:23,855|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-08-31 19:46:23,958|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-08-31 19:46:23,959|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'b26d09f5-baaf-482e-8423-687344734389', 'azureml.git.repository_uri': 'https://github.com/azure/azureml-examples', 'mlflow.source.git.repoURL': 'https://github.com/azure/azureml-examples', 'azureml.git.branch': 'cody/updates', 'mlflow.source.git.branch': 'cody/updates', 'azureml.git.commit': 'e31e4e1ecb1b12a9eeb292965f3f80fd919f52e6', 'mlflow.source.git.commit': 'e31e4e1ecb1b12a9eeb292965f3f80fd919f52e6', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-08-31 19:46:23,970|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-08-31 19:46:24,573|azureml|DEBUG|Installed with mlflow version 1.11.0.\\n2020-08-31 19:46:24,574|azureml.mlflow|DEBUG|Setting up a Remote MLflow run\\n2020-08-31 19:46:24,574|azureml.mlflow|DEBUG|Creating a tracking uri in eastus.experiments.azureml.net for workspace /subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourceGroups/cody-eastus-rg/providers/Microsoft.MachineLearningServices/workspaces/AzureML\\n2020-08-31 19:46:24,574|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2020-08-31 19:46:24,575|azureml.mlflow._internal.model_registry|DEBUG|Initializing the AzureMLflowModelRegistry\\n2020-08-31 19:46:24,575|azureml.mlflow|DEBUG|Setting MLflow tracking uri env var\\n2020-08-31 19:46:24,575|azureml.mlflow|DEBUG|Setting MLflow run id env var with pytorch-mnist-example_1598903102_fef081a2\\n2020-08-31 19:46:24,575|azureml.mlflow|DEBUG|Setting Mlflow experiment with pytorch-mnist-example\\n2020-08-31 19:46:24,576|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.type\\n2020-08-31 19:46:24,576|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.name\\n2020-08-31 19:46:24,576|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[START]\\n2020-08-31 19:46:24,762|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[STOP]\\n2020-08-31 19:46:24,764|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.RunClient.patch-async:False|DEBUG|[START]\\n2020-08-31 19:46:24,916|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.RunClient.patch-async:False|DEBUG|[STOP]\\n2020-08-31 19:46:24,917|azureml.WorkerPool|DEBUG|[START]\\n2020-08-31 19:46:24,917|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-08-31 19:46:24,917|azureml.RunStatusContext|DEBUG|[START]\\n2020-08-31 19:46:24,917|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-08-31 19:46:24,917|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-08-31 19:46:24,917|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-08-31 19:46:24,917|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/azureml/azureml/pytorch-mnist-example_1598903102_fef081a2/mounts/workspaceblobstore/azureml/pytorch-mnist-example_1598903102_fef081a2\\n2020-08-31 19:46:24,917|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-08-31 19:46:24,917|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/azureml/azureml/pytorch-mnist-example_1598903102_fef081a2/mounts/workspaceblobstore/azureml/pytorch-mnist-example_1598903102_fef081a2\\n2020-08-31 19:46:53,774|azureml.core.authentication|DEBUG|Time to expire 1814292.22597 seconds\\n2020-08-31 19:47:23,783|azureml.core.authentication|DEBUG|Time to expire 1814262.21649 seconds\\n2020-08-31 19:47:53,787|azureml.core.authentication|DEBUG|Time to expire 1814232.212509 seconds\\n2020-08-31 19:48:23,795|azureml.core.authentication|DEBUG|Time to expire 1814202.204524 seconds\\n2020-08-31 19:48:53,807|azureml.core.authentication|DEBUG|Time to expire 1814172.192508 seconds\\n2020-08-31 19:49:23,807|azureml.core.authentication|DEBUG|Time to expire 1814142.192222 seconds\\n2020-08-31 19:49:53,808|azureml.core.authentication|DEBUG|Time to expire 1814112.191924 seconds\\n2020-08-31 19:50:23,815|azureml.core.authentication|DEBUG|Time to expire 1814082.184532 seconds\\n2020-08-31 19:50:53,818|azureml.core.authentication|DEBUG|Time to expire 1814052.18201 seconds\\n2020-08-31 19:51:23,818|azureml.core.authentication|DEBUG|Time to expire 1814022.181768 seconds\\n2020-08-31 19:51:53,827|azureml.core.authentication|DEBUG|Time to expire 1813992.172538 seconds\\n2020-08-31 19:52:23,827|azureml.core.authentication|DEBUG|Time to expire 1813962.17225 seconds\\n2020-08-31 19:52:53,828|azureml.core.authentication|DEBUG|Time to expire 1813932.171987 seconds\\n2020-08-31 19:53:23,839|azureml.core.authentication|DEBUG|Time to expire 1813902.160534 seconds\\n2020-08-31 19:53:53,846|azureml.core.authentication|DEBUG|Time to expire 1813872.153897 seconds\\n2020-08-31 19:54:23,853|azureml.core.authentication|DEBUG|Time to expire 1813842.146909 seconds\\n2020-08-31 19:54:53,859|azureml.core.authentication|DEBUG|Time to expire 1813812.140536 seconds\\n2020-08-31 19:55:23,859|azureml.core.authentication|DEBUG|Time to expire 1813782.140242 seconds\\n2020-08-31 19:55:53,870|azureml.core.authentication|DEBUG|Time to expire 1813752.129718 seconds\\n2020-08-31 19:56:08,783|azureml.mlflow._internal.store_loader|DEBUG|Loading an existing AzureMLRestStore from the _AzureMLStoreLoader cache\\n2020-08-31 19:56:09,233|azureml.mlflow._internal.store_loader|DEBUG|Loading an existing AzureMLRestStore from the _AzureMLStoreLoader cache\\n2020-08-31 19:56:09,336|azureml.mlflow._internal.utils|DEBUG|Initializing the AzureMLflowArtifactRepository\\n2020-08-31 19:56:09,336|azureml.mlflow._internal.store_loader|DEBUG|Loading an existing AzureMLRestStore from the _AzureMLStoreLoader cache\\n2020-08-31 19:56:09,337|azureml.mlflow._internal.utils|DEBUG|Using the service context from the AzureMLRestStore store\\n2020-08-31 19:56:09,337|azureml.mlflow._internal.utils|INFO|Parsing artifact uri azureml://experiments/pytorch-mnist-example/runs/pytorch-mnist-example_1598903102_fef081a2/artifacts\\n2020-08-31 19:56:09,337|azureml.mlflow._internal.utils|INFO|Artifact uri azureml://experiments/pytorch-mnist-example/runs/pytorch-mnist-example_1598903102_fef081a2/artifacts info: {'experiment': 'pytorch-mnist-example', 'runid': 'pytorch-mnist-example_1598903102_fef081a2'}\\n2020-08-31 19:56:09,337|azureml.mlflow._internal.utils|DEBUG|AzureMLflowArtifactRepository for experiment pytorch-mnist-example\\n2020-08-31 19:56:09,337|azureml.mlflow._internal.utils|DEBUG|AzureMLflowArtifactRepository for run id pytorch-mnist-example_1598903102_fef081a2\\n2020-08-31 19:56:09,338|azureml.mlflow._internal.utils|DEBUG|AzureMLflowArtifactRepository for path None\\n2020-08-31 19:56:09,338|azureml.RunArtifactRepositoryClient|DEBUG|Uploading ['model/conda.yaml', 'model/MLmodel', 'model/data/pickle_module_info.txt', 'model/data/model.pth']\\n2020-08-31 19:56:09,338|azureml.RunArtifactRepositoryClient.upload_files|DEBUG|[Start]\\n2020-08-31 19:56:09,338|azureml.RunArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2020-08-31 19:56:09,888|azureml.RunArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2020-08-31 19:56:09,888|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: perform_upload\\n2020-08-31 19:56:09,888|azureml.RunArtifactRepositoryClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2020-08-31 19:56:09,888|azureml.RunArtifactRepositoryClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2020-08-31 19:56:09,889|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: perform_upload\\n2020-08-31 19:56:09,890|azureml.RunArtifactRepositoryClient.upload_files.1_perform_upload|DEBUG|Using basic handler - no exception handling\\n2020-08-31 19:56:09,890|azureml.RunArtifactRepositoryClient.upload_files|DEBUG|Adding task 1_perform_upload to queue of approximate size: 1\\n2020-08-31 19:56:09,893|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: perform_upload\\n2020-08-31 19:56:09,893|azureml.RunArtifactRepositoryClient.upload_files.2_perform_upload|DEBUG|Using basic handler - no exception handling\\n2020-08-31 19:56:09,894|azureml.RunArtifactRepositoryClient.upload_files|DEBUG|Adding task 2_perform_upload to queue of approximate size: 2\\n2020-08-31 19:56:09,894|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: perform_upload\\n2020-08-31 19:56:09,897|azureml.RunArtifactRepositoryClient.upload_files.3_perform_upload|DEBUG|Using basic handler - no exception handling\\n2020-08-31 19:56:09,900|azureml.RunArtifactRepositoryClient.upload_files|DEBUG|Adding task 3_perform_upload to queue of approximate size: 3\\n2020-08-31 19:56:09,900|azureml.RunArtifactRepositoryClient.upload_files|DEBUG|[Stop] - waiting default timeout\\n2020-08-31 19:56:09,900|azureml.RunArtifactRepositoryClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2020-08-31 19:56:09,901|azureml.RunArtifactRepositoryClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 120\\n2020-08-31 19:56:09,901|azureml.RunArtifactRepositoryClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_perform_upload), AsyncTask(1_perform_upload), AsyncTask(2_perform_upload), AsyncTask(3_perform_upload)].\\n2020-08-31 19:56:09,956|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/model/conda.yaml with size 175.\\n2020-08-31 19:56:09,961|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/model/data/pickle_module_info.txt with size 28.\\n2020-08-31 19:56:09,972|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/model/MLmodel with size 354.\\n2020-08-31 19:56:10,151|azureml.RunArtifactRepositoryClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2020-08-31 19:56:10,151|azureml.RunArtifactRepositoryClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2020-08-31 19:56:10,151|azureml.RunArtifactRepositoryClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2020-08-31 19:56:10,151|azureml.RunArtifactRepositoryClient.upload_files.1_perform_upload.WaitingTask|DEBUG|[START]\\n2020-08-31 19:56:10,152|azureml.RunArtifactRepositoryClient.upload_files.1_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2020-08-31 19:56:10,152|azureml.RunArtifactRepositoryClient.upload_files.1_perform_upload.WaitingTask|DEBUG|[STOP]\\n2020-08-31 19:56:10,152|azureml.RunArtifactRepositoryClient.upload_files.2_perform_upload.WaitingTask|DEBUG|[START]\\n2020-08-31 19:56:10,152|azureml.RunArtifactRepositoryClient.upload_files.2_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2020-08-31 19:56:10,152|azureml.RunArtifactRepositoryClient.upload_files.2_perform_upload.WaitingTask|DEBUG|[STOP]\\n2020-08-31 19:56:10,153|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.pytorch-mnist-example_1598903102_fef081a2/model/data/model.pth with size 4805879.\\n2020-08-31 19:56:10,402|azureml.RunArtifactRepositoryClient.upload_files.3_perform_upload.WaitingTask|DEBUG|[START]\\n2020-08-31 19:56:10,402|azureml.RunArtifactRepositoryClient.upload_files.3_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2020-08-31 19:56:10,403|azureml.RunArtifactRepositoryClient.upload_files.3_perform_upload.WaitingTask|DEBUG|[STOP]\\n2020-08-31 19:56:10,403|azureml.RunArtifactRepositoryClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\nWaiting on task: 1_perform_upload.\\nWaiting on task: 2_perform_upload.\\nWaiting on task: 3_perform_upload.\\n4 tasks left. Current duration of flush 0.0001246929168701172 seconds.\\nWaiting on task: 3_perform_upload.\\n1 tasks left. Current duration of flush 0.251267671585083 seconds.\\n\\n2020-08-31 19:56:10,403|azureml.RunArtifactRepositoryClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2020-08-31 19:56:10,407|azureml.mlflow._internal.store_loader|DEBUG|Loading an existing AzureMLRestStore from the _AzureMLStoreLoader cache\\n2020-08-31 19:56:10,463|azureml.mlflow._internal.store_loader|DEBUG|Loading an existing AzureMLRestStore from the _AzureMLStoreLoader cache\\n2020-08-31 19:56:10,669|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-08-31 19:56:10,669|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/azureml/azureml/pytorch-mnist-example_1598903102_fef081a2/mounts/workspaceblobstore/azureml/pytorch-mnist-example_1598903102_fef081a2\\n2020-08-31 19:56:10,669|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/azureml/azureml/pytorch-mnist-example_1598903102_fef081a2/mounts/workspaceblobstore/azureml/pytorch-mnist-example_1598903102_fef081a2 to /mnt/batch/tasks/shared/LS_root/jobs/azureml/azureml/pytorch-mnist-example_1598903102_fef081a2/mounts/workspaceblobstore/azureml/pytorch-mnist-example_1598903102_fef081a2\\n2020-08-31 19:56:10,670|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/azureml/azureml/pytorch-mnist-example_1598903102_fef081a2/mounts/workspaceblobstore/azureml/pytorch-mnist-example_1598903102_fef081a2\\n2020-08-31 19:56:10,670|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2020-08-31 19:56:10,670|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2020-08-31 19:56:10,670|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2|INFO|complete is not setting status for submitted runs.\\n2020-08-31 19:56:10,670|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-08-31 19:56:10,670|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-08-31 19:56:10,670|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-08-31 19:56:10,670|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-08-31 19:56:10,671|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-08-31 19:56:10,672|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-08-31 19:56:10,672|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-08-31 19:56:10,672|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-08-31 19:56:10,672|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-08-31 19:56:10,672|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-08-31 19:56:10,960|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-08-31 19:56:10,961|azureml.RunStatusContext|DEBUG|[STOP]\\n2020-08-31 19:56:10,961|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-08-31 19:56:10,961|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-08-31 19:56:10,961|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-08-31 19:56:10,961|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-08-31 19:56:10,961|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-08-31 19:56:10,961|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-08-31 19:56:10,961|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-08-31 19:56:10,962|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-08-31 19:56:10,962|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-08-31 19:56:10,962|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-08-31 19:56:10,962|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-08-31 19:56:10,962|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-08-31 19:56:10,962|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-08-31 19:56:11,131|azureml._SubmittedRun#pytorch-mnist-example_1598903102_fef081a2.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-08-31 19:56:11,131|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2020-08-31 19:56:11,131|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2020-08-31 19:56:11,131|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2020-08-31 19:56:11,132|azureml.WorkerPool|DEBUG|[STOP]\\n2020-08-31 19:56:11,273|azureml.mlflow._internal.store_loader|DEBUG|Loading an existing AzureMLRestStore from the _AzureMLStoreLoader cache\\n2020-08-31 19:56:11,273|azureml.mlflow._internal.store_loader|DEBUG|Loading an existing AzureMLRestStore from the _AzureMLStoreLoader cache\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.12.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "index": {
   "scenario": "training",
   "compute": "AML - GPU",
   "frameworks": "pytorch",
   "dataset": "mnist",
   "environment": "curated",
   "distribution": "None",
   "other": "None"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dkdc': conda)",
   "name": "python_defaultSpec_1598902295041"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}