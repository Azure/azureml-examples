{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd969e25",
   "metadata": {},
   "source": [
    "# Deploy machine learning models to Azure\n",
    "\n",
    "description: (preview) deploy your machine learning or deep learning model as a web service in the Azure cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996082fd",
   "metadata": {},
   "source": [
    "# Connect to your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9f14ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='chrjia-eastus2euap2', subscription_id='13e50845-67bc-4ac5-94db-48d493a6d9e8', resource_group='chrjia-rg')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9057aaf6",
   "metadata": {},
   "source": [
    "# Register your model\n",
    "\n",
    "A registered model is a logical container stored in the cloud, containing all files located at `model_path`, which is associated with a version number and other metadata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3cd0e",
   "metadata": {},
   "source": [
    "## Register a model from a local file\n",
    "\n",
    "You can register a model by providing the local path of the model. You can provide the path of either a folder or a single file on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf6e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model bidaf_onnx\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Download model\n",
    "urllib.request.urlretrieve(\"https://aka.ms/bidaf-9-model\", \"model.onnx\")\n",
    "\n",
    "# Register model\n",
    "model = Model.register(ws, model_name=\"bidaf_onnx\", model_path=\"./model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc200fe9",
   "metadata": {},
   "source": [
    "# Define an inference configuration\n",
    "\n",
    "The inference configuration below specifies that the machine learning deployment will use the file echo_score.py in the ./source_dir directory to process incoming requests and that it will use the Docker image with the Python packages specified in the project_environment environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e5efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment(name=\"project_environment\")\n",
    "dummy_inference_config = InferenceConfig(\n",
    "    environment=env, source_directory=\"./source_dir\", entry_script=\"./echo_score.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850e5f4",
   "metadata": {},
   "source": [
    "## Define a deployment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a6fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d34207",
   "metadata": {},
   "source": [
    "## Deploy your machine learning model\n",
    "\n",
    "A deployment configuration specifies the amount of memory and cores to reserve for your webservice will require in order to run, as well as configuration details of the underlying webservice. For example, a deployment configuration lets you specify that your service needs 2 gigabytes of memory, 2 CPU cores, 1 GPU core, and that you want to enable autoscaling.\n",
    "\n",
    "The options available for a deployment configuration differ depending on the compute target you choose. In a local deployment, all you can specify is which port your webservice will be served on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9762e02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model bidaf_onnx:26 to /tmp/azureml_em7gs8if/bidaf_onnx/26\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_673d52b5abe224c83574bc767a17fa28\n",
      " ---> 0884414da052\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 5225ed94d7f5\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjEzZTUwODQ1LTY3YmMtNGFjNS05NGRiLTQ4ZDQ5M2E2ZDllOCIsInJlc291cmNlR3JvdXBOYW1lIjoiY2hyamlhLXJnIiwiYWNjb3VudE5hbWUiOiJjaHJqaWEtZWFzdHVzMmV1YXAyIiwid29ya3NwYWNlSWQiOiI1OTkzZGVjMS01OTczLTQ4NTktOGJlMS03MDczMzJjNTQ5NWQifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 79937e7f3446\n",
      " ---> 04ab06cb34b7\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmps56ee6v0.py' /var/azureml-app/main.py\n",
      " ---> Running in 08005ed80df9\n",
      " ---> 39d7246b49c1\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 3d8c11b3f6e2\n",
      " ---> e0417420ad39\n",
      "Successfully built e0417420ad39\n",
      "Successfully tagged myservice:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:34380aabec6d8b307610ad7d279eb418ce0ad96460378c307059746508c6003e successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"myservice\", [model], dummy_inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede851f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05T09:03:07,605921500+00:00 - rsyslog/run \n",
      "2021-05-05T09:03:07,606122300+00:00 - gunicorn/run \n",
      "2021-05-05T09:03:07,606250100+00:00 - iot-server/run \n",
      "2021-05-05T09:03:07,607106700+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-05-05T09:03:07,676476700+00:00 - iot-server/finish 1 0\n",
      "2021-05-05T09:03:07,677607400+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 47\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-05-05 09:03:07,967 | root | INFO | Starting up app insights client\n",
      "2021-05-05 09:03:07,968 | root | INFO | Starting up request id generator\n",
      "2021-05-05 09:03:07,968 | root | INFO | Starting up app insight hooks\n",
      "2021-05-05 09:03:07,968 | root | INFO | Invoking user's init function\n",
      "This is init\n",
      "2021-05-05 09:03:07,968 | root | INFO | Users's init has completed successfully\n",
      "2021-05-05 09:03:07,971 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-05-05 09:03:07,971 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-05-05 09:03:07,972 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d47b4",
   "metadata": {},
   "source": [
    "## Call into your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e92e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test is {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "requests.get(\"http://localhost:6789\")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"query\": \"What color is the fox\",\n",
    "    \"context\": \"The quick brown fox jumped over the lazy dog.\",\n",
    "}\n",
    "data = json.dumps(data)\n",
    "response = requests.post(uri, data=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9e82c",
   "metadata": {},
   "source": [
    "Notice the use of the AZUREML_MODEL_DIR environment variable to locate your registered model. Now that you've added some pip packages, you also need to update your inference configuration to add in those additional packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b9d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(name=\"myenv\")\n",
    "python_packages = [\"nltk\", \"numpy\", \"onnxruntime\"]\n",
    "for package in python_packages:\n",
    "    env.python.conda_dependencies.add_pip_package(package)\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    environment=env, source_directory=\"./source_dir\", entry_script=\"./score.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0c387",
   "metadata": {},
   "source": [
    "## Deploy again and call your service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd084966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model bidaf_onnx:26 to /tmp/azureml_1182bbhn/bidaf_onnx/26\n",
      "Generating Docker build context.\n",
      "2021/05/05 09:08:26 Downloading source code...\n",
      "2021/05/05 09:08:27 Finished downloading source code\n",
      "2021/05/05 09:08:27 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/05/05 09:08:28 Successfully set up Docker network: acb_default_network\n",
      "2021/05/05 09:08:28 Setting up Docker configuration...\n",
      "2021/05/05 09:08:29 Successfully set up Docker configuration\n",
      "2021/05/05 09:08:29 Logging in to registry: chrjiaeastusc6ba5291.azurecr.io\n",
      "2021/05/05 09:08:30 Successfully logged into chrjiaeastusc6ba5291.azurecr.io\n",
      "2021/05/05 09:08:30 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/05/05 09:08:30 Scanning for dependencies...\n",
      "2021/05/05 09:08:30 Successfully scanned dependencies\n",
      "2021/05/05 09:08:30 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "Step 1/18 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
      "mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
      "Digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
      " ---> c942df5ba5d0\n",
      "Step 2/18 : USER root\n",
      " ---> Running in e5bc0f78e67e\n",
      "Removing intermediate container e5bc0f78e67e\n",
      " ---> b025d1a9195f\n",
      "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in d14837af41a3\n",
      "Removing intermediate container d14837af41a3\n",
      " ---> f7d99b28838f\n",
      "Step 4/18 : WORKDIR /\n",
      " ---> Running in d27d7f76e6c6\n",
      "Removing intermediate container d27d7f76e6c6\n",
      " ---> b892469250c2\n",
      "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 70cef76ed450\n",
      "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 8407cdfcd8db\n",
      "Removing intermediate container 8407cdfcd8db\n",
      " ---> 06d1b6a28120\n",
      "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 2aa356fd4508\n",
      "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in f3a7fc7a8017\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.bq9vcv0p.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.27.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.7.0-cp36-cp36m-manylinux2014_x86_64.whl (4.1 MB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.27.0\n",
      "  Downloading azureml_dataset_runtime-1.27.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting azureml-core~=1.27.0\n",
      "  Downloading azureml_core-1.27.0-py3-none-any.whl (2.2 MB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.4.4-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.15.8-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting pyarrow<2.0.0,>=0.17.0\n",
      "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting azureml-dataprep<2.15.0a,>=2.14.0a\n",
      "  Downloading azureml_dataprep-2.14.2-py3-none-any.whl (39.4 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Collecting python-dateutil>=2.5.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting adal>=0.4.5\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting six>=1.10\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pandas>=0.20.2\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting ruamel.yaml<1.0.0,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
      "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting docker<5.0.0\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
      "Collecting contextlib2<1.0.0\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting pyopenssl<21.0.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting jmespath<1.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-12.1.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting azureml-dataprep-native<34.0.0,>=33.0.0\n",
      "  Downloading azureml_dataprep_native-33.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azureml-dataprep-rslex<1.13.0a,>=1.12.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.12.1-cp36-cp36m-manylinux1_x86_64.whl (9.6 MB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux2010_x86_64.whl (32 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/python3.6/site-packages (from requests>=2.17.3->azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.bq9vcv0p.requirements.txt (line 1)) (2020.6.20)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.59.0-py2.py3-none-any.whl (67 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.11.0-py2.py3-none-any.whl (63 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.13.0-py2.py3-none-any.whl (133 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, liac-arff\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=b213c0794cd229fccaa72892a0bfcb2d11f9b03676a379a78c25829013e12284\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=2ff25e677c31a117598186166466bab964dedaf6e47aebbc9c79d06c083c358f\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=cf71d810c681ee1bb073fbc800692dbb5ae11546430e6f504deea66409445f16\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "Successfully built json-logging-py fusepy liac-arff\n",
      "Installing collected packages: configparser, werkzeug, applicationinsights, numpy, pyarrow, azureml-dataprep-native, portalocker, chardet, idna, urllib3, requests, pycparser, cffi, cryptography, PyJWT, msal, msal-extensions, six, azure-core, azure-identity, azureml-dataprep-rslex, cloudpickle, distro, dotnetcore2, azureml-dataprep, fusepy, azureml-dataset-runtime, MarkupSafe, Jinja2, click, itsdangerous, flask, dill, python-dateutil, liac-arff, adal, pytz, pandas, azureml-model-management-sdk, gunicorn, azure-common, isodate, oauthlib, requests-oauthlib, msrest, msrestazure, azure-mgmt-storage, backports.weakref, backports.tempfile, ruamel.yaml.clib, ruamel.yaml, azure-mgmt-keyvault, pyopenssl, pyasn1, ndg-httpsclient, azure-mgmt-authorization, azure-graphrbac, pathspec, zipp, typing-extensions, importlib-metadata, jsonpickle, websocket-client, docker, contextlib2, jeepney, SecretStorage, jmespath, azure-mgmt-resource, azure-mgmt-containerregistry, azureml-core, json-logging-py, azureml-defaults, regex, joblib, tqdm, nltk, protobuf, onnxruntime\n",
      "Successfully installed Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-2.1.0 SecretStorage-3.3.1 adal-1.2.7 applicationinsights-0.11.10 azure-common-1.1.27 azure-core-1.13.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.1.0 azure-mgmt-storage-11.2.0 azureml-core-1.27.0 azureml-dataprep-2.14.2 azureml-dataprep-native-33.0.0 azureml-dataprep-rslex-1.12.1 azureml-dataset-runtime-1.27.0 azureml-defaults-1.27.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.5 chardet-4.0.0 click-7.1.2 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.4.7 dill-0.3.3 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.20 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-4.0.1 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.6.0 jmespath-0.10.0 joblib-1.0.1 json-logging-py-0.2 jsonpickle-2.0.0 liac-arff-2.5.0 msal-1.11.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 nltk-3.6.2 numpy-1.19.5 oauthlib-3.1.0 onnxruntime-1.7.0 pandas-1.1.5 pathspec-0.8.1 portalocker-1.7.1 protobuf-3.15.8 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 python-dateutil-2.8.1 pytz-2021.1 regex-2021.4.4 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 six-1.15.0 tqdm-4.60.0 typing-extensions-3.10.0.0 urllib3-1.26.4 websocket-client-0.59.0 werkzeug-1.0.1 zipp-3.4.1\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.10.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0mWARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container f3a7fc7a8017\n",
      " ---> cb42b03aa1c8\n",
      "Step 9/18 : ENV PATH /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/bin:$PATH\n",
      " ---> Running in a9b4d735d8f5\n",
      "Removing intermediate container a9b4d735d8f5\n",
      " ---> 6c5658c0daec\n",
      "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 5aaf32f49c08\n",
      "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> a0bd1f4f1156\n",
      "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---> Running in 2e99e8a8c627\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 2e99e8a8c627\n",
      " ---> f48dccdcd4cb\n",
      "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1\n",
      " ---> Running in 9bc99bddefff\n",
      "Removing intermediate container 9bc99bddefff\n",
      " ---> afd9a50cfa86\n",
      "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 8c0a2901f87c\n",
      "Removing intermediate container 8c0a2901f87c\n",
      " ---> e995ae6b9376\n",
      "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 7b6e873beb29\n",
      "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in a4bfb91e67a0\n",
      "Removing intermediate container a4bfb91e67a0\n",
      " ---> 916798ede00d\n",
      "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 59886081e844\n",
      "Removing intermediate container 59886081e844\n",
      " ---> 23667c69e615\n",
      "Step 18/18 : CMD [\"bash\"]\n",
      " ---> Running in 02ae2916d674\n",
      "Removing intermediate container 02ae2916d674\n",
      " ---> aa879ae61cb4\n",
      "Successfully built aa879ae61cb4\n",
      "Successfully tagged chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7:latest\n",
      "Successfully tagged chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7:1\n",
      "2021/05/05 09:10:51 Successfully executed container: acb_step_0\n",
      "2021/05/05 09:10:51 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/05/05 09:10:51 Pushing image: chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7:1, attempt 1\n",
      "The push refers to repository [chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7]\n",
      "f42e3d50353c: Preparing\n",
      "ba0693cfb456: Preparing\n",
      "49e58047a182: Preparing\n",
      "07a439d47666: Preparing\n",
      "d6a96476dc02: Preparing\n",
      "2ad5aa60b163: Preparing\n",
      "c87b07a28c9b: Preparing\n",
      "632d5b530424: Preparing\n",
      "fea37e8f981f: Preparing\n",
      "3f3f8889d538: Preparing\n",
      "420340de7040: Preparing\n",
      "c3d9b0d7dd4c: Preparing\n",
      "4441896e1280: Preparing\n",
      "a64fe594a899: Preparing\n",
      "0d34930f20d5: Preparing\n",
      "18c9012f327d: Preparing\n",
      "e4a0bf630548: Preparing\n",
      "5276d2b930fc: Preparing\n",
      "e6feec0db89a: Preparing\n",
      "697949baa658: Preparing\n",
      "935c56d8b3f9: Preparing\n",
      "c3d9b0d7dd4c: Waiting\n",
      "4441896e1280: Waiting\n",
      "a64fe594a899: Waiting\n",
      "0d34930f20d5: Waiting\n",
      "18c9012f327d: Waiting\n",
      "e4a0bf630548: Waiting\n",
      "5276d2b930fc: Waiting\n",
      "e6feec0db89a: Waiting\n",
      "697949baa658: Waiting\n",
      "935c56d8b3f9: Waiting\n",
      "632d5b530424: Waiting\n",
      "fea37e8f981f: Waiting\n",
      "3f3f8889d538: Waiting\n",
      "420340de7040: Waiting\n",
      "2ad5aa60b163: Waiting\n",
      "c87b07a28c9b: Waiting\n",
      "07a439d47666: Pushed\n",
      "f42e3d50353c: Pushed\n",
      "49e58047a182: Pushed\n",
      "ba0693cfb456: Pushed\n",
      "2ad5aa60b163: Pushed\n",
      "632d5b530424: Pushed\n",
      "c87b07a28c9b: Pushed\n",
      "fea37e8f981f: Pushed\n",
      "420340de7040: Pushed\n",
      "3f3f8889d538: Pushed\n",
      "c3d9b0d7dd4c: Pushed\n",
      "18c9012f327d: Pushed\n",
      "4441896e1280: Pushed\n",
      "5276d2b930fc: Pushed\n",
      "e6feec0db89a: Pushed\n",
      "697949baa658: Pushed\n",
      "0d34930f20d5: Pushed\n",
      "a64fe594a899: Pushed\n",
      "e4a0bf630548: Pushed\n",
      "935c56d8b3f9: Pushed\n",
      "d6a96476dc02: Pushed\n",
      "1: digest: sha256:6f746ffb27142b251f5ba5dfd123fb33af73f4411cbbfefaf83764a6b4e72a51 size: 4721\n",
      "2021/05/05 09:12:32 Successfully pushed image: chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7:1\n",
      "2021/05/05 09:12:32 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/05/05 09:12:32 Pushing image: chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7:latest, attempt 1\n",
      "The push refers to repository [chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7]\n",
      "f42e3d50353c: Preparing\n",
      "ba0693cfb456: Preparing\n",
      "49e58047a182: Preparing\n",
      "07a439d47666: Preparing\n",
      "d6a96476dc02: Preparing\n",
      "2ad5aa60b163: Preparing\n",
      "c87b07a28c9b: Preparing\n",
      "632d5b530424: Preparing\n",
      "fea37e8f981f: Preparing\n",
      "3f3f8889d538: Preparing\n",
      "420340de7040: Preparing\n",
      "c3d9b0d7dd4c: Preparing\n",
      "4441896e1280: Preparing\n",
      "a64fe594a899: Preparing\n",
      "0d34930f20d5: Preparing\n",
      "18c9012f327d: Preparing\n",
      "e4a0bf630548: Preparing\n",
      "5276d2b930fc: Preparing\n",
      "e6feec0db89a: Preparing\n",
      "697949baa658: Preparing\n",
      "935c56d8b3f9: Preparing\n",
      "2ad5aa60b163: Waiting\n",
      "c87b07a28c9b: Waiting\n",
      "632d5b530424: Waiting\n",
      "fea37e8f981f: Waiting\n",
      "3f3f8889d538: Waiting\n",
      "420340de7040: Waiting\n",
      "c3d9b0d7dd4c: Waiting\n",
      "5276d2b930fc: Waiting\n",
      "e6feec0db89a: Waiting\n",
      "4441896e1280: Waiting\n",
      "a64fe594a899: Waiting\n",
      "697949baa658: Waiting\n",
      "935c56d8b3f9: Waiting\n",
      "0d34930f20d5: Waiting\n",
      "18c9012f327d: Waiting\n",
      "e4a0bf630548: Waiting\n",
      "49e58047a182: Layer already exists\n",
      "f42e3d50353c: Layer already exists\n",
      "d6a96476dc02: Layer already exists\n",
      "07a439d47666: Layer already exists\n",
      "2ad5aa60b163: Layer already exists\n",
      "ba0693cfb456: Layer already exists\n",
      "c87b07a28c9b: Layer already exists\n",
      "fea37e8f981f: Layer already exists\n",
      "632d5b530424: Layer already exists\n",
      "420340de7040: Layer already exists\n",
      "a64fe594a899: Layer already exists\n",
      "0d34930f20d5: Layer already exists\n",
      "c3d9b0d7dd4c: Layer already exists\n",
      "4441896e1280: Layer already exists\n",
      "5276d2b930fc: Layer already exists\n",
      "3f3f8889d538: Layer already exists\n",
      "e6feec0db89a: Layer already exists\n",
      "697949baa658: Layer already exists\n",
      "18c9012f327d: Layer already exists\n",
      "935c56d8b3f9: Layer already exists\n",
      "e4a0bf630548: Layer already exists\n",
      "latest: digest: sha256:6f746ffb27142b251f5ba5dfd123fb33af73f4411cbbfefaf83764a6b4e72a51 size: 4721\n",
      "2021/05/05 09:12:34 Successfully pushed image: chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7:latest\n",
      "2021/05/05 09:12:34 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 141.567841)\n",
      "2021/05/05 09:12:34 Populating digests for step ID: acb_step_0...\n",
      "2021/05/05 09:12:37 Successfully populated digests for step ID: acb_step_0\n",
      "2021/05/05 09:12:37 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 100.945359)\n",
      "2021/05/05 09:12:37 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.460380)\n",
      "2021/05/05 09:12:37 The following dependencies were found:\n",
      "2021/05/05 09:12:37 \n",
      "- image:\n",
      "    registry: chrjiaeastusc6ba5291.azurecr.io\n",
      "    repository: azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7\n",
      "    tag: latest\n",
      "    digest: sha256:6f746ffb27142b251f5ba5dfd123fb33af73f4411cbbfefaf83764a6b4e72a51\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
      "    tag: 20210301.v1\n",
      "    digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: chrjiaeastusc6ba5291.azurecr.io\n",
      "    repository: azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7\n",
      "    tag: \"1\"\n",
      "    digest: sha256:6f746ffb27142b251f5ba5dfd123fb33af73f4411cbbfefaf83764a6b4e72a51\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
      "    tag: 20210301.v1\n",
      "    digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
      "  git: {}\n",
      "\n",
      "Run ID: wb8 was successful after 4m12s\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_e1f2520e8a691cb15119fcbae8e452b7\n",
      " ---> aa879ae61cb4\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> ffee62f3e9c9\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjEzZTUwODQ1LTY3YmMtNGFjNS05NGRiLTQ4ZDQ5M2E2ZDllOCIsInJlc291cmNlR3JvdXBOYW1lIjoiY2hyamlhLXJnIiwiYWNjb3VudE5hbWUiOiJjaHJqaWEtZWFzdHVzMmV1YXAyIiwid29ya3NwYWNlSWQiOiI1OTkzZGVjMS01OTczLTQ4NTktOGJlMS03MDczMzJjNTQ5NWQifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in e11de941e36b\n",
      " ---> eab658af680a\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpw3ahfiqa.py' /var/azureml-app/main.py\n",
      " ---> Running in 3d08b840170d\n",
      " ---> c571803c03e3\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 945883f140df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---> 8f52b405a142\n",
      "Successfully built 8f52b405a142\n",
      "Successfully tagged myservice:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:e0417420ad39d7bf7012496def9fdfc5684f8654ea28c107277d54b098fb6e5e successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f79356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05T09:45:02,158831200+00:00 - gunicorn/run \n",
      "2021-05-05T09:45:02,159051900+00:00 - rsyslog/run \n",
      "2021-05-05T09:45:02,159105400+00:00 - iot-server/run \n",
      "2021-05-05T09:45:02,161448200+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-05-05T09:45:02,219046900+00:00 - iot-server/finish 1 0\n",
      "2021-05-05T09:45:02,220199100+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 46\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-05-05 09:45:02,786 | root | INFO | Starting up app insights client\n",
      "2021-05-05 09:45:02,786 | root | INFO | Starting up request id generator\n",
      "2021-05-05 09:45:02,786 | root | INFO | Starting up app insight hooks\n",
      "2021-05-05 09:45:02,787 | root | INFO | Invoking user's init function\n",
      "2021-05-05 09:45:22.075775200 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Word_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:45:22.075821800 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Char_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:45:22.075830000 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __OneFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:45:22.075834700 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:45:22.075839500 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:45:22.075844500 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __NegINF_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:45:22.075849500 [W:onnxruntime:, graph.cc:1074 Graph] Initializer _Const_0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:45:22,233 | root | INFO | Users's init has completed successfully\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "2021-05-05 09:45:22,235 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-05-05 09:45:22,235 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-05-05 09:45:22,236 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861af8f",
   "metadata": {},
   "source": [
    "Then ensure you can send a post request to the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0dac0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "uri = service.scoring_uri\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"query\": \"What color is the fox\",\n",
    "    \"context\": \"The quick brown fox jumped over the lazy dog.\",\n",
    "}\n",
    "data = json.dumps(data)\n",
    "response = requests.post(uri, data=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9aab6b",
   "metadata": {},
   "source": [
    "## Re-deploy to cloud\n",
    "\n",
    "Once you've confirmed your service works locally and chosen a remote compute target, you are ready to deploy to the cloud.\n",
    "\n",
    "Change your deploy configuration to correspond to the compute target you've chosen, in this case Azure Container Instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a4ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=0.5, memory_gb=1, auth_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4828de68",
   "metadata": {},
   "source": [
    "Deploy your service again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51029f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-05-05 15:16:18+05:30 Creating Container Registry if not exists.\n",
      "2021-05-05 15:16:18+05:30 Registering the environment.\n",
      "2021-05-05 15:16:19+05:30 Use the existing image.\n",
      "2021-05-05 15:16:19+05:30 Generating deployment configuration.\n",
      "2021-05-05 15:16:20+05:30 Submitting deployment to compute..\n",
      "2021-05-05 15:16:27+05:30 Checking the status of deployment myservice..\n",
      "2021-05-05 15:17:47+05:30 Checking the status of inference endpoint myservice.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d141a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05T09:47:41,597322400+00:00 - iot-server/run \n",
      "2021-05-05T09:47:41,596012800+00:00 - rsyslog/run \n",
      "2021-05-05T09:47:41,598341800+00:00 - gunicorn/run \n",
      "2021-05-05T09:47:41,626792700+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-05-05T09:47:42,223778200+00:00 - iot-server/finish 1 0\n",
      "2021-05-05T09:47:42,234556500+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (65)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 95\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-05-05 09:47:43,727 | root | INFO | Starting up app insights client\n",
      "2021-05-05 09:47:43,731 | root | INFO | Starting up request id generator\n",
      "2021-05-05 09:47:43,731 | root | INFO | Starting up app insight hooks\n",
      "2021-05-05 09:47:43,731 | root | INFO | Invoking user's init function\n",
      "2021-05-05 09:47:44.945542200 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Word_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.945782700 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Char_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.946390000 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __OneFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.948526800 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.948541300 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.948549300 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __NegINF_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.948556600 [W:onnxruntime:, graph.cc:1074 Graph] Initializer _Const_0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:45,397 | root | INFO | Users's init has completed successfully\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "2021-05-05 09:47:45,404 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-05-05 09:47:45,405 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-05-05 09:47:45,406 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-05-05 09:48:20,280 | root | INFO | Swagger file not present\n",
      "2021-05-05 09:48:20,281 | root | INFO | 404\n",
      "127.0.0.1 - - [05/May/2021:09:48:20 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-05-05 09:48:22,078 | root | INFO | Swagger file not present\n",
      "2021-05-05 09:48:22,079 | root | INFO | 404\n",
      "127.0.0.1 - - [05/May/2021:09:48:22 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5448133",
   "metadata": {},
   "source": [
    "## Call your remote webservice\n",
    "\n",
    "When you deploy remotely, you may have key authentication enabled. The example below shows how to get your service key with Python in order to make an inference request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd48987d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"brown\"]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core import Webservice\n",
    "\n",
    "service = Webservice(workspace=ws, name=\"myservice\")\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "key, _ = service.get_keys()\n",
    "\n",
    "# Set the appropriate headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
    "\n",
    "# Make the request and display the response and logs\n",
    "data = {\n",
    "    \"query\": \"What color is the fox\",\n",
    "    \"context\": \"The quick brown fox jumped over the lazy dog.\",\n",
    "}\n",
    "data = json.dumps(data)\n",
    "resp = requests.post(scoring_uri, data=data, headers=headers)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51a6b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05T09:47:41,597322400+00:00 - iot-server/run \n",
      "2021-05-05T09:47:41,596012800+00:00 - rsyslog/run \n",
      "2021-05-05T09:47:41,598341800+00:00 - gunicorn/run \n",
      "2021-05-05T09:47:41,626792700+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_993f5437f30a4b52fb397e48551edac1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-05-05T09:47:42,223778200+00:00 - iot-server/finish 1 0\n",
      "2021-05-05T09:47:42,234556500+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (65)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 95\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-05-05 09:47:43,727 | root | INFO | Starting up app insights client\n",
      "2021-05-05 09:47:43,731 | root | INFO | Starting up request id generator\n",
      "2021-05-05 09:47:43,731 | root | INFO | Starting up app insight hooks\n",
      "2021-05-05 09:47:43,731 | root | INFO | Invoking user's init function\n",
      "2021-05-05 09:47:44.945542200 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Word_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.945782700 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Char_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.946390000 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __OneFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.948526800 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.948541300 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.948549300 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __NegINF_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:44.948556600 [W:onnxruntime:, graph.cc:1074 Graph] Initializer _Const_0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-05 09:47:45,397 | root | INFO | Users's init has completed successfully\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "2021-05-05 09:47:45,404 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-05-05 09:47:45,405 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-05-05 09:47:45,406 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-05-05 09:48:20,280 | root | INFO | Swagger file not present\n",
      "2021-05-05 09:48:20,281 | root | INFO | 404\n",
      "127.0.0.1 - - [05/May/2021:09:48:20 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-05-05 09:48:22,078 | root | INFO | Swagger file not present\n",
      "2021-05-05 09:48:22,079 | root | INFO | 404\n",
      "127.0.0.1 - - [05/May/2021:09:48:22 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-05-05 09:54:32,658 | root | INFO | Swagger file not present\n",
      "2021-05-05 09:54:32,658 | root | INFO | 404\n",
      "127.0.0.1 - - [05/May/2021:09:54:32 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-05-05 09:54:37,461 | root | INFO | Validation Request Content-Type\n",
      "2021-05-05 09:54:37,461 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
      "['brown']\n",
      "2021-05-05 09:54:37,492 | root | INFO | 200\n",
      "127.0.0.1 - - [05/May/2021:09:54:37 +0000] \"POST /score HTTP/1.0\" 200 9 \"-\" \"python-requests/2.25.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ca0cb",
   "metadata": {},
   "source": [
    "## Delete resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a5a03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3af1a4",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f530f08",
   "metadata": {},
   "source": [
    "Try reading [our documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
