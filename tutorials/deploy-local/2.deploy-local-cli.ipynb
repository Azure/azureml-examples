{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd969e25",
   "metadata": {},
   "source": [
    "# Deploy machine learning models to Azure\n",
    "\n",
    "description: (preview) deploy your machine learning or deep learning model as a web service in the Azure cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996082fd",
   "metadata": {},
   "source": [
    "# Connect to your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9f14ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-canadacentral\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-ncus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjiaws-uksouth\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-wus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-cus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-eus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-neurope\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-eus2\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-wus2\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-wcus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-weurope\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-scus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-eastus2euap2\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"mlnotebooksexp\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-cuseuap3\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-cuseuap2\"\r\n",
      "  }\r\n",
      "]\r\n"
     ]
    }
   ],
   "source": [
    "!az login\n",
    "!az account set -s <my subscription>\n",
    "!az ml workspace list --resource-group=<my resource group>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9057aaf6",
   "metadata": {},
   "source": [
    "# Register your model\n",
    "\n",
    "A registered model is a logical container stored in the cloud, containing all files located at `model_path`, which is associated with a version number and other metadata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3cd0e",
   "metadata": {},
   "source": [
    "## Register a model from a local file\n",
    "\n",
    "You can register a model by providing the local path of the model. You can provide the path of either a folder or a single file on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf6e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model bidaf_onnx\n",
      "{\n",
      "  \"cpu\": \"\",\n",
      "  \"createdTime\": \"2021-04-30T13:09:22.148147+00:00\",\n",
      "  \"description\": \"\",\n",
      "  \"experimentName\": \"\",\n",
      "  \"framework\": \"Custom\",\n",
      "  \"frameworkVersion\": null,\n",
      "  \"gpu\": \"\",\n",
      "  \"id\": \"bidaf_onnx:17\",\n",
      "  \"memoryInGB\": \"\",\n",
      "  \"name\": \"bidaf_onnx\",\n",
      "  \"properties\": \"\",\n",
      "  \"runId\": \"\",\n",
      "  \"sampleInputDatasetId\": \"\",\n",
      "  \"sampleOutputDatasetId\": \"\",\n",
      "  \"tags\": \"\",\n",
      "  \"version\": 17\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!wget https://aka.ms/bidaf-9-model -o model.onnx\n",
    "!az ml model register -n bidaf_onnx -p ./model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d34207",
   "metadata": {},
   "source": [
    "## Deploy your machine learning model\n",
    "\n",
    "Replace bidaf_onnx:1 with the name of your model and its version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9762e02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model bidaf_onnx:1 to /tmp/azureml_tol3ow8v/bidaf_onnx/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_7610012a4379937742d36a55b47b6388\n",
      " ---> 79bfd0273b68\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 385ae6b06287\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjEzZTUwODQ1LTY3YmMtNGFjNS05NGRiLTQ4ZDQ5M2E2ZDllOCIsInJlc291cmNlR3JvdXBOYW1lIjoiY2hyamlhLXJnIiwiYWNjb3VudE5hbWUiOiJjaHJqaWEtZWFzdHVzMmV1YXAyIiwid29ya3NwYWNlSWQiOiI1OTkzZGVjMS01OTczLTQ4NTktOGJlMS03MDczMzJjNTQ5NWQifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 4851ff31e314\n",
      " ---> 1afd10d6ba97\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpjzbj1j5e.py' /var/azureml-app/main.py\n",
      " ---> Running in fa6fe4abcaab\n",
      " ---> e97b1aa70ffe\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 827eb966d549\n",
      " ---> 956b799b61ff\n",
      "Successfully built 956b799b61ff\n",
      "Successfully tagged myservice2:latest\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:32267\n",
      "{\n",
      "  \"computeType\": \"Local\",\n",
      "  \"environmentDetails\": null,\n",
      "  \"imageId\": null,\n",
      "  \"name\": \"myservice2\",\n",
      "  \"properties\": \"\",\n",
      "  \"scoringUri\": \"http://localhost:32267/score\",\n",
      "  \"state\": \"running\",\n",
      "  \"tags\": \"\",\n",
      "  \"updatedAt\": \"2021-04-30T18:39:53.697795\"\n",
      "}\n",
      "\u001b[91m{'Azure-cli-ml Version': '1.27.0', 'Error': TypeError(\"get_logs() got an unexpected keyword argument 'init'\",)}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!az ml model deploy -n myservice -m bidaf_onnx:1 --ic inferenceconfig.json --dc deploymentconfig.json\n",
    "!az ml service get-logs -n myservice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d47b4",
   "metadata": {},
   "source": [
    "## Call into your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e92e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 127.0.0.1:32267...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 32267 (#0)\n",
      "> GET / HTTP/1.1\n",
      "> Host: localhost:32267\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> \n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Server: nginx/1.10.3 (Ubuntu)\n",
      "< Date: Fri, 30 Apr 2021 13:14:58 GMT\n",
      "< Content-Type: text/html; charset=utf-8\n",
      "< Content-Length: 7\n",
      "< Connection: keep-alive\n",
      "< x-ms-request-id: 794f9b76-e9fc-4655-9dcc-980017381685\n",
      "< \n",
      "* Connection #0 to host localhost left intact\n",
      "HealthyNote: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 127.0.0.1:32267...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 32267 (#0)\n",
      "> POST /score HTTP/1.1\n",
      "> Host: localhost:32267\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> content-type:application/json\n",
      "> Content-Length: 94\n",
      "> \n",
      "* upload completely sent off: 94 out of 94 bytes\n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Server: nginx/1.10.3 (Ubuntu)\n",
      "< Date: Fri, 30 Apr 2021 13:14:58 GMT\n",
      "< Content-Type: application/json\n",
      "< Content-Length: 104\n",
      "< Connection: keep-alive\n",
      "< x-ms-run-function-failed: False\n",
      "< x-ms-request-id: c34a8768-9e24-4b14-b034-351afbfc3b3f\n",
      "< \n",
      "* Connection #0 to host localhost left intact\n",
      "\"test is {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\""
     ]
    }
   ],
   "source": [
    "!curl -v http://localhost:32267\n",
    "!curl -v -X POST -H \"content-type:application/json\" -d '{\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}' http://localhost:32267/score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9e82c",
   "metadata": {},
   "source": [
    "Notice the use of the AZUREML_MODEL_DIR environment variable to locate your registered model. Now that you've added some pip packages, you also need to update your inference configuration with [new configurations](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=azcli#tabpanel_7_azcli) to add in those additional packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0c387",
   "metadata": {},
   "source": [
    "## Deploy again and call your service\n",
    "\n",
    "Replace `bidaf_onnx:1` with the name of your model and its version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd084966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "{\n",
      "  \"computeType\": \"ACI\",\n",
      "  \"environmentDetails\": {\n",
      "    \"databricks\": {\n",
      "      \"eggLibraries\": [],\n",
      "      \"jarLibraries\": [],\n",
      "      \"mavenLibraries\": [],\n",
      "      \"pypiLibraries\": [],\n",
      "      \"rcranLibraries\": []\n",
      "    },\n",
      "    \"docker\": {\n",
      "      \"arguments\": [],\n",
      "      \"baseDockerfile\": null,\n",
      "      \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
      "      \"baseImageRegistry\": {\n",
      "        \"address\": null,\n",
      "        \"password\": null,\n",
      "        \"registryIdentity\": null,\n",
      "        \"username\": null\n",
      "      },\n",
      "      \"enabled\": false,\n",
      "      \"platform\": {\n",
      "        \"architecture\": \"amd64\",\n",
      "        \"os\": \"Linux\"\n",
      "      },\n",
      "      \"sharedVolumes\": true,\n",
      "      \"shmSize\": null\n",
      "    },\n",
      "    \"environmentVariables\": {\n",
      "      \"AZUREML_ENTRY_SCRIPT\": \"source_dir/echo_score.py\",\n",
      "      \"AZUREML_SOURCE_DIRECTORY\": \"source_dir\",\n",
      "      \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
      "    },\n",
      "    \"inferencingStackVersion\": null,\n",
      "    \"name\": \"my-deploy-env\",\n",
      "    \"python\": {\n",
      "      \"baseCondaEnvironment\": null,\n",
      "      \"condaDependencies\": {\n",
      "        \"channels\": [],\n",
      "        \"dependencies\": [\n",
      "          \"python=3.6.2\",\n",
      "          {\n",
      "            \"pip\": [\n",
      "              \"azureml-defaults\"\n",
      "            ]\n",
      "          }\n",
      "        ],\n",
      "        \"name\": \"azureml_4b37c633d9634b4aa1fd2bd743dc4a42\"\n",
      "      },\n",
      "      \"condaDependenciesFile\": null,\n",
      "      \"interpreterPath\": \"python\",\n",
      "      \"userManagedDependencies\": false\n",
      "    },\n",
      "    \"r\": null,\n",
      "    \"spark\": {\n",
      "      \"packages\": [],\n",
      "      \"precachePackages\": true,\n",
      "      \"repositories\": []\n",
      "    },\n",
      "    \"version\": \"1\"\n",
      "  },\n",
      "  \"imageId\": null,\n",
      "  \"name\": \"myservice5\",\n",
      "  \"properties\": {\n",
      "    \"azureml.git.branch\": \"deployLocalSamples\",\n",
      "    \"azureml.git.commit\": \"d1b15a65922839080429f237842fb6c7f0341278\",\n",
      "    \"azureml.git.dirty\": \"True\",\n",
      "    \"azureml.git.repository_uri\": \"https://github.com/HiteshTetarwal/azureml-examples.git\",\n",
      "    \"hasHttps\": \"False\",\n",
      "    \"hasInferenceSchema\": \"False\",\n",
      "    \"mlflow.source.git.branch\": \"deployLocalSamples\",\n",
      "    \"mlflow.source.git.commit\": \"d1b15a65922839080429f237842fb6c7f0341278\",\n",
      "    \"mlflow.source.git.repoURL\": \"https://github.com/HiteshTetarwal/azureml-examples.git\"\n",
      "  },\n",
      "  \"scoringUri\": \"http://8e1951f7-ad25-4dd0-bed5-4050f0e71cdd.eastus2.azurecontainer.io/score\",\n",
      "  \"state\": \"Healthy\",\n",
      "  \"tags\": \"\",\n",
      "  \"updatedAt\": \"2021-04-30T13:30:14.145635+00:00\"\n",
      "}\n",
      "[\n",
      "  \"2021-04-30T13:32:55,658385200+00:00 - gunicorn/run \\n2021-04-30T13:32:55,657223700+00:00 - iot-server/run \\n2021-04-30T13:32:55,662486800+00:00 - rsyslog/run \\n2021-04-30T13:32:55,761862900+00:00 - nginx/run \\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2021-04-30T13:32:56,190817200+00:00 - iot-server/finish 1 0\\n2021-04-30T13:32:56,228127700+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (67)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 92\\nInitialized PySpark session.\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user's init function\\nThis is init\\nUsers's init has completed successfully\\nScoring timeout is found from os.environ: 60000 ms\\nSwagger file not present\\n404\\n127.0.0.1 - - [30/Apr/2021:13:33:04 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [30/Apr/2021:13:33:06 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [30/Apr/2021:13:33:11 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\n\",\n",
      "  null\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!az ml model deploy -n myservice_redeploy -m bidaf_onnx:1 --ic inferenceconfig.json --dc re-deploymentconfig.json\n",
    "!az ml service get-logs -n myservice_redeploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861af8f",
   "metadata": {},
   "source": [
    "Then ensure you can send a post request to the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0dac0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\r\n",
      "*   Trying 127.0.0.1:32267...\r\n",
      "* TCP_NODELAY set\r\n",
      "* Connected to localhost (127.0.0.1) port 32267 (#0)\r\n",
      "> POST /score HTTP/1.1\r",
      "\r\n",
      "> Host: localhost:32267\r",
      "\r\n",
      "> User-Agent: curl/7.68.0\r",
      "\r\n",
      "> Accept: */*\r",
      "\r\n",
      "> content-type:application/json\r",
      "\r\n",
      "> Content-Length: 94\r",
      "\r\n",
      "> \r",
      "\r\n",
      "* upload completely sent off: 94 out of 94 bytes\r\n",
      "* Mark bundle as not supporting multiuse\r\n",
      "< HTTP/1.1 200 OK\r",
      "\r\n",
      "< Server: nginx/1.10.3 (Ubuntu)\r",
      "\r\n",
      "< Date: Fri, 30 Apr 2021 13:37:04 GMT\r",
      "\r\n",
      "< Content-Type: application/json\r",
      "\r\n",
      "< Content-Length: 104\r",
      "\r\n",
      "< Connection: keep-alive\r",
      "\r\n",
      "< x-ms-run-function-failed: False\r",
      "\r\n",
      "< x-ms-request-id: 087ea36b-6951-42e8-8fd3-435ae4bc720f\r",
      "\r\n",
      "< \r",
      "\r\n",
      "* Connection #0 to host localhost left intact\r\n",
      "\"test is {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\""
     ]
    }
   ],
   "source": [
    "!curl -v -X POST -H \"content-type:application/json\" -d '{\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}' http://localhost:32267/score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9aab6b",
   "metadata": {},
   "source": [
    "## Re-deploy to cloud\n",
    "\n",
    "Once you've confirmed your service works locally and chosen a remote compute target, you are ready to deploy to the cloud.\n",
    "Change your re-deploy configuration to correspond to the compute target you've chosen, in this case Azure Container Instances.\n",
    "\n",
    "Deploy your service again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51029f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "{\n",
      "  \"computeType\": \"ACI\",\n",
      "  \"environmentDetails\": {\n",
      "    \"databricks\": {\n",
      "      \"eggLibraries\": [],\n",
      "      \"jarLibraries\": [],\n",
      "      \"mavenLibraries\": [],\n",
      "      \"pypiLibraries\": [],\n",
      "      \"rcranLibraries\": []\n",
      "    },\n",
      "    \"docker\": {\n",
      "      \"arguments\": [],\n",
      "      \"baseDockerfile\": null,\n",
      "      \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
      "      \"baseImageRegistry\": {\n",
      "        \"address\": null,\n",
      "        \"password\": null,\n",
      "        \"registryIdentity\": null,\n",
      "        \"username\": null\n",
      "      },\n",
      "      \"enabled\": false,\n",
      "      \"platform\": {\n",
      "        \"architecture\": \"amd64\",\n",
      "        \"os\": \"Linux\"\n",
      "      },\n",
      "      \"sharedVolumes\": true,\n",
      "      \"shmSize\": null\n",
      "    },\n",
      "    \"environmentVariables\": {\n",
      "      \"AZUREML_ENTRY_SCRIPT\": \"source_dir/echo_score.py\",\n",
      "      \"AZUREML_SOURCE_DIRECTORY\": \"source_dir\",\n",
      "      \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
      "    },\n",
      "    \"inferencingStackVersion\": null,\n",
      "    \"name\": \"my-deploy-env\",\n",
      "    \"python\": {\n",
      "      \"baseCondaEnvironment\": null,\n",
      "      \"condaDependencies\": {\n",
      "        \"channels\": [],\n",
      "        \"dependencies\": [\n",
      "          \"python=3.6.2\",\n",
      "          {\n",
      "            \"pip\": [\n",
      "              \"azureml-defaults\"\n",
      "            ]\n",
      "          }\n",
      "        ],\n",
      "        \"name\": \"azureml_4b37c633d9634b4aa1fd2bd743dc4a42\"\n",
      "      },\n",
      "      \"condaDependenciesFile\": null,\n",
      "      \"interpreterPath\": \"python\",\n",
      "      \"userManagedDependencies\": false\n",
      "    },\n",
      "    \"r\": null,\n",
      "    \"spark\": {\n",
      "      \"packages\": [],\n",
      "      \"precachePackages\": true,\n",
      "      \"repositories\": []\n",
      "    },\n",
      "    \"version\": \"1\"\n",
      "  },\n",
      "  \"imageId\": null,\n",
      "  \"name\": \"testservice3\",\n",
      "  \"properties\": {\n",
      "    \"azureml.git.branch\": \"deployLocalSamples\",\n",
      "    \"azureml.git.commit\": \"d1b15a65922839080429f237842fb6c7f0341278\",\n",
      "    \"azureml.git.dirty\": \"True\",\n",
      "    \"azureml.git.repository_uri\": \"https://github.com/HiteshTetarwal/azureml-examples.git\",\n",
      "    \"hasHttps\": \"False\",\n",
      "    \"hasInferenceSchema\": \"False\",\n",
      "    \"mlflow.source.git.branch\": \"deployLocalSamples\",\n",
      "    \"mlflow.source.git.commit\": \"d1b15a65922839080429f237842fb6c7f0341278\",\n",
      "    \"mlflow.source.git.repoURL\": \"https://github.com/HiteshTetarwal/azureml-examples.git\"\n",
      "  },\n",
      "  \"scoringUri\": \"http://df284e09-6cce-40a8-8589-a7b2cef9b594.eastus2.azurecontainer.io/score\",\n",
      "  \"state\": \"Healthy\",\n",
      "  \"tags\": \"\",\n",
      "  \"updatedAt\": \"2021-04-30T13:37:22.721105+00:00\"\n",
      "}\n",
      "[\n",
      "  \"2021-04-30T13:39:36,471832300+00:00 - gunicorn/run \\n2021-04-30T13:39:36,485717300+00:00 - rsyslog/run \\n2021-04-30T13:39:36,484683000+00:00 - nginx/run \\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n2021-04-30T13:39:36,486742900+00:00 - iot-server/run \\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2021-04-30T13:39:36,954474600+00:00 - iot-server/finish 1 0\\n2021-04-30T13:39:36,961829700+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (65)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 90\\nInitialized PySpark session.\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user's init function\\nThis is init\\nUsers's init has completed successfully\\nScoring timeout is found from os.environ: 60000 ms\\nSwagger file not present\\n404\\n127.0.0.1 - - [30/Apr/2021:13:39:45 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [30/Apr/2021:13:39:48 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [30/Apr/2021:13:39:54 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\n\",\n",
      "  null\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!az ml model deploy -n myservice -m bidaf_onnx:1 --ic inferenceconfig.json --dc re-deploymentconfig.json\n",
    "!az ml service get-logs -n myservice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5448133",
   "metadata": {},
   "source": [
    "## Call your remote webservice\n",
    "\n",
    "When you deploy remotely, you may have key authentication enabled. The example below shows how to get your service key with Python in order to make an inference request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd48987d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"test is {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core import Webservice, Workspace\n",
    "\n",
    "ws = Workspace(subscription_id=\"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\n",
    "               resource_group=\"chrjia-rg\",\n",
    "               workspace_name=\"chrjia-eastus2euap2\")\n",
    "\n",
    "service = Webservice(workspace=ws, name='myservice')\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "key, _ = service.get_keys()\n",
    "\n",
    "# Set the appropriate headers\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response and logs\n",
    "data = {\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
    "data = json.dumps(data)\n",
    "resp = requests.post(scoring_uri, data=data, headers=headers)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a6b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-30T13:39:36,471832300+00:00 - gunicorn/run \n",
      "2021-04-30T13:39:36,485717300+00:00 - rsyslog/run \n",
      "2021-04-30T13:39:36,484683000+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2021-04-30T13:39:36,486742900+00:00 - iot-server/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b37c633d9634b4aa1fd2bd743dc4a42/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-04-30T13:39:36,954474600+00:00 - iot-server/finish 1 0\n",
      "2021-04-30T13:39:36,961829700+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (65)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 90\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "This is init\n",
      "Users's init has completed successfully\n",
      "Scoring timeout is found from os.environ: 60000 ms\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [30/Apr/2021:13:39:45 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [30/Apr/2021:13:39:48 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [30/Apr/2021:13:39:54 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [30/Apr/2021:13:40:11 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [30/Apr/2021:13:40:21 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Validation Request Content-Type\n",
      "Received input: {\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
      "Headers passed in (total 12):\n",
      "\tHost: localhost:5001\n",
      "\tX-Real-Ip: 127.0.0.1\n",
      "\tX-Forwarded-For: 127.0.0.1\n",
      "\tX-Forwarded-Proto: http\n",
      "\tConnection: close\n",
      "\tContent-Length: 94\n",
      "\tUser-Agent: python-requests/2.25.1\n",
      "\tAccept: */*\n",
      "\tAccept-Encoding: gzip, deflate\n",
      "\tAuthorization: Bearer rSd2Jru5iVaha5UU8T0vlFC3EHKT0jaj\n",
      "\tContent-Type: application/json\n",
      "\tX-Ms-Request-Id: 660bd4e8-8a20-487b-b109-3287e8883752\n",
      "Scoring Timer is set to 60.0 seconds\n",
      "received data {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\n",
      "200\n",
      "127.0.0.1 - - [30/Apr/2021:13:40:22 +0000] \"POST /score HTTP/1.0\" 200 104 \"-\" \"python-requests/2.25.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ca0cb",
   "metadata": {},
   "source": [
    "## Delete resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a5a03fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"bidaf_onnx:17\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az ml service delete -n myservice\n",
    "!az ml model delete bidaf_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3af1a4",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f530f08",
   "metadata": {},
   "source": [
    "Try reading [our documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
