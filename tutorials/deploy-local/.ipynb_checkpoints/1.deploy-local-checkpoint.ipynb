{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd969e25",
   "metadata": {},
   "source": [
    "# Deploy machine learning models to Azure\n",
    "\n",
    "description: (preview) deploy your machine learning or deep learning model as a web service in the Azure cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996082fd",
   "metadata": {},
   "source": [
    "# Connect to your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9f14ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='chrjia-eastus2euap2', subscription_id='13e50845-67bc-4ac5-94db-48d493a6d9e8', resource_group='chrjia-rg')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9057aaf6",
   "metadata": {},
   "source": [
    "# Register your model\n",
    "\n",
    "A registered model is a logical container stored in the cloud, containing all files located at `model_path`, which is associated with a version number and other metadata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3cd0e",
   "metadata": {},
   "source": [
    "## Register a model from a local file\n",
    "\n",
    "You can register a model by providing the local path of the model. You can provide the path of either a folder or a single file on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf6e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model bidaf_onnx\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from azureml.core.model import Model\n",
    "# Download model\n",
    "urllib.request.urlretrieve(\"https://aka.ms/bidaf-9-model\", 'model.onnx')\n",
    "\n",
    "# Register model\n",
    "model = Model.register(ws, model_name='bidaf_onnx', model_path='./model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc200fe9",
   "metadata": {},
   "source": [
    "# Define an inference configuration\n",
    "\n",
    "The inference configuration below specifies that the machine learning deployment will use the file echo_score.py in the ./source_dir directory to process incoming requests and that it will use the Docker image with the Python packages specified in the project_environment environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e5efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment(name='project_environment')\n",
    "inference_config = InferenceConfig(environment=env, source_directory='./source_dir', entry_script='./echo_score.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850e5f4",
   "metadata": {},
   "source": [
    "## Define a deployment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a6fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d34207",
   "metadata": {},
   "source": [
    "## Deploy your machine learning model\n",
    "\n",
    "A deployment configuration specifies the amount of memory and cores to reserve for your webservice will require in order to run, as well as configuration details of the underlying webservice. For example, a deployment configuration lets you specify that your service needs 2 gigabytes of memory, 2 CPU cores, 1 GPU core, and that you want to enable autoscaling.\n",
    "\n",
    "The options available for a deployment configuration differ depending on the compute target you choose. In a local deployment, all you can specify is which port your webservice will be served on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9762e02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelNotFound: Model with id bidaf_onnx:14 not found in provided workspace\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model bidaf_onnx:16 to /tmp/azureml__9jaobbc/bidaf_onnx/16\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_673d52b5abe224c83574bc767a17fa28\n",
      " ---> 0884414da052\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> debfdd287ac0\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjEzZTUwODQ1LTY3YmMtNGFjNS05NGRiLTQ4ZDQ5M2E2ZDllOCIsInJlc291cmNlR3JvdXBOYW1lIjoiY2hyamlhLXJnIiwiYWNjb3VudE5hbWUiOiJjaHJqaWEtZWFzdHVzMmV1YXAyIiwid29ya3NwYWNlSWQiOiI1OTkzZGVjMS01OTczLTQ4NTktOGJlMS03MDczMzJjNTQ5NWQifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in e092a63d1b2d\n",
      " ---> d6883fbeadd8\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmp67_pkw3d.py' /var/azureml-app/main.py\n",
      " ---> Running in 6dee06319cbb\n",
      " ---> 10994c7c94b9\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 8b5264d7742a\n",
      " ---> 5dd57e41e92f\n",
      "Successfully built 5dd57e41e92f\n",
      "Successfully tagged myservice:latest\n",
      "Container (name:zen_zhukovsky, id:3fe039a24fad8e1f7e08e670d0117974f5509e9fb0e8568fb3c9dd935972cba1) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:fa711db8b7a72a689ea04304e6642560cfd239f89e0b03ca195eb14ab5e3e744 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede851f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-30T12:53:00,348883000+00:00 - gunicorn/run \n",
      "2021-04-30T12:53:00,348822500+00:00 - rsyslog/run \n",
      "2021-04-30T12:53:00,348882800+00:00 - iot-server/run \n",
      "2021-04-30T12:53:00,348847400+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-04-30T12:53:00,521129700+00:00 - iot-server/finish 1 0\n",
      "2021-04-30T12:53:00,522075700+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (14)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 46\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-04-30 12:53:00,886 | root | INFO | Starting up app insights client\n",
      "2021-04-30 12:53:00,887 | root | INFO | Starting up request id generator\n",
      "2021-04-30 12:53:00,887 | root | INFO | Starting up app insight hooks\n",
      "2021-04-30 12:53:00,887 | root | INFO | Invoking user's init function\n",
      "This is init\n",
      "2021-04-30 12:53:00,887 | root | INFO | Users's init has completed successfully\n",
      "2021-04-30 12:53:00,890 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-04-30 12:53:00,890 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-04-30 12:53:00,890 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d47b4",
   "metadata": {},
   "source": [
    "## Call into your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e92e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test is {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "requests.get('http://localhost:6789')\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
    "data = json.dumps(data)\n",
    "response = requests.post(uri, data=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9e82c",
   "metadata": {},
   "source": [
    "Notice the use of the AZUREML_MODEL_DIR environment variable to locate your registered model. Now that you've added some pip packages, you also need to update your inference configuration to add in those additional packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b9d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(name='myenv')\n",
    "python_packages = ['nltk', 'numpy', 'onnxruntime']\n",
    "for package in python_packages:\n",
    "    env.python.conda_dependencies.add_pip_package(package)\n",
    "\n",
    "inf_config = InferenceConfig(environment=env, source_directory='./source_dir', entry_script='./score.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0c387",
   "metadata": {},
   "source": [
    "## Deploy again and call your service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd084966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model bidaf_onnx:16 to /tmp/azureml_agri1xl0/bidaf_onnx/16\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_673d52b5abe224c83574bc767a17fa28\n",
      " ---> 0884414da052\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 6ac5a662619a\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjEzZTUwODQ1LTY3YmMtNGFjNS05NGRiLTQ4ZDQ5M2E2ZDllOCIsInJlc291cmNlR3JvdXBOYW1lIjoiY2hyamlhLXJnIiwiYWNjb3VudE5hbWUiOiJjaHJqaWEtZWFzdHVzMmV1YXAyIiwid29ya3NwYWNlSWQiOiI1OTkzZGVjMS01OTczLTQ4NTktOGJlMS03MDczMzJjNTQ5NWQifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in d6d7f4ac3c32\n",
      " ---> 4f3ab2e502bc\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmp9losnro_.py' /var/azureml-app/main.py\n",
      " ---> Running in 146dfe834545\n",
      " ---> 851e8cab14b3\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 4f89b79ff9ba\n",
      " ---> 116dc62679cd\n",
      "Successfully built 116dc62679cd\n",
      "Successfully tagged myservice:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:5dd57e41e92f5b1bb6777d331ebfa188361c581b7435fc70ec398e240c1ad423 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f79356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-30T12:58:05,078164200+00:00 - iot-server/run \n",
      "2021-04-30T12:58:05,078539600+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2021-04-30T12:58:05,079400900+00:00 - gunicorn/run \n",
      "2021-04-30T12:58:05,084895700+00:00 - rsyslog/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-04-30T12:58:05,147401600+00:00 - iot-server/finish 1 0\n",
      "2021-04-30T12:58:05,148716100+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (14)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 47\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-04-30 12:58:05,430 | root | INFO | Starting up app insights client\n",
      "2021-04-30 12:58:05,432 | root | INFO | Starting up request id generator\n",
      "2021-04-30 12:58:05,432 | root | INFO | Starting up app insight hooks\n",
      "2021-04-30 12:58:05,432 | root | INFO | Invoking user's init function\n",
      "This is init\n",
      "2021-04-30 12:58:05,432 | root | INFO | Users's init has completed successfully\n",
      "2021-04-30 12:58:05,434 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-04-30 12:58:05,434 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-04-30 12:58:05,435 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861af8f",
   "metadata": {},
   "source": [
    "Then ensure you can send a post request to the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0dac0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test is {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "uri = service.scoring_uri\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
    "data = json.dumps(data)\n",
    "response = requests.post(uri, data=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9aab6b",
   "metadata": {},
   "source": [
    "## Re-deploy to cloud\n",
    "\n",
    "Once you've confirmed your service works locally and chosen a remote compute target, you are ready to deploy to the cloud.\n",
    "\n",
    "Change your deploy configuration to correspond to the compute target you've chosen, in this case Azure Container Instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a4ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 0.5, memory_gb = 1, auth_enabled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4828de68",
   "metadata": {},
   "source": [
    "Deploy your service again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51029f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-04-30 18:30:38+05:30 Creating Container Registry if not exists.\n",
      "2021-04-30 18:30:39+05:30 Registering the environment.\n",
      "2021-04-30 18:30:40+05:30 Use the existing image.\n",
      "2021-04-30 18:30:40+05:30 Generating deployment configuration.\n",
      "2021-04-30 18:30:42+05:30 Submitting deployment to compute..\n",
      "2021-04-30 18:31:30+05:30 Checking the status of deployment testservice1..\n",
      "2021-04-30 18:32:53+05:30 Checking the status of inference endpoint testservice1.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d141a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-30T13:02:51,581997500+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2021-04-30T13:02:51,584386300+00:00 - gunicorn/run \n",
      "2021-04-30T13:02:51,607040800+00:00 - iot-server/run \n",
      "2021-04-30T13:02:51,616880500+00:00 - rsyslog/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-04-30T13:02:52,028326300+00:00 - iot-server/finish 1 0\n",
      "2021-04-30T13:02:52,029585600+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (62)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 90\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-04-30 13:02:52,651 | root | INFO | Starting up app insights client\n",
      "2021-04-30 13:02:52,651 | root | INFO | Starting up request id generator\n",
      "2021-04-30 13:02:52,652 | root | INFO | Starting up app insight hooks\n",
      "2021-04-30 13:02:52,652 | root | INFO | Invoking user's init function\n",
      "This is init\n",
      "2021-04-30 13:02:52,653 | root | INFO | Users's init has completed successfully\n",
      "2021-04-30 13:02:52,690 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-04-30 13:02:52,690 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-04-30 13:02:52,691 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-04-30 13:02:58,192 | root | INFO | Swagger file not present\n",
      "2021-04-30 13:02:58,192 | root | INFO | 404\n",
      "127.0.0.1 - - [30/Apr/2021:13:02:58 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-04-30 13:03:04,236 | root | INFO | Swagger file not present\n",
      "2021-04-30 13:03:04,237 | root | INFO | 404\n",
      "127.0.0.1 - - [30/Apr/2021:13:03:04 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5448133",
   "metadata": {},
   "source": [
    "## Call your remote webservice\n",
    "\n",
    "When you deploy remotely, you may have key authentication enabled. The example below shows how to get your service key with Python in order to make an inference request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd48987d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"test is {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core import Webservice\n",
    "\n",
    "service = Webservice(workspace=ws, name='myservice')\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "key, _ = service.get_keys()\n",
    "\n",
    "# Set the appropriate headers\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response and logs\n",
    "data = {\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
    "data = json.dumps(data)\n",
    "resp = requests.post(scoring_uri, data=data, headers=headers)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51a6b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-30T13:02:51,581997500+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2021-04-30T13:02:51,584386300+00:00 - gunicorn/run \n",
      "2021-04-30T13:02:51,607040800+00:00 - iot-server/run \n",
      "2021-04-30T13:02:51,616880500+00:00 - rsyslog/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-04-30T13:02:52,028326300+00:00 - iot-server/finish 1 0\n",
      "2021-04-30T13:02:52,029585600+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (62)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 90\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-04-30 13:02:52,651 | root | INFO | Starting up app insights client\n",
      "2021-04-30 13:02:52,651 | root | INFO | Starting up request id generator\n",
      "2021-04-30 13:02:52,652 | root | INFO | Starting up app insight hooks\n",
      "2021-04-30 13:02:52,652 | root | INFO | Invoking user's init function\n",
      "This is init\n",
      "2021-04-30 13:02:52,653 | root | INFO | Users's init has completed successfully\n",
      "2021-04-30 13:02:52,690 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-04-30 13:02:52,690 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-04-30 13:02:52,691 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-04-30 13:02:58,192 | root | INFO | Swagger file not present\n",
      "2021-04-30 13:02:58,192 | root | INFO | 404\n",
      "127.0.0.1 - - [30/Apr/2021:13:02:58 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-04-30 13:03:04,236 | root | INFO | Swagger file not present\n",
      "2021-04-30 13:03:04,237 | root | INFO | 404\n",
      "127.0.0.1 - - [30/Apr/2021:13:03:04 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-04-30 13:03:14,115 | root | INFO | Swagger file not present\n",
      "2021-04-30 13:03:14,116 | root | INFO | 404\n",
      "127.0.0.1 - - [30/Apr/2021:13:03:14 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-04-30 13:03:25,488 | root | INFO | Validation Request Content-Type\n",
      "2021-04-30 13:03:25,488 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "received data {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\n",
      "2021-04-30 13:03:25,490 | root | INFO | 200\n",
      "127.0.0.1 - - [30/Apr/2021:13:03:25 +0000] \"POST /score HTTP/1.0\" 200 104 \"-\" \"python-requests/2.25.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ca0cb",
   "metadata": {},
   "source": [
    "## Delete resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a5a03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3af1a4",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f530f08",
   "metadata": {},
   "source": [
    "Try reading [our documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
