{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd969e25",
   "metadata": {},
   "source": [
    "# Deploy machine learning models to Azure\n",
    "\n",
    "description: (preview) deploy your machine learning or deep learning model as a web service in the Azure cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996082fd",
   "metadata": {},
   "source": [
    "# Connect to your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9f14ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-canadacentral\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-ncus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjiaws-uksouth\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-wus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-cus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-eus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-neurope\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-eus2\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-wus2\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-wcus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-weurope\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-scus\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-eastus2euap2\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"mlnotebooksexp\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-cuseuap3\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"resourceGroup\": \"chrjia-rg\",\r\n",
      "    \"subscriptionId\": \"13e50845-67bc-4ac5-94db-48d493a6d9e8\",\r\n",
      "    \"workspaceName\": \"chrjia-cuseuap2\"\r\n",
      "  }\r\n",
      "]\r\n"
     ]
    }
   ],
   "source": [
    "!az login\n",
    "!az account set -s 13e50845-67bc-4ac5-94db-48d493a6d9e8\n",
    "!az ml workspace list --resource-group=chrjia-rg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9057aaf6",
   "metadata": {},
   "source": [
    "# Register your model\n",
    "\n",
    "A registered model is a logical container stored in the cloud, containing all files located at `model_path`, which is associated with a version number and other metadata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3cd0e",
   "metadata": {},
   "source": [
    "## Register a model from a local file\n",
    "\n",
    "You can register a model by providing the local path of the model. You can provide the path of either a folder or a single file on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf6e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model bidaf_onnx\n",
      "{\n",
      "  \"cpu\": \"\",\n",
      "  \"createdTime\": \"2021-05-03T11:01:45.177024+00:00\",\n",
      "  \"description\": \"\",\n",
      "  \"experimentName\": \"\",\n",
      "  \"framework\": \"Custom\",\n",
      "  \"frameworkVersion\": null,\n",
      "  \"gpu\": \"\",\n",
      "  \"id\": \"bidaf_onnx:22\",\n",
      "  \"memoryInGB\": \"\",\n",
      "  \"name\": \"bidaf_onnx\",\n",
      "  \"properties\": \"\",\n",
      "  \"runId\": \"\",\n",
      "  \"sampleInputDatasetId\": \"\",\n",
      "  \"sampleOutputDatasetId\": \"\",\n",
      "  \"tags\": \"\",\n",
      "  \"version\": 22\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!wget https://aka.ms/bidaf-9-model -o model.onnx\n",
    "!az ml model register -n bidaf_onnx -p ./model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d34207",
   "metadata": {},
   "source": [
    "## Deploy your machine learning model\n",
    "\n",
    "Replace bidaf_onnx:1 with the name of your model and its version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9762e02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model bidaf_onnx:1 to /tmp/azureml_xbl32_fi/bidaf_onnx/1\n",
      "Generating Docker build context.\n",
      "2021/05/03 11:08:12 Downloading source code...\n",
      "2021/05/03 11:08:14 Finished downloading source code\n",
      "2021/05/03 11:08:14 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/05/03 11:08:15 Successfully set up Docker network: acb_default_network\n",
      "2021/05/03 11:08:15 Setting up Docker configuration...\n",
      "2021/05/03 11:08:16 Successfully set up Docker configuration\n",
      "2021/05/03 11:08:16 Logging in to registry: chrjiaeastusc6ba5291.azurecr.io\n",
      "2021/05/03 11:08:22 Successfully logged into chrjiaeastusc6ba5291.azurecr.io\n",
      "2021/05/03 11:08:22 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/05/03 11:08:22 Scanning for dependencies...\n",
      "2021/05/03 11:08:22 Successfully scanned dependencies\n",
      "2021/05/03 11:08:22 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "Step 1/18 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "8269c605f3f1: Waiting\n",
      "6504d449e70c: Waiting\n",
      "4e38f320d0d4: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "11917a028ca4: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "6cc007ad9140: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "8269c605f3f1: Download complete\n",
      "9b0d3db6dc03: Verifying Checksum\n",
      "9b0d3db6dc03: Download complete\n",
      "a1298f4ce990: Verifying Checksum\n",
      "a1298f4ce990: Download complete\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "6504d449e70c: Retrying in 5 seconds\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "6504d449e70c: Retrying in 4 seconds\n",
      "6c1698a608f3: Verifying Checksum\n",
      "6c1698a608f3: Download complete\n",
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "6504d449e70c: Retrying in 3 seconds\n",
      "6504d449e70c: Retrying in 2 seconds\n",
      "a1298f4ce990: Pull complete\n",
      "04a3282d9c4b: Pull complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "6504d449e70c: Retrying in 1 second\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "Digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      " ---> 93a72e6bd1ce\n",
      "Step 2/18 : USER root\n",
      " ---> Running in 4d4cca157442\n",
      "Removing intermediate container 4d4cca157442\n",
      " ---> 85ea7f74ded2\n",
      "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 425ac3efdab2\n",
      "Removing intermediate container 425ac3efdab2\n",
      " ---> fe78af62b895\n",
      "Step 4/18 : WORKDIR /\n",
      " ---> Running in 37f2904b9d07\n",
      "Removing intermediate container 37f2904b9d07\n",
      " ---> 555649fddc6a\n",
      "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 8227dd12bbec\n",
      "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 252cb4362ac1\n",
      "Removing intermediate container 252cb4362ac1\n",
      " ---> 9a522f27f531\n",
      "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> a9fb4d1eb974\n",
      "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in e0bbfe6fb4a3\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.10.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "pip-21.0.1           | 2.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "ca-certificates-2021 | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 1.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "setuptools-52.0.0    | 933 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "wheel-0.36.2         | 31 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "certifi-2020.12.5    | 144 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.27.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.7.0-cp36-cp36m-manylinux2014_x86_64.whl (4.1 MB)\n",
      "Collecting azureml-core~=1.27.0\n",
      "  Downloading azureml_core-1.27.0-py3-none-any.whl (2.2 MB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.27.0\n",
      "  Downloading azureml_dataset_runtime-1.27.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting pandas>=0.20.2\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Collecting python-dateutil>=2.5.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting six>=1.10\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting adal>=0.4.5\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting PyJWT<3,>=1.0.0\n",
      "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
      "Collecting cryptography>=1.1.0\n",
      "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-12.1.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting jmespath<1.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting contextlib2<1.0.0\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting docker<5.0.0\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting ruamel.yaml<1.0.0,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting pyopenssl<21.0.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting azureml-dataprep<2.15.0a,>=2.14.0a\n",
      "  Downloading azureml_dataprep-2.14.2-py3-none-any.whl (39.4 MB)\n",
      "Collecting pyarrow<2.0.0,>=0.17.0\n",
      "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azureml-dataprep-rslex<1.13.0a,>=1.12.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.12.1-cp36-cp36m-manylinux1_x86_64.whl (9.6 MB)\n",
      "Collecting azureml-dataprep-native<34.0.0,>=33.0.0\n",
      "  Downloading azureml_dataprep_native-33.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.11.0-py2.py3-none-any.whl (63 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.13.0-py2.py3-none-any.whl (133 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux2010_x86_64.whl (32 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/python3.6/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.27.0->azureml-defaults->-r /azureml-environment-setup/condaenv.8oehewl8.requirements.txt (line 1)) (2020.12.5)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
      "Collecting regex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading regex-2021.4.4-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.15.8-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, liac-arff\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=e81fce9c20b8ad8776e9da1402bea95be3fc4d1288c5d45efa6013cba64c41cc\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10502 sha256=47214e5f47a8b6ebb6d5df66557062613aaf48255b40507ca9dab10cee571c23\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=b380ea38ede795c7c8b1aa9a44bcd2de56aacb68601ea27b8f893f6f72f6b7ff\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "Successfully built json-logging-py fusepy liac-arff\n",
      "Installing collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, chardet, requests, six, portalocker, oauthlib, msal, requests-oauthlib, python-dateutil, msal-extensions, isodate, distro, azure-core, zipp, typing-extensions, numpy, msrest, dotnetcore2, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, websocket-client, ruamel.yaml.clib, pytz, pyopenssl, pyasn1, pyarrow, msrestazure, MarkupSafe, jeepney, importlib-metadata, backports.weakref, azureml-dataprep, azure-common, werkzeug, SecretStorage, ruamel.yaml, pathspec, pandas, ndg-httpsclient, liac-arff, jsonpickle, jmespath, Jinja2, itsdangerous, fusepy, docker, dill, contextlib2, click, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, tqdm, regex, protobuf, json-logging-py, joblib, gunicorn, flask, configparser, azureml-model-management-sdk, azureml-core, applicationinsights, onnxruntime, nltk, azureml-defaults\n",
      "\n",
      "Successfully installed Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-2.1.0 SecretStorage-3.3.1 adal-1.2.7 applicationinsights-0.11.10 azure-common-1.1.27 azure-core-1.13.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.1.0 azure-mgmt-storage-11.2.0 azureml-core-1.27.0 azureml-dataprep-2.14.2 azureml-dataprep-native-33.0.0 azureml-dataprep-rslex-1.12.1 azureml-dataset-runtime-1.27.0 azureml-defaults-1.27.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.5 chardet-4.0.0 click-7.1.2 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.4.7 dill-0.3.3 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.20 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-4.0.1 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.6.0 jmespath-0.10.0 joblib-1.0.1 json-logging-py-0.2 jsonpickle-2.0.0 liac-arff-2.5.0 msal-1.11.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 nltk-3.6.2 numpy-1.19.5 oauthlib-3.1.0 onnxruntime-1.7.0 pandas-1.1.5 pathspec-0.8.1 portalocker-1.7.1 protobuf-3.15.8 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 python-dateutil-2.8.1 pytz-2021.1 regex-2021.4.4 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 six-1.15.0 tqdm-4.60.0 typing-extensions-3.10.0.0 urllib3-1.26.4 websocket-client-0.58.0 werkzeug-1.0.1 zipp-3.4.1\n",
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "\n",
      "Removing intermediate container e0bbfe6fb4a3\n",
      " ---> 453ec97fb4ac\n",
      "Step 9/18 : ENV PATH /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/bin:$PATH\n",
      " ---> Running in fe6fd1c17be8\n",
      "Removing intermediate container fe6fd1c17be8\n",
      " ---> 78761038f343\n",
      "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 48a370488266\n",
      "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 7f6a2a97a8e4\n",
      "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520\n",
      " ---> Running in 8ae8d12ce12f\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Exception occured on getting conda environment details\n",
      "Failed to send materialized environment details\n",
      "Removing intermediate container 8ae8d12ce12f\n",
      " ---> fce2b98411c9\n",
      "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520\n",
      " ---> Running in 8b3daa4139f6\n",
      "Removing intermediate container 8b3daa4139f6\n",
      " ---> 78c52f67e848\n",
      "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 252b7935dbaa\n",
      "Removing intermediate container 252b7935dbaa\n",
      " ---> 7f5bec850d79\n",
      "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 2aec8013faec\n",
      "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in a18188423c31\n",
      "Removing intermediate container a18188423c31\n",
      " ---> d90b5d54ff0d\n",
      "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 0e3ee54604e4\n",
      "Removing intermediate container 0e3ee54604e4\n",
      " ---> aa1a5e847f2f\n",
      "Step 18/18 : CMD [\"bash\"]\n",
      " ---> Running in c3e907a1adf2\n",
      "Removing intermediate container c3e907a1adf2\n",
      " ---> f31b09e72b32\n",
      "Successfully built f31b09e72b32\n",
      "Successfully tagged chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_444d498040a1ecec3683d0ba62162807:latest\n",
      "Successfully tagged chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_444d498040a1ecec3683d0ba62162807:1\n",
      "2021/05/03 11:11:01 Successfully executed container: acb_step_0\n",
      "2021/05/03 11:11:01 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/05/03 11:11:01 Pushing image: chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_444d498040a1ecec3683d0ba62162807:1, attempt 1\n",
      "The push refers to repository [chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_444d498040a1ecec3683d0ba62162807]\n",
      "8ba342023822: Preparing\n",
      "889a89622065: Preparing\n",
      "957c05cc0f1a: Preparing\n",
      "95492844fc1a: Preparing\n",
      "4febb286aaf1: Preparing\n",
      "8ca4a96a2e52: Preparing\n",
      "3a925b00691c: Preparing\n",
      "d182b70055e4: Preparing\n",
      "b5b3a9d04269: Preparing\n",
      "e1171d4d60ca: Preparing\n",
      "6ef1a8ae63b7: Preparing\n",
      "85389f9ead9e: Preparing\n",
      "f2608f66a0e3: Preparing\n",
      "0e259b09e5f4: Preparing\n",
      "340dc32eb998: Preparing\n",
      "df18b66efaa6: Preparing\n",
      "ccdb13a20bf2: Preparing\n",
      "9513cdf4e497: Preparing\n",
      "7f083f9454c0: Preparing\n",
      "29f36b5893dc: Preparing\n",
      "85389f9ead9e: Waiting\n",
      "f2608f66a0e3: Waiting\n",
      "0e259b09e5f4: Waiting\n",
      "340dc32eb998: Waiting\n",
      "df18b66efaa6: Waiting\n",
      "ccdb13a20bf2: Waiting\n",
      "9513cdf4e497: Waiting\n",
      "7f083f9454c0: Waiting\n",
      "29f36b5893dc: Waiting\n",
      "6ef1a8ae63b7: Waiting\n",
      "8ca4a96a2e52: Waiting\n",
      "3a925b00691c: Waiting\n",
      "d182b70055e4: Waiting\n",
      "b5b3a9d04269: Waiting\n",
      "e1171d4d60ca: Waiting\n",
      "8ba342023822: Pushed\n",
      "957c05cc0f1a: Pushed\n",
      "95492844fc1a: Pushed\n",
      "889a89622065: Pushed\n",
      "d182b70055e4: Pushed\n",
      "8ca4a96a2e52: Pushed\n",
      "3a925b00691c: Pushed\n",
      "b5b3a9d04269: Pushed\n",
      "e1171d4d60ca: Pushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ef1a8ae63b7: Pushed\n",
      "\n",
      "340dc32eb998: Pushed\n",
      "0e259b09e5f4: Pushed\n",
      "ccdb13a20bf2: Pushed\n",
      "f2608f66a0e3: Pushed\n",
      "9513cdf4e497: Pushed\n",
      "7f083f9454c0: Pushed\n",
      "85389f9ead9e: Pushed\n",
      "29f36b5893dc: Pushed\n",
      "df18b66efaa6: Pushed\n",
      "4febb286aaf1: Pushed\n",
      "1: digest: sha256:4ccfa7c4d8d326a58662b8b5078bad65e211723b372f9196e73173a475dd8a66 size: 4509\n",
      "2021/05/03 11:12:26 Successfully pushed image: chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_444d498040a1ecec3683d0ba62162807:1\n",
      "2021/05/03 11:12:26 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/05/03 11:12:26 Pushing image: chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_444d498040a1ecec3683d0ba62162807:latest, attempt 1\n",
      "The push refers to repository [chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_444d498040a1ecec3683d0ba62162807]\n",
      "8ba342023822: Preparing\n",
      "889a89622065: Preparing\n",
      "957c05cc0f1a: Preparing\n",
      "95492844fc1a: Preparing\n",
      "4febb286aaf1: Preparing\n",
      "8ca4a96a2e52: Preparing\n",
      "3a925b00691c: Preparing\n",
      "d182b70055e4: Preparing\n",
      "b5b3a9d04269: Preparing\n",
      "e1171d4d60ca: Preparing\n",
      "6ef1a8ae63b7: Preparing\n",
      "85389f9ead9e: Preparing\n",
      "f2608f66a0e3: Preparing\n",
      "0e259b09e5f4: Preparing\n",
      "340dc32eb998: Preparing\n",
      "df18b66efaa6: Preparing\n",
      "ccdb13a20bf2: Preparing\n",
      "9513cdf4e497: Preparing\n",
      "7f083f9454c0: Preparing\n",
      "29f36b5893dc: Preparing\n",
      "3a925b00691c: Waiting\n",
      "d182b70055e4: Waiting\n",
      "b5b3a9d04269: Waiting\n",
      "e1171d4d60ca: Waiting\n",
      "6ef1a8ae63b7: Waiting\n",
      "85389f9ead9e: Waiting\n",
      "f2608f66a0e3: Waiting\n",
      "0e259b09e5f4: Waiting\n",
      "340dc32eb998: Waiting\n",
      "df18b66efaa6: Waiting\n",
      "ccdb13a20bf2: Waiting\n",
      "9513cdf4e497: Waiting\n",
      "7f083f9454c0: Waiting\n",
      "29f36b5893dc: Waiting\n",
      "8ca4a96a2e52: Waiting\n",
      "8ba342023822: Layer already exists\n",
      "957c05cc0f1a: Layer already exists\n",
      "95492844fc1a: Layer already exists\n",
      "889a89622065: Layer already exists\n",
      "4febb286aaf1: Layer already exists\n",
      "b5b3a9d04269: Layer already exists\n",
      "e1171d4d60ca: Layer already exists\n",
      "8ca4a96a2e52: Layer already exists\n",
      "3a925b00691c: Layer already exists\n",
      "d182b70055e4: Layer already exists\n",
      "f2608f66a0e3: Layer already exists\n",
      "6ef1a8ae63b7: Layer already exists\n",
      "340dc32eb998: Layer already exists\n",
      "85389f9ead9e: Layer already exists\n",
      "0e259b09e5f4: Layer already exists\n",
      "df18b66efaa6: Layer already exists\n",
      "ccdb13a20bf2: Layer already exists\n",
      "29f36b5893dc: Layer already exists\n",
      "7f083f9454c0: Layer already exists\n",
      "9513cdf4e497: Layer already exists\n",
      "latest: digest: sha256:4ccfa7c4d8d326a58662b8b5078bad65e211723b372f9196e73173a475dd8a66 size: 4509\n",
      "2021/05/03 11:12:28 Successfully pushed image: chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_444d498040a1ecec3683d0ba62162807:latest\n",
      "2021/05/03 11:12:28 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 159.686738)\n",
      "2021/05/03 11:12:28 Populating digests for step ID: acb_step_0...\n",
      "2021/05/03 11:12:31 Successfully populated digests for step ID: acb_step_0\n",
      "2021/05/03 11:12:31 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 84.629993)\n",
      "2021/05/03 11:12:31 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.585960)\n",
      "2021/05/03 11:12:31 The following dependencies were found:\n",
      "2021/05/03 11:12:31 \n",
      "- image:\n",
      "    registry: chrjiaeastusc6ba5291.azurecr.io\n",
      "    repository: azureml/azureml_444d498040a1ecec3683d0ba62162807\n",
      "    tag: latest\n",
      "    digest: sha256:4ccfa7c4d8d326a58662b8b5078bad65e211723b372f9196e73173a475dd8a66\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base\n",
      "    tag: intelmpi2018.3-ubuntu16.04\n",
      "    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: chrjiaeastusc6ba5291.azurecr.io\n",
      "    repository: azureml/azureml_444d498040a1ecec3683d0ba62162807\n",
      "    tag: \"1\"\n",
      "    digest: sha256:4ccfa7c4d8d326a58662b8b5078bad65e211723b372f9196e73173a475dd8a66\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base\n",
      "    tag: intelmpi2018.3-ubuntu16.04\n",
      "    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "  git: {}\n",
      "\n",
      "Run ID: wb7 was successful after 4m20s\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Logging into Docker registry chrjiaeastusc6ba5291.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM chrjiaeastusc6ba5291.azurecr.io/azureml/azureml_444d498040a1ecec3683d0ba62162807\n",
      " ---> f31b09e72b32\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> efe67003a635\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjEzZTUwODQ1LTY3YmMtNGFjNS05NGRiLTQ4ZDQ5M2E2ZDllOCIsInJlc291cmNlR3JvdXBOYW1lIjoiY2hyamlhLXJnIiwiYWNjb3VudE5hbWUiOiJjaHJqaWEtZWFzdHVzMmV1YXAyIiwid29ya3NwYWNlSWQiOiI1OTkzZGVjMS01OTczLTQ4NTktOGJlMS03MDczMzJjNTQ5NWQifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in cb64915aecc8\n",
      " ---> 131036b9de24\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmp1vzkd1qc.py' /var/azureml-app/main.py\n",
      " ---> Running in 13d3dc5250c0\n",
      " ---> 2cc5d83691cf\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in e9c98b6df2db\n",
      " ---> 843fb942a864\n",
      "Successfully built 843fb942a864\n",
      "Successfully tagged myservice11:latest\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:32267\n",
      "{\n",
      "  \"computeType\": \"Local\",\n",
      "  \"environmentDetails\": null,\n",
      "  \"imageId\": null,\n",
      "  \"name\": \"myservice11\",\n",
      "  \"properties\": \"\",\n",
      "  \"scoringUri\": \"http://localhost:32267/score\",\n",
      "  \"state\": \"running\",\n",
      "  \"tags\": \"\",\n",
      "  \"updatedAt\": \"2021-05-03T16:31:53.279413\"\n",
      "}\n",
      "\u001b[91m{'Azure-cli-ml Version': '1.27.0', 'Error': TypeError(\"get_logs() got an unexpected keyword argument 'init'\",)}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!az ml model deploy -n myservice -m bidaf_onnx:1 --ic inferenceconfig.json --dc deploymentconfig.json\n",
    "!az ml service get-logs -n myservice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d47b4",
   "metadata": {},
   "source": [
    "## Call into your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e92e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 127.0.0.1:32267...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 32267 (#0)\n",
      "> GET / HTTP/1.1\n",
      "> Host: localhost:32267\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> \n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Server: nginx/1.10.3 (Ubuntu)\n",
      "< Date: Mon, 03 May 2021 11:48:57 GMT\n",
      "< Content-Type: text/html; charset=utf-8\n",
      "< Content-Length: 7\n",
      "< Connection: keep-alive\n",
      "< x-ms-request-id: 4d000a9d-b3cb-4223-8de1-086c7d0aff22\n",
      "< \n",
      "* Connection #0 to host localhost left intact\n",
      "HealthyNote: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 127.0.0.1:32267...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 32267 (#0)\n",
      "> POST /score HTTP/1.1\n",
      "> Host: localhost:32267\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> content-type:application/json\n",
      "> Content-Length: 94\n",
      "> \n",
      "* upload completely sent off: 94 out of 94 bytes\n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Server: nginx/1.10.3 (Ubuntu)\n",
      "< Date: Mon, 03 May 2021 11:48:57 GMT\n",
      "< Content-Type: application/json\n",
      "< Content-Length: 9\n",
      "< Connection: keep-alive\n",
      "< x-ms-run-function-failed: False\n",
      "< x-ms-request-id: 61d7113d-1e20-4312-be3c-15e4240a166f\n",
      "< \n",
      "* Connection #0 to host localhost left intact\n",
      "[\"brown\"]"
     ]
    }
   ],
   "source": [
    "!curl -v http://localhost:32267\n",
    "!curl -v -X POST -H \"content-type:application/json\" -d '{\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}' http://localhost:32267/score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9e82c",
   "metadata": {},
   "source": [
    "Notice the use of the AZUREML_MODEL_DIR environment variable to locate your registered model. Now that you've added some pip packages, you also need to update your inference configuration with [new configurations](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=azcli#tabpanel_7_azcli) to add in those additional packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0c387",
   "metadata": {},
   "source": [
    "## Deploy again and call your service\n",
    "\n",
    "Replace `bidaf_onnx:1` with the name of your model and its version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd084966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "{\n",
      "  \"computeType\": \"ACI\",\n",
      "  \"environmentDetails\": {\n",
      "    \"databricks\": {\n",
      "      \"eggLibraries\": [],\n",
      "      \"jarLibraries\": [],\n",
      "      \"mavenLibraries\": [],\n",
      "      \"pypiLibraries\": [],\n",
      "      \"rcranLibraries\": []\n",
      "    },\n",
      "    \"docker\": {\n",
      "      \"arguments\": [],\n",
      "      \"baseDockerfile\": null,\n",
      "      \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
      "      \"baseImageRegistry\": {\n",
      "        \"address\": null,\n",
      "        \"password\": null,\n",
      "        \"registryIdentity\": null,\n",
      "        \"username\": null\n",
      "      },\n",
      "      \"enabled\": false,\n",
      "      \"platform\": {\n",
      "        \"architecture\": \"amd64\",\n",
      "        \"os\": \"Linux\"\n",
      "      },\n",
      "      \"sharedVolumes\": true,\n",
      "      \"shmSize\": null\n",
      "    },\n",
      "    \"environmentVariables\": {\n",
      "      \"AZUREML_ENTRY_SCRIPT\": \"source_dir/score.py\",\n",
      "      \"AZUREML_SOURCE_DIRECTORY\": \"source_dir\",\n",
      "      \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
      "    },\n",
      "    \"inferencingStackVersion\": null,\n",
      "    \"name\": \"my-deploy-env\",\n",
      "    \"python\": {\n",
      "      \"baseCondaEnvironment\": null,\n",
      "      \"condaDependencies\": {\n",
      "        \"channels\": [],\n",
      "        \"dependencies\": [\n",
      "          \"python=3.6.2\",\n",
      "          {\n",
      "            \"pip\": [\n",
      "              \"azureml-defaults\",\n",
      "              \"nltk\",\n",
      "              \"numpy\",\n",
      "              \"onnxruntime\"\n",
      "            ]\n",
      "          }\n",
      "        ],\n",
      "        \"name\": \"azureml_d1b0e61be4880220e8632d706cd2f520\"\n",
      "      },\n",
      "      \"condaDependenciesFile\": null,\n",
      "      \"interpreterPath\": \"python\",\n",
      "      \"userManagedDependencies\": false\n",
      "    },\n",
      "    \"r\": null,\n",
      "    \"spark\": {\n",
      "      \"packages\": [],\n",
      "      \"precachePackages\": true,\n",
      "      \"repositories\": []\n",
      "    },\n",
      "    \"version\": \"3\"\n",
      "  },\n",
      "  \"imageId\": null,\n",
      "  \"name\": \"myserviceredeploy1\",\n",
      "  \"properties\": {\n",
      "    \"azureml.git.branch\": \"deployLocalSamples\",\n",
      "    \"azureml.git.commit\": \"121a9e9c80abe654f57a752c6a48b39d0e51452d\",\n",
      "    \"azureml.git.dirty\": \"True\",\n",
      "    \"azureml.git.repository_uri\": \"https://github.com/HiteshTetarwal/azureml-examples.git\",\n",
      "    \"hasHttps\": \"False\",\n",
      "    \"hasInferenceSchema\": \"False\",\n",
      "    \"mlflow.source.git.branch\": \"deployLocalSamples\",\n",
      "    \"mlflow.source.git.commit\": \"121a9e9c80abe654f57a752c6a48b39d0e51452d\",\n",
      "    \"mlflow.source.git.repoURL\": \"https://github.com/HiteshTetarwal/azureml-examples.git\"\n",
      "  },\n",
      "  \"scoringUri\": \"http://90918971-ec0f-4a69-80bc-f384536a08fc.eastus2.azurecontainer.io/score\",\n",
      "  \"state\": \"Healthy\",\n",
      "  \"tags\": \"\",\n",
      "  \"updatedAt\": \"2021-05-03T11:49:53.394796+00:00\"\n",
      "}\n",
      "[\n",
      "  \"2021-05-03T11:52:27,552661900+00:00 - gunicorn/run \\n2021-05-03T11:52:27,551658300+00:00 - rsyslog/run \\n2021-05-03T11:52:27,553912500+00:00 - iot-server/run \\n2021-05-03T11:52:27,612809500+00:00 - nginx/run \\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2021-05-03T11:52:28,052956400+00:00 - iot-server/finish 1 0\\n2021-05-03T11:52:28,054249700+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (67)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 93\\nInitialized PySpark session.\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user's init function\\n2021-05-03 11:52:30.577352400 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Word_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 11:52:30.604728300 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Char_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 11:52:30.605423800 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __OneFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 11:52:30.605803600 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 11:52:30.606213400 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 11:52:30.606594300 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __NegINF_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 11:52:30.606853800 [W:onnxruntime:, graph.cc:1074 Graph] Initializer _Const_0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\nUsers's init has completed successfully\\n[nltk_data] Downloading package punkt to /root/nltk_data...\\n[nltk_data]   Unzipping tokenizers/punkt.zip.\\nScoring timeout is found from os.environ: 60000 ms\\nSwagger file not present\\n404\\n127.0.0.1 - - [03/May/2021:11:52:33 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [03/May/2021:11:52:36 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [03/May/2021:11:52:43 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\n\",\n",
      "  null\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!az ml model deploy -n myservice -m bidaf_onnx:1 --ic inferenceconfig.json --dc re-deploymentconfig.json\n",
    "!az ml service get-logs -n myservice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861af8f",
   "metadata": {},
   "source": [
    "Then ensure you can send a post request to the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0dac0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\r\n",
      "*   Trying 127.0.0.1:32267...\r\n",
      "* TCP_NODELAY set\r\n",
      "* Connected to localhost (127.0.0.1) port 32267 (#0)\r\n",
      "> POST /score HTTP/1.1\r",
      "\r\n",
      "> Host: localhost:32267\r",
      "\r\n",
      "> User-Agent: curl/7.68.0\r",
      "\r\n",
      "> Accept: */*\r",
      "\r\n",
      "> content-type:application/json\r",
      "\r\n",
      "> Content-Length: 94\r",
      "\r\n",
      "> \r",
      "\r\n",
      "* upload completely sent off: 94 out of 94 bytes\r\n",
      "* Mark bundle as not supporting multiuse\r\n",
      "< HTTP/1.1 200 OK\r",
      "\r\n",
      "< Server: nginx/1.10.3 (Ubuntu)\r",
      "\r\n",
      "< Date: Mon, 03 May 2021 11:53:49 GMT\r",
      "\r\n",
      "< Content-Type: application/json\r",
      "\r\n",
      "< Content-Length: 9\r",
      "\r\n",
      "< Connection: keep-alive\r",
      "\r\n",
      "< x-ms-run-function-failed: False\r",
      "\r\n",
      "< x-ms-request-id: ff1ab9f7-49a1-4667-b0e4-acd125e55d09\r",
      "\r\n",
      "< \r",
      "\r\n",
      "* Connection #0 to host localhost left intact\r\n",
      "[\"brown\"]"
     ]
    }
   ],
   "source": [
    "!curl -v -X POST -H \"content-type:application/json\" -d '{\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}' http://localhost:32267/score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9aab6b",
   "metadata": {},
   "source": [
    "## Re-deploy to cloud\n",
    "\n",
    "Once you've confirmed your service works locally and chosen a remote compute target, you are ready to deploy to the cloud.\n",
    "Change your re-deploy configuration to correspond to the compute target you've chosen, in this case Azure Container Instances.\n",
    "\n",
    "Deploy your service again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51029f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "{\n",
      "  \"computeType\": \"ACI\",\n",
      "  \"environmentDetails\": {\n",
      "    \"databricks\": {\n",
      "      \"eggLibraries\": [],\n",
      "      \"jarLibraries\": [],\n",
      "      \"mavenLibraries\": [],\n",
      "      \"pypiLibraries\": [],\n",
      "      \"rcranLibraries\": []\n",
      "    },\n",
      "    \"docker\": {\n",
      "      \"arguments\": [],\n",
      "      \"baseDockerfile\": null,\n",
      "      \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
      "      \"baseImageRegistry\": {\n",
      "        \"address\": null,\n",
      "        \"password\": null,\n",
      "        \"registryIdentity\": null,\n",
      "        \"username\": null\n",
      "      },\n",
      "      \"enabled\": false,\n",
      "      \"platform\": {\n",
      "        \"architecture\": \"amd64\",\n",
      "        \"os\": \"Linux\"\n",
      "      },\n",
      "      \"sharedVolumes\": true,\n",
      "      \"shmSize\": null\n",
      "    },\n",
      "    \"environmentVariables\": {\n",
      "      \"AZUREML_ENTRY_SCRIPT\": \"source_dir/score.py\",\n",
      "      \"AZUREML_SOURCE_DIRECTORY\": \"source_dir\",\n",
      "      \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
      "    },\n",
      "    \"inferencingStackVersion\": null,\n",
      "    \"name\": \"my-deploy-env\",\n",
      "    \"python\": {\n",
      "      \"baseCondaEnvironment\": null,\n",
      "      \"condaDependencies\": {\n",
      "        \"channels\": [],\n",
      "        \"dependencies\": [\n",
      "          \"python=3.6.2\",\n",
      "          {\n",
      "            \"pip\": [\n",
      "              \"azureml-defaults\",\n",
      "              \"nltk\",\n",
      "              \"numpy\",\n",
      "              \"onnxruntime\"\n",
      "            ]\n",
      "          }\n",
      "        ],\n",
      "        \"name\": \"azureml_d1b0e61be4880220e8632d706cd2f520\"\n",
      "      },\n",
      "      \"condaDependenciesFile\": null,\n",
      "      \"interpreterPath\": \"python\",\n",
      "      \"userManagedDependencies\": false\n",
      "    },\n",
      "    \"r\": null,\n",
      "    \"spark\": {\n",
      "      \"packages\": [],\n",
      "      \"precachePackages\": true,\n",
      "      \"repositories\": []\n",
      "    },\n",
      "    \"version\": \"3\"\n",
      "  },\n",
      "  \"imageId\": null,\n",
      "  \"name\": \"myservice12\",\n",
      "  \"properties\": {\n",
      "    \"azureml.git.branch\": \"deployLocalSamples\",\n",
      "    \"azureml.git.commit\": \"121a9e9c80abe654f57a752c6a48b39d0e51452d\",\n",
      "    \"azureml.git.dirty\": \"True\",\n",
      "    \"azureml.git.repository_uri\": \"https://github.com/HiteshTetarwal/azureml-examples.git\",\n",
      "    \"hasHttps\": \"False\",\n",
      "    \"hasInferenceSchema\": \"False\",\n",
      "    \"mlflow.source.git.branch\": \"deployLocalSamples\",\n",
      "    \"mlflow.source.git.commit\": \"121a9e9c80abe654f57a752c6a48b39d0e51452d\",\n",
      "    \"mlflow.source.git.repoURL\": \"https://github.com/HiteshTetarwal/azureml-examples.git\"\n",
      "  },\n",
      "  \"scoringUri\": \"http://d176c28f-743a-45a2-b0a3-98c30be6cc9d.eastus2.azurecontainer.io/score\",\n",
      "  \"state\": \"Healthy\",\n",
      "  \"tags\": \"\",\n",
      "  \"updatedAt\": \"2021-05-03T12:09:20.757429+00:00\"\n",
      "}\n",
      "[\n",
      "  \"2021-05-03T12:10:43,824441500+00:00 - rsyslog/run \\n2021-05-03T12:10:43,823476500+00:00 - iot-server/run \\n2021-05-03T12:10:43,840200400+00:00 - nginx/run \\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n2021-05-03T12:10:43,899717900+00:00 - gunicorn/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2021-05-03T12:10:44,320065700+00:00 - iot-server/finish 1 0\\n2021-05-03T12:10:44,330962300+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (66)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 91\\nInitialized PySpark session.\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user's init function\\n2021-05-03 12:10:47.031042100 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Word_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 12:10:47.031594400 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Char_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 12:10:47.031620600 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __OneFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 12:10:47.031638600 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 12:10:47.031712500 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 12:10:47.031732400 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __NegINF_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\n2021-05-03 12:10:47.031950800 [W:onnxruntime:, graph.cc:1074 Graph] Initializer _Const_0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\\nUsers's init has completed successfully\\n[nltk_data] Downloading package punkt to /root/nltk_data...\\n[nltk_data]   Unzipping tokenizers/punkt.zip.\\nScoring timeout is found from os.environ: 60000 ms\\nSwagger file not present\\n404\\n127.0.0.1 - - [03/May/2021:12:11:58 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [03/May/2021:12:12:02 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\nSwagger file not present\\n404\\n127.0.0.1 - - [03/May/2021:12:12:11 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 404 19 \\\"-\\\" \\\"Go-http-client/1.1\\\"\\n\",\n",
      "  null\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!az ml model deploy -n myservice -m bidaf_onnx:1 --ic inferenceconfig.json --dc re-deploymentconfig.json\n",
    "!az ml service get-logs -n myservice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5448133",
   "metadata": {},
   "source": [
    "## Call your remote webservice\n",
    "\n",
    "When you deploy remotely, you may have key authentication enabled. The example below shows how to get your service key with Python in order to make an inference request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd48987d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"brown\"]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core import Webservice, Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "service = Webservice(workspace=ws, name='myservice')\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "key, _ = service.get_keys()\n",
    "\n",
    "# Set the appropriate headers\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response and logs\n",
    "data = {\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
    "data = json.dumps(data)\n",
    "resp = requests.post(scoring_uri, data=data, headers=headers)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51a6b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-03T12:10:43,824441500+00:00 - rsyslog/run \n",
      "2021-05-03T12:10:43,823476500+00:00 - iot-server/run \n",
      "2021-05-03T12:10:43,840200400+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d1b0e61be4880220e8632d706cd2f520/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2021-05-03T12:10:43,899717900+00:00 - gunicorn/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-05-03T12:10:44,320065700+00:00 - iot-server/finish 1 0\n",
      "2021-05-03T12:10:44,330962300+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (66)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 91\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "2021-05-03 12:10:47.031042100 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Word_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-03 12:10:47.031594400 [W:onnxruntime:, graph.cc:1074 Graph] Initializer Char_Embedding appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-03 12:10:47.031620600 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __OneFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-03 12:10:47.031638600 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-03 12:10:47.031712500 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __ZeroFloat_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-03 12:10:47.031732400 [W:onnxruntime:, graph.cc:1074 Graph] Initializer __NegINF_Batch appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-05-03 12:10:47.031950800 [W:onnxruntime:, graph.cc:1074 Graph] Initializer _Const_0 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "Users's init has completed successfully\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "Scoring timeout is found from os.environ: 60000 ms\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [03/May/2021:12:11:58 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [03/May/2021:12:12:02 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [03/May/2021:12:12:11 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [03/May/2021:12:12:15 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Validation Request Content-Type\n",
      "Received input: {\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
      "Headers passed in (total 12):\n",
      "\tHost: localhost:5001\n",
      "\tX-Real-Ip: 127.0.0.1\n",
      "\tX-Forwarded-For: 127.0.0.1\n",
      "\tX-Forwarded-Proto: http\n",
      "\tConnection: close\n",
      "\tContent-Length: 94\n",
      "\tUser-Agent: python-requests/2.25.1\n",
      "\tAccept: */*\n",
      "\tAccept-Encoding: gzip, deflate\n",
      "\tAuthorization: Bearer vkAHeKQqonoj82X9Of6lMTFMN35AtoLK\n",
      "\tContent-Type: application/json\n",
      "\tX-Ms-Request-Id: b2c2d4dc-3c5a-4477-afe4-6816e4acde05\n",
      "Scoring Timer is set to 60.0 seconds\n",
      "{\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
      "['brown']\n",
      "200\n",
      "127.0.0.1 - - [03/May/2021:12:12:18 +0000] \"POST /score HTTP/1.0\" 200 9 \"-\" \"python-requests/2.25.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e601d",
   "metadata": {},
   "source": [
    "# Delete resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a9f8e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bidaf_onnx:15'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the current model id\n",
    "import os\n",
    "stream = os.popen('az ml model list --model-name=bidaf_onnx --latest --query \"[0].id\" -o tsv')\n",
    "MODEL_ID = stream.read()[0:-1]\n",
    "MODEL_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml service delete myservice\n",
    "!az ml model delete --model-id=$MODEL_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3af1a4",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f530f08",
   "metadata": {},
   "source": [
    "Try reading [our documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
