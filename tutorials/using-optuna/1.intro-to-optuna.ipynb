{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade lightgbm scikit-learn optuna plotly dask dask_optuna joblib gitpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Azure mlflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "mlflow.set_experiment(\"intro-to-optuna-tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "\n",
    "# get root of git repo\n",
    "prefix = Path(git.Repo(\".\", search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "# data path\n",
    "data_path = prefix.joinpath(\"data\", \"raw\", \"iris\", \"iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    import mlflow\n",
    "    import mlflow.lightgbm\n",
    "    import pandas as pd\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.metrics import accuracy_score, log_loss\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # prepare train and test data\n",
    "    iris = pd.read_csv(data_path)\n",
    "    enc = LabelEncoder()\n",
    "    X = iris.drop(\"species\", axis=1)\n",
    "    y = enc.fit_transform(iris.species)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    train_set = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    # set training parameters\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": 3,\n",
    "        \"boosting\": trial.suggest_categorical(\n",
    "            \"boosting\", [\"gbdt\", \"dart\", \"goss\"]\n",
    "        ),\n",
    "        \"num_iterations\": trial.suggest_int(\"num_iterations\", 10, 200),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 128),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.9),\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"colsample_bytree\": 1.0,\n",
    "        \"subsample\": 1.0,\n",
    "        \"seed\": trial.suggest_int(\"seed\", 0, 42),\n",
    "    }\n",
    "\n",
    "    # start run\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        # enable automatic logging\n",
    "        mlflow.lightgbm.autolog()\n",
    "\n",
    "        # train the lightgbm model\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            num_boost_round=trial.suggest_int(\"num_boost_round\", 8, 64),\n",
    "            valid_sets=[train_set],\n",
    "        )\n",
    "\n",
    "        # evaluate model\n",
    "        y_proba = model.predict(X_test)\n",
    "        y_pred = y_proba.argmax(axis=1)\n",
    "        loss = log_loss(y_test, y_proba)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # log metrics from evaluation\n",
    "        mlflow.log_metric(\"log_loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and run study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "c = Client()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from dask_optuna import DaskStorage\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"intro-to-optuna-tutorial\",\n",
    "    direction=\"minimize\",\n",
    "    sampler=TPESampler(),\n",
    "    storage=DaskStorage(),\n",
    ")\n",
    "\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    study.optimize(objective, n_trials=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_edf(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}