{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: training an image classification model\n",
    "\n",
    "**Learning Objectives** - By the end of this quickstart tutorial, you'll know how to train an image classification model on Azure ML platform.\n",
    "\n",
    "This tutorial covers:\n",
    "\n",
    "- Connect to workspace & set up a compute resource on the Azure Machine Learning Studio Notebook UI\n",
    "- Bring data in and prepare it to be used for training\n",
    "- Train a model for image classification\n",
    "- Metrics for optimizing your model\n",
    "- Deploy the model online & test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "- Basic understanding of Machine Learning \n",
    "- An active Azure subscription. If you don't have one, go to [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n",
    "- An Azure ML workspace. You'll be asked to set it up when you visit [Azure ML Studio](https://ml.azure.com) for the first time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Connect to AzureML workspace\n",
    "\n",
    "Before we dive in the code, you'll need to connect to your workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. `DefaultAzureCredential` should be capable of handling most scenarios. If you want to learn more about other available credentials, go to configure credential example, azure-identity reference doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "credential = InteractiveBrowserCredential()\n",
    "\n",
    "# Get a handle to the workspace. You can find the info on the workspace tab on ml.azure.com\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\", # this will look like xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n",
    "    resource_group_name=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<AML_WORKSPACE_NAME>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create compute\n",
    "\n",
    "In order to run a training job on Azure cloud, you will need to create a compute resource. This is easily handled through a set up wizard.\n",
    "\n",
    "<img src="media/placeholder_2.png" alt=\"Alt text\" width=\"100%\"/> \n", 
    "\n",
    "1. Click **...** menu button on the top of Notebook UI, and select **+Create Azure ML Compute Instance**.\n",
    "2. **Name** the compute\n",
    "3. Select **CPU** and **STANDARD_DS3_V2**. \n",
    "4. Click **Create**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a job environment\n",
    "To run an Azure Machine Learning training job, you'll need an environment. An environment is the software runtime and libraries that you want installed on the compute where you’ll be training. It is similar to your python environment on your local machine.\n",
    "\n",
    "Azure Machine Learning provides many curated or ready-made environments which are useful for common training and inference scenarios. You can also create your own “custom” environments using a docker image, or a conda configuration.\n",
    "\n",
    "In this example, you'll create a custom conda environment for your jobs, using a conda yaml file. First, create a directory to store the file in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dependencies_dir = \"./dependencies\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the file in the dependencies directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {dependencies_dir}/conda.yml\n",
    "name: model-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - numpy=1.21.2\n",
    "  - pip=21.2.4\n",
    "  - scikit-learn=0.24.2\n",
    "  - scipy=1.7.1\n",
    "  - pandas>=1.1,<1.2\n",
    "  - pip:\n",
    "    - inference-schema[numpy-support]==1.3.0\n",
    "    - xlrd==2.0.1\n",
    "    - mlflow== 1.26.1\n",
    "    - azureml-mlflow==1.42.0\n",
    "    - psutil>=5.8,<5.9\n",
    "    - tqdm>=4.59,<4.60\n",
    "    - ipykernel~=6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specification contains some usual packages, that you'll use in your job (numpy, pip).\n",
    "\n",
    "Use the yaml file to create and register this custom environment in your workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env_name = \"aml-scikit-learn\"\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Custom environment for Credit Card Defaults pipeline\",\n",
    "    tags={\"scikit-learn\": \"0.24.2\"},\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\"\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build the command job to train\n",
    "Now that you have all assets required to run your job, it's time to build the job itself, using the Azure ML Python SDK v2. We will be creating a command job.\n",
    "\n",
    "An AzureML command job is a resource that specifies all the details needed to execute your training code in the cloud: inputs and outputs, the type of hardware to use, software to install, and how to run your code. the command job contains information to execute a single command.\n",
    "\n",
    "**Create training script**\n",
    "\n",
    "Let's start by creating the training script - the *main.py* python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a source folder for the training script\n",
    "import os\n",
    "\n",
    "train_src_dir = \"./src\"\n",
    "os.makedirs(train_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script handles the preprocessing of the data, splitting it into test and train data. It then consumes this data to train a tree based model and return the output model. [MLFlow](https://mlflow.org/docs/latest/tracking.html) will be used to log the parameters and metrics during our pipeline run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training script - the main.py file\n",
    "%%writefile {train_src_dir}/main.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
    "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
    "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
    "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
    "    args = parser.parse_args()\n",
    "   \n",
    "    # start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    ###################\n",
    "    #<prepare the data>\n",
    "    ###################\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "    \n",
    "    credit_df = pd.read_excel(args.data, header=1, index_col=0)\n",
    "\n",
    "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
    "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
    "\n",
    "    train_df, test_df = train_test_split(\n",
    "        credit_df,\n",
    "        test_size=args.test_train_ratio,\n",
    "    )\n",
    "\n",
    "    ##################\n",
    "    #<train the model>\n",
    "    ##################\n",
    "    # extracting the label column\n",
    "    y_train = train_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_train = train_df.values\n",
    "\n",
    "    # extracting the label column\n",
    "    y_test = test_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_test = test_df.values\n",
    "\n",
    "    print(f\"Training with data of shape {X_train.shape}\")\n",
    "\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    ##########################\n",
    "    #<save and register model>\n",
    "    ##########################\n",
    "    # registering the model to the workspace\n",
    "    print(\"Registering the model via MLFlow\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=clf,\n",
    "        registered_model_name=args.registered_model_name,\n",
    "        artifact_path=args.registered_model_name,\n",
    "    )\n",
    "\n",
    "    # saving the model to a file\n",
    "    mlflow.sklearn.save_model(\n",
    "        sk_model=clf,\n",
    "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
    "    )\n",
    "    \n",
    "    # stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in this script, once the model is trained, the model file is saved and registered to the workspace. Now you can use the registered model in inferencing endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the Command**\n",
    "\n",
    "Now that you have a script that can perform the desired tasks, You'll use the general purpose command that can run command line actions. This command line action can be directly calling system commands or running a script.\n",
    "\n",
    "Here, you'll use input data, split ratio, learning rate and registered model name as input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "# name the model you registered earlier in the training script\n",
    "registered_model_name = \"credit_defaults_model\"\n",
    "\n",
    "# configure the command job\n",
    "job = command(    \n",
    "    inputs=dict(\n",
    "        #uri_file refers to a specific file as a data asset\n",
    "        data=Input(type=\"uri_file\", path=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"), \n",
    "        test_train_ratio=0.2, #input variable in main.py\n",
    "        learning_rate=0.25, #input variable in main.py\n",
    "        registered_model_name=registered_model_name #input variable in main.py\n",
    "        ),\n",
    "    code=\"./src/\", #location of source code\n",
    "    #The inputs/outputs are accessible in the command via the ${{ ... }} notation\n",
    "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\", \n",
    "    #This is the custom environment you created earlier\n",
    "    environment=\"aml-scikit-learn@latest\",\n",
    "    #This is the compute you created earlier\n",
    "    compute=\"cpu-cluster\",\n",
    "    #An experiment is a container for all the iterations one does on a certain project. All the jobs submitted under the same experiment name would be listed next to each other in Azure ML studio.\n",
    "    experiment_name=\"train_model_credit_default_prediction\",\n",
    "    display_name=\"credit_default_prediction\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submit the job ###\n",
    "It's now time to submit the job to run in AzureML. **The job will take 2 to 3 minutes to run**. It could take longer (up to 10 minutes) if the compute instance has been scaled down to zero nodes and custom environment is still building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the command job\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. View the result of a training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"job_PH.png\" alt=\"Alt text\" width=\"100%\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can view the result of a training job by **clicking the URL generated after submitting a job**. Alternatively, you can also click **Jobs** on the left navigation menu. A job is a grouping of many runs from a specified script or piece of code. Information for the run is stored under that job. \n",
    "1. Check **overview** to see the status of the job. Once when the job is **completed**, you will see useful metrics and log data. \n",
    "2. **Metrics** would display different visualizations of the metrics you specified in the script.\n",
    "3. **Images** ---- what does it do?\n",
    "4. **Child jobs** ---- need content\n",
    "5. **Outputs + logs** contains log files you need for troubleshooting or other monitoring purposes. \n",
    "6. **Code** contains the script/code used in the job.\n",
    "7. **Explanations**, **Fairness**, and **Monitoring** are used to see how your model performs against responsible AI standards. They are currently preview features and require additional package installations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Deploy the model as an online endpoint\n",
    "\n",
    "Now deploy your machine learning model as a web service in the Azure cloud, an [`online endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-endpoints).\n",
    "\n",
    "To deploy a machine learning service, you usually need:\n",
    "\n",
    "- The model assets (file, metadata) that you want to deploy. You've already registered these assets via MLflow in *main.py*.\n",
    "- Some code to run as a service. The code executes the model on a given input request. This entry script receives data submitted to a deployed web service and passes it to the model, then returns the model's response to the client. The script is specific to your model. The entry script must understand the data that the model expects and returns. When using a MLFlow model, as in this tutorial, this script is automatically created for you. Samples of scoring scripts can be found [here](https://github.com/Azure/azureml-examples/tree/sdk-preview/sdk/endpoints/online)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new online endpoint**\n",
    "\n",
    "Now that you have a registered model and an inference script, it's time to create your online endpoint. The endpoint name needs to be unique in the entire Azure region. For this tutorial, you'll create a unique name using UUID.\n",
    "\n",
    "[!NOTE] Expect the endpoint creation to take approximately 6 to 8 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "import uuid\n",
    "\n",
    "# creating a unique name with current datetime to avoid conflicts\n",
    "online_endpoint_name = \"credit-endpoint-\" + str(uuid.uuid4())[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    ")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is an online endpoint\",\n",
    "    auth_mode=\"key\", # use \"key\" for key-based authentication. Use \"aml_token\" for Azure Machine Learning token-based authentication. \n",
    "    tags={\n",
    "        \"training_dataset\": \"credit_defaults\", # these tags are optional\n",
    "        \"model_type\": \"sklearn.GradientBoostingClassifier\",\n",
    "    },\n",
    ")\n",
    "\n",
    "endpoint = ml_client.begin_create_or_update(endpoint)\n",
    "\n",
    "print(f\"Endpint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've created an endpoint, you can retrieve it as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print(\n",
    "    f'Endpint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deploy the model to the endpoint**\n",
    "\n",
    "Once the endpoint is created, deploy the model with the entry script. Each endpoint can have multiple deployments and direct traffic to these deployments can be specified using rules. Here you'll create a single deployment that handles 100% of the incoming traffic. We have chosen a color name for the deployment, for example, blue, green, red deployments, which is arbitrary.\n",
    "\n",
    "You can check the Models page on the Azure Machine Learning studio, to identify the latest version of your registered model. Alternatively, the code below will retrieve the latest version number for you to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pick the latest version of the model\n",
    "latest_model_version = max(\n",
    "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deploy the latest version of the model**\n",
    "\n",
    "[!NOTE] Expect this deployment to take approximately 6 to 8 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking the model to deploy. Here we use the latest version of our registered model.\n",
    "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
    "\n",
    "\n",
    "# create an online deployment.\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\", # we chose color names for the deployment, you can change.\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    instance_type=\"Standard_DS3_v2\", # this is the compute we created earlier\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "blue_deployment = ml_client.begin_create_or_update(blue_deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test with a sample query**\n",
    "\n",
    "Now that the model is deployed to the endpoint, you can run inference with it.\n",
    "\n",
    "Create a sample request file following the design expected in the run method in the score script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a source folder for the sample query\n",
    "deploy_dir = \"./deploy\"\n",
    "os.makedirs(deploy_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a json query for testing\n",
    "%%writefile {deploy_dir}/sample-request.json\n",
    "{\n",
    "  \"input_data\": {\n",
    "    \"columns\": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],\n",
    "    \"index\": [0, 1],\n",
    "    \"data\": [\n",
    "            [20000,2,2,1,24,2,2,-1,-1,-2,-2,3913,3102,689,0,0,0,0,689,0,0,0,0],\n",
    "            [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8]\n",
    "        ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the blue deployment with some sample data\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    request_file=\"./deploy/sample-request.json\",\n",
    "    deployment_name=\"blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean up resources**\n",
    "\n",
    "If you're not going to use the endpoint, delete it to stop using the resource. Make sure no other deployments are using an endpoint before you delete it.\n",
    "\n",
    "[!NOTE] Expect this step to take approximately 6 to 8 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the endpoint\n",
    "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad53975d6cd14b07e2ef76ca5c680233933f2b5b5c4b5fa1fc47a72f4636b78d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
