{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quickstart: How to train and deploy your model in Azure Machine Learning in 10 minutes\n",
        "\n",
        "In this quickstart, you learn how to get started with Azure Machine Learning. You will train an image classification model using the [MNIST](https://azure.microsoft.com/services/open-datasets/catalog/mnist/) dataset.\n",
        "\n",
        "You will learn how to:\n",
        "\n",
        "> * Download a dataset and look at the data\n",
        "> * Train an image classification model and log metrics\n",
        "> * Deploy the model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to your workspace and create an experiment\n",
        "\n",
        "You start with importing some libraries and creating an experiment to track the runs in your workspace. A workspace can have multiple experiments, and all the users that have access to the workspace can collaborate on them. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "from azureml.core import Experiment\n",
        "\n",
        "# connect to your workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# create experiment and start logging to a new run in the experiment\n",
        "experiment_name = \"azure-ml-in10-mins-tutorial\"\n",
        "exp = Experiment(workspace=ws, name=experiment_name)\n",
        "run = exp.start_logging(snapshot_directory=None)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612965916889
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data\n",
        "\n",
        "Before you train a model, you need to understand the data that you are using to train it. In this section you learn how to:\n",
        "\n",
        "* Download the MNIST dataset\n",
        "* Display some sample images\n",
        "\n",
        "### Download the MNIST dataset\n",
        "\n",
        "Use Azure Open Datasets to get the raw MNIST data files. [Azure Open Datasets](https://docs.microsoft.com/azure/open-datasets/overview-what-are-open-datasets) are curated public datasets that you can use to add scenario-specific features to machine learning solutions for more accurate models. Each dataset has a corrseponding class, `MNIST` in this case, to retrieve the data in different ways.\n",
        "\n",
        "Follow this [how-to](https://aka.ms/azureml/howto/createdatasets) if you want to learn more about Datasets and how to use them.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azureml.core import Dataset\n",
        "from azureml.opendatasets import MNIST\n",
        "\n",
        "data_folder = os.path.join(os.getcwd(), \"data\")\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "mnist_file_dataset = MNIST.get_file_dataset()\n",
        "mnist_file_dataset.download(data_folder, overwrite=True)\n",
        "\n",
        "mnist_file_dataset = mnist_file_dataset.register(\n",
        "    workspace=ws,\n",
        "    name=\"mnist_opendataset\",\n",
        "    description=\"training and test dataset\",\n",
        "    create_new_version=True,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612965922274
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take a look at the data\n",
        "Load the compressed files into `numpy` arrays. Then use `matplotlib` to plot 30 random images from the dataset with their labels above them. \n",
        "\n",
        "Note this step requires a `load_data` function that's included in an `utils.py` file. This file is placed in the same folder as this notebook. The `load_data` function simply parses the compressed files into numpy arrays."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import load_data\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "\n",
        "# note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the model converge faster.\n",
        "X_train = (\n",
        "    load_data(\n",
        "        glob.glob(\n",
        "            os.path.join(data_folder, \"**/train-images-idx3-ubyte.gz\"), recursive=True\n",
        "        )[0],\n",
        "        False,\n",
        "    )\n",
        "    / 255.0\n",
        ")\n",
        "X_test = (\n",
        "    load_data(\n",
        "        glob.glob(\n",
        "            os.path.join(data_folder, \"**/t10k-images-idx3-ubyte.gz\"), recursive=True\n",
        "        )[0],\n",
        "        False,\n",
        "    )\n",
        "    / 255.0\n",
        ")\n",
        "y_train = load_data(\n",
        "    glob.glob(\n",
        "        os.path.join(data_folder, \"**/train-labels-idx1-ubyte.gz\"), recursive=True\n",
        "    )[0],\n",
        "    True,\n",
        ").reshape(-1)\n",
        "y_test = load_data(\n",
        "    glob.glob(\n",
        "        os.path.join(data_folder, \"**/t10k-labels-idx1-ubyte.gz\"), recursive=True\n",
        "    )[0],\n",
        "    True,\n",
        ").reshape(-1)\n",
        "\n",
        "\n",
        "# now let's show some randomly chosen images from the traininng set.\n",
        "count = 0\n",
        "sample_size = 30\n",
        "plt.figure(figsize=(16, 6))\n",
        "for i in np.random.permutation(X_train.shape[0])[:sample_size]:\n",
        "    count = count + 1\n",
        "    plt.subplot(1, sample_size, count)\n",
        "    plt.axhline(\"\")\n",
        "    plt.axvline(\"\")\n",
        "    plt.text(x=10, y=-10, s=y_train[i], fontsize=18)\n",
        "    plt.imshow(X_train[i].reshape(28, 28), cmap=plt.cm.Greys)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612965929041
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model and log metrics\n",
        "\n",
        "The model is trained using the code below. You created a new experiment in your workspace, and your training runs and metrics will be registered there so that this information is available after you've finished training your model.\n",
        "\n",
        "You will be using the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier from the [SciKit Learn framework](https://scikit-learn.org/) to classify the data.\n",
        "\n",
        "* **Note: The model training take around 1 minute to complete.**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "reg = 0.5\n",
        "clf = LogisticRegression(\n",
        "    C=1.0 / reg, solver=\"liblinear\", multi_class=\"auto\", random_state=42\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# make predictions using the test set and calculate the accuracy\n",
        "y_hat = clf.predict(X_test)\n",
        "\n",
        "# calculate accuracy on the prediction\n",
        "acc = np.average(y_hat == y_test)\n",
        "print(\"Accuracy is\", acc)\n",
        "\n",
        "run.log(\"regularization rate\", np.float(reg))\n",
        "run.log(\"accuracy\", np.float(acc))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612966046970
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version control your models with the model registry\n",
        "\n",
        "You can use model registration to store and version your models in your workspace. Registered models are identified by name and version. Each time you register a model with the same name as an existing one, the registry increments the version. Azure Machine Learning supports any model that can be loaded through Python 3.\n",
        "\n",
        "The code below does:\n",
        "\n",
        "1. Saves the model to disk\n",
        "1. Uploads the model file to the run \n",
        "1. Registers the uploaded model file\n",
        "1. Transitions the run to a completed state"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from azureml.core.model import Model\n",
        "\n",
        "path = \"sklearn_mnist_model.pkl\"\n",
        "joblib.dump(value=clf, filename=path)\n",
        "\n",
        "run.upload_file(name=path, path_or_stream=path)\n",
        "\n",
        "model = run.register_model(\n",
        "    model_name=\"sklearn_mnist_model\",\n",
        "    model_path=path,\n",
        "    description=\"Mnist handwriting recognition\",\n",
        ")\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612881042710
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View model in the model registry \n",
        "\n",
        "You can see the stored model by navigating to **Models** in the left-hand menu. Click on the **sklearn_mnist_model** and you can see the details of the model, like the experiment run id that created the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model\n",
        "\n",
        "The next cells deploys the model to an Azure Container Instance so that you can score data in real-time (Azure Machine Learning also provides mechanisms to do batch scoring). A real-time endpoint allows application developers to integrate machine learning into their apps.\n",
        "\n",
        "* **Note: The deployment takes around 3 minutes to complete.**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# create environment for the deploy\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# to install required packages\n",
        "env = Environment(\"quickstart-env\")\n",
        "cd = CondaDependencies.create(\n",
        "    pip_packages=[\"azureml-dataset-runtime[pandas,fuse]\", \"azureml-defaults\"],\n",
        "    conda_packages=[\"scikit-learn==0.22.1\"],\n",
        ")\n",
        "\n",
        "env.python.conda_dependencies = cd\n",
        "\n",
        "# Register environment to re-use later\n",
        "env.register(workspace=ws)\n",
        "\n",
        "# create config file\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "aciconfig = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=1,\n",
        "    memory_gb=1,\n",
        "    tags={\"data\": \"MNIST\", \"method\": \"sklearn\"},\n",
        "    description=\"Predict MNIST with sklearn\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612881061728
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import uuid\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.model import Model\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "model = Model(ws, \"sklearn_mnist_model\")\n",
        "\n",
        "\n",
        "myenv = Environment.get(workspace=ws, name=\"quickstart-env\", version=\"1\")\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
        "\n",
        "service_name = \"sklearn-mnist-svc-\" + str(uuid.uuid4())[:4]\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aciconfig,\n",
        ")\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [*scoring script*](score.py) file referenced in the code above can be found in the same folder as this notebook, and has two functions:\n",
        "\n",
        "1. an `init` function that executes once when the service starts - in this function you normally get the model from the registry and set global variables\n",
        "1. a `run(data)` function that executes each time a call is made to the service. In this function, you normally deserialize the json, run a prediction and output the predicted result.\n",
        "\n",
        "\n",
        "## Test the model service\n",
        "\n",
        "You can test the model by sending a raw HTTP request to test the web service. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# scoring web service HTTP endpoint\n",
        "print(service.scoring_uri)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612881527399
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# send raw HTTP request to test the web service.\n",
        "import requests\n",
        "\n",
        "# send a random row from the test set to score\n",
        "random_index = np.random.randint(0, len(X_test) - 1)\n",
        "input_data = '{\"data\": [' + str(list(X_test[random_index])) + \"]}\"\n",
        "\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "# for AKS deployment you'd need to the service key in the header as well\n",
        "# api_key = service.get_key()\n",
        "# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)}\n",
        "\n",
        "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
        "\n",
        "print(\"POST to url\", service.scoring_uri)\n",
        "# print(\"input data:\", input_data)\n",
        "print(\"label:\", y_test[random_index])\n",
        "print(\"prediction:\", resp.text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612881538381
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View the results of your training\n",
        "\n",
        "When you're finished with an experiment run you can always return to view the results of your model training here in the Azure Machine Learning studio:\n",
        "\n",
        "1. Select **Experiments** (left-hand menu)\n",
        "1. Select **sklearn-mnist**\n",
        "1. Select **Run 1**\n",
        "1. Select the **Metrics** Tab\n",
        "\n",
        "The metrics tab will display the parameter values that were logged to the run.\n",
        "\n",
        "### View the model in the model registry\n",
        "\n",
        "You can see the stored model by navigating to **Models** in the left-hand menu bar. Click on the **sklearn_mnist_model** and you can see the details of the model like the experiement run id that created the model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Control cost and clean up resources\n",
        "\n",
        "To clean up the resources after this quickstart, first you delete the Model service using:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to keep workspace and only delete endpoint (it will incur cost while running)\n",
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612881556520
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to control cost further you can also stop the compute instance this notebook is running on by clicking the \"Stop compute\" button next to the status dropdown in the menu above.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "\n",
        "In this quickstart, you have seen how to run your machine learning code in Azure Machine Learning. \n",
        "\n",
        "It is often the case that once you have your machine learning code working in a development environment that you want to productionize this by using the Python SDK and run the code as a **_job_** - ideally on a schedule or trigger (for example, arrival of new data). To this end, we recommend that you follow the next quickstart in this series, [**Learn how to get started with Azure ML Job Submission**](GettingStartedWithPythonSDK.ipynb). This quickstart is focused on running jobs-based machine learning code in the cloud."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8",
      "language": "python",
      "name": "python3.8"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}