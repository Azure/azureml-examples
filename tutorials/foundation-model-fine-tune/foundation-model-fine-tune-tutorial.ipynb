{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to fine tune a foundation model on Azure Machine Learning using SDK v2\n",
    "\n",
    "Fine tuning a [foundational model](https://learn.microsoft.com/en-us/azure/machine-learning/concept-foundation-models?view=azureml-api-2) has several advantages. First of all, a foundation model may not be optimized for your specific use case, and fine tuning would allow you to customize it for your needs and better performance. Secondly, it allows you to incorporate your own data into the model, which can result in better accuracy and more relevant results. Training on your own data could also improve reducing bias and more reflective of the unique characteristics of your domain. Ultimately, it could give you a competitive edge on your product as customizing the model to your specific needs can make a big difference in your product experience. \n",
    "\n",
    "In this tutorial, we will walk you through the steps to fine tune a natural language processing (NLP) model to analyze sentiments expressed in single sentences written in English, using `emotion dataset` and `text-classification` components from the Azure Machine Learning system registry. \n",
    "\n",
    "By the end of this tutorial, you'll have the fine tuned model deployed to an online endpoint for real time inference, which can classify input texts into one of the six emotions: anger, fear, joy, love, sadness, and surprise. Let's get started!  \n",
    "\n",
    "The steps are:\n",
    "\n",
    ">* Pick a model to fine tune\n",
    ">* Setup pre-requisites such as compute\n",
    ">* Pick and explore training data\n",
    ">* Configure & submit the fine tuning job\n",
    ">* Review training and evaluation metrics\n",
    ">* Register the fine tuned model\n",
    ">* Deploy the fine tuned model for real time inference\n",
    ">* Clean up resources\n",
    "\n",
    "**Training data**\n",
    "\n",
    "We will use the [emotion](https://huggingface.co/datasets/dair-ai/emotion) dataset. A copy of this dataset is available in the [emotion-dataset](./emotion-dataset/) folder. \n",
    "\n",
    "**Model**\n",
    "\n",
    "Models that can perform the `fill-mask` task are generally good foundation models to fine tune for `text-classification`. We will use the `bert-base-uncased` model in this notebook. If you opened this notebook from a specific model card, remember to replace the specific model name. Optionally, if you need to fine tune a model that is available on HuggingFace, but not available in `azureml` system registry, you can either [import](https://github.com/Azure/azureml-examples) the model or use the `huggingface_id` parameter instruct the components to pull the model directly from [HuggingFace](https://huggingface.co). \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pick a model to fine tune\n",
    "\n",
    "![alt text](./media/model_catalog.png \"Title\")\n",
    "\n",
    "For `text-classification`, models that support `fill-mask` tasks are good candidates because they're pretrained language models that can understand the context of a given text and predict the missing words or tokens in it. This ability to understand the context of a text and predict missing words make `fill-mask` models highly effective in capturing the meaning of the text and identifying its underlying sentiment or emotion.\n",
    "\n",
    "Let's select a model to fine tune!\n",
    "\n",
    "1. Sign into [Azure Machine Learning studio](ml.azure.com)\n",
    "2. Select `model catalog` on the left navigation bar\n",
    "3. Search for `bert-base-uncased` on the model catalog\n",
    "4. Select the `bert-base-uncased` model to see the model card \n",
    "\n",
    "On the model card, you can find the model name `bert-base-uncased`. This is the only reference you need in order to fine tune the model on the Notebook using SDK v2. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set up your workstation for fine tuning\n",
    "\n",
    "Let's set up your workstation so you can use `Azure Machine Learning SDK v2` to fine tune the model. Follow these steps: \n",
    "\n",
    "#### 1. Install dependencies.\n",
    "\n",
    "Install dependencies by running the next cell. This isn't an optional step if running in a new environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml\n",
    "%pip install azure-identity\n",
    "%pip install datasets==2.9.0\n",
    "%pip install mlflow\n",
    "%pip install azureml-mlflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create handle to workspace\n",
    "Before we dive in the code, you need a way to reference your workspace. Create `ml_client` for a handle to the workspace. Then use `ml_client` to manage resources and jobs.\n",
    "\n",
    "In the next cell, enter your `Subscription ID`, `Resource Group` name and `Workspace` name. To find these values:\n",
    "\n",
    "- In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
    "- Copy the value for workspace, resource group and subscription ID into the code.\n",
    "- You'll need to copy one value, close the area and paste, then come back for the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "# authenticate\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group_name=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<WORKSPACE_NAME>\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Connect to `azureml` system registry & import the model\n",
    "\n",
    "In order to access the preregistered foundation models hosted on the model catalog, you need to connect to `azureml` registry. Run the next cell to connect to the system registry and import the `bert-base-uncased` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# This line of code connects to the azureml system registry that allows you access foundation models, fine tuning pipelines, and environments.\n",
    "registry_ml_client = MLClient(credential, registry_name=\"azureml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Let's import the model we chose earlier.\n",
    "model_name = \"bert-base-uncased\"\n",
    "model_version = \"1\" # If you want to use a specific version of the model, use a different number.\n",
    "foundation_model = registry_ml_client.models.get(model_name, model_version)\n",
    "print(\n",
    "    \"\\n\\nUsing model name: {0}, version: {1}, id: {2} for fine tuning\".format(\n",
    "        foundation_model.name, foundation_model.version, foundation_model.id\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Set an optional experiment name\n",
    "This step is optional but useful if you want to find this fine tuning job easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = \"text-classification-emotion-detection\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Check or create a compute cluster\n",
    "For fine tuning tasks, you need a GPU compute cluster for the best results. The duration of the fine tuning depends on the capacity of the GPU SKU you choose. That is because a single GPU node can have multiple GPU cards. \n",
    "\n",
    "For example, in one node of `Standard_ND40rs_v2` there are eight NVIDIA GPUs. Meanwhile in `Standard_NC12s_v2` there are two NVIDIA V100 GPUs. When all GPUs in the node get utilized (by configuring the parameter in `gpus_per_node`), you get the most efficient fine tune run. You can read more about Azure's [GPU optimized VM offerings](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu) and the recommended compute SKUs ([ncv3-series](https://learn.microsoft.com/en-us/azure/virtual-machines/ncv3-series), [ndv2-series](https://learn.microsoft.com/en-us/azure/virtual-machines/ndv2-series)).\n",
    "\n",
    "In this tutorial, you'll use `Standard_NC6s_v3` which takes about 15-20 m to complete the fine tuning run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "import time\n",
    "\n",
    "# If you already have a gpu cluster, mention it here. Else will create a new one with the name 'gpu-cluster-big'\n",
    "compute_cluster = \"gpu-cluster-big\"\n",
    "try:\n",
    "    compute = workspace_ml_client.compute.get(compute_cluster)\n",
    "except Exception as ex:\n",
    "    compute = AmlCompute(\n",
    "        name=compute_cluster,\n",
    "        size=\"Standard_NC6s_v3\", # If you run into an out of quota error, change to a comparable SKU.\n",
    "        max_instances=2,  # For multi node training set this to an integer value more than 1\n",
    "    )\n",
    "    workspace_ml_client.compute.begin_create_or_update(compute).wait()\n",
    "\n",
    "# NC6s_v2 has 1 node. Change this if you are using a different SKU.\n",
    "gpus_per_node = 1 \n",
    "\n",
    "# If gpu_count_found not found, then print an error\n",
    "if gpu_count_found:\n",
    "    print(f\"Number of GPU's in compute {compute.size}: {gpus_per_node}\")\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Number of GPU's in compute {compute.size} not found. Available skus are: {available_sku_sizes}.\"\n",
    "        f\"This should not happen. Please check the selected compute cluster: {compute_cluster} and try again.\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare the dataset for fine-tuning the model\n",
    "\n",
    "There are two options to prepare the dataset for fine tuning. The first option is to choose the fine tune option on the model catalog where you found ` bert-base-uncased` model earlier. The second option is to prepare a dataset that matches your use case for fine tuning. This tutorial focuses on the second option.  \n",
    "\n",
    "You're going to use the [emotion](https://huggingface.co/datasets/dair-ai/emotion) dataset. You can find a copy of this dataset in the emotion-dataset folder that came with this notebook. \n",
    "\n",
    "#### 1. Visualize some data rows\n",
    "It's important to understand the data and its features. Let's start by taking a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# Set the max column width to 0 to display the full text\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", 0\n",
    ") \n",
    "\n",
    "# Load the ./emotion-dataset/train.jsonl file into a pandas dataframe and show the first 5 rows \n",
    "df = pd.read_json(\"./emotion-dataset/train.jsonl\", lines=True)\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Replace numerical categories in data with the actual string labels\n",
    "\n",
    "This data set uses numerical categories. For example, 0 refers to `sadness`. To get string labels such as `anger`, `joy`, etc., replace the categories. Run the next cell to get the string labels.\n",
    "\n",
    "You can see the detailed mapping in the [./emotion-dataset/label.json](./emotion-dataset/label.json). If you skip this step, the model returns numerical categories such as 0, 1, 2, etc. and you have to map them to what the category represents yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load the id2label json element of the ./emotion-dataset/label.json file into pandas table with keys as 'label' column of int64 type and values as 'label_string' column as string type\n",
    "import json\n",
    "\n",
    "with open(\"./emotion-dataset/label.json\") as f:\n",
    "    id2label = json.load(f)\n",
    "    id2label = id2label[\"id2label\"]\n",
    "    label_df = pd.DataFrame.from_dict(\n",
    "        id2label, orient=\"index\", columns=[\"label_string\"]\n",
    "    )\n",
    "    label_df[\"label\"] = label_df.index.astype(\"int64\")\n",
    "    label_df = label_df[[\"label\", \"label_string\"]]\n",
    "label_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load test.jsonl, train.jsonl and validation.jsonl form the ./emotion-dataset folder into pandas dataframes\n",
    "test_df = pd.read_json(\"./emotion-dataset/test.jsonl\", lines=True)\n",
    "train_df = pd.read_json(\"./emotion-dataset/train.jsonl\", lines=True)\n",
    "validation_df = pd.read_json(\"./emotion-dataset/validation.jsonl\", lines=True)\n",
    "\n",
    "# Join the train, validation and test dataframes with the id2label dataframe to get the label_string column\n",
    "train_df = train_df.merge(label_df, on=\"label\", how=\"left\")\n",
    "validation_df = validation_df.merge(label_df, on=\"label\", how=\"left\")\n",
    "test_df = test_df.merge(label_df, on=\"label\", how=\"left\")\n",
    "\n",
    "# Show the first 5 rows of the train dataframe\n",
    "train_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Save data\n",
    "Now the string labels are applied, let's save the dataset.\n",
    "\n",
    "For the fine tuning tutorial demonstration purposes, you're going to save a smaller dataset containing 10% of the original dataset into `train`, `validation` and `test` files. **Keep in mind that the fine tuned model will have lower accuracy, hence it should not be put to real-world use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save 10% of the rows from the train, validation and test dataframes into files with small_ prefix in the ./emotion-dataset folder\n",
    "train_df.sample(frac=0.1).to_json(\n",
    "    \"./emotion-dataset/small_train.jsonl\", orient=\"records\", lines=True\n",
    ")\n",
    "validation_df.sample(frac=0.1).to_json(\n",
    "    \"./emotion-dataset/small_validation.jsonl\", orient=\"records\", lines=True\n",
    ")\n",
    "test_df.sample(frac=0.1).to_json(\n",
    "    \"./emotion-dataset/small_test.jsonl\", orient=\"records\", lines=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Configure and submit the fine tuning job using the model and data as inputs\n",
    "\n",
    "To submit a fine tuning job using a foundation model, you're going to build a pipeline. There are two reasons for using a pipeline. \n",
    "\n",
    "First, since you're fine tuning an existing foundation model, you may not have access to the training code. Azure Machine Learning can generate the training code, which is hosted in the `azureml` registry, which requires using a pipeline. Second, fine tuning job requires several steps, including tokenization, converting English text to numeric representation, passing tokenized data to fine tune, and evaluation. It would make sense to componentize these discrete steps, building a pipeline.\n",
    "\n",
    "You're going to create a job that uses the `text-classification` pipeline component. [Learn more]() about all the parameters supported for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import CommandComponent, PipelineComponent, Job, Component\n",
    "from azure.ai.ml import PyTorchDistribution, Input\n",
    "\n",
    "# Fetch the pipeline component\n",
    "pipeline_component_func = registry_ml_client.components.get(\n",
    "    name=\"text_classification_pipeline\", label=\"latest\"\n",
    ")\n",
    "\n",
    "# Define the pipeline job\n",
    "@pipeline()\n",
    "def create_pipeline():\n",
    "    finetuning_job = pipeline_component_func(\n",
    "        # Specify the foundation model available in the azureml system registry id identified in step #1\n",
    "        mlflow_model_path=foundation_model.id,\n",
    "        # Huggingface_id = 'bert-base-uncased', # if you want to use a huggingface model, uncomment this line and comment the above line\n",
    "        compute_model_import=compute_cluster,\n",
    "        compute_preprocess=compute_cluster,\n",
    "        compute_finetune=compute_cluster,\n",
    "        compute_model_evaluation=compute_cluster,\n",
    "        # Map the dataset splits to parameters\n",
    "        train_file_path=Input(\n",
    "            type=\"uri_file\", path=\"./emotion-dataset/small_train.jsonl\"\n",
    "        ),\n",
    "        validation_file_path=Input(\n",
    "            type=\"uri_file\", path=\"./emotion-dataset/small_validation.jsonl\"\n",
    "        ),\n",
    "        test_file_path=Input(\n",
    "            type=\"uri_file\", path=\"./emotion-dataset/small_test.jsonl\"\n",
    "        ),\n",
    "        # Evaluation_config=Input(\n",
    "        #     type=\"uri_file\", path=\"./text-classification-config.json\"\n",
    "        # ),\n",
    "        # The following parameters map to the dataset fields\n",
    "        sentence1_key=\"text\",\n",
    "        label_key=\"label_string\",\n",
    "        # Training settings\n",
    "        number_of_gpu_to_use_finetuning=gpus_per_node,  # set to the number of GPUs available in the compute\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=2e-5,\n",
    "    )\n",
    "    return {\n",
    "        # Map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model\n",
    "        # Registering the model is required to deploy the model to an online or batch endpoint\n",
    "        \"trained_model\": finetuning_job.outputs.mlflow_model_folder\n",
    "    }\n",
    "\n",
    "\n",
    "pipeline_object = create_pipeline()\n",
    "\n",
    "# Don't use cached results from previous jobs\n",
    "pipeline_object.settings.force_rerun = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the pipeline job is configured, let's submit the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Submit the pipeline job\n",
    "pipeline_job = workspace_ml_client.jobs.create_or_update(\n",
    "    pipeline_object, experiment_name=experiment_name\n",
    ")\n",
    "# Wait for the pipeline job to complete\n",
    "workspace_ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Review training and evaluation metrics\n",
    "\n",
    "Now the pipeline job is submitted, you can view the job in Azure Machine Learning studio to analyze logs, metrics, and outputs of jobs. This way, you can create custom charts and compare metrics across different fine tuning jobs. See this [doc](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics?tabs=interactive#view-jobsruns-information-in-the-studio) to learn more about job metrics.\n",
    "\n",
    "You may also want to programmatically log the same information so that it can be used by other services. In that case, use the following MLflow code, which is the recommended client for logging and querying metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# This is optional code if you want to programmatically log the metrics to be used by other services.\n",
    "import mlflow, json\n",
    "\n",
    "mlflow_tracking_uri = workspace_ml_client.workspaces.get(\n",
    "    workspace_ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "# Concatenate 'tags.mlflow.rootRunId=' and pipeline_job.name in single quotes as a filter variable\n",
    "filter = \"tags.mlflow.rootRunId='\" + pipeline_job.name + \"'\"\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[experiment_name], filter_string=filter, output_format=\"list\"\n",
    ")\n",
    "training_run = None\n",
    "evaluation_run = None\n",
    "# Get the training and evaluation runs.\n",
    "# CONFIRMATION NEEDED: Using a hacky way till 'Bug 2320997: not able to show eval metrics in FT notebooks - mlflow client now showing display names' is fixed\n",
    "for run in runs:\n",
    "    # Check if run.data.metrics.epoch exists\n",
    "    if \"epoch\" in run.data.metrics:\n",
    "        training_run = run\n",
    "    # Else, check if run.data.metrics.accuracy exists\n",
    "    elif \"accuracy\" in run.data.metrics:\n",
    "        evaluation_run = run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if training_run:\n",
    "    print(\"Training metrics:\\n\\n\")\n",
    "    print(json.dumps(training_run.data.metrics, indent=2))\n",
    "else:\n",
    "    print(\"No Training job found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if evaluation_run:\n",
    "    print(\"Evaluation metrics:\\n\\n\")\n",
    "    print(json.dumps(evaluation_run.data.metrics, indent=2))\n",
    "else:\n",
    "    print(\"No Evaluation job found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Register the fine tuned model with the workspace\n",
    "\n",
    "Register the model from the output of the fine tuning job. There are several benefits to register a fine tuned model to the Azure Machine Learning platform.\n",
    " \n",
    "- **Versioning & Traceability**: Tracks lineage between the fine tuned model and the fine tuning job. The fine tuning job, further, tracks lineage to the foundation model, data and training code.\n",
    "\n",
    "- **Reusability**: Once a model is registered, it can be reused across different experiments, pipelines, and deployments. This eliminates the need to recreate the model each time and saves time and effort.\n",
    "\n",
    "- **Collaboration**: Registered models can be easily shared with other team members, making it easier to collaborate on machine learning projects. This enables team members to work together on the same model and share their insights and feedback. \n",
    "\n",
    "- **Deployment**: Registered models can be easily deployed to production environments, making it easier to integrate machine learning models into business applications. Azure Machine Learning provides several deployment options, including Azure Kubernetes Service, Azure Container Instances, and Azure Functions. \n",
    "\n",
    "- **Monitoring**: Registered models can be monitored and evaluated over time to ensure that they continue to perform well in production environments. This enables you to detect and address issues early on and maintain the performance of your machine learning models.\n",
    "\n",
    "Use the following code to register the fine tuned model. Once registered, you can find the model under the Models tab of Azure Machine Learning studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Generating a unique timestamp that can be used for names and versions that need to be unique\n",
    "timestamp = str(int(time.time()))\n",
    "\n",
    "# Check if the `trained_model` output is available\n",
    "print(\"pipeline job outputs: \", workspace_ml_client.jobs.get(pipeline_job.name).outputs)\n",
    "\n",
    "# Fetch the model from pipeline job output - not working, hence fetching from fine tune child job\n",
    "model_path_from_job = \"azureml://jobs/{0}/outputs/{1}\".format(\n",
    "    pipeline_job.name, \"trained_model\"\n",
    ")\n",
    "\n",
    "finetuned_model_name = model_name + \"-emotion-detection\"\n",
    "finetuned_model_name = finetuned_model_name.replace(\"/\", \"-\")\n",
    "print(\"path to register model: \", model_path_from_job)\n",
    "prepare_to_register_model = Model(\n",
    "    path=model_path_from_job,\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    name=finetuned_model_name,\n",
    "    version=timestamp,  # Use timestamp as version to avoid version conflict\n",
    "    description=model_name + \" fine tuned model for emotion detection\",\n",
    ")\n",
    "\n",
    "print(\"prepare to register model: \\n\", prepare_to_register_model)\n",
    "\n",
    "# Register the model from pipeline job output\n",
    "registered_model = workspace_ml_client.models.create_or_update(\n",
    "    prepare_to_register_model\n",
    ")\n",
    "\n",
    "print(\"registered model: \\n\", registered_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Deploy the fine tuned model to an online endpoint\n",
    "Online endpoints give a durable REST API that can be used to integrate with applications that need to use the model. In this tutorial, you're going to use Managed Online Endpoint API, which handles many backend configurations for you.\n",
    "\n",
    "Let's start by creating an online endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import time, sys\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "\n",
    "# Create online endpoint - endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
    "online_endpoint_name = \"emotion-\" + timestamp\n",
    "\n",
    "# Create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"Online endpoint for \"\n",
    "    + registered_model.name\n",
    "    + \", fine tuned model for emotion detection\",\n",
    "    auth_mode=\"key\",\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying a model requires a compute resource. In this tutorial, you're going to use `Standard_DS3_v2` which takes about X minutes to complete the deployment. \n",
    "\n",
    "You can also read about [the list of other SKUs supported for deployment](https://learn.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a deployment\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=\"demo\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_DS3_v2\", # If you run into an out of quota error, change to a comparable SKU.\n",
    "    instance_count=1,\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {\"demo\": 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test the endpoint with sample data\n",
    "\n",
    "Now the fine tuned model is deployed, we need to test if the model is working properly. You'llfirst fetch some sample data from the test dataset, and save as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Read ./emotion-dataset/small_test.jsonl into a pandas dataframe\n",
    "test_df = pd.read_json(\"./emotion-dataset/small_test.jsonl\", lines=True)\n",
    "\n",
    "# Take 10 random samples\n",
    "test_df = test_df.sample(n=10)\n",
    "\n",
    "# Rebuild index\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rename the label_string column to ground_truth_label\n",
    "test_df = test_df.rename(columns={\"label_string\": \"ground_truth_label\"})\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a json object with the key as \"inputs\" and value as a list of values from the text column of the test dataframe\n",
    "test_json = {\"inputs\": {\"input_string\": test_df[\"text\"].tolist()}}\n",
    "\n",
    "# Save the json object to a file named sample_score.json in the ./emotion-dataset folder\n",
    "with open(\"./emotion-dataset/sample_score.json\", \"w\") as f:\n",
    "    json.dump(test_json, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a sample data, let's test the online endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Score the sample_score.json file using the online endpoint with the azureml endpoint invoke method\n",
    "response = workspace_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=\"demo\",\n",
    "    request_file=\"./emotion-dataset/sample_score.json\",\n",
    ")\n",
    "print(\"raw response: \\n\", response, \"\\n\")\n",
    "\n",
    "# Convert the response to a pandas dataframe and rename the label column as scored_label\n",
    "response_df = pd.read_json(response)\n",
    "response_df = response_df.rename(columns={0: \"scored_label\"})\n",
    "response_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the test dataframe and the response dataframe on the index\n",
    "merged_df = pd.merge(test_df, response_df, left_index=True, right_index=True)\n",
    "merged_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Delete the online endpoint\n",
    "Congratulation! You have completed the foundational model fine tuning tutorial.\n",
    "\n",
    "Don't forget to delete the online endpoint, else you'll leave the billing meter running for the compute used by the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# This code deletes the endpoint\n",
    "ml_client.online_endpoints.begin_delete(name=online_endpoint_name).result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
