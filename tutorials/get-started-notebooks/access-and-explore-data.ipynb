{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Upload, access and explore your data in Azure Machine Learning\n",
        "\n",
        "In this tutorial you'll learn how to:\n",
        "\n",
        "> * Upload your data to cloud storage\n",
        "> * Create an Azure ML data asset\n",
        "> * Access your data in a notebook for interactive development\n",
        "> * Create new versions of data assets\n",
        "\n",
        "The start of a machine learning project typically involves exploratory data analysis (EDA), data-preprocessing (cleaning, feature engineering), and the building of Machine Learning model prototypes to validate hypotheses. This _prototyping_ project phase is highly interactive. It lends itself to development in an IDE or a Jupyter notebook, with a _Python interactive console_. This tutorial will describe these ideas.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "**_Note: Update the link when Sheri is done with the pre-req docs_**\n",
        "\n",
        "* Select **Python 3.10 - SDK V2** in the upper right dropdown\n",
        "\n",
        "* Complete the [Quickstart: Get started with Azure Machine Learning](quickstart-create-resources.md) to:\n",
        "  * Create a workspace.\n",
        "  * Create a cloud-based compute instance to use for your development environment.\n",
        "\n",
        "### Download the data used in this tutorial\n",
        "\n",
        "For data ingestion, the Azure Data Explorer handles raw data in [these](https://learn.microsoft.com/en-us/azure/data-explorer/ingestion-supported-formats) formats. This tutorial will use this [CSV-format credit card client data sample](https://azuremlexamples.blob.core.windows.net/datasets/credit_card/default_of_credit_card_clients.csv). We'll see the steps proceed in an Azure Machine Learning resource. In that resource, we'll create a local folder with the suggested name of **get-started-notebooks**.\n",
        "\n",
        "> [!NOTE]\n",
        "> This tutorial depends on data placed in an Azure ML resource directory location. For this tutorial, 'local' means a directory location in that Azure ML resource. \n",
        "\n",
        "This image shows the Azure ML Files (directory) panel:\n",
        "\n",
        "![Files (directory) panel](20230209_img_1.png)\n",
        "\n",
        "The next step relies on the Azure ML terminal window. To use this feature, first select Open Terminal below the three dots, as shown in this image:\n",
        "\n",
        "![Files (directory) panel](20230209_img_2.png)\n",
        "\n",
        "The terminal window will open in a new tab. You can type terminal commands at the highlighted command prompt, shown in this image:\n",
        "\n",
        "![Files (directory) panel](20230209_img_3.png)\n",
        "\n",
        "Upload the data to your compute instance after you download it, or use this command in the terminal window to get the file:\n",
        "\n",
        "```\n",
        "cd get-started-notebooks # cd to the location you would like to store the data\n",
        "wget https://azuremlexamples.blob.core.windows.net/datasets/credit_card/default_of_credit_card_clients.csv\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "[Learn more about this data on the UCI Machine Learning Repository.](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)\n",
        "\n",
        "## Connect to the workspace\n",
        "\n",
        "Before you dive in the code, you'll need to connect to your Azure ML workspace. \n",
        "\n",
        "We're using `DefaultAzureCredential` to get access to workspace. \n",
        "`DefaultAzureCredential` is used to handle most Azure SDK authentication scenarios. \n",
        "\n",
        "Reference for more available credentials if it doesn't work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/python/api/azure-identity/azure.identity?view=azure-python).\n",
        "\n",
        "In this cell, enter your Subscription ID, Resource Group name and Workspace name. To find these values:\n",
        "\n",
        "1. In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
        "1. Copy the value for workspace, resource group and subscription ID into the code.  \n",
        "1. You'll need to copy one value, close the area and paste, then come back for the next one."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
        "    resource_group_name=\"<RESOURCE_GROUP>\",\n",
        "    workspace_name=\"<AML_WORKSPACE_NAME>\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1675966726847
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Upload data to cloud storage\n",
        "\n",
        "Azure ML uses Uniform Resource Identifiers (URIs), which point to storage locations in the cloud. A URI makes it easy to access data in notebooks and jobs. Data URI formats look similar to the web URL's that you use in your web browser to access web pages. For example:\n",
        "\n",
        "* Access data from public https server: `https://<account_name>.blob.core.windows.net/<container_name>/<folder>/<file>`\n",
        "* Access data from Azure Data Lake Gen 2: `abfss://<file_system>@<account_name>.dfs.core.windows.net/<folder>/<file>`\n",
        "\n",
        "An Azure ML data asset is similar to web browser bookmarks (favorites). Instead of remembering long storage paths (URIs) that point to your most frequently used data, you can create a data asset, and then access that asset with a friendly name.\n",
        "\n",
        "Data asset creation also creates a *reference* to the data source location, along with a copy of its metadata. Because the data remains in its existing location, you incur no extra storage cost, and don't risk data source integrity. You can create Data assets from Azure ML datastores, Azure Storage, public URLs, and local files.\n",
        "\n",
        "> [!TIP]\n",
        "> For smaller-size data uploads, Azure ML data asset creation works well for data uploads from local machine resources to cloud storage. This approach avoids the need for extra tools or utilities. However, a larger-size data upload might require a dedicated tool or utility - for example, **azcopy**. The azcopy command-line tool moves data to and from Azure Storage. Learn more about [azcopy](https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10).\n",
        "\n",
        "The next notebook cell creates the data asset. Here, the code sample will upload the raw data file to the designated cloud storage resource. This upload operation requires unique **version** and **name** properties in the **my_data** block. Otherwise, the cell will fail. To run this cell code more than once with the same **name** value, change the **version** value each time you run the code. As another workaround, you can also comment out the **version** value. This approach will create new data asset each time the cell runs, and it will auto-increment the version numbers of those versions, starting from 1:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# update <path> to be the location of where you downloaded the data on your\n",
        "# local filesystem\n",
        "\n",
        "# NOTE: we could call out if user should update the path accordingly\n",
        "my_path = './get-started-notebooks/default_of_credit_card_clients.csv'\n",
        "\n",
        "# define the data asset\n",
        "\n",
        "# The version value is optional in this statement. Without it, this code\n",
        "# can re-execute this cell with the given name and version values.\n",
        "# In this case, AutoML will create new data assets each time the cell\n",
        "# executes, and it will auto-increment the version number of those\n",
        "# data assets, starting from 1.\n",
        "\n",
        "my_data = Data(\n",
        "    name=\"credit-cardss\",\n",
        "    version=\"2\",\n",
        "    description=\"Credit card data\",\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        ")\n",
        "\n",
        "# create data asset\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1675461156382
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "You'll notice that the data has been uploaded to the default Azure ML _Datastore_. An Azure Machine Learning datastore is a _reference_ to an _existing_ storage account on Azure. A datastore offers these benefits:\n",
        "\n",
        "1. A common and easy-to-use API, to interact with different storage types (Blob/Files/ADLS) and authentication methods.\n",
        "1. An easier way to discover useful datastores, when working as a team.\n",
        "1. In your scripts, a way to hide connection information for credential-based data access (service principal/SAS/key).\n",
        "\n",
        "\n",
        "\n",
        "## Accessing your data in a notebook\n",
        "\n",
        "Pandas directly support URIs - this example shows how to read a CSV file from an Azure ML Datastore:\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"azureml://subscriptions/<subid>/resourcegroups/<rgname>/workspaces/<workspace_name>/datastores/<datastore_name>/paths/<folder>/<filename>.csv\")\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, as mentioned previously, it can become hard to remember these URIs. Additionally, you must manually substitute all **<_substring_>** values in the **pd.read_csv** command with the real values for your resources. You'll want to create data assets for frequently accessed data. This Python code shows how to access the CSV file in Pandas:\n",
        "\n",
        "> [!IMPORTANT]\n",
        "> In a notebook cell, execute this code to install the `azureml-fsspec` Python library in your Jupyter kernel:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U azureml-fsspec"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Note: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# get a handle of the data asset and print the URI\n",
        "data_asset = ml_client.data.get(name=\"credit-card\", version=\"1\")\n",
        "print(f'Data asset URI: {data_asset.path}')\n",
        "\n",
        "# read into pandas - note that you will see 2 headers in your data frame - that is ok, for now\n",
        "\n",
        "df = pd.read_csv(data_asset.path)\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675445030495
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read [Access data from Azure cloud storage during interactive development](how-to-access-data-interactive.md) to learn more about data access in a notebook.\n",
        "\n",
        "## Create a new version of the data asset\n",
        "\n",
        "You might have noticed that the data needs a little light cleaning, to make it fit to train a machine learning model. It has:\n",
        "\n",
        "* two headers\n",
        "* a client ID column; we would not use this feature in Machine Learning\n",
        "* spaces in the response variable name\n",
        "\n",
        "Also, compared to the CSV format, the Parquet file format becomes a better way to store this data. Parquet offers compression, and it maintains schema. Therefore, to clean the data and store it in Parquet, use:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in data again, this time using the 2nd row as the header\n",
        "df = pd.read_csv(data_asset.path, header=1)\n",
        "# rename column\n",
        "df.rename(columns={'default payment next month': 'default'}, inplace=True)\n",
        "# remove ID column\n",
        "df.drop('ID', axis=1, inplace=True)\n",
        "\n",
        "# write file to filesystem\n",
        "df.to_parquet('./cleaned-credit-card.parquet')"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675445038545
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data dictionary\n",
        "\n",
        "The uploaded data contains 23 explanatory variables and 1 response variable, as mapped in the Table below:\n",
        "\n",
        "|Column Name(s) | Variable Type  |Description  |\n",
        "|---------|---------|---------|\n",
        "|X1     |   Explanatory      |    Amount of the given credit (NT dollar): it includes both the individual consumer credit and their family (supplementary) credit.    |\n",
        "|X2     |   Explanatory      |   Gender (1 = male; 2 = female).      |\n",
        "|X3     |   Explanatory      |   Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).      |\n",
        "|X4     |   Explanatory      |    Marital status (1 = married; 2 = single; 3 = others).     |\n",
        "|X5     |   Explanatory      |    Age (years).     |\n",
        "|X6-X11     | Explanatory        |  History of past payment. We tracked the past monthly payment records (from April to September  2005). -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.      |\n",
        "|X12-17     | Explanatory        |  Amount of bill statement (NT dollar) from April to September  2005.      |\n",
        "|X18-23     | Explanatory        |  Amount of previous payment (NT dollar) from April to September  2005.      |\n",
        "|Y     | Response        |    Default payment (Yes = 1, No = 0)     |\n",
        "\n",
        "Next, create a new _version_ of the data asset (the data will automatically upload to cloud storage):\n",
        "\n",
        "> [!NOTE]\n",
        ">\n",
        "> * This Python code cell sets **name** and **version** values for the data asset it creates. As a result, the code in this cell will fail if executed more than once, without a change to these values. Fixed **name** and **version** values offer a way to pass values that work for specific situations, without concern for auto-generated or randomly-generated values.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, create a new *version* of the data asset (the data is automatically uploaded to cloud storage):\n",
        "\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './cleaned-credit-card.parquet'\n",
        "\n",
        "# Define the data asset, and use tags to make it clear the asset can be used in training\n",
        "\n",
        "# Note: we will brainstorm what's the best way to do the comment below\n",
        "\n",
        "# The version value is optional in this statement. Without it, this code\n",
        "# can re-execute this cell with the given name and version values.\n",
        "# In this case, AutoML will create new data assets each time the cell\n",
        "# executes, and it will auto-increment the version number of those\n",
        "# data assets, starting from 1.\n",
        "\n",
        "my_data = Data(\n",
        "    name=\"credit-card\",\n",
        "    version=\"2\",\n",
        "    description=\"Default of credit card clients data.\",\n",
        "    tags={\n",
        "        \"training_data\": \"true\",\n",
        "        \"format\": \"parquet\"\n",
        "    },\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE\n",
        ")\n",
        "\n",
        "## create the data asset\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675382989789
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "The cleaned parquet file is the latest version data source. This code shows the CSV version result set first, then the Parquet version:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# get a handle of the data asset and print the URI\n",
        "data_asset_v1 = ml_client.data.get(name=\"credit-card\", version=\"1\")\n",
        "data_asset_v2 = ml_client.data.get(name=\"credit-card\", version=\"2\")\n",
        "\n",
        "# print the v1 data\n",
        "print(f'V1 Data asset URI: {data_asset_v1.path}')\n",
        "v1df = pd.read_csv(data_asset_v1.path)\n",
        "print(v1df.head(5))\n",
        "\n",
        "#print the v2 data\n",
        "print(\"_____________________________________________________________________________________________________________\\n\")\n",
        "print(f'V2 Data asset URI: {data_asset_v2.path}')\n",
        "v2df = pd.read_parquet(data_asset_v2.path)\n",
        "print(v2df.head(5))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "V1 Data asset URI: azureml://subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/fbs-rg/workspaces/FBS-Workspace/datastores/workspaceblobstore/paths/UI/2022-12-15_223329_UTC/default_of_credit_card_clients.csv\n  Unnamed: 0         X1   X2         X3        X4   X5     X6     X7     X8  \\\n0         ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3   \n1          1      20000    2          2         1   24      2      2     -1   \n2          2     120000    2          2         2   26     -1      2      0   \n3          3      90000    2          2         2   34      0      0      0   \n4          4      50000    2          2         1   37      0      0      0   \n\n      X9  ...        X15        X16        X17       X18       X19       X20  \\\n0  PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3   \n1     -1  ...          0          0          0         0       689         0   \n2      0  ...       3272       3455       3261         0      1000      1000   \n3      0  ...      14331      14948      15549      1518      1500      1000   \n4      0  ...      28314      28959      29547      2000      2019      1200   \n\n        X21       X22       X23                           Y  \n0  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n1         0         0         0                           1  \n2      1000         0      2000                           1  \n3      1000      1000      5000                           0  \n4      1100      1069      1000                           0  \n\n[5 rows x 25 columns]\n_____________________________________________________________________________________________________________\n\nV2 Data asset URI: azureml://subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/fbs-rg/workspaces/FBS-Workspace/datastores/workspaceblobstore/paths/LocalUpload/972d801ec6250defbf94d7aa5bc433e1/cleaned-credit-card.parquet\n   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n0      20000    2          2         1   24      2      2     -1     -1   \n1     120000    2          2         2   26     -1      2      0      0   \n2      90000    2          2         2   34      0      0      0      0   \n3      50000    2          2         1   37      0      0      0      0   \n4      50000    1          2         1   57     -1      0     -1      0   \n\n   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n0     -2  ...          0          0          0         0       689         0   \n1      0  ...       3272       3455       3261         0      1000      1000   \n2      0  ...      14331      14948      15549      1518      1500      1000   \n3      0  ...      28314      28959      29547      2000      2019      1200   \n4      0  ...      20940      19146      19131      2000     36681     10000   \n\n   PAY_AMT4  PAY_AMT5  PAY_AMT6  default  \n0         0         0         0        1  \n1      1000         0      2000        1  \n2      1000      1000      5000        0  \n3      1100      1069      1000        0  \n4      9000       689       679        0  \n\n[5 rows x 24 columns]\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675383001940
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        "Read [Create data assets](how-to-create-data-assets.md) for more information about data assets.\n",
        "\n",
        "Read [Create datastores](how-to-datastore.md) to learn more about datastores.\n",
        "\n",
        "Now, you can train a model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "52018653a280796ddf8e50b3c9e20a616cd949148570d3142cd79b620301346b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}