{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Internal notes\n",
        "- descriptions should be refined a lot\n",
        "- not tested for work\n",
        "\n",
        "# Open Questions\n",
        "- Do we include two deployments (blue/green)?\n",
        "- Do we check the status of the deployment after testing (sending a sample data)\n",
        "    - described in [Azure ML Tutorial Work Sheet_MIR.docx](https://microsoft-my.sharepoint.com/:w:/p/saoh/EaMP222FLapPjqcMot-zWCwBBUy0RyCXGDOolxsMmhSwAg?e=zfOqvf&ovuser=72f988bf-86f1-41af-91ab-2d7cd011db47%2Cshnagata%40microsoft.com&clickparams=eyJBcHBOYW1lIjoiVGVhbXMtRGVza3RvcCIsIkFwcFZlcnNpb24iOiIyNy8yMjExMjkxNzQwMCIsIkhhc0ZlZGVyYXRlZFVzZXIiOmZhbHNlfQ%3D%3D)\n",
        "    - I think check the status before testing (right after the deploying) is better (shohei)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Deploy the model as an online endpoint\n",
        "\n",
        "Now deploy your machine learning model as a web service in the Azure cloud, an [`online endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-endpoints).\n",
        "\n",
        "To deploy a machine learning service, you usually need:\n",
        "\n",
        "* The model assets (file, metadata) that you want to deploy. You've already registered these assets in your training job.\n",
        "* Some code to run as a service. The code executes the model on a given input request. This entry script receives data submitted to a deployed web service and passes it to the model, then returns the model's response to the client. The script is specific to your model. The entry script must understand the data that the model expects and returns. With an MLFlow model, as in this tutorial, this script is automatically created for you. Samples of scoring scripts can be found [here](https://github.com/Azure/azureml-examples/tree/sdk-preview/sdk/endpoints/online).\n",
        "\n",
        "## Prerequisites\n",
        "If you already completed tutorial 5, you have everything you need.\n",
        "\n",
        "If you’re starting from here, you need to do the following: \n",
        "\n",
        "- Create a workspace, create compute resource,  \n",
        "- Configure the environment: Dev environment would be set up in article 2. Skip if you have already done it. If you haven’t done it, go read tutorial 2. We probably want to make it explicit what additional environment configuration is needed for inferencing. \n",
        "- We’ll provide the model files ~~(they’ll register later)~~. \n",
        "- Make sure to have enough quota for the compute resources (VM SKUs) \n",
        "\n",
        "## Connect to the workspace (configure auth)\n",
        "Before you dive in the code, you'll need to connect to your Azure ML workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
        "\n",
        "We're using `DefaultAzureCredential` to get access to workspace. \n",
        "`DefaultAzureCredential` is used to handle most Azure SDK authentication scenarios. \n",
        "\n",
        "Reference for more available credentials if it doesn't work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/python/api/azure-identity/azure.identity?view=azure-python)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"f66b853e-91bc-4852-9a4e-506ac873520a\",\n",
        "    resource_group_name=\"rg-azureml\",\n",
        "    workspace_name=\"ml-lab\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import required AzureML libraries for model deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import libraries\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check what you need\n",
        "Again, these resources are needed to be specifed in the definition of Online deployment. \n",
        "\n",
        "- Model: \n",
        "    - Registered\n",
        "- Environment (specific to model):\n",
        "    - conda.yaml and docker image (you don’t need to install docker; you need a link to the docker image)\n",
        "    - Automatically generated for MLflow models. You don't need to specify this time.\n",
        "- Compute resource\n",
        "    - VM SkU is to be specified \n",
        "- Scoring script\n",
        "    - The scoring script which takes input requests and returns the scored results.\n",
        "    - Automatically generated for MLflow models. You don't need to specify this time."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check if the model is registerd\n",
        "If you already completed tutorial 5, your model was registered in the training script.\n",
        "We recommend registering model as a best practice.\n",
        "\n",
        "You can check the **Models** page on Azure ML studio, to identify the latest version of your registered model. Alternatively, the code below will retrieve the latest version number for you to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "registered_model_name = \"credit_defaults_model\"\n",
        "\n",
        "# Let's pick the latest version of the model\n",
        "latest_model_version = max(\n",
        "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Create a new online endpoint\n",
        "\n",
        "Now that you have a registered model and an inference script (auto-generated this time), it's time to create your online endpoint. The endpoint name needs to be unique in the entire Azure region. For this tutorial, you'll create a unique name using [`UUID`](https://en.wikipedia.org/wiki/Universally_unique_identifier#:~:text=A%20universally%20unique%20identifier%20(UUID,%2C%20for%20practical%20purposes%2C%20unique.).\n",
        "\n",
        "> [!NOTE]\n",
        "> Expect the endpoint creation to take approximately 6 to 8 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "# Creating a unique name for the endpoint\n",
        "online_endpoint_name = \"credit-endpoint-\" + str(uuid.uuid4())[:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# define an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"this is an online endpoint\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\n",
        "        \"training_dataset\": \"credit_defaults\",\n",
        "        \"model_type\": \"sklearn.GradientBoostingClassifier\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# create the online endpoint\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "\n",
        "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Once you've created an endpoint, you can retrieve it as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "print(\n",
        "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Deploy the model to the endpoint\n",
        "\n",
        "Once the endpoint is created, deploy the model with the entry script. Each endpoint can have multiple deployments. Direct traffic to these deployments can be specified using rules. Here you'll create a single deployment that handles 100% of the incoming traffic. We have chosen a color name for the deployment, for example, *blue*, *green*, *red* deployments, which is arbitrary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
        "\n",
        "\n",
        "# define an online deployment\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "# create the online deployment\n",
        "blue_deployment = ml_client.begin_create_or_update(blue_deployment).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check the status of the endpoint\n",
        "You can check the status to see whether the model was deployed without error:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "print(f\"Name: {endpoint.name}\\nStatus: {endpoint.provisioning_state}\\nDescription: {endpoint.description}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test with a sample query (Manually send test data)\n",
        "\n",
        "Now that the model is deployed to the endpoint, you can run inference with it.\n",
        "\n",
        "Create a sample request file following the design expected in the run method in the score script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a directory to store a sample request file\n",
        "import os\n",
        "deploy_dir = \"./deploy\"\n",
        "os.makedirs(deploy_dir, exist_ok=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a sample request file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile {deploy_dir}/sample-request.json\n",
        "{\n",
        "  \"input_data\": {\n",
        "    \"columns\": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],\n",
        "    \"index\": [0, 1],\n",
        "    \"data\": [\n",
        "            [20000,2,2,1,24,2,2,-1,-1,-2,-2,3913,3102,689,0,0,0,0,689,0,0,0,0],\n",
        "            [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8]\n",
        "        ]\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test the blue deployment with some sample data\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"blue\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get logs of the deployment\n",
        "Check the logs to see whether the endpoint/deployment were invoked successfuly\n",
        "If you face errors, see [Troubleshooting online endpoints deployment](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints?tabs=cli)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logs = ml_client.online_deployments.get_logs(name=\"blue\", endpoint_name=online_endpoint_name, lines=50)\n",
        "print(logs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a new deployment"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (scale)\n",
        "Show manual, mention (link) auto-scale. Do this for model #2 only. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (split traffic)\n",
        "Split production traffic between deployments"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete the old deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK V2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
