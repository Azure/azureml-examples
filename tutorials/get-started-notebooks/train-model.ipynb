{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 1: Training a model\n",
        "\n",
        "*[Sanghee's note: this tutorial will be coming after the prototpying tutorial, so you'll want to keep the intro consistent. The first paragraph is a high level overview for everything, so we want to tweak this to be specific to the training. Also, let's not introduce Azure ML specific terminology such as 'command job' in the intro paragraph as users don't know what it is yet. Consider changing 'you'll learn how to submit a command job' to something 'you'll learn how to submit a training job to the cloud', you get the idea. Also, let's remove the portion about the deployment as that will be handled in the deployment tutorial by Mope]*\n",
        "\n",
        "\n",
        "Learn how a data scientist uses Azure Machine Learning (Azure ML) to train a model, then use the model for a classifier. This tutorial will help you become familiar with the core concepts of Azure ML and their most common usage (training a model). In this example we use the associated credit card dataset to show how you can use AutoML for a classification problem. The goal is to predict if a customer has a high likelihood of defaulting on a credit card payment. To complete this tutorial, please ensure you have completed the prerequisite tutorial for prototyping. [link-to-notebook]\n",
        "\n",
        "This article is paired with a ready to run (Python Notebook) where you can train[link-to-notebook] a model from Azure studio or your local machine. To train a model you need to submit a *job*. In this tutorial, you'll learn how to submit a *command job* to run your *training script* on a specified *compute resource*, configured with the *job environment* necessary to run the script. Submitting a *command job* will allow you to run a custom training script for your model. \n",
        "\n",
        "The training script handles the data preparation, then trains and registers a model. This tutorial will take you through steps to submit a cloud-based training job (command job). If you would like to learn more about how to load your data into Azure, please follow this link. \n",
        "[comment]: <> (I added this last line to preface that we will not be going over how to load data, some scientists make specifically looking for this. so in this instance I think it would be beneficial to link to the other tutorial., any thoughts? \n",
        "\n",
        "*[Sanghee's note]: I think this is a good idea, please work with Sheri to ensure this is done consistently across the tutorials)*\n",
        "\n",
        "*[Sanghee's note for below]: let's include 'data' to the bulletpoint 4. 'configured with the appropriate job env and the data source'*\n",
        "*[Sam Revised below]*\n",
        "\n",
        "The steps you'll take are:\n",
        "\n",
        "> * Connect to your Azure ML workspace\n",
        "> * Create your compute resource and job environment\n",
        "> * Create your training script\n",
        "> * Create and run your command job to run the training script on the compute resource, configured with the appropriate job environment and the data source\n",
        "> * View the output of your training script\n",
        "> * Deploy the newly-trained model as an endpoint\n",
        "> * Call the Azure ML endpoint for inferencing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "*[Sanghee's note: please work with Sheri so all tutorial articles are consistent]*\n",
        "* An Azure subscription. If you don't have an Azure subscription, [create a free account](https://aka.ms/AMLFree) before you begin.\n",
        "* A working Azure ML workspace. A workspace can be created via Azure Portal, Azure CLI, or Python SDK. [Read more](https://docs.microsoft.com/azure/machine-learning/how-to-manage-workspace?tabs=python).\n",
        "* An Azure Machine Learning [workspace]()\n",
        "* A workspace and compute instance which you can create by  completing the [Quickstart: Get started with Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/quickstart-create-resources#create-compute-instance)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Different ways to train models in Azure Machine Learning\n",
        "*[Sanghee's note] I think for the flow of the article, we will want to add a paragraph to ease in. Also, let's use a common language first to describe our features. Something like, 'Azure Machine Learning offers different ways to train models. Construct a `command` job function to run your own training script, use AutoML to generate a baseline model and a training script, or modify an existing example from the Github Examples repo.' I am also wondering whether we should include a comparison table instead of bullet points.*\n",
        "*[Sams revision: I thought that a table was a bit more restrictive in terms of use cases. I figured we didnt want to tell customers what they should use and instead we should allow them to decide and then offer an explanation of each type. I thougt the bullet points gave a quick summary of each and will let customers decide which they want to pursue.  I think a table is an interesting idea but maybe for a different tutorial? because there is also other ways to train in Azure. We didnt mention designer either and i dont know if we should in this tutorial. What do you think ? I also re worded the below paragraph]*\n",
        "\n",
        "Azure Machine Learning offers several ways to train models. Users can select their method of training based on complexity of the model, data size, and training speed requirements. Here are some of the ways to train in Azure Machine Learning:\n",
        "\n",
        "1. Command Job: A command job is a function that will allow you to use your own training script to train your model. This can also be defined as a custom training job. A command job in Azure Machine Learning is a type of job that runs a script or command in a specified environment. You can use command jobs to train models, process data, or any other custom code you want to execute in the cloud. \n",
        "1. AutoML: AutoML is a supplemental tool to reduce the amount of time a data scientist spends finding a model that works best with their data. Instead of rewriting a training script for each model, AutoML runs each model automatically, along with hyperparameter tuning of each model to help ensure its accuracy. After AutoML has found a model you are happy with, you can continue improving upon the model by tweaking the script or continuing hyperparameter tuning.\n",
        "1. Github Examples: Github examples are great ways of training along side an explained tutorial. In Azure Machine Learning's examples repo, there are completed tutorial paired with Python Notebooks that you can run code and learn to train a model. Users are able to modify and run existing scripts from the Github Examples Repo containing scenarios including classification, natural language processing, and anomaly detection. \n",
        "\n",
        "*[Sanghee's note: let's add a transitional sentence or two here, something like, 'in this tutorial, you'll be learning how to create a custom training job.]*\n",
        "*[Sam revision] revised wording based on feedback*\n",
        "\n",
        "In this tutorial, we will focus on using a command job to create a custom training job that we will use to train a model. For any custom training job, these below items are required:\n",
        "> * compute \n",
        "> * environment\n",
        "> * data\n",
        "> * command job \n",
        "> * training script\n",
        "[comment]: <> (is the command script and training script the same thing? I think it will be in this case)\n",
        "*[Sanghee's note: the `command` job in SDK allows configuring everything together to submit a custom training job. A training script is main.py]*\n",
        "*[Sam Revision] then we would change command script to command job, correct?*\n",
        "\n",
        "In this tutorial we will provide all items listed above for the purpose of our example: creating a classifier to predict customers who have a high likelihood of defaulting on credit card payments.\n",
        "\n",
        "*[Sanghee's note: I think this model predicts who would default on the credit card payment. I think I know why you got it mixed up though - we probably talked about a fraud scenario in one of our meetings as a possibility!]* \n",
        "*[Sam revision] revised wording based on feedback*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to the workspace\n",
        "\n",
        "Before you dive in the code, you'll need to connect to your Azure ML workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
        "\n",
        "We're using `DefaultAzureCredential` to get access to workspace. \n",
        "`DefaultAzureCredential` is used to handle most Azure SDK authentication scenarios. \n",
        "\n",
        "Reference for more available credentials if it doesn't work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/python/api/azure-identity/azure.identity?view=azure-python).\n",
        "\n",
        "To connect your code to Azure ML, we will be using MLClient. MLClient allows us to make cloud based code runs locally or in the Azure Studio. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1676410402229
        },
        "name": "credential"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'azure.ai'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Handle to the workspace\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m \u001b[39mimport\u001b[39;00m MLClient\n\u001b[0;32m      4\u001b[0m \u001b[39m# Authentication package\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39midentity\u001b[39;00m \u001b[39mimport\u001b[39;00m DefaultAzureCredential\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azure.ai'"
          ]
        }
      ],
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, in this If you want to use a browser to login and authenticate, you can use the following code instead. In this example, you'll use the `DefaultAzureCredential`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1675199380659
        }
      },
      "outputs": [],
      "source": [
        "# Handle to the workspace\n",
        "# from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "# from azure.identity import InteractiveBrowserCredential\n",
        "# credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find these values:\n",
        "\n",
        "1. In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
        "1. Copy the value for workspace, resource group and subscription ID into the code.  \n",
        "1. You'll need to copy one value, close the area and paste, then come back for the next one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1675199384262
        },
        "name": "ml_client"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'MLClient' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Get a handle to the workspace\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ml_client \u001b[39m=\u001b[39m MLClient(\n\u001b[0;32m      3\u001b[0m     credential\u001b[39m=\u001b[39mcredential,\n\u001b[0;32m      4\u001b[0m     subscription_id\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m65a1016d-0f67-45d2-b838-b8f373d6d52e\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     resource_group_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mssalgado-rg\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     workspace_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mssalgado-test\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m )\n",
            "\u001b[1;31mNameError\u001b[0m: name 'MLClient' is not defined"
          ]
        }
      ],
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"65a1016d-0f67-45d2-b838-b8f373d6d52e\",\n",
        "    resource_group_name=\"ssalgado-rg\",\n",
        "    workspace_name=\"ssalgado-test\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result is a handler to the workspace that you'll use to manage other resources and jobs.\n",
        "\n",
        "> [!IMPORTANT]\n",
        "> Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (in the notebook below, that will happen during compute creation)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a compute resource to run your job\n",
        "\n",
        "You'll need a compute resource for running a job. It can be single or multi-node machines with Linux or Windows OS, or a specific compute fabric like Spark. In Azure, there are two compute resources that you can choose from: instance and cluster. A compute instance contains one node of computation resources while a compute cluster contains several. For the purpose of training, we recommend using a compute cluster because it allows the user to distribute calculations on multiple nodes of computation which results in a faster training experience. \n",
        "\n",
        "In Azure, a job can refer to several tasks that Azure allows its users to do: training, pipeline creation, deployment, etc. For this tutorial and our purpose of training a machine learning model we will be using *job* as a reference to running training computations (*training job*).\n",
        "\n",
        "*[Sanghee's note: I think we need to unpack some concepts here.* \n",
        "*1) we need to establish that compute cluster is what users want to use for training (vs instance) because it allows the scale-up on the nodes. Compute instance only has a single node. In the prev tutorial (prototyping), we establish that compute instance is needed to run a cloud workstation (notebook/terminal). We get this question a lot (what's the difference btw CI and Cluster?) so we want to establish the mental model here. Cluster = for training and deployment]*\n",
        "*2) we need to establish what a job is. Now this is a tricky part - a job can be different things: training, pipeline, deployment, etc. In the context of this tutorial however, it might be better to keep it simple as 'you'll need a compute resource to run your training job'. What you think?*\n",
        "*[Sam revised]*\n",
        "\n",
        "You'll provision a Linux compute cluster. See the [full list on VM sizes and prices](https://azure.microsoft.com/pricing/details/machine-learning/) .\n",
        "\n",
        "For this example, you only need a basic cluster, so you'll use a Standard_DS3_v2 model with 2 vCPU cores, 7-GB RAM and create an Azure ML Compute.\n",
        "\n",
        "*[Sanghee's note: could you ask Sheri what is an 'Azure ML Compute'? It's capitalised so I want to understand if there is a reason for it]*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1675199389284
        },
        "name": "cpu_compute_target"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You already have a cluster named cpu-cluster, we'll reuse it as is.\n",
            "AMLCompute with name cpu-cluster is created, the compute size is STANDARD_DS3_V2\n"
          ]
        }
      ],
      "source": [
        "#Sanghee's note: there is a mention of 'Azure ML compute object'. I'll follow up with an email if this is a terminology we use. \n",
        "\n",
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure ML compute object with the intended parameters\n",
        "    cpu_cluster1 = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure ML Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS3_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=4,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster1)\n",
        "\n",
        "print(\n",
        "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a job environment\n",
        "\n",
        "To run your AzureML job on your compute resource, you'll need an [environment](https://docs.microsoft.com/azure/machine-learning/concept-environments). An environment lists the software runtime and libraries that you want installed on the compute where you’ll be training. It's similar to your python environment on your local machine.\n",
        "\n",
        "AzureML provides many curated or ready-made environments, which are useful for common training and inference scenarios. You can also create your own custom environments using a docker image, or a conda configuration.\n",
        "\n",
        "In this example, you'll create a custom conda environment for your jobs, using a conda yaml file.\n",
        "\n",
        "First, create a directory to store the file in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1675199393166
        },
        "name": "dependencies_dir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dependencies_dir = \"./dependencies\"\n",
        "os.makedirs(dependencies_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, create the file in the dependencies directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "name": "write_model"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./dependencies/conda.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile {dependencies_dir}/conda.yml\n",
        "name: model-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - numpy=1.21.2\n",
        "  - pip=21.2.4\n",
        "  - scikit-learn=0.24.2\n",
        "  - scipy=1.7.1\n",
        "  - pandas>=1.1,<1.2\n",
        "  - pip:\n",
        "    - inference-schema[numpy-support]==1.3.0\n",
        "    - xlrd==2.0.1\n",
        "    - mlflow== 1.26.1\n",
        "    - azureml-mlflow==1.42.0\n",
        "    - psutil>=5.8,<5.9\n",
        "    - tqdm>=4.59,<4.60\n",
        "    - ipykernel~=6.0\n",
        "    - matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The specification contains some usual packages, that you'll use in your job (numpy, pip).\n",
        "\n",
        "Reference this *yaml* file to create and register this custom environment in your workspace:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1675199401145
        },
        "name": "custom_env_name"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment with name aml-scikit-learn is registered to workspace, the environment version is 2\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "custom_env_name = \"aml-scikit-learn\"\n",
        "\n",
        "custom_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for Credit Card Defaults job\",\n",
        "    tags={\"scikit-learn\": \"0.24.2\"},\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
        ")\n",
        "custom_job_env = ml_client.environments.create_or_update(custom_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {custom_job_env.name} is registered to workspace, the environment version is {custom_job_env.version}\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure a training job using the command function\n",
        "\n",
        "*[Sanghee's note: I am wondering if we should consider changing the heading here since other headings are all call-to-action aka 'Do X'. Maybe we could consider 'Train a model on Azure ML platform' or 'Configure a training job using command function'. This paragraph basically covers the high level concept. What do you think is appropriate here?]* \n",
        "*[Sam revised]: I like the second wording a lot and I think youre right about call to action*\n",
        "\n",
        "You'll create an Azure ML *command job* to train a model for credit default prediction. The command job is used to run a *training script* in a specified environment on a specified compute resource.  You've already created the environment and the compute resource.  Next you'll create the training script. In our specific case, we will be training our dataset to produce a classifier using the `GradientBoostingClassifier` model. \n",
        "\n",
        "The *training script* handles the data preparation, training and registering of the trained model. The method `train_test_split` handles splitting the dataset into test and training data. In this tutorial, you'll create a Python training script. \n",
        "\n",
        "Command jobs can be run from CLI, Python SDK, or studio interface. In this tutorial, you'll use the Azure ML Python SDK v2 to create and run the command job.\n",
        "\n",
        "After running the training job, if you need to learn more about deploying the model you can follow the next tutorial in this series.\n",
        "\n",
        "*[Sanghee's note: how might we rephrase 'you'll deploy the model' since it will be the next tutorial?]*\n",
        "*[Sam Revised] does this revision still sound ok? Or should we remove this line*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create training script\n",
        "\n",
        "Let's start by creating the training script - the *main.py* python file.\n",
        "\n",
        "First create a source folder for the script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1675199406326
        },
        "name": "train_src_dir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "train_src_dir = \"./src\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This script handles the preprocessing of the data, splitting it into test and train data. It then consumes this data to train a tree based model and return the output model. \n",
        "\n",
        "[MLFlow](https://mlflow.org/docs/latest/tracking.html) will be used to log the parameters and metrics during our job. The MLFlow package allows you to keep track of metrics and results for each model Azure trains. We will be using MLFlow to first get the best model for our data, then we will be viewing the model's metrics on the Azure studio. If you would like to learn more about how MLFLow works (please visit this link)[./concept-mlflow]. If you would like to learn more about how Azure Machine Learning uses the MLflow model's concept to enable deployment workflows (please visit this link). [./concept-mlflow-models.md]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "name": "write_main"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {train_src_dir}/main.py\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "    args = parser.parse_args()\n",
        "   \n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    ###################\n",
        "    #<prepare the data>\n",
        "    ###################\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    print(\"input data:\", args.data)\n",
        "    \n",
        "    credit_df = pd.read_excel(args.data, header=1, index_col=0)\n",
        "\n",
        "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
        "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
        "\n",
        "    #Split train and test datasets\n",
        "    train_df, test_df = train_test_split(\n",
        "        credit_df,\n",
        "        test_size=args.test_train_ratio,\n",
        "    )\n",
        "    ####################\n",
        "    #</prepare the data>\n",
        "    ####################\n",
        "\n",
        "    ##################\n",
        "    #<train the model>\n",
        "    ##################\n",
        "    # Extracting the label column\n",
        "    y_train = train_df.pop(\"default payment next month\")\n",
        "\n",
        "    # convert the dataframe values to array\n",
        "    X_train = train_df.values\n",
        "\n",
        "    # Extracting the label column\n",
        "    y_test = test_df.pop(\"default payment next month\")\n",
        "\n",
        "    # convert the dataframe values to array\n",
        "    X_test = test_df.values\n",
        "\n",
        "    print(f\"Training with data of shape {X_train.shape}\")\n",
        "\n",
        "    clf = GradientBoostingClassifier(\n",
        "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    ###################\n",
        "    #</train the model>\n",
        "    ###################\n",
        "\n",
        "    ##########################\n",
        "    #<save and register model>\n",
        "    ##########################\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=clf,\n",
        "        registered_model_name=args.registered_model_name,\n",
        "        artifact_path=args.registered_model_name,\n",
        "    )\n",
        "\n",
        "    # Saving the model to a file\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=clf,\n",
        "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
        "    )\n",
        "    ###########################\n",
        "    #</save and register model>\n",
        "    ###########################\n",
        "    \n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*[Sanghee's note: I think we need one sentence here to explain what model registry is. It feels abrupt to see the mention of the model registry coming out of nowhere]*\n",
        "*[Sam Revised below]*\n",
        "\n",
        "In this script, once the model is trained, the model file is saved and registered to the workspace. Registering your model allows you to store and version your models in the Azure cloud, in your workspace. Once you register a model, you can find all other registered model in one place in the Azure Studio called the model registry. The model registry helps you organize and keep track of your trained models. You'll also be able to use registered models when deploying endpoints, which we will talk more about in a later section of this article. [insert-hyper-link]\n",
        "\n",
        "## Configure the command\n",
        "\n",
        "*[Sanghee's note: below sentence is a bit awkward for me because data is described in the paragraph but the rest of the parameters are in the bullet point. Should we move the data to be its own bullet point for consistency? Thoughts?]*\n",
        "*[Sam Revised] I think this paragraph splits up the ideas in a good way. Although I dont know much about what is happening in this command method. *\n",
        "\n",
        "Now that you have a script that can perform the classification task, you'll use the general purpose **command** that can run command line actions. This command line action can be directly calling system commands or by running a script. \n",
        "\n",
        "Here, you'll create input variables to specify the input data, split ratio, learning rate and registered model name.  The command script will:\n",
        "* Use the compute created earlier to run this command.\n",
        "* Use the environment created earlier - you can use the `@latest` notation to indicate the latest version of the environment when the command is run.\n",
        "* Configure some metadata like display name, experiment name etc. An *experiment* is a container for all the iterations you do on a certain project. All the jobs submitted under the same experiment name would be listed next to each other in Azure ML studio.\n",
        "* Configure the command line action itself - `python main.py` in this case. The inputs/outputs are accessible in the command via the `${{ ... }}` notation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1675199418763
        },
        "name": "registered_model_name"
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "registered_model_name = \"credit_defaults_model\"\n",
        "\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\",\n",
        "        ),\n",
        "        test_train_ratio=0.2,\n",
        "        learning_rate=0.25,\n",
        "        registered_model_name=registered_model_name,\n",
        "    ),\n",
        "    code=\"./src/\",  # location of source code\n",
        "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
        "    environment=\"aml-scikit-learn@latest\",\n",
        "    compute=\"cpu-cluster\",\n",
        "    experiment_name=\"train_model_credit_default_prediction\",\n",
        "    display_name=\"credit_default_prediction\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the job \n",
        "\n",
        "*[Sanghee's note: Azure Studio > Azure Machine Learning Studio. Also, do we need a full description here when we are going to walk the user about the details page? thoughts?]*\n",
        "*[Sams revision: I reworded further below in the cell below the code. but what do you mean walk the user through? Im not sure what else to explain but that might just be me being used to the studio by now. I can add an image of the studio with boxes to show where a user would select \"overview\", \"metrics\", \"output\", etc. Would that help to walk through? Ill try out the bulleted list though.   ]\n",
        "\n",
        "It's now time to submit the job to run in AzureML. This time you'll use `create_or_update`  on `ml_client.jobs`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1675199425929
        },
        "name": "create_job"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>train_model_credit_default_prediction</td><td>jovial_celery_yvzx4cgjdr</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/jovial_celery_yvzx4cgjdr?wsid=/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourcegroups/ssalgado-rg/workspaces/ssalgado-test&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "Command({'parameters': {}, 'init': False, 'type': 'command', 'status': 'Starting', 'log_files': None, 'name': 'jovial_celery_yvzx4cgjdr', 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '8c71e15d-d124-4e82-b2c3-8f642b9a1a0b'}, 'id': '/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/ssalgado-rg/providers/Microsoft.MachineLearningServices/workspaces/ssalgado-test/jobs/jovial_celery_yvzx4cgjdr', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ssalgado2/code/Users/ssalgado/azureml-in-a-day', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f7b4c15fc10>, 'serialize': <msrest.serialization.Serializer object at 0x7f7b4c15ff70>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'credit_default_prediction', 'experiment_name': 'train_model_credit_default_prediction', 'compute': 'cpu-cluster', 'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f7b4c15e200>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f7b4c15fc70>}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls', 'mode': 'ro_mount'}, 'test_train_ratio': '0.2', 'learning_rate': '0.25', 'registered_model_name': 'credit_defaults_model'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.jovial_celery_yvzx4cgjdr', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f7b4c15ed10>, 'test_train_ratio': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f7b4c15e8c0>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f7b4c15e800>, 'registered_model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f7b4c15f4f0>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f7b4c15efe0>}, 'component': CommandComponent({'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'name': 'jovial_celery_yvzx4cgjdr', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f7b4c15fc10>, 'serialize': <msrest.serialization.Serializer object at 0x7f7b4c15f700>, 'command': 'python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}', 'code': '/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/ssalgado-rg/providers/Microsoft.MachineLearningServices/workspaces/ssalgado-test/codes/c5220b0f-db50-4d1b-91ae-484606dda6f7/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/ssalgado-rg/providers/Microsoft.MachineLearningServices/workspaces/ssalgado-test/environments/aml-scikit-learn/versions/2', 'distribution': None, 'resources': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'credit_default_prediction', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls', 'mode': 'ro_mount'}, 'test_train_ratio': {'type': 'string', 'default': '0.2'}, 'learning_rate': {'type': 'string', 'default': '0.25'}, 'registered_model_name': {'type': 'string', 'default': 'credit_defaults_model'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.jovial_celery_yvzx4cgjdr', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f7b4c15e200>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f7b4c15fc70>}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f7b4c15fc10>}, 'instance_id': 'fafd2bd0-bf70-43c0-93f9-f01a0341f336', 'source': 'BUILDER', 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'aml-scikit-learn:2', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'swept': False})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.create_or_update(job)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View job output and wait for job completion\n",
        "\n",
        "*[Sanghee's note: please incorporate my note in the prev email and remove the deployment portion~ let me know if you need any help describing the job details page. We will want to do more than what I originally included in the studio onboarding notebook]*\n",
        "\n",
        "*[Reference] You can view the result of a training job by clicking the URL generated after submitting a job. Alternatively, you can also click Jobs on the left navigation menu. A job is a grouping of many runs from a specified script or piece of code. Information for the run is stored under that job.*\n",
        "\n",
        "*Overview is where you can see the status of the job.*\n",
        "*Metrics would display different visualizations of the metrics you specified in the script.*\n",
        "*Images is where you can view any image artifacts that you have logged with MLflow.*\n",
        "*Child jobs contains child jobs if you added them.*\n",
        "*Outputs + logs contains log files you need for troubleshooting or other monitoring purposes.*\n",
        "*Code contains the script/code used in the job.*\n",
        "*Explanations and Fairness are used to see how your model performs against responsible AI standards. They are currently preview* *features and require additional package installations.*\n",
        "*Monitoring is where you can view metrics for the performance of compute resources.*\n",
        "\n",
        "\n",
        "View the job in Azure ML studio by selecting the link in the output of the previous cell. The output of this job will look like this in Azure ML studio. Explore the tabs for various details like metrics, outputs etc. Once completed, the job will register a model in your workspace as a result of training. \n",
        "\n",
        "![Screenshot that shows the job overview](media/view-job.gif \"View the job in studio\")\n",
        "\n",
        "> [!IMPORTANT]\n",
        "> Wait until the status of the job is complete before returning to this notebook to continue. The job will take 2 to 3 minutes to run. It could take longer (up to 10 minutes) if the compute cluster has been scaled down to zero nodes and custom environment is still building.\n",
        "\n",
        "After the job is done running, the code above will print a link to the job's details page on Azure Studio. Alternatively, you can also click Jobs on the left navigation menu. A job is a grouping of many runs from a specified script or piece of code. Information for the run is stored under that job. The details page will give an overview of the job, the time it took to run, when it was created, etc. The page will also have tabs to other information about the job such as metrics, Outputs + logs, and code. Listed below are the tabs available in the job's details page:\n",
        "> * Overview: The overview section provides basic information about the job, including its status, start and end times, and the type of job that was run\n",
        "> * Inputs: The input section lists the data and code that were used as inputs for the job. This can include datasets, scripts, environment configurations, and other resources that were used during training. \n",
        "> * Outputs + logs: The Outputs + logs tab will contain logs generated while the job was running. This tab will assist in troubleshooting if anything goes wrong with your training script or model creation.\n",
        "> * Metrics: The metrics tab will showcase key performance metrics from your model such as training score, f1 score, and precision score. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Learn about creating a multi step pipeline for this script [Create production ML pipelines in a Jupyter notebook](https://github.com/Azure/azureml-examples/blob/main/tutorials/e2e-ds-experience/e2e-ml-workflow.ipynb)."
      ]
    }
  ],
  "metadata": {
    "categories": [
      "SDK v2",
      "tutorials"
    ],
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3c425d57ea17353a75c8e873bab29be31f0fc62d987f8368209dcfe798564f51"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
