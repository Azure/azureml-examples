{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Draft for Prototype with a Cloud workstation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sanghee's note]\n",
    "- CI setup is in the resource setup article. We explain that CI is needed in order to run Notebook/Terminal. While this is not a requirement, we highly recommend setting up CI for tutorials. \n",
    "- Order of progression: Data tutorial > prototype > training > deployment > pipeline\n",
    "- We will do some explanation of Notebook in the data tutorial as needed. Same for the prototyping, we will only explain what user will use.\n",
    "- Do we want continuity from the data tutorial to the prototyping tutorial? My inclination is that we teach users how to clean up and register the full, training data in the data tutorial, and use the registered data asset in the training tutorial; meanwhile, in the prototyping tutorial, we instruct the user to download and upload a small test dataset to use. I think it is more realistic that way. Thoughts?\n",
    "- Do we want continuity to the training tutorial? I think either way is fine, but I am partial to continuity so that users who use the entire series don't get too confused. We could start by a simpler script here, ask user to modify it and convert to main.py. In the training tutorial, we provide the full script again but users would recognize it is the same script. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download assets required for this tutorial\n",
    "In this tutorial, you'll be learning how to bring an existing project to Azure Machine Learning Notebook and run the prototyping code. As a pre-requisite of this tutorial, download the sample project files first.\n",
    "\n",
    "- data set link\n",
    "- main.py (maybe? - user can copy & paste from the .py or from the doc - it is a bit awkward bc we convert back to py at the end; we could just provide the script to copy & paste in the doc as well. We won't be providing a notebook here - Leah & I discussed this and when we want user to copy & paste into the notebook, providing another notebook doesn't make sense.)  \n",
    "- conda.yml (maybe? - if this would make sense in the custom env instruction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Azure Machine Learning Notebook\n",
    "Re-use the instruction Sheri already has here.\n",
    "\n",
    "## Connect to Compute Instance if you haven't already\n",
    "Re-use the instruction Sheri already has here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload your file\n",
    "In order to prototype, you'll need a small test dataset and a training script. Let's upload them.\n",
    "\n",
    "Re-use the instruction Sheri already has here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a new environment to make your code work (create a new kernel)\n",
    "In order to make your script work, you will need to make sure you have a development environment configured with libraries used in the training script.\n",
    "\n",
    "(Sanghee's note: Leah I am totally making this up based on what I see on Studio as an example; you need to tell me what would work!) \n",
    "\n",
    "This is just an example: Azure Machine Learning provides pre-made environments so that you don't have to install everything. Let's open the conda.yml file to see what dependencies are required (if we provide a conda.yml file as part of the downloadable asset, we can make this work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name: prototyping-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - numpy=1.21.2\n",
    "  - pip=21.2.4\n",
    "  - scikit-learn=0.24.2\n",
    "  - scipy=1.7.1\n",
    "  - pandas>=1.1,<1.2\n",
    "  - pip:\n",
    "    - inference-schema[numpy-support]==1.3.0\n",
    "    - xlrd==2.0.1\n",
    "    - mlflow== 1.26.1\n",
    "    - azureml-mlflow==1.42.0\n",
    "    - psutil>=5.8,<5.9\n",
    "    - tqdm>=4.59,<4.60\n",
    "    - ipykernel~=6.0\n",
    "    - matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a custom environment based on a pre-made environment image.\n",
    "\n",
    "1. Go to **Environment**\n",
    "1. Select **Custom Environment**\n",
    "1. Click **Create**\n",
    "1. Name it **prototyping-env**\n",
    "1. Select **Start from an existing environment**\n",
    "1. Choose **Scikitlearn 1.0**\n",
    "1. Click **Next**\n",
    "1. Add dependencies to **RUN pip install**\n",
    "1. Click **Next**\n",
    "1. Add a tag so you can recognize the custom environment. Add **Scikitlearn** **mlflow==1.26.1** **matplotlib**.\n",
    "1. Click **Create** \n",
    "\n",
    "(Sanghee's note: I don't know how to load a custom kernel into the notebook CI. We may have to teach user how to restart?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the notebook\n",
    "\n",
    "Now the environment is set up, let's run the code.\n",
    "\n",
    "Re-use additional instructions Sheri already has - this may be a good place to also showcase the Variable Explorer.\n",
    "\n",
    "Note on the script: this script was originally written to run as a command job package, we need to modify this to run as a prototype (ex. load the data, take out the model registration, etc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
    "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
    "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
    "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
    "    args = parser.parse_args()\n",
    "   \n",
    "    # Start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    ###################\n",
    "    #<prepare the data>\n",
    "    ###################\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "    \n",
    "    credit_df = pd.read_excel(args.data, header=1, index_col=0)\n",
    "\n",
    "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
    "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
    "\n",
    "    train_df, test_df = train_test_split(\n",
    "        credit_df,\n",
    "        test_size=args.test_train_ratio,\n",
    "    )\n",
    "    ####################\n",
    "    #</prepare the data>\n",
    "    ####################\n",
    "\n",
    "    ##################\n",
    "    #<train the model>\n",
    "    ##################\n",
    "    # Extracting the label column\n",
    "    y_train = train_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_train = train_df.values\n",
    "\n",
    "    # Extracting the label column\n",
    "    y_test = test_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_test = test_df.values\n",
    "\n",
    "    print(f\"Training with data of shape {X_train.shape}\")\n",
    "\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    ###################\n",
    "    #</train the model>\n",
    "    ###################\n",
    "\n",
    "    ##########################\n",
    "    #<save and register model>\n",
    "    ##########################\n",
    "    # Registering the model to the workspace\n",
    "    print(\"Registering the model via MLFlow\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=clf,\n",
    "        registered_model_name=args.registered_model_name,\n",
    "        artifact_path=args.registered_model_name,\n",
    "    )\n",
    "\n",
    "    # Saving the model to a file\n",
    "    mlflow.sklearn.save_model(\n",
    "        sk_model=clf,\n",
    "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
    "    )\n",
    "    ###########################\n",
    "    #</save and register model>\n",
    "    ###########################\n",
    "    \n",
    "    # Stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate the code based on the test run result\n",
    "\n",
    "We explain the test result and instruct the user to change a parameter.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the notebook to a python script\n",
    "\n",
    "Re-use the instruction Sheri already has."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad53975d6cd14b07e2ef76ca5c680233933f2b5b5c4b5fa1fc47a72f4636b78d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
