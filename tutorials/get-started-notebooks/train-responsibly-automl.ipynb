{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Azure Machine Learning Day 1\n",
    "\n",
    "[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n",
    "\n",
    "In this tutorial we will be learning how to use Azure Machine Learning AutoML to train a model. AutoML allows the user to reduce the manual labor time when finding a model that best fits the current data. AutoML will cycle through multiple models and sets of hyper-parameters to find the best fit. AutoML has several tasks users can choose from: Classification, Regression, and Forecasting. In this example we use the associated credit card dataset to show how you can use AutoML for a classification problem. The goal is to predict if a credit card transaction is considered a fraudulent charge.\n",
    "\n",
    "In this example you will learn how you can save time by letting AutoML train multiple iterations of models on your data and allow you to choose the model you wish to work further on.\n",
    "\n",
    "The steps you'll take are:\n",
    "\n",
    "> [!div class=\"checklist\"]\n",
    "> * Connect to your Azure ML workspace\n",
    "> * Create your compute resource and job environment\n",
    "> * Create an MLTable Data Asset\n",
    "> * Create a Compute Target \n",
    "> * Create and run your AutoML Job \n",
    "> * View the results from the Best AutoML Run\n",
    "> * Call the Azure ML endpoint for inferencing\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* Complete the [Quickstart: Get started with Azure Machine Learning](quickstart-create-resources.md) to:\n",
    "    * Create a workspace.\n",
    "    * Create a cloud-based compute instance to use for your development environment.\n",
    "\n",
    "* Create a new notebook or copy our notebook.\n",
    "    * Follow the [Quickstart: Run Juypter notebook in Azure Machine Learning studio](quickstart-run-notebooks.md) steps to create a new notebook.\n",
    "    * Or use the steps in the quickstart to [clone the v2 tutorials folder](quickstart-run-notebooks.md#learn-from-sample-notebooks), then open the notebook from the **tutorials/azureml-in-a-day/azureml-in-a-day.ipynb** folder in your **File** section.\n",
    "\n",
    "-----Ensure this link is changed with the day 1 tutorial notebook\n",
    "\n",
    "## Run your notebook\n",
    "\n",
    "1. On the top bar, select the compute instance you created during the  [Quickstart: Get started with Azure Machine Learning](quickstart-create-resources.md)  to use for running the notebook.\n",
    "\n",
    "2. Make sure that the kernel, found on the top right, is `Python 3.10 - SDK v2`.  If not, use the dropdown to select this kernel.\n",
    "\n",
    "\n",
    "> [!Important]\n",
    "> The rest of this tutorial contains cells of the tutorial notebook.  Copy/paste them into your new notebook, or switch to the notebook now if you cloned it.\n",
    ">\n",
    "> To run a single code cell in a notebook, click the code cell and hit **Shift+Enter**. Or, run the entire notebook by choosing **Run all** from the top toolbar.\n",
    "\n",
    "## Download required packages\n",
    "\n",
    "Before you dive in the code, you'll need to run the code below to install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Azure Machine Learning packages\n",
    "!pip install --pre azure-ai-ml\n",
    "!pip install azureml-mlflow\n",
    "!pip install mlflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Azure Machine Learning Workspace\n",
    "The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
    "\n",
    "We're using `DefaultAzureCredential` to get access to workspace. \n",
    "`DefaultAzureCredential` is used to handle most Azure SDK authentication scenarios. \n",
    "\n",
    "#### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import AzureCliCredential\n",
    "from azure.ai.ml import MLClient, automl, Input\n",
    "\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.automl import (\n",
    "    classification,\n",
    "    ClassificationPrimaryMetrics,\n",
    "    ClassificationModels,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the MLClient from azure.ai.ml to get a handle to the required Azure Machine Learning workspace. We use the default azure authentication for this tutorial. Check the configuration notebook for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLClient is part of the Azure Machine Learning Python SDK and provides a way to access the Azure Machine Learning Cloud Platform. Instead of using the Azure Studio, with MLClient and the Python SDK you can locally create and manage workspaces, train and deploy models, create and use data assets all from your text editor. You can also use MLClient for the same purpose within the Azure Studio when you are running code in the Notebooks tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id=\"65a1016d-0f67-45d2-b838-b8f373d6d52e\"\n",
    "    resource_group=\"ssalgado-rg\"\n",
    "    workspace=\"ssalgado-test\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Azure Machine Learning Workspace Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = ml_client.workspaces.get(name=ml_client.workspace_name)\n",
    "\n",
    "subscription_id = ml_client.connections._subscription_id\n",
    "resource_group = workspace.resource_group\n",
    "workspace_name = ml_client.workspace_name\n",
    "\n",
    "output = {}\n",
    "output[\"Workspace\"] = workspace_name\n",
    "output[\"Subscription ID\"] = subscription_id\n",
    "output[\"Resource Group\"] = resource_group\n",
    "output[\"Location\"] = workspace.location\n",
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLTable with input Training Data\n",
    "\n",
    "**Create MLTable data input:**\n",
    "AutoML requires the data you input to be in MLTable format. For the sake of this example we will explain the steps to creating an ML Table asset as you would complete them through a local notebook. This process will be similar if you are following along to this notebook in the Azure Studio. \n",
    "\n",
    "1. Create a folder with name of your dataset. Example: `demo-dataset-mltable-folder`\n",
    "1. Name and upload your data in .csv format in the folder you created in step 1. Example: `demo-dataset.csv`\n",
    "1. Create a .yaml file called `MLTable.yaml` in the folder you created in step 1.\n",
    "\n",
    "---We need next steps if we are explaining how to create an MLTable Data Asset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This folder will serve as your dataset for this job. We will use the path to the folder you created to train our model. \n",
    "First we will create a data asset with the folder you created. Your `path` will be whatever you named your folder in the previous step. If you used the example name, your path would be `./demo-dataset-mltable-folder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training MLTable defined locally, with local data to be uploaded\n",
    "my_training_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, path=\"./data/training-mltable-folder\"\n",
    ")\n",
    "\n",
    "# WITH REMOTE PATH: If available already in the cloud/workspace-blob-store\n",
    "# my_training_data_input  = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/Classification/Train\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute target setup\n",
    "\n",
    "**Create or Attach existing AmlCompute**\n",
    "A compute target is required to execute the Automated ML run. In this tutorial, you create AmlCompute as your training compute resource.\n",
    "\n",
    "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist.\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** \n",
    "If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "compute_name = \"cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    _ = ml_client.compute.get(compute_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "except ResourceNotFoundError:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute(\n",
    "        name=compute_name,\n",
    "        type=\"amlcompute\",\n",
    "        size=\"STANDARD_DS12_V2\",\n",
    "        idle_time_before_scale_down=120,\n",
    "        min_instances=0,\n",
    "        max_instances=6,\n",
    "    )\n",
    "    ml_client.begin_create_or_update(compute_config).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and run the AutoML classification job\n",
    "In this section we will configure and run the AutoML classification job.\n",
    "\n",
    "**Configure the job through the classification() factory function**\n",
    "\n",
    "*classification() parameters:*\n",
    "\n",
    "The `classification()` factory function allows user to configure AutoML for the classification task for the most common scenarios with the following properties.\n",
    "\n",
    "- `target_column_name` - The name of the column to target for predictions. It must always be specified. This parameter is applicable to 'training_data', 'validation_data' and 'test_data'.\n",
    "- `primary_metric` - The metric that AutoML will optimize for Classification model selection.\n",
    "- `training_data` - The data to be used for training. It should contain both training feature columns and a target column. Optionally, this data can be split for segregating a validation or test dataset. \n",
    "You can use a registered MLTable in the workspace using the format '<mltable_name>:<version>' OR you can use a local file or folder as a MLTable. For e.g Input(mltable='my_mltable:1') OR Input(mltable=MLTable(local_path=\"./data\"))\n",
    "The parameter 'training_data' must always be provided.\n",
    "- `compute` - The compute on which the AutoML job will run. In this example we are using a compute called 'cpu-cluster' present in the workspace. You can replace it any other compute in the workspace. \n",
    "- `name` - The name of the Job/Run. This is an optional property. If not specified, a random name will be generated.\n",
    "- `experiment_name` - The name of the Experiment. An Experiment is like a folder with multiple runs in Azure ML Workspace that should be related to the same logical machine learning experiment.\n",
    "\n",
    "*set_limits() function parameters:*\n",
    "This is an optional configuration method to configure limits parameters such as timeouts.     \n",
    "    \n",
    "- `timeout_minutes` - Maximum amount of time in minutes that the whole AutoML job can take before the job terminates. This timeout includes setup, featurization and training runs but does not include the ensembling and model explainability runs at the end of the process since those actions need to happen once all the trials (children jobs) are done. If not specified, the default job's total timeout is 6 days (8,640 minutes). To specify a timeout less than or equal to 1 hour (60 minutes), make sure your dataset's size is not greater than 10,000,000 (rows times column) or an error results.\n",
    "\n",
    "- `trial_timeout_minutes` - Maximum time in minutes that each trial (child job) can run for before it terminates. If not specified, a value of 1 month or 43200 minutes is used.\n",
    "    \n",
    "- `max_trials` - The maximum number of trials/runs each with a different combination of algorithm and hyperparameters to try during an AutoML job. If not specified, the default is 1000 trials. If using 'enable_early_termination' the number of trials used can be smaller.\n",
    "    \n",
    "- `max_concurrent_trials` - Represents the maximum number of trials (children jobs) that would be executed in parallel. It's a good practice to match this number with the number of nodes your cluster.\n",
    "    \n",
    "- `enable_early_termination` - Whether to enable early termination if the score is not improving in the short term. \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since AutoML will be running multiple instances of each model with a different combination of hyper-parameters, it is important to set a max trail run variable so AutoML will stop running when it has found a model and parameter combination that is sufficient. While we are trying to test to find a basis point for the model and hyper-parameters, we will be setting a max trial run of around 5. If you would like to get a more accurate model you can set a higher number of max trials, but this will increase the job's training time. Once we have found a models and set of hyper-parameters we like, we can further improve improve upon that model manually or by increasing the number of trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General job parameters\n",
    "max_trials = 5\n",
    "exp_name = \"dpv2-classifier-experiment\"\n",
    "\n",
    "#Note: This job can take 15 minutes or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the AutoML classification job with the related factory-function.\n",
    "\n",
    "classification_job = automl.classification(\n",
    "    compute=compute_name,\n",
    "    experiment_name=exp_name,\n",
    "    training_data=my_training_data_input,\n",
    "    target_column_name=\"y\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    n_cross_validations=5,\n",
    "    enable_model_explainability=True,\n",
    "    tags={\"my_custom_tag\": \"My custom value\"},\n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "classification_job.set_limits(\n",
    "    timeout_minutes=600,\n",
    "    trial_timeout_minutes=20,\n",
    "    max_trials=max_trials,\n",
    "    # max_concurrent_trials = 4,\n",
    "    # max_cores_per_trial: -1,\n",
    "    enable_early_termination=True,\n",
    ")\n",
    "\n",
    "# Training properties are optional\n",
    "classification_job.set_training(\n",
    "    blocked_training_algorithms=[ClassificationModels.LOGISTIC_REGRESSION],\n",
    "    enable_onnx_compatible_models=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the Command**\n",
    "Using the MLClient created earlier, we will now run this Command in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    classification_job\n",
    ")  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Azure Studio link to models Automl ran\n",
    "ml_client.jobs.stream(returned_job.name) waits until the specified job is finished\n",
    "This line could take a while (15 minutes or more) and will output a link to the Azure studio to view the models that Automl ran against the inputted data. The list will also include the accuracy scores and other metrics for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.stream(returned_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(returned_job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Best Trial (Best Model's trial/run)\n",
    "Use the MLFLowClient to access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Trial.\n",
    "\n",
    "Since AutoML trains several models with different hyper-parameters, we need a way to keep track of each model's results. The MLFlow package allows you to keep track of metrics and results for each model AutoML trains. We will be using MLFlow to first get the best model for our data, then we will get the model's parent run to see if we can access more information about our data by comparing the parent and child run.\n",
    "\n",
    "**Initialize MLFlow Client:**\n",
    "The models and artifacts that are produced by AutoML can be accessed via the MLFlow interface. Initialize the MLFlow client here, and set the backend as Azure ML, via. the MLFlow Client.\n",
    "\n",
    "**Obtain the tracking URI for MLFlow:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
    "    name=ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MLFLOW TRACKING URI\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get AutoML Parent Job:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = returned_job.name\n",
    "\n",
    "# Example if providing an specific Job name/ID\n",
    "# job_name = \"b4e95546-0aa1-448e-9ad6-002e3207b4fc\"\n",
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
    "\n",
    "print(\"Parent Run: \")\n",
    "print(mlflow_parent_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print parent run tags. 'automl_best_child_run_id' tag should be there.\n",
    "print(mlflow_parent_run.data.tags)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get best child run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model's child run\n",
    "\n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Found best child run id: \", best_child_run_id)\n",
    "\n",
    "best_run = mlflow_client.get_run(best_child_run_id)\n",
    "\n",
    "print(\"Best child run: \")\n",
    "print(best_run)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get best model run's metric:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.data.metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make improvements to the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c425d57ea17353a75c8e873bab29be31f0fc62d987f8368209dcfe798564f51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
