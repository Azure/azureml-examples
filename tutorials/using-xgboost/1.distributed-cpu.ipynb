{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed XGBoost (CPU)\n",
    "\n",
    "Scaling out on AmlCompute is simple! The code from the previous notebook has been modified and adapted in [src/run.py](src/run.py). In particular, changes include:\n",
    "\n",
    "- import and initialize dask_mpi\n",
    "- use argparse to allow for command line argument inputs\n",
    "- mlflow logging \n",
    "\n",
    "The [environment.yml](environment.yml) contains the conda environment specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Remotely\n",
    "\n",
    "Simply use ``MpiConfiguration`` with the desired node count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig, Experiment, Environment\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "arguments = [\"--num_boost_round\", 100, \"--learning_rate\", 0.2, \"--gamma\", 0]\n",
    "env = Environment.from_conda_specification(\"xgboost-cpu-tutorial\", \"environment.yml\")\n",
    "mpi_config = MpiConfiguration(node_count=30)\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=\"src\",\n",
    "    script=\"run.py\",\n",
    "    arguments=arguments,\n",
    "    compute_target=\"cpu-cluster\",\n",
    "    environment=env,\n",
    "    distributed_job_config=mpi_config,\n",
    ")\n",
    "run = Experiment(ws, \"xgboost-cpu-tutorial\").submit(src)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Widget\n",
    "\n",
    "Optionally, view the output in the run widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for testing, wait for the run to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
