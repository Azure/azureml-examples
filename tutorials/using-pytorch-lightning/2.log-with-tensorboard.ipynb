{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log metrics with TensorBoard in PyTorch Lightning\n",
    "\n",
    "description: log tensorboard metrics with pytorch lightning and visualize metrics in tensorboard\n",
    "\n",
    "Lightning supports many popular [logging frameworks](https://pytorch-lightning.readthedocs.io/en/stable/loggers.html). In this tutorial we will go over using the built-in TensorBoard logger and leveraging Azure ML's TensorBoard integration to visualize the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "\n",
    "# get root of git repo\n",
    "prefix = Path(git.Repo(\".\", search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "# training script\n",
    "source_dir = prefix.joinpath(\n",
    "    \"code\", \"train\", \"pytorch-lightning\", \"mnist-autoencoder\"\n",
    ")\n",
    "script_name = \"train-with-tensorboard-logging.py\"\n",
    "\n",
    "# environment file\n",
    "environment_file = prefix.joinpath(\"environments\", \"pt-lightning.yml\")\n",
    "\n",
    "# azure ml settings\n",
    "environment_name = \"pt-lightning\"\n",
    "experiment_name = \"pt-lightning-tensorboard-example\"\n",
    "cluster_name = \"gpu-K80-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create environment\n",
    "\n",
    "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment. This notebook will use the same environment definition that was used for part 1 of the tutorial. Note that TensorBoard is the default logger in Lightning and comes preinstalled, so you don't need to add the **tensorboard** package as a dependency to the environment for the remote job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment.from_conda_specification(environment_name, environment_file)\n",
    "\n",
    "# specify a GPU base image\n",
    "env.docker.enabled = True\n",
    "env.docker.base_image = (\n",
    "    \"mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable logging in training script\n",
    "\n",
    "In *train_with_tensorboard_logging.py*:\n",
    "\n",
    "### 1. Specify location to write logs\n",
    "Specify the path of the location for the logger to write logs out to. In this tutorial, we add a `--logdir` argument to the training script, with the default value of `./logs`. This is the path you should write your TensorBoard logs out to if you would like to use the Azure ML TensorBoard integration (see the following section). You can override the default value if you wish to write logs to a different path.\n",
    "\n",
    "### 2. Create a TensorBoardLogger\n",
    "Create a `TensorBoardLogger` in your training script and pass it to the `logger` parameter of the `Trainer()` call.\n",
    "\n",
    "```python\n",
    "    tb_logger = TensorBoardLogger(args.logdir)\n",
    "    trainer = pl.Trainer.from_argparse_args(args, logger=tb_logger)\n",
    "```\n",
    "    \n",
    "### 3. Log metrics\n",
    "You can then log metrics and other objects in your script. In this tutorial's training script, we leverage Lightning's automatic log functionalities to log the loss metric by calling `self.log()` inside the `training_step()` method.\n",
    "\n",
    "\n",
    "For more information on logging and the configurable options, see Lightning's [Logging](https://pytorch-lightning.readthedocs.io/en/stable/logging.html) documentation and the [TensorBoardLogger](https://pytorch-lightning.readthedocs.io/en/stable/logging.html#tensorboard) reference documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and run training job\n",
    "\n",
    "Create a ScriptRunConfig to specify the training script & arguments, environment, and cluster to run on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig, Experiment\n",
    "\n",
    "cluster = ws.compute_targets[cluster_name]\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=source_dir,\n",
    "    script=script_name,\n",
    "    arguments=[\n",
    "        \"--max_epochs\",\n",
    "        25,\n",
    "        \"--gpus\",\n",
    "        2,\n",
    "        \"--accelerator\",\n",
    "        \"ddp\",\n",
    "        \"--logdir\",\n",
    "        \"./logs\",\n",
    "    ],\n",
    "    compute_target=cluster,\n",
    "    environment=env,\n",
    ")\n",
    "\n",
    "run = Experiment(ws, experiment_name).submit(src)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize logs in TensorBoard\n",
    "\n",
    "Azure ML provides an integration for users to easily stream and visualize the logs from their remote job in TensorBoard. To use this functionality, make sure you have the **azureml-tensorboard** and **tensorflow** packages on your machine where you are running this notebook.\n",
    "\n",
    "You can launch TensorBoard either during your job or after it completes. First, create an Azure ML TensorBoard object and pass it the run(s) with the logs you wish to visualize. The TensorBoard constructor takes an array of runs, so if you only want to visualize one run, pass it in as a single-element array.\n",
    "\n",
    "Then, call the `start()` method, which will launch and start the TensorBoard server on your local machine. This will give you the URI from where you can access TensorBoard in your browser. By default this will be http://localhost:6006/. You can change the port that the TensorBoard instance will run on by specifying the `port` parameter to the `TensorBoard()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.tensorboard import Tensorboard\n",
    "\n",
    "tb = Tensorboard([run])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you are done using TensorBoard, be sure to call `stop()` to stop the TensorBoard instance, otherwise it will continue to run until you shut down your notebook kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on using TensorBoard to visualize your Azure ML experiments, see [Visualize metrics with TensorBoard](https://docs.microsoft.com/azure/machine-learning/how-to-monitor-tensorboard) and the [TensorBoard reference documentation](https://docs.microsoft.com/python/api/azureml-tensorboard/azureml.tensorboard.tensorboard?view=azure-ml-py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}