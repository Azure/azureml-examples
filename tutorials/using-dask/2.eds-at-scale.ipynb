{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Science (EDS) at scale with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade \"dask-cloudprovider[azure]\" dask-lightgbm lightgbm dask distributed bokeh adlfs fsspec fastparquet pyarrow python-snappy lz4 gitpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile dask.yml\n",
    "name: dask-tutorial\n",
    "channels:\n",
    "  - defaults\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8.5\n",
    "  - pip\n",
    "  - lz4\n",
    "  - pip:\n",
    "    - azureml-mlflow\n",
    "    - azureml-dataprep\n",
    "    - dask\n",
    "    - distributed\n",
    "    - pyarrow\n",
    "    - fastparquet\n",
    "    - bokeh\n",
    "    - mpi4py\n",
    "    - adlfs\n",
    "    - fsspec\n",
    "    - optuna\n",
    "    - dask_optuna\n",
    "    - lightgbm\n",
    "    - dask-lightgbm\n",
    "    - dask-ml\n",
    "    - xgboost\n",
    "    - notebook\n",
    "    - jupyterlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dask Cluster on AML Compute\n",
    "\n",
    "Using https://github.com/dask/dask-cloudprovider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from dask.distributed import Client\n",
    "from dask_cloudprovider import AzureMLCluster\n",
    "\n",
    "env = Environment.from_conda_specification(\"dask-tutorial\", \"dask.yml\")\n",
    "cluster = AzureMLCluster(\n",
    "    ws,\n",
    "    vm_size=\"STANDARD_DS5_V2\",\n",
    "    environment_definition=env,\n",
    "    initial_node_count=40,\n",
    "    scheduler_idle_timeout=1200,\n",
    ")\n",
    "\n",
    "c = Client(cluster)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_name = \"isdweatherdatacontainer\"\n",
    "\n",
    "storage_options = {\"account_name\": \"azureopendatastorage\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "fs = AzureBlobFileSystem(**storage_options)\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "files = fs.glob(f\"{container_name}/ISDWeather/year=*/month=*/*.parquet\")\n",
    "files = [f\"az://{file}\" for file in files]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import dask.dataframe as dd\n",
    "\n",
    "npartitions = 256\n",
    "engine = \"pyarrow\"\n",
    "blocksize = \"1GB\"\n",
    "\n",
    "ddf = dd.read_parquet(\n",
    "    files, storage_options=storage_options, engine=engine, blocksize=blocksize\n",
    ").repartition(npartitions=npartitions)\n",
    "ddf = ddf.set_index(\n",
    "    dd.to_datetime(ddf.datetime).dt.floor(\"d\"), sorted=False\n",
    ").persist()\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "len(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "len(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbs = round(ddf.memory_usage(index=True, deep=True).sum().compute() / 1e9, 2)\n",
    "print(f\"ddf is {gbs} GBs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "places = (\n",
    "    ddf.groupby(ddf.index)[[\"longitude\", \"latitude\", \"year\"]].mean().compute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.scatter(places.longitude, places.latitude, c=places.year)\n",
    "plt.title(\"Lat/long\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "plt.scatter(places.longitude, places.latitude, c=places.year)\n",
    "plt.title(\"Lat/long\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.xlim([-50, -30])  # zoom in\n",
    "plt.ylim([35, 40])  # zoom in\n",
    "plt.grid()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "means = ddf.groupby(ddf.index).mean().compute()\n",
    "means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for col in list(means.columns):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    # plt.style.use('dark_background')\n",
    "    means[col].plot(color=\"b\")\n",
    "    plt.title(\"Average of {}\".format(col))\n",
    "    plt.xlim([datetime(2008, 1, 1), datetime(2021, 1, 1)])\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and persist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[\"temperature\"] = ddf[\"temperature\"] * (9 / 5) + 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_name = ds.container_name\n",
    "\n",
    "storage_options = {\n",
    "    \"account_name\": ds.account_name,\n",
    "    \"account_key\": ds.account_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#  ddf.to_csv(\"az://{container_name}/data/dask/isd\", storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data and train LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(ddf.columns)\n",
    "cols = [\n",
    "    col\n",
    "    for col in cols\n",
    "    if ddf.dtypes[col] != \"object\"\n",
    "    and col not in [\"version\", \"datetime\", \"temperature\"]\n",
    "]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ddf[cols].persist()\n",
    "y = ddf.temperature.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from dask_lightgbm import LGBMRegressor\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 31,\n",
    "    \"num_iterations\": 100,\n",
    "    \"learning_rate\": 0.01,\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor(**params)\n",
    "lgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = lgbm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rmse = ((((y.to_dask_array() - y_pred) ** 2).mean()) ** 0.5).compute()\n",
    "print(f\"Training RMSE: {round(rmse, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close Cluster and Client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    c.close()\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}