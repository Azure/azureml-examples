{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimiziation (HPO) with Dask and Optuna, locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade lightgbm dask_optuna optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "\n",
    "# get root of git repo\n",
    "prefix = Path(git.Repo(\".\", search_parent_directories=True).working_tree_dir)\n",
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import time\n",
    "import mlflow\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define functions\n",
    "def preprocess_data(df):\n",
    "    X = df.drop([\"species\"], axis=1)\n",
    "    y = df[\"species\"]\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    y = enc.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, enc\n",
    "\n",
    "\n",
    "def train_model(params, num_boost_round, X_train, X_test, y_train, y_test):\n",
    "    t1 = time.time()\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test)\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[test_data],\n",
    "        valid_names=[\"test\"],\n",
    "    )\n",
    "    t2 = time.time()\n",
    "\n",
    "    return model, t2 - t1\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_proba = model.predict(X_test)\n",
    "    y_pred = y_proba.argmax(axis=1)\n",
    "    loss = log_loss(y_test, y_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define an objective for optuna to optimize\n",
    "def objective(trial):\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "        mlflow.set_experiment(\"using-dask-hpo-with-optuna-local-tutorial\")\n",
    "        # start mlflow run\n",
    "        with mlflow.start_run():\n",
    "            # enable autologging\n",
    "            mlflow.lightgbm.autolog()\n",
    "\n",
    "            # generate parameters\n",
    "            num_boost_round = trial.suggest_int(\"num_boost_round\", 1, 100)\n",
    "            params = {\n",
    "                \"objective\": \"multiclass\",\n",
    "                \"num_class\": 3,\n",
    "                \"boosting\": trial.suggest_categorical(\n",
    "                    \"boosting\", [\"gbdt\", \"dart\", \"goss\"]\n",
    "                ),\n",
    "                \"num_iterations\": trial.suggest_int(\"num_iterations\", 10, 100),\n",
    "                \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 63),\n",
    "                # \"num_threads\": trial.suggest_categorical(\"num_threads\", [1, 2, 4]),\n",
    "                \"learning_rate\": trial.suggest_loguniform(\n",
    "                    \"learning_rate\", 10e-5, 0.1\n",
    "                ),\n",
    "                \"metric\": \"multi_logloss\",\n",
    "                # \"seed\": trial.suggest_categorical(\"seed\", [1, 3, 5, 7, 11, 13, 42]),\n",
    "                \"verbose\": 0,\n",
    "            }\n",
    "\n",
    "            # read in dataset\n",
    "            df = pd.read_csv(\n",
    "                prefix.joinpath(\"data\", \"raw\", \"iris\", \"iris.csv\")\n",
    "            )\n",
    "\n",
    "            # preprocess data\n",
    "            X_train, X_test, y_train, y_test, enc = preprocess_data(df)\n",
    "\n",
    "            # train model\n",
    "            model, train_time = train_model(\n",
    "                params, num_boost_round, X_train, X_test, y_train, y_test\n",
    "            )\n",
    "            mlflow.log_metric(\"training_time\", train_time)\n",
    "\n",
    "            # evaluate model\n",
    "            loss, acc = evaluate_model(model, X_test, y_test)\n",
    "            mlflow.log_metrics({\"loss\": loss, \"accuracy\": acc})\n",
    "\n",
    "            return loss\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"test\")\n",
    "study.optimize(objective, n_trials=8, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import joblib\n",
    "import optuna\n",
    "import dask_optuna\n",
    "from dask.distributed import Client\n",
    "\n",
    "c = Client()\n",
    "print(c)\n",
    "print(c.dashboard_link)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "storage = dask_optuna.DaskStorage()\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"aml-tutorial\",\n",
    "    sampler=sampler,\n",
    "    storage=storage,\n",
    ")\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    study.optimize(objective, n_trials=500, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = study.trials_dataframe()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('temp': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ee542e58b9e48d64b181316c44da28c3cc0b18445c18860dd41752baf840b46a"
    }
   },
   "name": "Python 3.7.6 64-bit ('temp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
