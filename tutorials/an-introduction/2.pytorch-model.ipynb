{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Train your first ML model (Part 2 of 3)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the [previous tutorial](1.hello-world.ipynb), you ran a trivial \"hello world!\" script in the cloud using Azure Machine Learning's Python SDK. This time you take it a step further by submitting a script that will train a machine learning model. This example will help you understand how Azure Machine Learning eases consistent behavior between debugging on a compute instance or laptop development environment, and remote runs.\n",
    "\n",
    "Learning these concepts means that by the end of this session, you can:\n",
    "\n",
    "* Use Conda to define an Azure Machine Learning environment\n",
    "* Train a model in the cloud\n",
    "* Log metrics to Azure Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "## Your machine learning code\n",
    "\n",
    "This tutorial shows you how to train a PyTorch model on the CIFAR 10 dataset using an Azure Machine Learning Cluster. In this case you will be using a CPU cluster, but this could equally be a GPU cluster. Whilst this tutorial uses PyTorch, the steps we show you apply to *any* machine learning code. \n",
    "\n",
    "Note the code is based on [this introductory example from PyTorch](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile net.py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model import Net\n",
    "\n",
    "# download CIFAR 10 data\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=4, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # define convolutional network\n",
    "    net = Net()\n",
    "\n",
    "    # set up pytorch loss /  optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # train the network\n",
    "    for epoch in range(2):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # unpack the data\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:\n",
    "                loss = running_loss / 2000\n",
    "                print(f\"epoch={epoch + 1}, batch={i + 1:5}: loss {loss:.2f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile pytorch.yml\n",
    "name: an-introduction-tutorial\n",
    "channels:\n",
    "  - defaults\n",
    "  - pytorch\n",
    "  - anaconda\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - pip\n",
    "  - pip:\n",
    "    - torch\n",
    "    - torchvision\n",
    "    - mlflow\n",
    "    - matplotlib\n",
    "    - azureml-mlflow\n",
    "    - azureml-dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your machine learning code to Azure Machine Learning\n",
    "\n",
    "The difference to the control script below and the one used to submit \"hello world\" is that you adjust the environment to be set from the conda dependencies file you created earlier.\n",
    "\n",
    "> <span style=\"color:purple; font-weight:bold\">! NOTE <br>\n",
    "> The first time you run this script, Azure Machine Learning will build a new docker image from your PyTorch environment. The whole run could take 5-10 minutes to complete. You can see the docker build logs in the widget by selecting the `20_image_build_log.txt` in the log files dropdown. This image will be reused in future runs making them run much quicker.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remote run",
     "batchai",
     "configure run",
     "use notebook widget"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment, ScriptRunConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "env = Environment.from_conda_specification(\n",
    "    name=\"pytorch-tutorial\", file_path=\"pytorch.yml\",\n",
    ")\n",
    "exp = Experiment(workspace=ws, name=\"an-introduction-train-tutorial\")\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=\".\",\n",
    "    script=\"train.py\",\n",
    "    compute_target=\"cpu-cluster\",\n",
    "    environment=env,\n",
    ")\n",
    "\n",
    "run = exp.submit(src)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the control code\n",
    "\n",
    "Compared to the control script that submitted the \"hello world\" example, this control script introduces the following:\n",
    "\n",
    "| Code | Description\n",
    "| --- | --- |\n",
    "| `env = Environment.from_conda_specification( ...)` | Azure Machine Learning provides the concept of an `Environment` to represent a reproducible, <br>versioned Python environment for running experiments. Here you have created it from a yaml conda dependencies file.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are many ways to create AML environments, including [from a pip requirements.txt](https://docs.microsoft.com/python/api/azureml-core/azureml.core.environment.environment?view=azure-ml-py&preserve-view=true#from-pip-requirements-name--file-path-), or even [from an existing local Conda environment](https://docs.microsoft.com/python/api/azureml-core/azureml.core.environment.environment?view=azure-ml-py&preserve-view=true#from-existing-conda-environment-name--conda-environment-name-).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your image is built, select `70_driver_log.txt` to see the output of your training script, which should look like:\n",
    "\n",
    "```txt\n",
    "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
    "...\n",
    "Files already downloaded and verified\n",
    "epoch=1, batch= 2000: loss 2.19\n",
    "...\n",
    "epoch=2, batch=12000: loss 1.27\n",
    "Finished Training\n",
    "```\n",
    "\n",
    "Environments can be registered to a workspace with `env.register(ws)`, allowing them to be easily shared, reused, and versioned. Environments make it easy to reproduce previous results and to collaborate with your team.\n",
    "\n",
    "Azure Machine Learning also maintains a collection of curated environments. These environments cover common ML scenarios and are backed by cached Docker images. Cached Docker images make the first remote run faster.\n",
    "\n",
    "In short, using registered environments can save you time! More details can be found on the [environments documentation](./how-to-use-environments.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log training metrics\n",
    "\n",
    "Now that you have a model training in Azure Machine Learning, start tracking some performance metrics.\n",
    "The current training script prints metrics to the terminal. Azure Machine Learning provides a\n",
    "mechanism for logging metrics with more functionality. By adding a few lines of code, you gain the ability to visualize metrics in the studio and to compare metrics between multiple runs.\n",
    "\n",
    "### Machine learning code updates\n",
    "\n",
    "In the `../../code/train/pytorch/cifar10-cnn` directory you will notice the [train-with-logging.py](../../code/train/pytorch/cifar10-cnn/train-with-logging.py) script has been modified with one additional line that will log the loss to the Azure Machine Learning Studio:\n",
    "\n",
    "```python\n",
    "# in train.py\n",
    "import mlflow\n",
    "...\n",
    "mlflow.log_metric(\"loss\", loss)\n",
    "```\n",
    "\n",
    "Metrics in Azure Machine Learning are:\n",
    "\n",
    "- Organized by experiment and run so it's easy to keep track of and\n",
    "compare metrics\n",
    "- Equipped with a UI so we can visualize training performance in the studio or in the notebook widget\n",
    "- **Designed to scale** You can submit concurrent experiments and the Azure Machine Learning cluster will scale out (up to the maximum node count of the cluster) to run the experiments in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your machine learning code to Azure Machine Learning\n",
    "Submit your code once more. This time the widget includes the metrics where you can now see live updates on the model training loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remote run",
     "batchai",
     "configure run",
     "use notebook widget",
     "get metrics"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment, ScriptRunConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "env = Environment.from_conda_specification(\n",
    "    name=\"pytorch-env-tutorial\", file_path=\"pytorch.yml\",\n",
    ")\n",
    "exp = Experiment(\n",
    "    workspace=ws, name=\"an-introduction-train-with-logging-tutorial\"\n",
    ")\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=\".\",\n",
    "    script=\"train-with-logging.py\",\n",
    "    compute_target=\"cpu-cluster\",\n",
    "    environment=env,\n",
    ")\n",
    "\n",
    "run = exp.submit(src)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "In this session, you upgraded from a basic \"hello world!\" script to a more realistic\n",
    "training script that required a specific Python environment to run. You saw how\n",
    "to take a local Conda environment to the cloud with Azure Machine Learning Environments. Finally, you\n",
    "saw how in a few lines of code you can log metrics to Azure Machine Learning.\n",
    "\n",
    "In the next session, you'll see how to work with data in Azure Machine Learning by uploading the CIFAR10\n",
    "dataset to Azure.\n",
    "\n",
    "[Tutorial: Bring your own data](3.pytorch-model-cloud-data.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "samkemp"
   }
  ],
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "notice": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
