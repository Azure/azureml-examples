{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning the T5 model with Azure ML using Azure Container for PyTorch leveraging State of art technologies to generate news headlines style summary \n",
        "\n",
        "This sample shows how to fine tune T5 model to generate summary of a news article. We then deploy it to an online endpoint for real time inference. The model is trained on tiny sample of the dataset with a small number of epochs to illustrate the fine tuning approach.\n",
        "\n",
        "### Requirements/Prerequisites\n",
        "- An Azure acoount with active subscription [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
        "- Azure Machine Learning workspace [Configure workspace](../../../configuration.ipynb) \n",
        "- Python Environment\n",
        "- Install Azure ML Python SDK Version 2\n",
        "\n",
        "### Learning Objectives\n",
        "- Fine tune T5 small model for Summarization task with Azure ML \n",
        "- Leverage state of art ACPT environment with accelerators\n",
        "- Increase training efficiency using Deepspeed and Onnxruntime\n",
        "- Model Evaluation\n",
        "- Register the model with AzureML\n",
        "- Deploy and inference using MIR and onnxruntime\n"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 1. Setup pre-requisites\n",
        "* Install dependencies\n",
        "* Connect to AzureML Workspace. Learn more at [set up SDK authentication](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk). Replace  `<WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` below.\n",
        "* Connect to `azureml` system registry\n",
        "* Set an optional experiment name\n",
        "* Check or create compute. A single GPU node can have multiple GPU cards. For example, in one node of `Standard_ND40rs_v2` there are 8 NVIDIA V100 GPUs while in `Standard_NC12s_v3`, there are 2 NVIDIA V100 GPUs. Refer to the [docs](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu) for this information. The number of GPU cards per node is set in the param `gpus_per_node` below. Setting this value correctly will ensure utilization of all GPUs in the node. The recommended GPU compute SKUs can be found [here](https://learn.microsoft.com/en-us/azure/virtual-machines/ncv3-series) and [here](https://learn.microsoft.com/en-us/azure/virtual-machines/ndv2-series)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.1 Install dependencies \r\n",
        "* Run below cell. This is not an optional step if running in a new environment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install azure-ai-ml\n",
        "%pip install azure-identity\n",
        "%pip install datasets==2.9.0\n",
        "%pip install mlflow\n",
        "%pip install azureml-mlflow"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2 Connect to the workspace\r\n",
        "\r\n",
        "Connect to your Azure Machine Learning workspace. The [Azure Machine Learning workspace](concept-workspace.md) is the top-level resource for the service. It provides you with a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\r\n",
        "\r\n",
        "We're using `DefaultAzureCredential` to get access to the workspace. This credential should be capable of handling most Azure SDK authentication scenarios.\r\n",
        "\r\n",
        "If `DefaultAzureCredential` doesn't work for you, see [`azure-identity reference documentation`](/python/api/azure-identity/azure.identity) or [`Set up authentication`](how-to-setup-authentication.md?tabs=sdk) for more available credentials."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient, Input\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import load_component\n",
        "from azure.identity import (\n",
        "    DefaultAzureCredential,\n",
        "    InteractiveBrowserCredential,\n",
        "    ClientSecretCredential,\n",
        ")\n",
        "from azure.ai.ml.entities import AmlCompute\n",
        "import time\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential=credential)\n",
        "except:\n",
        "    ml_client = MLClient(\n",
        "        credential,\n",
        "        subscription_id=\"<SUBSCRIPTION_ID>\",\n",
        "        resource_group_name=\"<RESOURCE_GROUP>\",\n",
        "        workspace_name=\"<WORKSPACE_NAME>\",\n",
        "    )\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684094071790
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.3 Create a compute resource to run the job\r\n",
        "\r\n",
        "Azure Machine Learning needs a compute resource to run a job. This resource can be single or multi-node machines with Linux or Windows OS.\r\n",
        "In the following example script, we provision a Standard_ND40rs_v2 and create an Azure Machine Learning compute."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = \"summarization-news-summary\"\r\n",
        "\r\n",
        "# If you already have a gpu cluster, mention it here. Else will create a new one with the name 'gpu-cluster-big'\r\n",
        "compute_cluster = \"T5trainingCompute\"\r\n",
        "try:\r\n",
        "    compute = ml_client.compute.get(compute_cluster)\r\n",
        "except Exception as ex:\r\n",
        "    compute = AmlCompute(\r\n",
        "        name=compute_cluster,\r\n",
        "        size=\"Standard_ND40rs_v2\",\r\n",
        "        max_instances=2,  # For multi node training set this to an integer value more than 1\r\n",
        "    )\r\n",
        "    ml_client.compute.begin_create_or_update(compute).wait()\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684094096152
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### 3. Pick the dataset for fine-tuning the model\n",
        "\n",
        "> The [CNN DailyMail](https://huggingface.co/datasets/cnn_dailymail) dataset is larger than 1GB when uncompressed. The [download-dataset.py](./news-summary-dataset/download-dataset.py) has supports downloading a smaller fraction of the dataset. \n",
        "\n",
        "We want this sample to run quickly, so a copy of the fraction of dataset is used for fine tuning job.This means the fine tuned model will have lower accuracy, hence it should not be put to real-world use. \n",
        "* Visualize some data rows. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"cnn_dailymail\"\n",
        "dataset_config_name = \"3.0.0\"\n",
        "\n",
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\n",
        "        dataset_name,\n",
        "        dataset_config_name,\n",
        ")\n",
        "raw_datasets[\"train\"].column_names\n",
        "raw_datasets[\"train\"].to_pandas().head(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684094107847
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Create Custom Environment using Azure Container for Pytorch\r\n",
        "\r\n",
        "> We will be creating a custom environment using existing ACPT curated environment consisting of state of art technologies."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Env_Name = \"ACPT-T5\"\r\n",
        "from azure.ai.ml.entities import Environment, BuildContext\r\n",
        "env_docker_context = Environment(\r\n",
        "    build=BuildContext(path=\"environment/context\"),\r\n",
        "    name=Env_Name,\r\n",
        "    description=\"Environment created from a Docker context.\",\r\n",
        ")\r\n",
        "ml_client.environments.create_or_update(env_docker_context)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683738061023
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Finetune T5 small model for Summarization task\r\n",
        "\r\n",
        "Models that support `translation` tasks are good candidates to fine tune for `summarization`. In this example, we use the `t5-small` model for summarization task."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command, Input, Output\r\n",
        "from azure.ai.ml.entities import Data, JobService\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "job = command(\r\n",
        "    code=\".\",\r\n",
        "    command=\"python train_summarization_deepspeed_optum.py --model_name_or_path t5-small --dataset_name cnn_dailymail --dataset_config '3.0.0' \\\r\n",
        "        --do_train \\\r\n",
        "        --num_train_epochs=1 \\\r\n",
        "        --per_device_train_batch_size=16 \\\r\n",
        "        --per_device_eval_batch_size=16  \\\r\n",
        "        --output_dir outputs \\\r\n",
        "        --overwrite_output_dir \\\r\n",
        "        --fp16 \\\r\n",
        "        --deepspeed ds_config.json \\\r\n",
        "        --max_train_samples=10 \\\r\n",
        "        --max_eval_samples=10 \\\r\n",
        "        --optim adamw_ort_fused\",\r\n",
        "    compute=\"T5TrainingCompute\",\r\n",
        "    environment=\"acpt-t5@latest\",\r\n",
        "    instance_count=1,  \r\n",
        "    distribution={\r\n",
        "        \"type\": \"PyTorch\",\r\n",
        "        \"process_count_per_instance\": 8,\r\n",
        "    },\r\n",
        ") # basic environment comes with my workspace\r\n",
        "\r\n",
        "job = ml_client.jobs.create_or_update(job)\r\n",
        "job.studio_url"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684128821775
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Register the fine tuned model with the workspace\r\n",
        "\r\n",
        "We will register the model from the output of the fine tuning job. This will track lineage between the fine tuned model and the fine tuning job. The fine tuning job, further, tracks lineage to the foundation model, data and training code."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To register the example model, follow these steps:\r\n",
        "\r\n",
        "1. Go to the [Azure Machine Learning studio](https://ml.azure.com).\r\n",
        "1. In the left navigation bar, select the **Models** page.\r\n",
        "1. Select **Register**, and then choose **From local files**.\r\n",
        "1. Select __Unspecified type__ for the __Model type__.\r\n",
        "1. Select __Browse__, and choose __Browse folder__ and point to folder containing model and weights\r\n",
        "1. Select __Next__ after the folder upload is completed.\r\n",
        "1. Enter a friendly __Name__ for the model. The steps in this article assume the model is named `model-1`.\r\n",
        "1. Select __Next__, and then __Register__ to complete registration."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "timestamp = str(int(time.time()))\r\n",
        "model_name = \"T5Model\"\r\n",
        "\r\n",
        "#Onnx model registration\r\n",
        "modelpath = \"azureml://jobs/{jobname}/outputs/artifacts/outputs/onnx\".format(jobname = job.name)\r\n",
        "cloud_model = Model(\r\n",
        "    path=modelpath,\r\n",
        "    name=model_name+\"_onnx\",\r\n",
        "    type=AssetTypes.CUSTOM_MODEL,\r\n",
        "    description=\"Model created from cloud path.\",\r\n",
        "    version=timestamp,\r\n",
        ")\r\n",
        "ml_client.models.create_or_update(cloud_model)\r\n",
        "\r\n",
        "#MLFlow model registration\r\n",
        "mlflow_modelpath = \"azureml://jobs/{jobname}/outputs/artifacts/outputs/mlflow\".format(jobname = job.name)\r\n",
        "cloud_model = Model(\r\n",
        "    path=mlflow_modelpath,\r\n",
        "    name=model_name+\"_mlflow\",\r\n",
        "    type=AssetTypes.MLFLOW_MODEL,\r\n",
        "    description=\"Model created from cloud path.\",\r\n",
        "    version=timestamp,\r\n",
        ")\r\n",
        "ml_client.models.create_or_update(cloud_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684095153856
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.dsl import pipeline\r\n",
        "from azure.ai.ml import Input\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "test_data = \"small_test-inference.jsonl\"\r\n",
        "\r\n",
        "# fetch the pipeline component\r\n",
        "registry = \"azureml\"\r\n",
        "subscription_id = ml_client.subscription_id\r\n",
        "resource_group = ml_client.resource_group_name\r\n",
        "\r\n",
        "pipeline_component_func = registry_ml_client.components.get(\r\n",
        "    name=\"model_evaluation_pipeline\", label=\"latest\"\r\n",
        ")\r\n",
        "\r\n",
        "model = ml_client.models.get(name=model_name+\"_mlflow\", version = timestamp)\r\n",
        "\r\n",
        "# define the pipeline job\r\n",
        "@pipeline()\r\n",
        "def evaluation_pipeline(mlflow_model):\r\n",
        "    evaluation_job = pipeline_component_func(\r\n",
        "        # specify the foundation model available in the azureml system registry or a model from the workspace\r\n",
        "        # mlflow_model = Input(type=AssetTypes.MLFLOW_MODEL, path=f\"{mlflow_model_path}\"),\r\n",
        "        mlflow_model=mlflow_model,\r\n",
        "        # test data\r\n",
        "        test_data=Input(type=AssetTypes.URI_FILE, path=test_data),\r\n",
        "        # The following parameters map to the dataset fields\r\n",
        "        input_column_names=\"article\",\r\n",
        "        label_column_name=\"highlights\",\r\n",
        "        # Evaluation settings\r\n",
        "        task=\"text-summarization\",\r\n",
        "        # config file containing the details of evaluation metrics to calculate\r\n",
        "        # evaluation_config=Input(type=AssetTypes.URI_FILE, path=\"eval-config.json\"),\r\n",
        "        # config cluster/device job is running on\r\n",
        "        # set device to GPU/CPU on basis if GPU count was found\r\n",
        "        device=\"gpu\",\r\n",
        "    )\r\n",
        "    return {\"evaluation_result\": evaluation_job.outputs.evaluation_result}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684095559851
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submit the pipeline job for each model that we want to evaluate\r\n",
        "# you could consider submitting the pipeline jobs in parallel, provided your cluster has multiple nodes\r\n",
        "import time\r\n",
        "pipeline_jobs = []\r\n",
        "\r\n",
        "\r\n",
        "pipeline_object = evaluation_pipeline(\r\n",
        "    mlflow_model=Input(type=AssetTypes.MLFLOW_MODEL, path=f\"{model.id}\"),\r\n",
        ")\r\n",
        "# don't reuse cached results from previous jobs\r\n",
        "pipeline_object.settings.force_rerun = True\r\n",
        "pipeline_object.settings.default_compute = compute_cluster\r\n",
        "pipeline_object.display_name = f\"eval-{model.name}-{timestamp}\"\r\n",
        "pipeline_job = ml_client.jobs.create_or_update(\r\n",
        "    pipeline_object, experiment_name=experiment_name\r\n",
        ")\r\n",
        "# add model['name'] and pipeline_job.name as key value pairs to a dictionary\r\n",
        "pipeline_jobs.append({\"model_name\": model.name, \"job_name\": pipeline_job.name})\r\n",
        "# wait for the pipeline job to complete\r\n",
        "ml_client.jobs.stream(pipeline_job.name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684096237840
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow, json\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "mlflow_tracking_uri = ml_client.workspaces.get(\r\n",
        "    ml_client.workspace_name\r\n",
        ").mlflow_tracking_uri\r\n",
        "mlflow.set_tracking_uri(mlflow_tracking_uri)\r\n",
        "\r\n",
        "metrics_df = pd.DataFrame()\r\n",
        "for job in pipeline_jobs:\r\n",
        "    # concat 'tags.mlflow.rootRunId=' and pipeline_job.name in single quotes as filter variable\r\n",
        "    filter = \"tags.mlflow.rootRunId='\" + job[\"job_name\"] + \"'\"\r\n",
        "    runs = mlflow.search_runs(\r\n",
        "        experiment_names=[experiment_name], filter_string=filter, output_format=\"list\"\r\n",
        "    )\r\n",
        "    # get the compute_metrics runs.\r\n",
        "    # using a hacky way till 'Bug 2320997: not able to show eval metrics in FT notebooks - mlflow client now showing display names' is fixed\r\n",
        "    for run in runs:\r\n",
        "        # else, check if run.data.metrics.accuracy exists\r\n",
        "        if \"rouge1\" in run.data.metrics:\r\n",
        "            # get the metrics from the mlflow run\r\n",
        "            run_metric = run.data.metrics\r\n",
        "            # add the model name to the run_metric dictionary\r\n",
        "            run_metric[\"model_name\"] = job[\"model_name\"]\r\n",
        "            # convert the run_metric dictionary to a pandas dataframe\r\n",
        "            temp_df = pd.DataFrame(run_metric, index=[0])\r\n",
        "            # concat the temp_df to the metrics_df\r\n",
        "            metrics_df = pd.concat([metrics_df, temp_df], ignore_index=True)\r\n",
        "\r\n",
        "# move the model_name columns to the first column\r\n",
        "cols = metrics_df.columns.tolist()\r\n",
        "cols = cols[-1:] + cols[:-1]\r\n",
        "metrics_df = metrics_df[cols]\r\n",
        "metrics_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684096363837
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Deploy the fine tuned model to an online endpoint\r\n",
        "Online endpoints give a durable REST API that can be used to integrate with applications that need to use the model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import (\r\n",
        "    ManagedOnlineEndpoint,\r\n",
        "    ManagedOnlineDeployment,\r\n",
        "    Model,\r\n",
        "    Environment,\r\n",
        "    CodeConfiguration,\r\n",
        ")\r\n",
        "# Define an endpoint name\r\n",
        "endpoint_name = \"my-endpoint\"\r\n",
        "\r\n",
        "# Example way to define a random name\r\n",
        "import datetime\r\n",
        "\r\n",
        "endpoint_name = \"endpt-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\r\n",
        "\r\n",
        "# create an online endpoint\r\n",
        "endpoint = ManagedOnlineEndpoint(\r\n",
        "    name = endpoint_name, \r\n",
        "    description=\"this is a endpoint for T5 summarization model\",\r\n",
        "    auth_mode=\"key\"\r\n",
        ")\r\n",
        "\r\n",
        "env = Environment(\r\n",
        "    image=\"mcr.microsoft.com/azureml/curated/acpt-t5:latest\",\r\n",
        ")\r\n",
        "\r\n",
        "model = ml_client.models.get(name=model_name+\"_onnx\", version = timestamp)\r\n",
        "\r\n",
        "blue_deployment = ManagedOnlineDeployment(\r\n",
        "    name=\"blue\",\r\n",
        "    endpoint_name=endpoint_name,\r\n",
        "    model=model,\r\n",
        "    environment=env,\r\n",
        "    code_configuration=CodeConfiguration(\r\n",
        "        code=\".\", scoring_script=\"score_onnx.py\"\r\n",
        "    ),\r\n",
        "    instance_type=\"Standard_F16s_v2\",\r\n",
        "    instance_count=1,\r\n",
        ")\r\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).wait()\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684097937903
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).wait()\r\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684097779896
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invoke the endpoint to score data by using your model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the blue deployment with some sample data\r\n",
        "ml_client.online_endpoints.invoke(\r\n",
        "    endpoint_name=endpoint_name,\r\n",
        "    deployment_name=\"blue\",\r\n",
        "    request_file=\"payload.json\",\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Delete the online endpoint\r\n",
        "Don't forget to delete the online endpoint, else you will leave the billing meter running for the compute used by the endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=endpoint_name).wait()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683925114097
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}