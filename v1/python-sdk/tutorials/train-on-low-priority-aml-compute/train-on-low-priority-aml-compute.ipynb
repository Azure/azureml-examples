{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733a17f0",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "\n",
    "# Train on Low-Priority AML Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013bc5b9",
   "metadata": {},
   "source": [
    "_**A tutorial on training models using low-priority AML compute**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64715df7",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [MNIST Dataset](#MNIST-Dataset)\n",
    "1. [Setup](#Setup)\n",
    "1. [Model Checkpointing](#Model-Checkpointing)\n",
    "1. [Create a Low-Priority Cluster](#Create-a-Low-Priority-Cluster)\n",
    "1. [Experiment](#Experiment)\n",
    "1. [Handling Metrics](#Handling-Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f5ac2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook discusses training models using [low-priority compute](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-optimize-cost#low-pri-vm). Training on low-priority compute can cost much less than on dedicated compute.\n",
    "\n",
    "When creating a compute cluster, its priority must be specified. The priority can either be _dedicated_ (default) or _low priority_. (See [this API doc](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.amlcompute.amlcomputeprovisioningconfiguration?view=azure-ml-py) for details.)\n",
    "\n",
    "A job using dedicated compute is granted uninterrupted access to a VM. In contrast, a job using low-priority compute is not. A job using low-priority compute is only granted temporary access to a VM. The hardware used by low-priority jobs may be ceded to / preempted by higher priority jobs, depending on region-wide availability of hardware and other factors.\n",
    "\n",
    "When a job using low-priority compute is preempted, that job must stop running. The job waits for low-priority compute to become available again in the region. Once compute again becomes available, something notable happens: the run restarts \"from scratch\" on the new compute. In other words, previous state on the compute is lost, and the submitted Python script is re-invoked fresh on the new compute.\n",
    "\n",
    "This means that, without special handling, every time a training run is preempted and restarted, the model will start training again from scratch. For instance, when training a DNN model, every time the run is preempted and restarted, the run will start training from epoch 0 again. For this reason, we need some special handling in the training script to save state between preemptions, so previous work can be reused after restarts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08aa64",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "All models will be trained on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/), which consists of images of handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab66c9f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import some dependencies we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from azureml.core import Experiment, Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from helper import launch_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8c8a9",
   "metadata": {},
   "source": [
    "As part of the setup you have already created an Azure ML `Workspace`. Let's also create an `Experiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Choose a name for experiment\n",
    "experiment_name = \"low-priority-compute-tutorial\"\n",
    "\n",
    "# Initialize the experiment\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output[\"Subscription ID\"] = ws.subscription_id\n",
    "output[\"Workspace\"] = ws.name\n",
    "output[\"Resource Group\"] = ws.resource_group\n",
    "output[\"Location\"] = ws.location\n",
    "output[\"Experiment Name\"] = experiment.name\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "outputDf = pd.DataFrame(data=output, index=[\"\"])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fde802",
   "metadata": {},
   "source": [
    "## Model Checkpointing\n",
    "\n",
    "### How to Checkpoint\n",
    "\n",
    "When training a DNN on low-priority compute, you can checkpoint the training state periodically.\n",
    "\n",
    "In the [training script](training_script/training_script.py) used with this notebook, we checkpoint the state after each epoch:\n",
    "\n",
    "```python\n",
    "for epoch in range(...):\n",
    "    ...\n",
    "    train_epoch(...)\n",
    "\n",
    "    save_checkpoint(model, optimizer, epoch)\n",
    "    ...\n",
    "```\n",
    "\n",
    "`save_checkpoint` is implemented as:\n",
    "```python\n",
    "MODEL_CHECKPOINT_PATH = \"model_checkpoints/checkpoint.pt\"\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch):\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        },\n",
    "        MODEL_CHECKPOINT_PATH,\n",
    "    )\n",
    "    ...\n",
    "```\n",
    "\n",
    "This code saves a copy of of the relevant information to `MODEL_CHECKPOINT_PATH`. This info includes the latest model weights and optimizer state.\n",
    "\n",
    "\n",
    "### Uploading the Checkpoint to the Cloud\n",
    "\n",
    "Saving to `MODEL_CHECKPOINT_PATH` on the compute triggers an automatic upload of the model to blob storage. This is because when we launch a script run in [helper.py](helper.py) , we pass an `OutputFileDatasetConfig`:\n",
    "\n",
    "```python\n",
    "output_dataset_config = OutputFileDatasetConfig(\n",
    "    name=\"model_checkpoints\",\n",
    "    destination=output_dataset_destination,\n",
    "    source=\"model_checkpoints/\",\n",
    ")\n",
    "\n",
    "...\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    ...\n",
    "    arguments=[output_dataset_config, ...],\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "Under the hood, this ensures that the blob folder represented by `destination` is mounted to the local `model_checkpoints` directory on the compute. This means that, whenever a file is written to the `model_checkpoints` directory on the compute, it will automatically be uploaded to `destination` relative path in the default blob storage account. Also, any file available in the `destination` blob storage directory is available in the `model_checkpoints` directory on the compute. Note that if the `destination` parameter is empty, the default destination is `/dataset/{run_id}/model_checkpoints/` in the default blob storage account. See the documentation on [OutputFileDatasetConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.output_dataset_config.outputfiledatasetconfig?view=azure-ml-py) for more info.\n",
    "\n",
    "\n",
    "### Loading Checkpoints at the Start of a Run\n",
    "\n",
    "Finally, at the start of our training script, we have:\n",
    "\n",
    "```python\n",
    "if checkpoint_file_exists:\n",
    "    ...\n",
    "    model, optimizer, starting_epoch = load_checkpoint()\n",
    "    starting_epoch += 1\n",
    "else:\n",
    "    model = init_model()\n",
    "    optimizer = init_optimizer(model)\n",
    "    starting_epoch = 0\n",
    "```\n",
    "\n",
    "This means that, when the script starts, by default, it will check to see if a checkpoint already exists in storage. If a saved checkpoint exists, the script will load the saved state, and continue from there. Otherwise, the script will start training a new model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a1071",
   "metadata": {},
   "source": [
    "## Create a Low-Priority Cluster\n",
    "\n",
    "Define a function to create a compute cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compute_cluster(workspace, name, vm_priority=\"dedicated\"):\n",
    "    \"\"\"Create a compute cluster.\"\"\"\n",
    "    try:\n",
    "        compute_target = ComputeTarget(workspace=ws, name=name)\n",
    "        print(f\"Found existing cluster for {name} -- using it\")\n",
    "        return compute_target\n",
    "    except ComputeTargetException:\n",
    "        compute_config = AmlCompute.provisioning_configuration(\n",
    "            vm_size=\"Standard_NC6\", max_nodes=4, vm_priority=vm_priority\n",
    "        )\n",
    "        compute_target = ComputeTarget.create(ws, name, compute_config)\n",
    "        print(f\"Creating cluster {name}\")\n",
    "        compute_target.wait_for_completion(show_output=True)\n",
    "        return compute_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f29da",
   "metadata": {},
   "source": [
    "Invoke the function to create a low-priority compute cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pri_compute = create_compute_cluster(\n",
    "    workspace=ws, name=\"low-pri-compute-cluster\", vm_priority=\"lowpriority\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee76bcc",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Let's do an experiment simulating the preemption and restart that would happen on low-priority compute.\n",
    "\n",
    "Preemption of low-priority compute isn't something that we can demonstrate directly. Azure decides to preempt compute based on region-wide availability of hardware and other factors. However, we can try to simulate preemption using dedicated compute.\n",
    "\n",
    "### Setup\n",
    "\n",
    "Create a high priority compute cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1622abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = create_compute_cluster(workspace=ws, name=\"gpu-cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101df2e",
   "metadata": {},
   "source": [
    "### First Run\n",
    "Launch a run for 2 epochs on dedicated compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0803286",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1 = launch_run(experiment=experiment, compute_target=compute, num_epochs=2)\n",
    "\n",
    "run1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea52534",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e372b1",
   "metadata": {},
   "source": [
    "Checking metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1_metrics = run1.get_metrics()\n",
    "run1_metrics[\"training_epoch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20dc6f",
   "metadata": {},
   "source": [
    "We can see that the run only trained epochs 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9c7d6",
   "metadata": {},
   "source": [
    "### Second Run\n",
    "\n",
    "Let's start a second run that continues where the first run left off.\n",
    "\n",
    "The first run should have saved a checkpoint in the `/dataset/{run1.id}/model_checkpoints/` directory in the default blob storage account. When we start the second run, let's override the checkpoint path in storage from its default of `/dataset/{run2.id}/model_checkpoints/` to `/dataset/{run1.id}/model_checkpoints/`. The second run should continue training the model from where the first run left off. Let's see if that's the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069aeb93",
   "metadata": {},
   "source": [
    "Kicking off the second run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run2 = launch_run(\n",
    "    experiment=experiment,\n",
    "    compute_target=compute,\n",
    "    num_epochs=4,\n",
    "    output_dataset_storage_path=f\"/dataset/{run1.id}/model_checkpoints/\",\n",
    ")\n",
    "\n",
    "run2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0cdfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run2.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee5450",
   "metadata": {},
   "source": [
    "Checking the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd630af",
   "metadata": {},
   "outputs": [],
   "source": [
    "run2_metrics = run2.get_metrics()\n",
    "run2_metrics[\"training_epoch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9881bd78",
   "metadata": {},
   "source": [
    "We see that, as expected, the second run trained 2 epochs, and it picked up where the first run left off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a487c",
   "metadata": {},
   "source": [
    "### Validation Accuracy\n",
    "\n",
    "We can also plot the model's accuracy on the validation set after each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    run1_metrics[\"training_epoch\"],\n",
    "    run1_metrics[\"validation_accuracy\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"\",\n",
    "    ms=12,\n",
    "    label=\"Run 1\",\n",
    ")\n",
    "plt.plot(\n",
    "    run2_metrics[\"training_epoch\"],\n",
    "    run2_metrics[\"validation_accuracy\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"\",\n",
    "    ms=12,\n",
    "    label=\"Run 2\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(\"Epoch vs Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validaion Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd12d6",
   "metadata": {},
   "source": [
    "From the chart above, we can see that the model's accuracy on the validation set improved with each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8255a6",
   "metadata": {},
   "source": [
    "## Handling Metrics\n",
    "\n",
    "When a preempted job is resumed, metrics from previous runs are still present. This is something to keep in mind.\n",
    "\n",
    "You probably also want to ensure all metrics are flushed (a.k.a. sent from local compute to the metrics servers) around the same time that the model checkpoint is saved. This reduces the likelihood of a race condition where the checkpoint is saved and the run is preempted, but recent metrics for the run haven't yet been flushed and hence are lost.\n",
    "\n",
    "In the training script, you can see that we flush metrics right before saving the checkpoint:\n",
    "\n",
    "```python\n",
    "run.flush()\n",
    "save_checkpoint(model, optimizer, epoch)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}