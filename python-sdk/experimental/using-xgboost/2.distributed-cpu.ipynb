{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed XGBoost (CPU)\n",
    "\n",
    "Scaling out on AmlCompute is simple! The code from the previous notebook has been modified and adapted in [src/run.py](src/run.py). In particular, changes include:\n",
    "\n",
    "- use ``dask_mpi`` to initialize Dask on MPI\n",
    "- use ``argparse`` to allow for command line argument inputs\n",
    "- use ``mlflow`` logging \n",
    "\n",
    "The [environment.yml](environment.yml) contains the conda environment specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Remotely\n",
    "\n",
    "Simply use ``MpiConfiguration`` with the desired node count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: see the [``dask-mpi`` documentation](http://mpi.dask.org/en/latest/) for details on how the Dask workers and scheduler are started.\n",
    "\n",
    "By default with the Azuer ML MPI configuration, two nodes are used for the scheduler and script process.\n",
    "\n",
    "This means you should add two additional nodes to reach the desired number of worker nodes. Additionally, we need to pass in the number of vCPUs per node, which will be used to intiialize the same number of threads via ``dask_mpi.initialize(nthreads=args.cpus_per_node)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 8 + 2  # number of workers + 2 needed for scheduler and script process\n",
    "cpus_per_node = 4  # number of vCPUs per node; to initialize one thread per CPU\n",
    "\n",
    "print(f\"Nodes: {nodes}\\nCPUs/node: {cpus_per_node}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = [\n",
    "    \"--cpus_per_node\",\n",
    "    cpus_per_node,\n",
    "    \"--num_boost_round\",\n",
    "    100,\n",
    "    \"--learning_rate\",\n",
    "    0.2,\n",
    "    \"--gamma\",\n",
    "    0,\n",
    "]\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig, Experiment, Environment\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "env = Environment.from_conda_specification(\"xgboost-cpu-tutorial\", \"environment.yml\")\n",
    "mpi_config = MpiConfiguration(node_count=nodes)\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=\"src\",\n",
    "    script=\"run.py\",\n",
    "    arguments=arguments,\n",
    "    compute_target=\"cpu-cluster\",\n",
    "    environment=env,\n",
    "    distributed_job_config=mpi_config,\n",
    "    max_run_duration_seconds=60 * 60,\n",
    ")\n",
    "run = Experiment(ws, \"xgboost-cpu-tutorial\").submit(src)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Widget\n",
    "\n",
    "Optionally, view the output in the run widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for testing, wait for the run to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
