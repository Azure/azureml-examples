{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing a Fictitious Model for Hyperparameter Tuning  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the challenges in the practice of hyperparameter tuning is the computational resources it consumes, where for even a simple classification model, the running time and computational cost could be a concern. To ease such difficulty, this notebook defines a calculation-based model with four outputs that mimic the following performance metrics for a hypothetical classifier:\n",
    "\n",
    "* Precision\n",
    "* Recall\n",
    "* Training loss\n",
    "* Model accuracy\n",
    "\n",
    "These four outputs are affected by three input variables that mimic the following tuning parameters for the classifier: \n",
    "\n",
    "* Threshold\n",
    "* Number of epochs\n",
    "* Learning rate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall vs Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with defining two outputs that mimic `Precision` and `Recall` in a binary classification problem as functions of an input that mimics threshold, denoted with `thr`, using the following equations:\n",
    "\n",
    "$Precision(thr) = 0.1 + 0.9/( 1 + 5000e^{-20 \\times thr} )$\n",
    "\n",
    "$Recall(thr) = 1/(1 + 10^{-5}e^{20 \\times thr})$\n",
    "\n",
    "Taking all other parameters fixed, next figure shows how the two equations above emulate `Precision` and `Recall` as functions of `thr` in a hypothetical binary classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = np.arange(0, 1, 0.01)\n",
    "precision = 0.1 + 0.9 / (1 + 5000 * np.exp(-20 * thr))\n",
    "recall = 1 / (1 + 1e-5 * np.exp(20 * thr))\n",
    "\n",
    "prec_rec = [precision, recall]\n",
    "labels = [\"Precision\", \"Recall\"]\n",
    "for i in range(len(prec_rec)):\n",
    "    plt.plot(thr, prec_rec[i], label=labels[i])\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loss and Model Accuracy vs Number of Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the third output that mimics training `Loss` as a function of the second input that mimics number of `epochs` in a deep learning algorithm, using the following equation:\n",
    "\n",
    "$Loss(epoch) = 3 + 7e^{-0.05 \\times epoch}$\n",
    "\n",
    "As another function of number of `epochs`, we define our fourth output that mimics model `Accuracy` using the following equation:\n",
    "\n",
    "$Accuracy(epoch) = 0.95 - 3 [\\log(3-0.025 \\times epoch)]^2$\n",
    "\n",
    "Next figure shows how these two equations emulate training `Loss` and model `Accuracy` as performance metrics, changing with the number of `epochs` as a tuning parameter. Notice how the effect of data overfitting creates a peak on the model accuracy curve while the training loss can still decrease by increasing the number of epochs. Also notice that for a better visualization, the plot shows `Accuracy` in 10x its value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = np.arange(0, 100, 1)\n",
    "loss = 3 + 7 * np.exp(-0.05 * epoch)\n",
    "accuracy = 0.95 - 3 * (np.log10(3 - 0.025 * epoch)) ** 2\n",
    "\n",
    "los_acc_epoch = [loss, 10 * accuracy]\n",
    "labels = [\"Loss\", \"Accuracy (x10)\"]\n",
    "for i in range(len(los_acc_epoch)):\n",
    "    plt.plot(epoch, los_acc_epoch[i], label=labels[i])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loss and Model Accuracy vs Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we introduce the third model input to mimic the learning rate, denoted with `lr`, in a model learning algorithm. Taking all other parameters fixed, we use the following equations to emulate the change in training `Loss` and model `Accuracy` as the outputs while `lr` changes as an input:\n",
    "\n",
    "$Loss(lr) = 0.6 + [\\log(0.9-\\log(lr))]^2$\n",
    "\n",
    "$Accuracy(lr) = 0.98 â€“ [\\log(0.7-0.5\\log(lr))]^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = np.logspace(-4, 0.8)\n",
    "z = np.log10(lr)\n",
    "loss = 0.6 + (np.log10(0.9 - z)) ** 2\n",
    "accuracy = 0.98 - (np.log10(0.7 - 0.5 * z)) ** 2\n",
    "\n",
    "los_acc_lr = [loss, accuracy]\n",
    "labels = [\"Loss\", \"Accuracy\"]\n",
    "plt.xscale(\"log\")\n",
    "for i in range(len(los_acc_lr)):\n",
    "    plt.plot(lr, los_acc_lr[i], label=labels[i])\n",
    "plt.ylabel(\"Loss / Accuracy\")\n",
    "plt.xlabel(\"learning rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning as a Multivariable Optimization Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a more realistic model of hyperparameter tuning, it is important to understand that finding an optimal set of hyperparameters often leads to solving a multivariable optimization problem. In such problems, the effect of changing one tuning parameter is not limited to only one performance metric, but also affects (all) other metrics in a competing scenario, meaning that improving one metric is often a detriment to others. \n",
    "\n",
    "So far, we have created a set of deterministic univariate functions that correlate our four imaginary performance metrics (model outputs) to one tuning parameter (model input) at a time, assuming the two other parameters are fixed. To make a more realistic model of hyperparameter tuning as a multivariable optimization problem, we define the following multivariate functions:\n",
    "\n",
    "$Accuracy(epoch, \\; lr) = k_A \\times Accuracy(epoch) \\times Accuracy(lr)$\n",
    "\n",
    "$Precision(thr, \\; epoch, \\; lr) = k_P \\times Precision(thr) \\times Accuracy(epoch, \\; lr)$\n",
    "\n",
    "$Recall(thr, \\; epoch, \\; lr) = k_R \\times Recall(thr) \\times Accuracy(epoch, \\; lr)$\n",
    "\n",
    "$Loss(epoch, \\; lr) = k_L \\times Loss(epoch) \\times Loss(lr)$\n",
    "\n",
    "where $k_A$, $k_P$, $k_R$ and $k_L$ are constant scalar factors with default values of 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model with HyperDrive Step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AzureML HyperDrive package automates efficient hyperparameter tuning by specifying the primary metric we want hyperparameter tuning to optimize. Each training run is evaluated for the primary metric, and the early termination policy uses it to identify low-performance runs.\n",
    "\n",
    "To make our fictitious model handy with the HyperDrive step, we also define the traditional F-measure or balanced F-score that combines precision and recall as\n",
    "\n",
    "$F_1 = 2 \\times (Precision \\times Recall)/(Precision + Recall)$\n",
    "\n",
    "See an [example](./HyperDrive_MultiStep_Training_Pipeline.ipynb) of using this model in a hyperparameter tuning pipeline."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eac405e3a102007e39b7d474266b3f29064fe1851bc7a4c3889e65ca4778a0ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('azure-examples': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
