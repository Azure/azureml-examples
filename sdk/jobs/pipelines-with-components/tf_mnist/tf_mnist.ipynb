{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prerequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import required libraries\n",
    "from azure.ml import MLClient\n",
    "from azure.ml.entities import Code, Dataset\n",
    "from azure.identity import InteractiveBrowserCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter details of your AML workspace\n",
    "subscription_id = '<SUBSCRIPTION_ID>'\n",
    "resource_group = '<RESOURCE_GROUP>'\n",
    "workspace = '<AML_WORKSPACE_NAME>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(InteractiveBrowserCredential(), subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pipeline job\n",
    "\n",
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "from azure.ml.dsl import Pipeline\n",
    "from azure.ml.entities import Component\n",
    "from pathlib import Path\n",
    "\n",
    "parent_dir = ''\n",
    "\n",
    "# 1. Get component definition and transfer component to functions\n",
    "tf_component = Component.load(path=parent_dir + \"./component.yml\")\n",
    "tf_func = dsl.load_component(component=tf_component)\n",
    "\n",
    "# 2. Construct pipeline\n",
    "@dsl.pipeline(\n",
    "    description=\"Train using TF component\",\n",
    ")\n",
    "def sample_pipeline():\n",
    "    tf_job = tf_func(epochs=1)\n",
    "    tf_job.compute = \"cpu-cluster\"\n",
    "    tf_job.outputs.trained_model_output.mode = \"upload\"\n",
    "    tf_job.distribution.worker_count = 1\n",
    "    tf_job.distribution.distributionType = \"tensorflow\"\n",
    "    tf_job.resources.instance_count = 2\n",
    "\n",
    "# create pipeline instance\n",
    "pipeline = sample_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit job to workspace\n",
    "returned_job = ml_client.jobs.create_or_update(pipeline, experiment_name=\"tf_mnist\", continue_run_on_step_failure=True)\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e9e0e270b75c5e6da2e22113ba4f77b864d68f95da6601809c29e46c73ae6bb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
