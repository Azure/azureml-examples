{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6b685d",
   "metadata": {},
   "source": [
    "TODO: does this work locally AND remotely?\n",
    "TODO: \"This is a N part series of tutorials\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aadfd2",
   "metadata": {},
   "source": [
    "# PyTorch image classification from prep to deployment (part I data preparation)\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial you should be able to use Azure Machine Learning (AzureML) to:\n",
    "- ingest a large dataset from a simple url\n",
    "- quickly implement basic commands for data preparation\n",
    "- assemble a pipeline with custom data preparation (python) scripts\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you need:\n",
    "- to have provisioned an AzureML workspace\n",
    "- to have permissions to create simple SKUs in your resource group\n",
    "- a python environment\n",
    "\n",
    "**Motivations** - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf27f86",
   "metadata": {},
   "source": [
    "# 1. Introduction to the end-to-end scenario\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641f516",
   "metadata": {},
   "source": [
    "# 2. Set up the pipeline resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbefdd",
   "metadata": {},
   "source": [
    "## 2.1. Connect to your AzureML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99101368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle to the workspace\n",
    "from azure.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import InteractiveBrowserCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    InteractiveBrowserCredential(), \n",
    "    subscription_id = '<SUBSCRIPTION_ID>', \n",
    "    resource_group = '<RESOURCE_GROUP>', \n",
    "    workspace = '<AML_WORKSPACE_NAME>'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405eae5b",
   "metadata": {},
   "source": [
    "# 3. Implement a reusable data preparation pipeline\n",
    "\n",
    "motivation..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ab207",
   "metadata": {},
   "source": [
    "## 3.1. Unzip archives with a simple command (no code component)\n",
    "\n",
    "In our use case, we want to shortcut having to download locally and upload the data into AzureML. So first, we'll have to unzip the archives provided from the COCO web urls. Unzipping is not the most complex operation. Running it in a reusable manner in a cloud pipeline job can require a lot of boilerplate code. Instead of writing a python script for that purpose, we just want to run the command itself.\n",
    "\n",
    "Here, we will embed the unzip call in a [CommandComponent](TODO) that specifies inputs, outputs and environment of that command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88190d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "from azure.ml.entities import CommandComponent, JobInput, JobOutput\n",
    "\n",
    "download_unzip_component = CommandComponent(\n",
    "    name=\"download_and_unzip\", # optional: this will show in the UI\n",
    "\n",
    "    # this component has no code, just a simple unzip command\n",
    "    # TODO: command = \"wgetls -lr ${{inputs.archive_path}}; unzip ${{inputs.archive_path}} -d ${{outputs.extracted_data}}\",\n",
    "    command = \"curl -o local_archive.zip ${{inputs.url}} && unzip local_archive.zip -d ${{outputs.extracted_data}}\",\n",
    "\n",
    "    # inputs and outputs need to match with the command\n",
    "    inputs = {\n",
    "        'url': { 'type': 'string' }\n",
    "    },\n",
    "    outputs = {\n",
    "        'extracted_data': { 'type': 'path' }\n",
    "    },\n",
    "\n",
    "    # we're using a curated environment\n",
    "    environment = 'AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:9',\n",
    ")\n",
    "\n",
    "# we'll package this unzip command as a component to use within a pipeline\n",
    "download_unzip_component_func = dsl.load_component(component=download_unzip_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda23d6f",
   "metadata": {},
   "source": [
    "## 3.2. Custom python script for extracting annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc968181",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_annotations_func = dsl.load_component(yaml_file=\"./components/coco_extract_annotations/spec.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(parse_annotations_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00903f3a",
   "metadata": {},
   "source": [
    "## 3.3. Assemble as a pipeline in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "\n",
    "# the dsl decorator tells the sdk that we are defining an AML pipeline\n",
    "@dsl.pipeline(\n",
    "    compute=\"cpu-d14-v2\", #\"cpu-cluster\", # TODO: document\n",
    "    description=\"e2e images preparation\", # TODO: document\n",
    ")\n",
    "def coco_preparation_pipeline(annotations_archive_url, train_archive_url, valid_archive_url, category_id, category_name):\n",
    "    # TODO: document\n",
    "    annotations_unzip_step = download_unzip_component_func(\n",
    "        url=annotations_archive_url\n",
    "    )\n",
    "\n",
    "    # TODO: document\n",
    "    train_unzip_step = download_unzip_component_func(\n",
    "        url=train_archive_url\n",
    "    )\n",
    "\n",
    "    # TODO: document\n",
    "    valid_unzip_step = download_unzip_component_func(\n",
    "        url=valid_archive_url\n",
    "    )\n",
    "\n",
    "    # TODO: document\n",
    "    parse_annotations_step = parse_annotations_func(\n",
    "        annotations_dir=annotations_unzip_step.outputs.extracted_data,\n",
    "        category_id=category_id,\n",
    "        category_name=category_name\n",
    "    )\n",
    "\n",
    "    # TODO: document\n",
    "    return {\n",
    "        \"train_images\": train_unzip_step.outputs.extracted_data,\n",
    "        \"valid_images\": valid_unzip_step.outputs.extracted_data,\n",
    "        \"train_annotations\": parse_annotations_step.outputs.train_annotations,\n",
    "        \"valid_annotations\": parse_annotations_step.outputs.valid_annotations,\n",
    "    }\n",
    "\n",
    "# TODO: document\n",
    "help(coco_preparation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import Dataset\n",
    "from azure.ml.entities import JobInput, JobOutput\n",
    "\n",
    "pipeline_instance = coco_preparation_pipeline(\n",
    "    annotations_archive_url=\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\",\n",
    "    train_archive_url=\"http://images.cocodataset.org/zips/train2017.zip\",\n",
    "    valid_archive_url=\"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "    category_id=1,\n",
    "    category_name=\"contains_person\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the pipeline job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_instance,\n",
    "    \n",
    "    # Project's name\n",
    "    experiment_name=\"e2e_image_sample\",\n",
    "    \n",
    "    # If there is no dependency, pipeline run will continue even after the failure of one component\n",
    "    continue_run_on_step_failure=True,\n",
    ")\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26664b",
   "metadata": {},
   "source": [
    "# 2. Training a distributed gpu job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "\n",
    "training_func = dsl.load_component(yaml_file=\"./components/pytorch_dl_train/spec.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(training_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "\n",
    "# the dsl decorator tells the sdk that we are defining an AML pipeline\n",
    "@dsl.pipeline(\n",
    "    compute=\"gpu-cluster\", #\"cpu-cluster\", # TODO: document\n",
    "    description=\"e2e images classification\", # TODO: document\n",
    ")\n",
    "def coco_model_training(training_images, validation_images, training_annotations, validation_annotations, epochs=1, nodes=1):\n",
    "    # TODO: document\n",
    "    training_step = training_func(\n",
    "        train_images=training_images,\n",
    "        valid_images=validation_images,\n",
    "        train_annotations=training_annotations,\n",
    "        valid_annotations=validation_annotations,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    training_step.distribution.instance_count  = nodes\n",
    "\n",
    "    # TODO: document\n",
    "    return {\n",
    "        \"model\": training_step.outputs.trained_model\n",
    "    }\n",
    "\n",
    "# TODO: document\n",
    "help(coco_model_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c14fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import Dataset\n",
    "from azure.ml.entities import JobInput, JobOutput\n",
    "\n",
    "pipeline_instance = coco_model_training(\n",
    "    training_images=ml_client.datasets.get(\"coco_val2017\", version=1),\n",
    "    validation_images=ml_client.datasets.get(\"coco_val2017\", version=1),\n",
    "    training_annotations=ml_client.datasets.get(\"coco_val2017_annotations\", version=2),\n",
    "    validation_annotations=ml_client.datasets.get(\"coco_val2017_annotations\", version=2),\n",
    "    epochs=10,\n",
    "    nodes=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the pipeline job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_instance,\n",
    "    \n",
    "    # Project's name\n",
    "    experiment_name=\"e2e_image_sample\",\n",
    "    \n",
    "    # If there is no dependency, pipeline run will continue even after the failure of one component\n",
    "    continue_run_on_step_failure=True,\n",
    ")\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829cb92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
