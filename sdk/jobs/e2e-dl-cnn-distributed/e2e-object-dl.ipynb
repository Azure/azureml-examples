{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6b685d",
   "metadata": {},
   "source": [
    "TODO: does this work locally AND remotely?\n",
    "TODO: \"This is a N part series of tutorials\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aadfd2",
   "metadata": {},
   "source": [
    "# PyTorch image classification from prep to deployment (part I)\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial you should be able to use Azure Machine Learning (AzureML) to:\n",
    "- ingest a large dataset from a simple url\n",
    "- quickly implement basic commands for data preparation\n",
    "- assemble a pipeline with custom data preparation (python) scripts\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you need:\n",
    "- to have provisioned an AzureML workspace\n",
    "- to have permissions to create simple SKUs in your resource group\n",
    "- a python environment\n",
    "\n",
    "**Motivations** - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf27f86",
   "metadata": {},
   "source": [
    "# End-to-end scenario\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641f516",
   "metadata": {},
   "source": [
    "# 1. Set up the pipeline resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99101368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle to the workspace\n",
    "from azure.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import InteractiveBrowserCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ced11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    InteractiveBrowserCredential(), \n",
    "    # subscription_id = '<SUBSCRIPTION_ID>', \n",
    "    # resource_group = '<RESOURCE_GROUP>', \n",
    "    # workspace = '<AML_WORKSPACE_NAME>'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405eae5b",
   "metadata": {},
   "source": [
    "# 2. Implement a reusable data preparation pipeline\n",
    "\n",
    "motivation..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ab207",
   "metadata": {},
   "source": [
    "## 2.1. Unzip archives with a simple command (no code component)\n",
    "\n",
    "In our use case, we want to shortcut having to download locally and upload the data into AzureML. So first, we'll have to unzip the archives provided from the COCO web urls. Unzipping is not the most complex operation. Running it in a reusable manner in a cloud pipeline job can require a lot of boilerplate code. Instead of writing a python script for that purpose, we just want to run the command itself.\n",
    "\n",
    "Here, we will embed the unzip call in a [CommandComponent](TODO) that specifies inputs, outputs and environment of that command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88190d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "from azure.ml.entities import CommandComponent, JobInput, JobOutput\n",
    "\n",
    "download_unzip_component = CommandComponent(\n",
    "    name=\"download_and_unzip\", # optional: this will show in the UI\n",
    "\n",
    "    # this component has no code, just a simple unzip command\n",
    "    # TODO: command = \"wgetls -lr ${{inputs.archive_path}}; unzip ${{inputs.archive_path}} -d ${{outputs.extracted_data}}\",\n",
    "    command = \"curl -o local_archive.zip ${{inputs.url}} && unzip local_archive.zip -d ${{outputs.extracted_data}}\",\n",
    "\n",
    "    # inputs and outputs need to match with the command\n",
    "    inputs = {\n",
    "        'url': { 'type': 'string' }\n",
    "    },\n",
    "    outputs = {\n",
    "        'extracted_data': { 'type': 'path' }\n",
    "    },\n",
    "\n",
    "    # we're using a curated environment\n",
    "    environment = 'AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:9',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00903f3a",
   "metadata": {},
   "source": [
    "## 2.2. Write a reusable pipeline in python\n",
    "\n",
    "The component we just created can now be loaded as a [component](TODO): a reusable step in a pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c17abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll package this unzip command as a component to use within a pipeline\n",
    "download_unzip_component_func = dsl.load_component(component=download_unzip_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a44973",
   "metadata": {},
   "source": [
    "This step can be used as a python function with arguments and parameters. The `inputs` and `ouputs` of the command component can be provided as python variables. We use the decorator `@dsl.pipeline` to construct an AzureML pipeline assembling components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "\n",
    "# the dsl decorator tells the sdk that we are defining an AML pipeline\n",
    "@dsl.pipeline(\n",
    "    compute=\"cpu-d14-v2\", #\"cpu-cluster\", # TODO: document\n",
    "    description=\"e2e images preparation\", # TODO: document\n",
    ")\n",
    "def coco_preparation_pipeline(annotations_archive_url, train_archive_url, valid_archive_url, category_id, category_name):\n",
    "    # TODO: document\n",
    "    annotations_unzip_step = download_unzip_component_func(\n",
    "        url=annotations_archive_url\n",
    "    )\n",
    "\n",
    "    # TODO: document\n",
    "    train_unzip_step = download_unzip_component_func(\n",
    "        url=train_archive_url\n",
    "    )\n",
    "\n",
    "    # TODO: document\n",
    "    valid_unzip_step = download_unzip_component_func(\n",
    "        url=valid_archive_url\n",
    "    )\n",
    "\n",
    "    # TODO: document\n",
    "    return {\n",
    "        \"train_images\": train_unzip_step.outputs.extracted_data,\n",
    "        \"valid_images\": valid_unzip_step.outputs.extracted_data,\n",
    "        \"trainval_annotations\": annotations_unzip_step.outputs.extracted_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d7718",
   "metadata": {},
   "source": [
    "The pipeline we just created, decorated by `@dsl.pipeline` can also be called from python, as a sub-pipeline within another pipeline, creating more complex workflows (we'll see in next section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: document\n",
    "help(coco_preparation_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b40f0d1",
   "metadata": {},
   "source": [
    "## 2.3. Run an instance of this pipeline in AzureML\n",
    "\n",
    "When calling the pipeline function decorated with `@dsl.pipeline`, we will create an instance of this pipeline with the given arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import Dataset\n",
    "from azure.ml.entities import JobInput, JobOutput\n",
    "\n",
    "pipeline_instance = coco_preparation_pipeline(\n",
    "    annotations_archive_url=\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\",\n",
    "    train_archive_url=\"http://images.cocodataset.org/zips/train2017.zip\",\n",
    "    valid_archive_url=\"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "    category_id=1,\n",
    "    category_name=\"contains_person\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232807f6",
   "metadata": {},
   "source": [
    "That instance can be submitted to AzureML and run as an experiment there. Use the [`MLClient`](TODO) to create this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the pipeline job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_instance,\n",
    "    \n",
    "    # Project's name\n",
    "    experiment_name=\"e2e_image_sample\",\n",
    "    \n",
    "    # If there is no dependency, pipeline run will continue even after the failure of one component\n",
    "    continue_run_on_step_failure=True,\n",
    ")\n",
    "\n",
    "# get a URL for the status of the job\n",
    "print(\"The url to see your live job running is returned by the sdk:\")\n",
    "print(returned_job.services[\"Studio\"].endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149a504",
   "metadata": {},
   "source": [
    "![](media/image-prep-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26664b",
   "metadata": {},
   "source": [
    "# 3. Training a distributed gpu job\n",
    "\n",
    "To run a pytorch training on multiple gpus, you have multiple options.\n",
    "\n",
    "In the following, we'll use the `pytorch` distribution setting to run a job using [`DistributedDataParallel`](TODO): multiple instances of the script will be running on each node (one per gpu on that node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c4f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "\n",
    "parse_annotations_func = dsl.load_component(yaml_file=\"./components/coco_extract_annotations/spec.yaml\")\n",
    "training_func = dsl.load_component(yaml_file=\"./components/pytorch_dl_train/spec.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973d3888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function coco_model_training_devel in module __main__:\n",
      "\n",
      "coco_model_training_devel(validation_images, trainval_annotations, category_id, category_name, epochs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ml import dsl\n",
    "\n",
    "# the dsl decorator tells the sdk that we are defining an AML pipeline\n",
    "@dsl.pipeline(\n",
    "    description=\"e2e images classification\", # TODO: document\n",
    ")\n",
    "def coco_model_training_devel(validation_images, trainval_annotations, category_id, category_name, epochs):\n",
    "    # TODO: document\n",
    "    parse_annotations_step = parse_annotations_func(\n",
    "        annotations_dir=trainval_annotations,\n",
    "        category_id=category_id,\n",
    "        category_name=category_name\n",
    "    )\n",
    "    parse_annotations_step.compute=\"cpu-cluster\"\n",
    "\n",
    "    training_step = training_func(\n",
    "        train_images=validation_images, # use validation as training\n",
    "        valid_images=validation_images,\n",
    "        train_annotations=parse_annotations_step.outputs.valid_annotations, # use validation as training\n",
    "        valid_annotations=parse_annotations_step.outputs.valid_annotations,\n",
    "        num_epochs=epochs,\n",
    "        register_model_as=\"coco_model\"\n",
    "    )\n",
    "    training_step.compute=\"gpu-cluster\"\n",
    "\n",
    "    # use process_count_per_instance to parallelize on multiple gpus\n",
    "    training_step.distribution.process_count_per_instance  = 4 # set to number of gpus on instance\n",
    "\n",
    "    # use instance_count to increase the number of nodes (machines)\n",
    "    training_step.resources.instance_count  = 2\n",
    "\n",
    "    # TODO: document\n",
    "    return {\n",
    "        \"model\": training_step.outputs.trained_model\n",
    "    }\n",
    "\n",
    "# TODO: document\n",
    "help(coco_model_training_devel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c14fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import Dataset\n",
    "from azure.ml.entities import JobInput, JobOutput\n",
    "\n",
    "pipeline_instance = coco_model_training_devel(\n",
    "    validation_images=ml_client.datasets.get(\"coco_val2017\", version=1),\n",
    "    trainval_annotations=ml_client.datasets.get(\"coco_trainval2017_annotations\", version=1),\n",
    "    epochs=1,\n",
    "    category_id=1,\n",
    "    category_name=\"person\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1d9d13",
   "metadata": {},
   "outputs": [
    {
     "ename": "UserErrorException",
     "evalue": "Required input simulated_latency_in_ms for component training_step not provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jeomhove\\source\\azureml-examples\\sdk\\jobs\\e2e-dl-cnn-distributed\\e2e-object-dl.ipynb Cell 25'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=0'>1</a>\u001b[0m \u001b[39m# submit the pipeline job\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=1'>2</a>\u001b[0m returned_job \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49mjobs\u001b[39m.\u001b[39;49mcreate_or_update(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=2'>3</a>\u001b[0m     pipeline_instance,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=3'>4</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=4'>5</a>\u001b[0m     \u001b[39m# Project's name\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=5'>6</a>\u001b[0m     experiment_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39me2e_image_sample\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=6'>7</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=7'>8</a>\u001b[0m     \u001b[39m# If there is no dependency, pipeline run will continue even after the failure of one component\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=8'>9</a>\u001b[0m     continue_run_on_step_failure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=11'>12</a>\u001b[0m \u001b[39m# get a URL for the status of the job\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jeomhove/source/azureml-examples/sdk/jobs/e2e-dl-cnn-distributed/e2e-object-dl.ipynb#ch0000024?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe url to see your live job running is returned by the sdk:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\amle2edlimage\\lib\\site-packages\\azure\\ml\\_operations\\job_operations.py:210\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[1;34m(self, job, description, compute, tags, experiment_name, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/_operations/job_operations.py?line=206'>207</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(job, Job):\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/_operations/job_operations.py?line=207'>208</a>\u001b[0m     \u001b[39m# For non-Job type instance, try to convert it to a job.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/_operations/job_operations.py?line=208'>209</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/_operations/job_operations.py?line=209'>210</a>\u001b[0m         job \u001b[39m=\u001b[39m job\u001b[39m.\u001b[39;49m_to_job(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/_operations/job_operations.py?line=210'>211</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/_operations/job_operations.py?line=211'>212</a>\u001b[0m         \u001b[39m# If the job instance is not Job or _JobLike, raise error\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/_operations/job_operations.py?line=212'>213</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to parse \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(job)\u001b[39m}\u001b[39;00m\u001b[39m to job.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\amle2edlimage\\lib\\site-packages\\azure\\ml\\dsl\\_pipeline.py:96\u001b[0m, in \u001b[0;36mPipeline._to_job\u001b[1;34m(self, continue_run_on_step_failure)\u001b[0m\n\u001b[0;32m     <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=93'>94</a>\u001b[0m built_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_outputs()\n\u001b[0;32m     <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=94'>95</a>\u001b[0m \u001b[39m# Build the jobs to dict\u001b[39;00m\n\u001b[1;32m---> <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=95'>96</a>\u001b[0m component_jobs \u001b[39m=\u001b[39m {name: node\u001b[39m.\u001b[39m_to_job() \u001b[39mfor\u001b[39;00m name, node \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodes\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m     <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=97'>98</a>\u001b[0m settings \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=98'>99</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontinue_run_on_step_failure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\amle2edlimage\\lib\\site-packages\\azure\\ml\\dsl\\_pipeline.py:96\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=93'>94</a>\u001b[0m built_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_outputs()\n\u001b[0;32m     <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=94'>95</a>\u001b[0m \u001b[39m# Build the jobs to dict\u001b[39;00m\n\u001b[1;32m---> <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=95'>96</a>\u001b[0m component_jobs \u001b[39m=\u001b[39m {name: node\u001b[39m.\u001b[39;49m_to_job() \u001b[39mfor\u001b[39;00m name, node \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodes\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m     <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=97'>98</a>\u001b[0m settings \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_pipeline.py?line=98'>99</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontinue_run_on_step_failure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\amle2edlimage\\lib\\site-packages\\azure\\ml\\dsl\\_component.py:194\u001b[0m, in \u001b[0;36mComponent._to_job\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=188'>189</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_job\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ComponentJob:\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=189'>190</a>\u001b[0m     \u001b[39m\"\"\"Convert current parameterized component instance to a command job object before submission.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=190'>191</a>\u001b[0m \n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=191'>192</a>\u001b[0m \u001b[39m    :return: Built component job.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=192'>193</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=193'>194</a>\u001b[0m     built_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_inputs()\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=194'>195</a>\u001b[0m     built_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_outputs()\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=196'>197</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_entity\u001b[39m.\u001b[39mid:\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=197'>198</a>\u001b[0m         \u001b[39m# If component is remote, directly pass it's asset id\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\amle2edlimage\\lib\\site-packages\\azure\\ml\\dsl\\_component.py:156\u001b[0m, in \u001b[0;36mComponent._build_inputs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=151'>152</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=152'>153</a>\u001b[0m         \u001b[39m# TODO: move this to _validate_inputs\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=153'>154</a>\u001b[0m         \u001b[39m# TODO: add \"optional\" property to ComponentInput when we don't rely on schema to parse component\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=154'>155</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_entity\u001b[39m.\u001b[39minputs[key]\u001b[39m.\u001b[39m_optional \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=155'>156</a>\u001b[0m             \u001b[39mraise\u001b[39;00m UserErrorException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRequired input \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m for component \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m not provided.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///~/Miniconda3/envs/amle2edlimage/lib/site-packages/azure/ml/dsl/_component.py?line=156'>157</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n",
      "\u001b[1;31mUserErrorException\u001b[0m: Required input simulated_latency_in_ms for component training_step not provided."
     ]
    }
   ],
   "source": [
    "# submit the pipeline job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_instance,\n",
    "    \n",
    "    # Project's name\n",
    "    experiment_name=\"e2e_image_sample\",\n",
    "    \n",
    "    # If there is no dependency, pipeline run will continue even after the failure of one component\n",
    "    continue_run_on_step_failure=True,\n",
    ")\n",
    "\n",
    "# get a URL for the status of the job\n",
    "print(\"The url to see your live job running is returned by the sdk:\")\n",
    "print(returned_job.services[\"Studio\"].endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829cb92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
