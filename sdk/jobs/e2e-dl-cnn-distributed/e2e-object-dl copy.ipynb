{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6b685d",
   "metadata": {},
   "source": [
    "TODO: does this work locally AND remotely?\n",
    "TODO: \"This is a N part series of tutorials\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aadfd2",
   "metadata": {},
   "source": [
    "# PyTorch image classification from prep to deployment (part I data preparation)\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial you should be able to use Azure Machine Learning (AzureML) to:\n",
    "- ingest a large dataset from a simple url\n",
    "- quickly implement basic commands for data preparation\n",
    "- assemble a pipeline with custom data preparation (python) scripts\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you need:\n",
    "- to have provisioned an AzureML workspace\n",
    "- to have permissions to create simple SKUs in your resource group\n",
    "- a python environment\n",
    "\n",
    "**Motivations** - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf27f86",
   "metadata": {},
   "source": [
    "# 1. Introduction to the end-to-end scenario\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641f516",
   "metadata": {},
   "source": [
    "# 2. Set up the pipeline resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbefdd",
   "metadata": {},
   "source": [
    "## 2.1. Connect to your AzureML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99101368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle to the workspace\n",
    "from azure.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import InteractiveBrowserCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ced11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    InteractiveBrowserCredential(), \n",
    "    subscription_id = '48bbc269-ce89-4f6f-9a12-c6f91fcb772d',\n",
    "    resource_group_name = 'aml1p-rg',\n",
    "    workspace_name = 'aml1p-ml-eus2'\n",
    "    #subscription_id = '<SUBSCRIPTION_ID>', \n",
    "    #resource_group = '<RESOURCE_GROUP>', \n",
    "    #workspace = '<AML_WORKSPACE_NAME>'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a5db4",
   "metadata": {},
   "source": [
    "## 2.2. Create a compute resource\n",
    "\n",
    "Each step of an AML pipelines can use a different compute resource for running the specific job of that step. It can be single or multi-node machines with Linux or Windows OS, or a specific compute fabric like spark.\n",
    "\n",
    "In this section, we provision a Linux compute cluster for our tasks in this tutorial. Let's start by listing the available VM sizes available for use. Check the docs for the [full list on VM sizes and prices](https://azure.microsoft.com/en-ca/pricing/details/machine-learning/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import AmlCompute, Compute\n",
    "import pandas as pd\n",
    "\n",
    "# Let's have a peak at the most important properties\n",
    "VM_dict = {\n",
    "    vm.name: {\n",
    "        \"family\": vm.family,\n",
    "        \"hdd_size\": vm.os_vhd_size_mb,\n",
    "        \"memory\": vm.memory_gb,\n",
    "        \"cpus\": vm.v_cp_us,\n",
    "        \"gpus\": vm.gpus,\n",
    "    }\n",
    "    for vm in ml_client.compute.list_sizes()\n",
    "}\n",
    "VM_df = pd.DataFrame.from_dict(VM_dict, orient='index')\n",
    "\n",
    "# Let's take a look at one VM Family, you can change the code and explore more\n",
    "VM_df[VM_df['family']=='standardDSv2Family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vm in ml_client.compute.list_sizes():\n",
    "    print(vm)\n",
    "    for value in vm.estimated_vm_prices.values:\n",
    "        print(value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053660f",
   "metadata": {},
   "source": [
    "For this tutorial we only need a basic cluster, let's pick `Standard_DS2_v2` and create am AML Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b87db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the AML compute object with the intended parameters\n",
    "cluster_basic = AmlCompute(\n",
    "    # Name assigned to the compute cluster\n",
    "    name=\"cpu-cluster\",\n",
    "    \n",
    "    # AML Compte is AML's on-demand VM service\n",
    "    type=\"amlcompute\",\n",
    "   \n",
    "    # VM Family\n",
    "    size=\"Standard_DS2_v2\",\n",
    "    \n",
    "    # Minimum running nodes when there is no job running\n",
    "    min_instances=0,\n",
    "    \n",
    "    # nodes in cluster\n",
    "    max_instances=2,\n",
    "    \n",
    "    # How many seconds will the node running after the job termination\n",
    "    idle_time_before_scale_down=120,\n",
    "    \n",
    "    # dedicated or LowPriority. The latter is cheaper but there is a chance of job termination \n",
    "    tier='dedicated'\n",
    ")\n",
    "\n",
    "# Now, we pass the object to clinet's create_or_update method\n",
    "ml_client.begin_create_or_update(cluster_basic)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b8ed658",
   "metadata": {},
   "source": [
    "from azure.ml.entities import Dataset\n",
    "\n",
    "coco_trainval_path = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "\n",
    "coco_trainval_dataset = Dataset(\n",
    "    name=\"coco_trainval2017_zip\",\n",
    "    paths=[dict(file=coco_trainval_path)],\n",
    "    description=\"annotations_trainval2017.zip\",\n",
    "    tags={'source_type':'web',\n",
    "          'source':'cocodataset.org'\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405eae5b",
   "metadata": {},
   "source": [
    "# 3. Implement a reusable data preparation pipeline\n",
    "\n",
    "motivation..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ab207",
   "metadata": {},
   "source": [
    "## 3.1. Unzip archives with a simple command (no code component)\n",
    "\n",
    "In our use case, we want to shortcut having to download locally and upload the data into AzureML. So first, we'll have to unzip the archives provided from the COCO web urls. Unzipping is not the most complex operation. Running it in a reusable manner in a cloud pipeline job can require a lot of boilerplate code. Instead of writing a python script for that purpose, we just want to run the command itself.\n",
    "\n",
    "Here, we will embed the unzip call in a [CommandComponent](TODO) that specifies inputs, outputs and environment of that command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88190d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "from azure.ml.entities import CommandComponent, JobInput, JobOutput\n",
    "\n",
    "unzip_component = CommandComponent(\n",
    "    name=\"Unzip\", # optional: this will show in the UI\n",
    "    \n",
    "    # this component has no code, just a simple unzip command\n",
    "    # TODO: command = \"ls -lr ${{inputs.archive_path}}; unzip ${{inputs.archive_path}} -d ${{outputs.extracted_data}}\",\n",
    "    command = \"ls -lr ${{inputs.archive_path}}; unzip ${{inputs.archive_path}}/*.zip -d ${{outputs.extracted_data}}\",\n",
    "\n",
    "    # inputs and outputs need to match with the command\n",
    "    inputs = {\n",
    "        'archive_path': { 'type': 'path' }\n",
    "    },\n",
    "    outputs = {\n",
    "        'extracted_data': { 'type': 'path' }\n",
    "    },\n",
    "    \n",
    "    # we're using a curated environment\n",
    "    environment = 'AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:9',\n",
    ")\n",
    "\n",
    "# we'll package this unzip command as a component to use within a pipeline\n",
    "unzip_component_func = dsl.load_component(component=unzip_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda23d6f",
   "metadata": {},
   "source": [
    "## 3.2. Custom python script for extracting annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc968181",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_annotations_func = dsl.load_component(yaml_file=\"./components/coco_extract_annotations/spec.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(parse_annotations_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00903f3a",
   "metadata": {},
   "source": [
    "## 3.3. Assemble as a pipeline in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import dsl\n",
    "\n",
    "# we'll package this unzip command as a component to use within a pipeline\n",
    "unzip_component_func = dsl.load_component(component=unzip_component)\n",
    "parse_annotations_func = dsl.load_component(yaml_file=\"./components/coco_extract_annotations/spec.yaml\")\n",
    "\n",
    "# the dsl decorator tells the sdk that we are defining an AML pipeline\n",
    "@dsl.pipeline(\n",
    "    compute=\"cpu-d14-v2\", #\"cpu-cluster\",\n",
    "    description=\"e2e images preparation\",\n",
    ")\n",
    "def coco_preparation_pipeline(annotations_archive, train_archive, valid_archive, category_id, category_name, use_val_as_train=False):\n",
    "    annotations_unzip_step = unzip_component_func(\n",
    "        archive_path=annotations_archive\n",
    "    )\n",
    "\n",
    "    if use_val_as_train:\n",
    "        train_unzip_step = unzip_component_func(\n",
    "            archive_path=valid_archive\n",
    "        )\n",
    "    else:\n",
    "        train_unzip_step = unzip_component_func(\n",
    "            archive_path=train_archive\n",
    "        )\n",
    "    custom_outputs['train_images'] = train_unzip_step.outputs.extracted_data\n",
    "\n",
    "    valid_unzip_step = unzip_component_func(\n",
    "        archive_path=valid_archive\n",
    "    )\n",
    "    custom_outputs['valid_images'] = valid_unzip_step.outputs.extracted_data\n",
    "\n",
    "    parse_annotations_step = parse_annotations_func(\n",
    "        annotations_dir=annotations_unzip_step.outputs.extracted_data,\n",
    "        category_id=category_id,\n",
    "        category_name=category_name\n",
    "    )\n",
    "    if use_val_as_train:\n",
    "        custom_outputs[\"train_annotations\"] = parse_annotations_step.outputs.train_annotations\n",
    "        custom_outputs[\"valid_annotations\"] = parse_annotations_step.outputs.valid_annotations\n",
    "    else:\n",
    "        custom_outputs[\"train_annotations\"] = parse_annotations_step.outputs.valid_annotations\n",
    "        custom_outputs[\"valid_annotations\"] = parse_annotations_step.outputs.valid_annotations\n",
    "\n",
    "    return custom_outputs\n",
    "\n",
    "help(coco_preparation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import Dataset\n",
    "from azure.ml.entities import JobInput, JobOutput\n",
    "\n",
    "pipeline_instance = coco_preparation_pipeline(\n",
    "    # TODO: annotations_archive=JobInput(file=\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"),\n",
    "    annotations_archive=ml_client.datasets.get(\"coco_annotatons_trainval2017_archive\", version=\"1\"),\n",
    "    # TODO: train_archive=JobInput(file=\"http://images.cocodataset.org/zips/train2017.zip\"),\n",
    "    train_archive=ml_client.datasets.get(\"coco_train2017_archive\", version=\"1\"),\n",
    "    # TODO: valid_archive=JobInput(file=\"http://images.cocodataset.org/zips/val2017.zip\"),\n",
    "    valid_archive=ml_client.datasets.get(\"coco_val2017_archive\", version=\"1\"),\n",
    "    category_id=1,\n",
    "    category_name=\"contains_person\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the pipeline job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_instance,\n",
    "    \n",
    "    # Project's name\n",
    "    experiment_name=\"e2e_image_preparation\",\n",
    "    \n",
    "    # If there is no dependency, pipeline run will continue even after the failure of one component\n",
    "    continue_run_on_step_failure=True,\n",
    ")\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4f64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
