{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline with Components from yaml\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace. [Check this notebook for creating a workspace](/sdk/resources/workspace/workspace.ipynb) \n",
    "- A Compute Cluster. [Check this notebook to create a compute cluster](/sdk/resources/compute/compute.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](/sdk/README.md#getting-started)\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Connect to your AML workspace from the Python SDK\n",
    "- Define and load `CommandComponent` from YAML\n",
    "- Create `Pipeline` using loaded component.\n",
    "\n",
    "**Motivations** - This notebook covers the scenario that user define components using yaml then use these components to build pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.ml import MLClient, dsl\n",
    "from azure.ml.entities import JobInput, load_component\n",
    "from azure.ml._constants import AssetTypes\n",
    "import piprunpkg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure credential\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. When an access token is needed, it requests one using multiple identities(`EnvironmentCredential, ManagedIdentityCredential, SharedTokenCacheCredential, VisualStudioCodeCredential, AzureCliCredential, AzurePowerShellCredential`) in turn, stopping when one provides a token.\n",
    "Reference [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for more information.\n",
    "\n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "Reference [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python) for all available credentials if it does not work for you.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token('https://management.azure.com/.default')\n",
    "except Exception as ex:\n",
    "    # If exception happens when retrieve token, try exclude the failed credential like this then try again:\n",
    "    # Exclude VSCode credential:\n",
    "    # credential = DefaultAzureCredential(exclude_visual_studio_code_credential=True)\n",
    "    raise Exception(\"Failed to retrieve a token from the included credentials due to the following exception, try to add `exclude_xxx_credential=True` to `DefaultAzureCredential` and try again.\") from ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ml` to get a handle to the required Azure Machine Learning workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ml_client = MLClient.from_config(credential=credential)\n",
    "except Exception as ex:\n",
    "    # NOTE: Update following workspace information if not correctly configure before\n",
    "    client_config = {\n",
    "        \"subscription_id\": \"<SUBSCRIPTION_ID>\",\n",
    "        \"resource_group\": \"<RESOURCE_GROUP>\",\n",
    "        \"workspace_name\": \"<WORKSPACE_NAME>\"\n",
    "    }\n",
    "\n",
    "    if client_config[\"subscription_id\"].startswith('<'):\n",
    "        print(\"please update your <SUBSCRIPTION_ID> <RESOURCE_GROUP> <WORKSPACE_NAME> in notebook cell\")\n",
    "        raise ex\n",
    "    else:  # write and reload from config file\n",
    "        import json, os\n",
    "        config_path = \"../../.azureml/config.json\"\n",
    "        os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
    "        with open(config_path, \"w\") as fo:\n",
    "            fo.write(json.dumps(client_config))\n",
    "        ml_client = MLClient.from_config(credential=credential, path=config_path)\n",
    "print(ml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Retrieve or create an Azure Machine Learning compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve an already attached Azure Machine Learning Compute.\n",
    "cluster_name = \"cpu-cluster\"\n",
    "try:\n",
    "    ml_client.compute.get(name=cluster_name)\n",
    "except Exception:\n",
    "    print('Creating a new compute target...')\n",
    "    from azure.ml.entities import AmlCompute\n",
    "    compute = AmlCompute(\n",
    "        name=cluster_name,\n",
    "        size=\"Standard_D2_v2\",\n",
    "        max_instances=2\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define and create components into workspace\n",
    "## 2.1 Load components from YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '.'\n",
    "#parent_dir = \"D:\\\\practice\\\\azureml-examples\\\\sdk\\\\jobs\\\\pipelines\\\\1a_pipeline_with_components_from_yaml\"\n",
    "train_model = load_component(yaml_file=parent_dir + \"/train_model.yml\")\n",
    "score_data = load_component(yaml_file=parent_dir + \"/score_data.yml\")\n",
    "eval_model = load_component(yaml_file=parent_dir + \"/eval_model.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Inspect loaded component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
      "name: train_model\n",
      "version: 0.0.1\n",
      "display_name: Train Model\n",
      "description: A dummy training component\n",
      "type: command\n",
      "inputs:\n",
      "  training_data:\n",
      "    type: uri_folder\n",
      "  max_epochs:\n",
      "    type: integer\n",
      "    optional: true\n",
      "  learning_rate:\n",
      "    type: number\n",
      "    default: '0.01'\n",
      "  learning_rate_schedule:\n",
      "    type: string\n",
      "    default: time-based\n",
      "outputs:\n",
      "  model_output:\n",
      "    type: uri_folder\n",
      "command: python train.py  --training_data ${{inputs.training_data}}  [--max_epochs\n",
      "  ${{inputs.max_epochs}}]  --learning_rate ${{inputs.learning_rate}}  --learning_rate_schedule\n",
      "  ${{inputs.learning_rate_schedule}}  --model_output ${{outputs.model_output}}\n",
      "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:5\n",
      "code: azureml:./train_src\n",
      "is_deterministic: true\n",
      "tags: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the component as yaml\n",
    "print(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'azure.ml.entities._component.command_component.CommandComponent'>\n",
      "Help on function [component] Train Model:\n",
      "\n",
      "[component] Train Model(*, training_data: 'uri_folder' = None, max_epochs: 'int' = None, learning_rate: 'float' = None, learning_rate_schedule: 'str' = None)\n",
      "    A dummy training component\n",
      "    \n",
      "    Component yaml:\n",
      "    ```yaml\n",
      "    $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
      "    type: command\n",
      "    \n",
      "    name: train_model\n",
      "    display_name: Train Model\n",
      "    description: A dummy training component\n",
      "    version: 0.0.1\n",
      "    inputs:\n",
      "      training_data: \n",
      "        type: uri_folder\n",
      "      max_epochs:\n",
      "        type: integer\n",
      "        optional: true\n",
      "      learning_rate: \n",
      "        type: number\n",
      "        default: 0.01\n",
      "      learning_rate_schedule: \n",
      "        type: string\n",
      "        default: time-based \n",
      "    outputs:\n",
      "      model_output:\n",
      "        type: uri_folder\n",
      "    code: ./train_src\n",
      "    environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:5\n",
      "    command: >-\n",
      "      python train.py \n",
      "      --training_data ${{inputs.training_data}} \n",
      "      [--max_epochs ${{inputs.max_epochs}}] \n",
      "      --learning_rate ${{inputs.learning_rate}} \n",
      "      --learning_rate_schedule ${{inputs.learning_rate_schedule}} \n",
      "      --model_output ${{outputs.model_output}}\n",
      "    \n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect more information\n",
    "print(type(train_model))\n",
    "help(train_model._func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sample pipeline job\n",
    "## 3.1 Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct pipeline\n",
    "@dsl.pipeline(\n",
    "    default_compute=\"cpu-cluster\",\n",
    "    description=\"E2E dummy train-score-eval pipeline with components defined via yaml\",\n",
    ")\n",
    "def pipeline_with_components_from_yaml(\n",
    "    training_input,\n",
    "    test_input,\n",
    "    training_max_epochs=20,\n",
    "    training_learning_rate=1.8,\n",
    "    learning_rate_schedule=\"time-based\",\n",
    "):\n",
    "    # Call component obj as function: apply given inputs & parameters to create a node in pipeline\n",
    "    train_with_sample_data = train_model(\n",
    "        training_data=training_input,\n",
    "        max_epochs=training_max_epochs,\n",
    "        learning_rate=training_learning_rate,\n",
    "        learning_rate_schedule=learning_rate_schedule,\n",
    "    )\n",
    "\n",
    "    score_with_sample_data = score_data(\n",
    "        model_input=train_with_sample_data.outputs.model_output, \n",
    "        test_data=test_input\n",
    "    )\n",
    "    score_with_sample_data.outputs.score_output.mode = \"upload\"\n",
    "\n",
    "    eval_with_sample_data = eval_model(\n",
    "        scoring_result=score_with_sample_data.outputs.score_output\n",
    "    )\n",
    "\n",
    "    # Return: pipeline outputs\n",
    "    return {\n",
    "        \"trained_model\": train_with_sample_data.outputs.model_output,\n",
    "        \"scored_data\": score_with_sample_data.outputs.score_output,\n",
    "        \"evaluation_report\": eval_with_sample_data.outputs.eval_output,\n",
    "    }\n",
    "\n",
    "pipeline = pipeline_with_components_from_yaml(\n",
    "    training_input = JobInput(type=AssetTypes.URI_FOLDER, path=parent_dir + \"/data/\"),\n",
    "    test_input = JobInput(type=AssetTypes.URI_FOLDER, path=parent_dir + \"/data/\"),\n",
    "    training_max_epochs=20,\n",
    "    training_learning_rate=1.8,\n",
    "    learning_rate_schedule=\"time-based\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: helpful_sugar_g160163tmn\n",
      "display_name: pipeline_with_components_from_yaml\n",
      "description: E2E dummy train-score-eval pipeline with components defined via yaml\n",
      "type: pipeline\n",
      "inputs:\n",
      "  training_input:\n",
      "    mode: ro_mount\n",
      "    type: uri_folder\n",
      "    path: azureml:./data/\n",
      "  test_input:\n",
      "    mode: ro_mount\n",
      "    type: uri_folder\n",
      "    path: azureml:./data/\n",
      "  training_max_epochs: 20\n",
      "  training_learning_rate: 1\n",
      "  learning_rate_schedule: time-based\n",
      "outputs:\n",
      "  trained_model: null\n",
      "  scored_data: null\n",
      "  evaluation_report: null\n",
      "tags: {}\n",
      "jobs:\n",
      "  train_with_sample_data:\n",
      "    $schema: '{}'\n",
      "    type: command\n",
      "    inputs:\n",
      "      training_data: ${{parent.inputs.training_input}}\n",
      "      max_epochs: ${{parent.inputs.training_max_epochs}}\n",
      "      learning_rate: ${{parent.inputs.training_learning_rate}}\n",
      "      learning_rate_schedule: ${{parent.inputs.learning_rate_schedule}}\n",
      "    outputs:\n",
      "      model_output: ${{parent.outputs.trained_model}}\n",
      "    command: python train.py  --training_data ${{inputs.training_data}}  [--max_epochs\n",
      "      ${{inputs.max_epochs}}]  --learning_rate ${{inputs.learning_rate}}  --learning_rate_schedule\n",
      "      ${{inputs.learning_rate_schedule}}  --model_output ${{outputs.model_output}}\n",
      "    code: ./train_src\n",
      "    component:\n",
      "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
      "      name: train_model\n",
      "      version: 0.0.1\n",
      "      display_name: Train Model\n",
      "      description: A dummy training component\n",
      "      type: command\n",
      "      inputs:\n",
      "        training_data:\n",
      "          type: uri_folder\n",
      "        max_epochs:\n",
      "          type: integer\n",
      "          optional: true\n",
      "        learning_rate:\n",
      "          type: number\n",
      "          default: '0.01'\n",
      "        learning_rate_schedule:\n",
      "          type: string\n",
      "          default: time-based\n",
      "      outputs:\n",
      "        model_output:\n",
      "          type: uri_folder\n",
      "      command: python train.py  --training_data ${{inputs.training_data}}  [--max_epochs\n",
      "        ${{inputs.max_epochs}}]  --learning_rate ${{inputs.learning_rate}}  --learning_rate_schedule\n",
      "        ${{inputs.learning_rate_schedule}}  --model_output ${{outputs.model_output}}\n",
      "      environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:5\n",
      "      code: azureml:./train_src\n",
      "      is_deterministic: true\n",
      "      tags: {}\n",
      "    environment_variables: {}\n",
      "  score_with_sample_data:\n",
      "    $schema: '{}'\n",
      "    type: command\n",
      "    inputs:\n",
      "      model_input: ${{parent.jobs.train_with_sample_data.outputs.model_output}}\n",
      "      test_data: ${{parent.inputs.test_input}}\n",
      "    outputs:\n",
      "      score_output: ${{parent.outputs.scored_data}}\n",
      "    command: python score.py  --model_input ${{inputs.model_input}}  --test_data ${{inputs.test_data}}\n",
      "      --score_output ${{outputs.score_output}}\n",
      "    code: ./score_src\n",
      "    component:\n",
      "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
      "      name: score_data\n",
      "      version: 0.0.1\n",
      "      display_name: Score Data\n",
      "      description: A dummy scoring component\n",
      "      type: command\n",
      "      inputs:\n",
      "        model_input:\n",
      "          type: uri_folder\n",
      "        test_data:\n",
      "          type: uri_folder\n",
      "      outputs:\n",
      "        score_output:\n",
      "          type: uri_folder\n",
      "      command: python score.py  --model_input ${{inputs.model_input}}  --test_data\n",
      "        ${{inputs.test_data}} --score_output ${{outputs.score_output}}\n",
      "      environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:5\n",
      "      code: azureml:./score_src\n",
      "      is_deterministic: true\n",
      "      tags: {}\n",
      "    environment_variables: {}\n",
      "  eval_with_sample_data:\n",
      "    $schema: '{}'\n",
      "    type: command\n",
      "    inputs:\n",
      "      scoring_result: ${{parent.jobs.score_with_sample_data.outputs.score_output}}\n",
      "    outputs:\n",
      "      eval_output: ${{parent.outputs.evaluation_report}}\n",
      "    command: python eval.py  --scoring_result ${{inputs.scoring_result}}  --eval_output\n",
      "      ${{outputs.eval_output}}\n",
      "    code: ./eval_src\n",
      "    component:\n",
      "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
      "      name: eval_model\n",
      "      version: 0.0.1\n",
      "      display_name: Eval Model\n",
      "      description: A dummy evaluate component\n",
      "      type: command\n",
      "      inputs:\n",
      "        scoring_result:\n",
      "          type: uri_folder\n",
      "      outputs:\n",
      "        eval_output:\n",
      "          type: uri_folder\n",
      "      command: python eval.py  --scoring_result ${{inputs.scoring_result}}  --eval_output\n",
      "        ${{outputs.eval_output}}\n",
      "      environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:5\n",
      "      code: azureml:./eval_src\n",
      "      is_deterministic: true\n",
      "      tags: {}\n",
      "    environment_variables: {}\n",
      "compute: azureml:cpu-cluster\n",
      "experiment_name: 1a_pipeline_with_components_from_yaml\n",
      "settings: {}\n",
      "properties: {}\n",
      "\n",
      "d:\\practice\\azureml-examples\\sdk\\jobs\\pipelines\\1a_pipeline_with_components_from_yaml\n",
      "{'training_input': <azure.ml.entities._job.pipeline._io.PipelineInput object at 0x00000262F1F99F40>, 'test_input': <azure.ml.entities._job.pipeline._io.PipelineInput object at 0x00000262F1F99E80>, 'training_max_epochs': <azure.ml.entities._job.pipeline._io.PipelineInput object at 0x00000262F1F99D60>, 'training_learning_rate': <azure.ml.entities._job.pipeline._io.PipelineInput object at 0x00000262F1F99E50>, 'learning_rate_schedule': <azure.ml.entities._job.pipeline._io.PipelineInput object at 0x00000262F1F99DC0>}\n",
      "INFO:executor:############################################train_with_sample_data##############################################\n",
      "DEBUG:executor:start running job train_with_sample_data\n",
      "INFO:executor:hello training world...\n",
      "INFO:executor:Training data path: d:\\practice\\azureml-examples\\sdk\\jobs\\pipelines\\1a_pipeline_with_components_from_yaml\\data\n",
      "INFO:executor:Max epochs: 20\n",
      "INFO:executor:Learning rate: 1.8\n",
      "INFO:executor:Learning rate: time-based\n",
      "INFO:executor:Model output path: d:\\practice\\azureml-examples\\sdk\\jobs\\pipelines\\1a_pipeline_with_components_from_yaml\\./local-run-output/notebook_1a_native\\train_with_sample_data\n",
      "INFO:executor:mounted_path files: \n",
      "INFO:executor:['sample1.csv']\n",
      "INFO:executor:reading file: sample1.csv ...\n",
      "INFO:executor:\"Month\", \"Average\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\"\n",
      "INFO:executor:\"May\",  0.1,  0,  0, 1, 1, 0, 0, 0, 2, 0,  0,  0\n",
      "INFO:executor:\"Jun\",  0.5,  2,  1, 1, 0, 0, 1, 1, 2, 2,  0,  1\n",
      "INFO:executor:\"Jul\",  0.7,  5,  1, 1, 2, 0, 1, 3, 0, 2,  2,  1\n",
      "INFO:executor:\"Aug\",  2.3,  6,  3, 2, 4, 4, 4, 7, 8, 2,  2,  3\n",
      "INFO:executor:\"Sep\",  3.5,  6,  4, 7, 4, 2, 8, 5, 2, 5,  2,  5\n",
      "INFO:executor:\"Oct\",  2.0,  8,  0, 1, 3, 2, 5, 1, 5, 2,  3,  0\n",
      "INFO:executor:\"Nov\",  0.5,  3,  0, 0, 1, 1, 0, 1, 0, 1,  0,  1\n",
      "INFO:executor:\"Dec\",  0.0,  1,  0, 1, 0, 0, 0, 0, 0, 0,  0,  1\n",
      "INFO:executor:\n",
      "INFO:executor:\n",
      "INFO:executor:\n",
      "INFO:executor:job train_with_sample_data finished with result: True\n",
      "INFO:executor:############################################score_with_sample_data##############################################\n",
      "DEBUG:executor:start running job score_with_sample_data\n",
      "INFO:executor:hello scoring world...\n",
      "INFO:executor:Model path: d:\\practice\\azureml-examples\\sdk\\jobs\\pipelines\\1a_pipeline_with_components_from_yaml\\./local-run-output/notebook_1a_native\\train_with_sample_data\n",
      "INFO:executor:Test data path: d:\\practice\\azureml-examples\\sdk\\jobs\\pipelines\\1a_pipeline_with_components_from_yaml\\data\n",
      "INFO:executor:Scoring output path: d:\\practice\\azureml-examples\\sdk\\jobs\\pipelines\\1a_pipeline_with_components_from_yaml\\./local-run-output/notebook_1a_native\\score_with_sample_data\n",
      "INFO:executor:Model:  This is a dummy model with id: e780b057-82d2-4521-bd0a-5edb1ff9caaa generated at: Apr-29-2022 10:55:23\n",
      "INFO:executor:\n",
      "INFO:executor:\n",
      "INFO:executor:job score_with_sample_data finished with result: True\n",
      "INFO:executor:############################################eval_with_sample_data##############################################\n",
      "DEBUG:executor:start running job eval_with_sample_data\n",
      "INFO:executor:hello evaluation world...\n",
      "INFO:executor:Scoring result path: d:\\practice\\azureml-examples\\sdk\\jobs\\pipelines\\1a_pipeline_with_components_from_yaml\\./local-run-output/notebook_1a_native\\score_with_sample_data\n",
      "INFO:executor:Evaluation output path: d:\\practice\\azureml-examples\\sdk\\jobs\\pipelines\\1a_pipeline_with_components_from_yaml\\./local-run-output/notebook_1a_native\\eval_with_sample_data\n",
      "INFO:executor:\n",
      "INFO:executor:job eval_with_sample_data finished with result: True\n",
      "INFO:executor:pipeline helpful_sugar_g160163tmn finished successfully!\n"
     ]
    }
   ],
   "source": [
    "# Inspect built pipeline\n",
    "print(pipeline)\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "from piprunpkg import run_pipeline, CuratedEnvironmentDefaultRunMode\n",
    "print(os.getcwd())\n",
    "output_root_dir = \"./local-run-output/notebook_1a_native\"\n",
    "run_pipeline(output_root_dir=output_root_dir, pipeline_job=pipeline, curated_env_default_run_mode=CuratedEnvironmentDefaultRunMode.CONTAINER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Submit pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit pipeline job to workspace\n",
    "pipeline_job = ml_client.jobs.create_or_update(pipeline, experiment_name=\"pipeline_samples\")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "You can see further examples of running a pipeline job [here](/sdk/jobs/pipelines/README.md)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Create pipeline with CommandComponents from local YAML file"
  },
  "interpreter": {
   "hash": "3e9e0e270b75c5e6da2e22113ba4f77b864d68f95da6601809c29e46c73ae6bb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
