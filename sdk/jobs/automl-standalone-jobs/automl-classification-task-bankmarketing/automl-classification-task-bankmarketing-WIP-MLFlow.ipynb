{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: Train \"the best\" classifier model for the UCI Bank Marketing dataset.\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace. [Check this notebook for creating a workspace](/sdk/resources/workspace/workspace.ipynb) \n",
    "- A Compute Cluster. [Check this notebook to create a compute cluster](/sdk/resources/compute/compute.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](/sdk/README.md#getting-started)\n",
    "- The latest MLFlow packages:\n",
    "\n",
    "    pip install azureml-mlflow\n",
    "\n",
    "    pip install mlflow\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Connect to your AML workspace from the Python SDK\n",
    "- Create an `AutoML classification Job` with the 'classification()' factory-fuction.\n",
    "- Submit and run the AutoML classification job\n",
    "- Obtaing the model and score predictions with it\n",
    "\n",
    "**Motivations** - This notebook explains how to setup and run an AutoML classification job. This is one of the nine ML-tasks supported by AutoML. Other ML-tasks are 'regression', 'time-series forecasting', 'image classification', 'image object detection', 'nlp text classification', etc.\n",
    "\n",
    "In this example we use the UCI Bank Marketing dataset to showcase how you can use AutoML for a classification problem. The classification goal is to predict if the client will subscribe to a term deposit with the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "gather": {
     "logged": 1634852261599
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from azure.ml import MLClient\n",
    "\n",
    "from azure.ml._constants import AssetTypes\n",
    "from azure.ml import automl\n",
    "from azure.ml.entities import JobInput\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Workspace details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "gather": {
     "logged": 1634852261744
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Enter details of your AML workspace\n",
    "\n",
    "# CDLTLL\n",
    "region = 'centraluseuap' #'<REGION>' ## example: westus\n",
    "subscription_id = '102a16c3-37d3-48a8-9237-4c9b1e8e80e0' #'<SUBSCRIPTION_ID>'\n",
    "resource_group = 'automlpmdemo' # '<RESOURCE_GROUP>'\n",
    "workspace = 'cesardl-automl-centraluseuap-ws' # '<AML_WORKSPACE_NAME>'\n",
    "\n",
    "# SAGAR\n",
    "# region = 'centraluseuap' #'<REGION>' ## example: westus\n",
    "# subscription_id = \"381b38e9-9840-4719-a5a0-61d9585e1e91\" #'<SUBSCRIPTION_ID>'\n",
    "# resource_group = \"sasum_centraluseuap_rg\" # '<RESOURCE_GROUP>'\n",
    "# workspace = \"sasum-centraluseuap-ws\" # '<AML_WORKSPACE_NAME>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Obtain the tracking URI for MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFlow Tracking URI: azureml://centraluseuap.api.azureml.ms/mlflow/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-centraluseuap-ws\n"
     ]
    }
   ],
   "source": [
    "# This URI can also be found with a CLI command:\n",
    "# /> az ml workspace show --query mlflow_tracking_uri\n",
    "\n",
    "## Construct AzureML MLFLOW TRACKING URI\n",
    "def get_azureml_mlflow_tracking_uri(region, subscription_id, resource_group, workspace):\n",
    "    return \"azureml://{}.api.azureml.ms/mlflow/v1.0/subscriptions/{}/resourceGroups/{}/providers/Microsoft.MachineLearningServices/workspaces/{}\".format(region, subscription_id, resource_group, workspace)\n",
    "\n",
    "MLFLOW_TRACKING_URI = get_azureml_mlflow_tracking_uri(region, subscription_id, resource_group, workspace)\n",
    "\n",
    "## Make sure the MLflow URI looks something like this: \n",
    "## azureml://<REGION>.api.azureml.ms/mlflow/v1.0/subscriptions/<SUBSCRIPTION_ID>/resourceGroups/<RESOURCE_GROUP>/providers/Microsoft.MachineLearningServices/workspaces/<AML_WORKSPACE_NAME>\n",
    "\n",
    "print(\"MLFlow Tracking URI:\", MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current tracking uri: azureml://centraluseuap.api.azureml.ms/mlflow/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-centraluseuap-ws\n"
     ]
    }
   ],
   "source": [
    "# Set the MLFLOW TRACKING URI\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [interactive authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.interactivebrowsercredential?view=azure-python) for this tutorial. More advanced connection methods can be found [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "gather": {
     "logged": 1634852261884
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#get a handle to the workspace\n",
    "credential = InteractiveBrowserCredential() # DefaultAzureCredential()\n",
    "#credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Initialize MLFlow Client\n",
    "The models and artifacts that are produced by AutoML can be accessed via the MLFlow interface. \n",
    "Initialize the MLFlow client here, and set the backend as Azure ML, via. the MLFlow Client.\n",
    "\n",
    "*IMPORTANT*, remember you need to have installed the latest MLFlow packages with:\n",
    "\n",
    "    pip install azureml-mlflow\n",
    "\n",
    "    pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/30 18:54:59 INFO mlflow.tracking.fluent: Experiment with name 'dpv2-sdk-classifier-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', experiment_id='3ba5733e-d535-4eec-93bf-3da829f5be00', lifecycle_stage='active', name='dpv2-sdk-classifier-experiment', tags={}>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the experiment name in MLFlow\n",
    "# Experiment Name is used in MLFlow and AutoML Job, later.\n",
    "exp_name = \"dpv2-sdk-classifier-experiment\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configure and run the AutoML classification job\n",
    "In this section we will configure and run the AutoML classification job.\n",
    "\n",
    "## 2.1 Configure the job through the classification() factory function\n",
    "\n",
    "### classification() parameters:\n",
    "\n",
    "The `classification()` factory function allows user to configure AutoML for the classification task for the most common scenarios with the following properties.\n",
    "\n",
    "- `target_column_name` - The name of the column to target for predictions. It must always be specified. This parameter is applicable to 'training_data', 'validation_data' and 'test_data'.\n",
    "- `primary_metric` - The metric that AutoML will optimize for Classification model selection.\n",
    "- `training_data` - The data to be used for training. It should contain both training feature columns and a target column. Optionally, this data can be split for segregating a validation or test dataset. \n",
    "You can use a registered MLTable in the workspace using the format '<mltable_name>:<version>' OR you can use a local file or folder as a MLTable. For e.g JobInput(mltable='my_mltable:1') OR JobInput(mltable=MLTable(local_path=\"./data\"))\n",
    "The parameter 'training_data' must always be provided.\n",
    "- `compute` - The compute on which the AutoML job will run. In this example we are using a compute called 'cpu-cluster' present in the workspace. You can replace it any other compute in the workspace. \n",
    "- `name` - The name of the Job/Run. This is an optional property. If not specified, a random name will be generated.\n",
    "- `experiment_name` - The name of the Experiment. An Experiment is like a folder with multiple runs in Azure ML Workspace that should be related to the same logical machine learning experiment.\n",
    "\n",
    "### set_limits() parameters:\n",
    "This is an optional configuration method to configure limits parameters such as timeouts.     \n",
    "    \n",
    "- timeout_minutes - Maximum amount of time in minutes that the whole AutoML job can take before the job terminates. This timeout includes setup, featurization and training runs but does not include the ensembling and model explainability runs at the end of the process since those actions need to happen once all the trials (children jobs) are done. If not specified, the default job's total timeout is 6 days (8,640 minutes). To specify a timeout less than or equal to 1 hour (60 minutes), make sure your dataset's size is not greater than 10,000,000 (rows times column) or an error results.\n",
    "\n",
    "- trial_timeout_minutes - Maximum time in minutes that each trial (child job) can run for before it terminates. If not specified, a value of 1 month or 43200 minutes is used.\n",
    "    \n",
    "- max_trials - The maximum number of trials/runs each with a different combination of algorithm and hyperparameters to try during an AutoML job. If not specified, the default is 1000 trials. If using 'enable_early_termination' the number of trials used can be smaller.\n",
    "    \n",
    "- max_concurrent_trials - Represents the maximum number of trials (children jobs) that would be executed in parallel. It's a good practice to match this number with the number of nodes your cluster.\n",
    "    \n",
    "- enable_early_termination - Whether to enable early termination if the score is not improving in the short term. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLTables for training dataset\n",
    "\n",
    "my_training_data_input = JobInput(type=AssetTypes.MLTABLE, path=\"./mltable-folder\")\n",
    "\n",
    "# Remote MLTable definition\n",
    "# my_training_data_input  = JobInput(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/Classification/Train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "gather": {
     "logged": 1634852262026
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create the AutoML classification job with the related factory-function.\n",
    "\n",
    "classification_job = automl.classification(\n",
    "                        compute = \"cpu-cluster\",\n",
    "                        # name=\"dpv2-classifier-job-02\",\n",
    "                        experiment_name = exp_name,\n",
    "                        training_data = my_training_data_input,\n",
    "                        target_column_name = \"y\",\n",
    "                        primary_metric = \"accuracy\",\n",
    "                        n_cross_validations=5,\n",
    "                        enable_model_explainability=True,\n",
    "                        tags={\"my_custom_tag\": \"My custom value\"},\n",
    "\n",
    "                        # These are temporal properties needed in Private Preview\n",
    "                        properties={\n",
    "                            \"_automl_internal_enable_mltable_quick_profile\": True,\n",
    "                            \"_automl_internal_label\": \"latest\",\n",
    "                            \"_automl_internal_save_mlflow\": True\n",
    "                        }\n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "classification_job.set_limits(timeout = 600, #timeout_minutes\n",
    "                              trial_timeout = 20, #trial_timeout_minutes\n",
    "                              max_trials = 5, \n",
    "                              max_concurrent_trials = 4,\n",
    "                              # max_cores_per_trial: -1,\n",
    "                              enable_early_termination=True)\n",
    "\n",
    "# Training properties are optional\n",
    "classification_job.set_training(blocked_models=[\"LogisticRegression\"],\n",
    "                                enable_onnx_compatible_models=True)\n",
    "\n",
    "# Featurization properties are optional\n",
    "# classification_job.set_featurization(# drop_columns=[\"not_needed_column\"], # Optional\n",
    "#                                      # enable_dnn_featurization=True         # Enable if there are text columns\n",
    "#                                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Run the CommandJob\n",
    "Using the `MLClient` created earlier, we will now run this CommandJob in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "gather": {
     "logged": 1634852267930
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(classification_job)  # submit the job to the backend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassificationJob({'log_verbosity': 'Info', 'task_type': <TaskType.CLASSIFICATION: 'Classification'>, 'environment_id': None, 'environment_variables': None, 'outputs': {}, 'display_name': '182d7e7d-412d-4a65-8795-92f881660837', 'type': 'automl', 'status': 'NotStarted', 'log_files': None, 'name': '182d7e7d-412d-4a65-8795-92f881660837', 'description': None, 'tags': {'my_custom_tag': 'My custom value'}, 'properties': {'_automl_internal_enable_mltable_quick_profile': 'True', '_automl_internal_label': 'latest', '_automl_internal_save_mlflow': 'True', 'mlflow.source.git.repoURL': 'git@github.com:Azure/azureml-examples.git', 'mlflow.source.git.branch': 'automl-preview', 'mlflow.source.git.commit': 'ba86c6051764c60c70bb858f38eb4cb76dc59f1e', 'azureml.git.dirty': 'True'}, 'id': '/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-centraluseuap-ws/jobs/182d7e7d-412d-4a65-8795-92f881660837', 'base_path': './', 'creation_context': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.SystemData object at 0x000001FCC6882250>, 'serialize': <msrest.serialization.Serializer object at 0x000001FCC1702340>, 'experiment_name': 'dpv2-sdk-classifier-experiment', 'compute': 'cpu-cluster', 'services': {'Tracking': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x000001FCC1792430>, 'Studio': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x000001FCC176F610>}, 'resources': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.ResourceConfiguration object at 0x000001FCC6882A00>, 'data': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.TableVerticalDataSettings object at 0x000001FCC176F520>, 'featurization': None, 'limits': <azure.ml.entities._job.automl.tabular.limit_settings.TabularLimitSettings object at 0x000001FCC1781DC0>, 'training': <azure.ml.entities._job.automl.training_settings.TrainingSettings object at 0x000001FCC1702B50>, 'allowed_models': None, 'blocked_models': ['LogisticRegression'], 'primary_metric': 'Accuracy'})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Created job: \")\n",
    "returned_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/182d7e7d-412d-4a65-8795-92f881660837?wsid=/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourcegroups/automlpmdemo/workspaces/cesardl-automl-centraluseuap-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995b064e-5c51-4592-b53a-14314d1de067\n"
     ]
    }
   ],
   "source": [
    "print(returned_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the Best Trial (Best Model's trial/run)\n",
    "Or any trial based on a custom criteria. Use the MLFLowClient to access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the parent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = returned_job.name\n",
    "\n",
    "# Example if providing an specific Job name/ID\n",
    "# job_name = \"c15b6d6f-969b-40b4-b3d7-2b2ef9d26226\"\n",
    "\n",
    "# mlflow_client was initialized at the begining of the notebook\n",
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
    "\n",
    "# Print it\n",
    "# mlflow_parent_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my_custom_tag': 'My custom value',\n",
       " 'model_explain_run': 'best_run',\n",
       " 'pipeline_id': '',\n",
       " 'score': '',\n",
       " 'predicted_cost': '',\n",
       " 'fit_time': '',\n",
       " 'training_percent': '',\n",
       " 'iteration': '',\n",
       " 'run_preprocessor': '',\n",
       " 'run_algorithm': '',\n",
       " 'automl_best_child_run_id': '995b064e-5c51-4592-b53a-14314d1de067_4',\n",
       " 'model_explain_best_run_child_id': '995b064e-5c51-4592-b53a-14314d1de067_4',\n",
       " 'mlflow.rootRunId': '995b064e-5c51-4592-b53a-14314d1de067',\n",
       " 'mlflow.runName': '995b064e-5c51-4592-b53a-14314d1de067'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_parent_run.data.tags\n",
    "\n",
    "# If 'automl_best_child_run_id' is not there, wait until it's there.\n",
    "# Do not run the next cell until 'automl_best_child_run_id' tag is there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best model's child run\n",
    "\n",
    "**IMPORTANT:** This cell might fail if the tags data are still not available in the parent run.\n",
    "That data is created with 'eventual consistency' so sometimes might not be there instantly.\n",
    "\n",
    "TO DO: We might need a synchronization mechanism to \"wait for eventual consistency\", \"wait until the 'automl_best_child_run_id' tag is there...\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best child run id:  995b064e-5c51-4592-b53a-14314d1de067_4\n"
     ]
    }
   ],
   "source": [
    "# Get the best model's child run\n",
    "\n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Found best child run id: \", best_child_run_id)\n",
    "\n",
    "best_run = mlflow_client.get_run(best_child_run_id)\n",
    "\n",
    "# best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best model run's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_score_macro</th>\n",
       "      <td>0.799371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_macro</th>\n",
       "      <td>0.949015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_weighted</th>\n",
       "      <td>0.956556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss</th>\n",
       "      <td>0.194514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.736779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.915266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_weighted</th>\n",
       "      <td>0.908142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_accuracy</th>\n",
       "      <td>0.959601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_micro</th>\n",
       "      <td>0.915266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_micro</th>\n",
       "      <td>0.915266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_macro</th>\n",
       "      <td>0.829042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_micro</th>\n",
       "      <td>0.915266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_micro</th>\n",
       "      <td>0.981129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_macro</th>\n",
       "      <td>0.736779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_micro</th>\n",
       "      <td>0.981902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_weighted</th>\n",
       "      <td>0.949015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_weighted</th>\n",
       "      <td>0.910359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_macro</th>\n",
       "      <td>0.762786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_macro_recall</th>\n",
       "      <td>0.473557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_weighted</th>\n",
       "      <td>0.915266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_correlation</th>\n",
       "      <td>0.532327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0\n",
       "precision_score_macro             0.799371\n",
       "AUC_macro                         0.949015\n",
       "average_precision_score_weighted  0.956556\n",
       "log_loss                          0.194514\n",
       "balanced_accuracy                 0.736779\n",
       "accuracy                          0.915266\n",
       "precision_score_weighted          0.908142\n",
       "weighted_accuracy                 0.959601\n",
       "precision_score_micro             0.915266\n",
       "recall_score_micro                0.915266\n",
       "average_precision_score_macro     0.829042\n",
       "f1_score_micro                    0.915266\n",
       "AUC_micro                         0.981129\n",
       "recall_score_macro                0.736779\n",
       "average_precision_score_micro     0.981902\n",
       "AUC_weighted                      0.949015\n",
       "f1_score_weighted                 0.910359\n",
       "f1_score_macro                    0.762786\n",
       "norm_macro_recall                 0.473557\n",
       "recall_score_weighted             0.915266\n",
       "matthews_correlation              0.532327"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(best_run.data.metrics, index=[0]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the best model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local folder\n",
    "local_dir = \"./artifact_downloads\"\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts downloaded in: C:\\Users\\CESARDL.CESARDLSB2-MSFT\\GitAMLRepos\\azureml-examples-automl-preview-branch\\sdk\\jobs\\automl-standalone-jobs\\automl-classification-task-bankmarketing\\artifact_downloads\\outputs\n",
      "Artifacts: ['conda_env_v_1_0_0.yml', 'engineered_feature_names.json', 'env_dependencies.json', 'featurization_summary.json', 'internal_cross_validated_models.pkl', 'model.pkl', 'pipeline_graph.json', 'run_id.txt', 'scoring_file_v_1_0_0.py', 'scoring_file_v_2_0_0.py']\n"
     ]
    }
   ],
   "source": [
    "# Download run's artifacts/outputs\n",
    "local_path = mlflow_client.download_artifacts(best_run.info.run_id, \"outputs\", local_dir)\n",
    "print(\"Artifacts downloaded in: {}\".format(local_path))\n",
    "print(\"Artifacts: {}\".format(os.listdir(local_path)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'sh'\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat ./artifact_downloads/outputs/MLmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "You can see further examples of other AutoML tasks such as Image-Classification, Image-Object-Detection, NLP-Text-Classification, Time-Series-Forcasting, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-automl-bugbash] *",
   "language": "python",
   "name": "conda-env-.conda-automl-bugbash-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
