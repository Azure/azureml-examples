{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML - Sentiment Analysis scenario: Train \"the best\" NLP Text Classification Multi-class model for a 'Sentiment Labeled Sentences' dataset.\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace. [Check this notebook for creating a workspace](/sdk/resources/workspace/workspace.ipynb) \n",
    "- A Compute Cluster. [Check this notebook to create a compute cluster](/sdk/resources/compute/compute.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](/sdk/README.md#getting-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1634852261599
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from azure.ml import MLClient\n",
    "\n",
    "from azure.ml._constants import AssetTypes\n",
    "from azure.ml.entities import JobInput\n",
    "\n",
    "from azure.ml import automl\n",
    "# from azure.ml.automl import text_classification\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [interactive authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.interactivebrowsercredential?view=azure-python) for this tutorial. More advanced connection methods can be found [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gather": {
     "logged": 1634852261744
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Enter details of your AML workspace\n",
    "\n",
    "# CDLTLL-GPU\n",
    "# subscription_id = '381b38e9-9840-4719-a5a0-61d9585e1e91' #'<SUBSCRIPTION_ID>'\n",
    "# resource_group = 'cesardl-automl-eastus2euap-resgrp' # '<RESOURCE_GROUP>'\n",
    "# workspace = 'cesardl-dist-training-eastus-ws' # '<AML_WORKSPACE_NAME>'\n",
    "\n",
    "# SAGAR\n",
    "# subscription_id = \"381b38e9-9840-4719-a5a0-61d9585e1e91\" #'<SUBSCRIPTION_ID>'\n",
    "# resource_group = \"sasum_centraluseuap_rg\" # '<RESOURCE_GROUP>'\n",
    "# workspace = \"sasum-centraluseuap-ws\" # '<AML_WORKSPACE_NAME>'\n",
    "\n",
    "# CDLTLL\n",
    "# subscription_id = '102a16c3-37d3-48a8-9237-4c9b1e8e80e0' #'<SUBSCRIPTION_ID>'\n",
    "# resource_group = 'automlpmdemo' # '<RESOURCE_GROUP>'\n",
    "# workspace = 'cesardl-automl-centraluseuap-ws' # '<AML_WORKSPACE_NAME>'\n",
    "\n",
    "# JUAMARTI\n",
    "# subscription_id = \"381b38e9-9840-4719-a5a0-61d9585e1e91\"\n",
    "# resource_group = \"juamarti\"\n",
    "# workspace = \"centraluseuap_phmantri\"\n",
    "\n",
    "subscription_id = \"381b38e9-9840-4719-a5a0-61d9585e1e91\"\n",
    "resource_group = \"sasum_centraluseuap_rg\"\n",
    "workspace = \"sasum-centraluseuap-ws\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gather": {
     "logged": 1634852261884
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#get a handle to the workspace\n",
    "credential = InteractiveBrowserCredential() # DefaultAzureCredential()\n",
    "#credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data\n",
    "\n",
    "**NOTE:** In this PRIVATE PREVIEW we're defining the MLTable in a separate folder and .YAML file.\n",
    "In later versions, you'll be able to do it all in Python APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset files downloaded...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Destination folders\n",
    "training_mltable_path = \"./training-mltable-folder/\"\n",
    "validation_mltable_path = \"./validation-mltable-folder/\"\n",
    "\n",
    "# Download dataset files and copy within each MLTable folder\n",
    "\n",
    "training_download_url = \"https://raw.githubusercontent.com/dotnet/spark/main/examples/Microsoft.Spark.CSharp.Examples/MachineLearning/Sentiment/Resources/yelptrain.csv\"\n",
    "training_data_file = training_mltable_path + \"yelp_training_set.csv\"\n",
    "urllib.request.urlretrieve(training_download_url, filename=training_data_file)\n",
    "\n",
    "valid_download_url = \"https://raw.githubusercontent.com/dotnet/spark/main/examples/Microsoft.Spark.CSharp.Examples/MachineLearning/Sentiment/Resources/yelptest.csv\"\n",
    "valid_data_file = validation_mltable_path + \"yelp_validation_set.csv\"\n",
    "urllib.request.urlretrieve(valid_download_url, filename=valid_data_file)\n",
    "\n",
    "print(\"Dataset files downloaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training MLTable defined locally, with local data to be uploaded\n",
    "my_training_data_input = JobInput(type=AssetTypes.MLTABLE, path=training_mltable_path)\n",
    "\n",
    "# Validation MLTable defined locally, with local data to be uploaded\n",
    "my_validation_data_input = JobInput(type=AssetTypes.MLTABLE, path=validation_mltable_path)\n",
    "\n",
    "# WITH REMOTE PATH: If available already in the cloud/workspace-blob-store\n",
    "# my_training_data_input = JobInput(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/my_training_mltable\")\n",
    "# my_validation_data_input = JobInput(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/my_validation_mltable\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Configure and run the AutoML NLP Text Classification Multiclass training job\n",
    "In this section we will configure and run the AutoML job, for training the model.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "gather": {
     "logged": 1634852262026
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute is not a known attribute of class <class 'azure.ml._restclient.v2022_02_01_preview.models._models_py3.NlpVerticalDataSettings'> and will be ignored\n",
      "experiment_name is not a known attribute of class <class 'azure.ml._restclient.v2022_02_01_preview.models._models_py3.NlpVerticalDataSettings'> and will be ignored\n",
      "tags is not a known attribute of class <class 'azure.ml._restclient.v2022_02_01_preview.models._models_py3.NlpVerticalDataSettings'> and will be ignored\n",
      "properties is not a known attribute of class <class 'azure.ml._restclient.v2022_02_01_preview.models._models_py3.NlpVerticalDataSettings'> and will be ignored\n"
     ]
    }
   ],
   "source": [
    "# Create the AutoML Image Classification Multiclass job with the related factory-function.\n",
    "\n",
    "text_classification_job = automl.text_classification(\n",
    "                            compute = \"gpu-cluster\",\n",
    "                            # name=\"dpv2-nlp-text-classification-multiclass-job-01\",\n",
    "                            experiment_name = \"dpv2-nlp-text-classification-experiment\",\n",
    "                            training_data = my_training_data_input,                           \n",
    "                            validation_data = my_validation_data_input,  \n",
    "                            target_column_name=\"Sentiment\",\n",
    "                            primary_metric = \"accuracy\",\n",
    "                            tags={\"owner\": \"cesardl\"},\n",
    "    \n",
    "                            properties={\n",
    "                                \"_automl_internal_enable_mltable_quick_profile\": True,\n",
    "                                # \"_automl_internal_scenario\": \"TextDNN-Candidate\",\n",
    "                            }\n",
    ")\n",
    "\n",
    "text_classification_job.set_limits(timeout=120, max_concurrent_trials=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Run the CommandJob\n",
    "Using the `MLClient` created earlier, we will now run this CommandJob in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "gather": {
     "logged": 1634852267930
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading training-mltable-folder (0.03 MBs): 100%|##########| 31262/31262 [00:00<00:00, 98000.95it/s]\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading validation-mltable-folder (0.03 MBs): 100%|##########| 30846/30846 [00:00<00:00, 77114.84it/s]\n",
      "\u001b[39m\n",
      "\n",
      "Exception: 'dict' object has no attribute 'data'.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CESARDL.CESARDLSB2-MSFT\\.conda\\envs\\automldpv2_wheel1\\lib\\site-packages\\azure\\ml\\entities\\_job\\job.py\", line 244, in _from_rest_object\n",
      "    return AutoMLJob._load_from_rest(job_rest_object)\n",
      "  File \"C:\\Users\\CESARDL.CESARDLSB2-MSFT\\.conda\\envs\\automldpv2_wheel1\\lib\\site-packages\\azure\\ml\\entities\\_job\\automl\\automl_job.py\", line 78, in _load_from_rest\n",
      "    return class_type._from_rest_object(obj)\n",
      "  File \"C:\\Users\\CESARDL.CESARDLSB2-MSFT\\.conda\\envs\\automldpv2_wheel1\\lib\\site-packages\\azure\\ml\\entities\\_job\\automl\\nlp\\text_classification_job.py\", line 124, in _from_rest_object\n",
      "    validation_data=JobInput(type=AssetTypes.MLTABLE, path=data_settings.validation_data.data.uri),\n",
      "AttributeError: 'dict' object has no attribute 'data'\n",
      "\n",
      "Unable to parse the job resource: {\n",
      "  \"id\": \"/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sasum_centraluseuap_rg/providers/Microsoft.MachineLearningServices/workspaces/sasum-centraluseuap-ws/jobs/85f04d4d-8a03-402e-8759-57a114d1d779\",\n",
      "  \"name\": \"85f04d4d-8a03-402e-8759-57a114d1d779\",\n",
      "  \"type\": \"Microsoft.MachineLearningServices/workspaces/jobs\",\n",
      "  \"system_data\": {\n",
      "    \"created_by\": \"Cesar De la Torre Llorente\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"created_at\": \"2022-03-25T00:54:10.09666Z\"\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"properties\": {\n",
      "      \"_automl_internal_enable_mltable_quick_profile\": \"True\",\n",
      "      \"mlflow.source.git.repoURL\": \"git@github.com:Azure/azureml-examples.git\",\n",
      "      \"mlflow.source.git.branch\": \"automl-preview\",\n",
      "      \"mlflow.source.git.commit\": \"1a370e819b00d848362cf66240681e5d697dec65\",\n",
      "      \"azureml.git.dirty\": \"True\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"owner\": \"cesardl\"\n",
      "    },\n",
      "    \"compute_id\": \"/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sasum_centraluseuap_rg/providers/Microsoft.MachineLearningServices/workspaces/sasum-centraluseuap-ws/computes/gpu-cluster\",\n",
      "    \"display_name\": \"85f04d4d-8a03-402e-8759-57a114d1d779\",\n",
      "    \"experiment_name\": \"dpv2-nlp-text-classification-experiment\",\n",
      "    \"is_archived\": false,\n",
      "    \"job_type\": \"AutoML\",\n",
      "    \"services\": {\n",
      "      \"Tracking\": {\n",
      "        \"endpoint\": \"azureml://master.api.azureml-test.ms/mlflow/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sasum_centraluseuap_rg/providers/Microsoft.MachineLearningServices/workspaces/sasum-centraluseuap-ws?\",\n",
      "        \"job_service_type\": \"Tracking\"\n",
      "      },\n",
      "      \"Studio\": {\n",
      "        \"endpoint\": \"https://ml.azure.com/runs/85f04d4d-8a03-402e-8759-57a114d1d779?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/sasum_centraluseuap_rg/workspaces/sasum-centraluseuap-ws\",\n",
      "        \"job_service_type\": \"Studio\"\n",
      "      }\n",
      "    },\n",
      "    \"status\": \"NotStarted\",\n",
      "    \"outputs\": {},\n",
      "    \"resources\": {\n",
      "      \"instance_count\": 1\n",
      "    },\n",
      "    \"task_details\": {\n",
      "      \"data_settings\": {\n",
      "        \"target_column_name\": \"Sentiment\",\n",
      "        \"training_data\": {\n",
      "          \"data\": {\n",
      "            \"mode\": \"ReadOnlyMount\",\n",
      "            \"uri\": \"./training-mltable-folder/\",\n",
      "            \"job_input_type\": \"MLTable\"\n",
      "          }\n",
      "        },\n",
      "        \"validation_data\": {\n",
      "          \"data\": {\n",
      "            \"description\": null,\n",
      "            \"uri\": \"./validation-mltable-folder/\",\n",
      "            \"mode\": \"ReadOnlyMount\",\n",
      "            \"jobInputType\": \"MLTable\"\n",
      "          },\n",
      "          \"validationDataSize\": null\n",
      "        }\n",
      "      },\n",
      "      \"limit_settings\": {\n",
      "        \"max_concurrent_trials\": 4,\n",
      "        \"max_trials\": 1,\n",
      "        \"timeout\": \"PT2H\"\n",
      "      },\n",
      "      \"log_verbosity\": \"Info\",\n",
      "      \"task_type\": \"TextClassification\",\n",
      "      \"primary_metric\": \"Accuracy\"\n",
      "    }\n",
      "  }\n",
      "}.\n",
      "\n"
     ]
    },
    {
     "ename": "JobParsingError",
     "evalue": "'dict' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\automldpv2_wheel1\\lib\\site-packages\\azure\\ml\\entities\\_job\\job.py\u001b[0m in \u001b[0;36m_from_rest_object\u001b[1;34m(cls, job_rest_object)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mjob_rest_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mRestJobType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTO_ML\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mAutoMLJob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_from_rest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_rest_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mjob_rest_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mRestJobType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPELINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\automldpv2_wheel1\\lib\\site-packages\\azure\\ml\\entities\\_job\\automl\\automl_job.py\u001b[0m in \u001b[0;36m_load_from_rest\u001b[1;34m(cls, obj)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_rest_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\automldpv2_wheel1\\lib\\site-packages\\azure\\ml\\entities\\_job\\automl\\nlp\\text_classification_job.py\u001b[0m in \u001b[0;36m_from_rest_object\u001b[1;34m(cls, obj)\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mtraining_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mJobInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAssetTypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMLTABLE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mJobInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAssetTypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMLTABLE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJobParsingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-889dda2ad18f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Submit the AutoML job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mreturned_job\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mml_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_or_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_classification_job\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# submit the job to the backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Created job: {returned_job}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\automldpv2_wheel1\\lib\\site-packages\\azure\\ml\\_telemetry\\activity.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mlog_activity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_name\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\automldpv2_wheel1\\lib\\site-packages\\azure\\ml\\_operations\\job_operations.py\u001b[0m in \u001b[0;36mcreate_or_update\u001b[1;34m(self, job, description, compute, tags, experiment_name, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             )\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resolve_azureml_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_rest_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_archive_or_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_archived\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\automldpv2_wheel1\\lib\\site-packages\\azure\\ml\\entities\\_job\\job.py\u001b[0m in \u001b[0;36m_from_rest_object\u001b[1;34m(cls, job_rest_object)\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[1;34mf\"Exception: {ex}.\\n{traceback.format_exc()}\\n\"\u001b[0m \u001b[1;34mf\"Unable to parse the job resource: {error_message}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             )\n\u001b[1;32m--> 254\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJobParsingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Unsupported job type {job_rest_object.properties.job_type}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJobParsingError\u001b[0m: 'dict' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# Submit the AutoML job\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(text_classification_job)  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a URL for the status of the job\n",
    "print(\"Open the following link to observe the AutoML training job/run:\")\n",
    "\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "You can see further examples of other AutoML tasks such as Regression, Image-Object-Detection, NLP-Text-Classification, Time-Series-Forcasting, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
