{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: Train \"the best\" Time-Series Forecasting model for the Energy Demand Dataset.\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace. [Check this notebook for creating a workspace](/sdk/resources/workspace/workspace.ipynb) \n",
    "- A Compute Cluster. [Check this notebook to create a compute cluster](/sdk/resources/compute/compute.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](/sdk/README.md#getting-started)\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Connect to your AML workspace from the Python SDK\n",
    "- Create an `AutoML time-series forecasting Job` with the 'forecasting()' factory-fuction.\n",
    "- Train the model using AmlCompute by submitting/running the AutoML forecasting training job\n",
    "- Obtaing the model and score predictions with it\n",
    "\n",
    "**Motivations** - This notebook explains how to setup and run an AutoML forecasting job. This is one of the nine ML-tasks supported by AutoML. Other ML-tasks are 'regression', 'classification', 'image classification', 'image object detection', 'nlp text classification', etc.\n",
    "\n",
    "In this example we use the associated New York City energy demand dataset to showcase how you can use AutoML for a simple forecasting problem and explore the results. The goal is predict the energy demand for the next 48 hours based on historic time-series data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1634852261599
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from azure.ml import MLClient\n",
    "\n",
    "from azure.ml._constants import AssetTypes\n",
    "from azure.ml.automl import forecasting\n",
    "from azure.ml.entities import JobInput\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [interactive authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.interactivebrowsercredential?view=azure-python) for this tutorial. More advanced connection methods can be found [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1634852261744
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Enter details of your AML workspace\n",
    "\n",
    "# SAGAR\n",
    "# subscription_id = \"381b38e9-9840-4719-a5a0-61d9585e1e91\" #'<SUBSCRIPTION_ID>'\n",
    "# resource_group = \"sasum_centraluseuap_rg\" # '<RESOURCE_GROUP>'\n",
    "# workspace = \"sasum-centraluseuap-ws\" # '<AML_WORKSPACE_NAME>'\n",
    "\n",
    "# CDLTLL\n",
    "subscription_id = '102a16c3-37d3-48a8-9237-4c9b1e8e80e0' #'<SUBSCRIPTION_ID>'\n",
    "resource_group = 'automlpmdemo' # '<RESOURCE_GROUP>'\n",
    "workspace = 'cesardl-automl-centraluseuap-ws' # '<AML_WORKSPACE_NAME>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1634852261884
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#get a handle to the workspace\n",
    "credential = InteractiveBrowserCredential() # DefaultAzureCredential()\n",
    "#credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data\n",
    "\n",
    "We will use energy consumption [data from New York City](http://mis.nyiso.com/public/P-58Blist.htm) for model training. \n",
    "The data is stored in a tabular format and includes energy demand and basic weather data at an hourly frequency. \n",
    "\n",
    "With Azure Machine Learning MLTables you can keep a single copy of data in your storage, easily access data during model training, share data and collaborate with other users. \n",
    "Below, we will upload the data by creating an MLTable to be used for training.\n",
    "\n",
    "**NOTE:** In this PRIVATE PREVIEW we're defining the MLTable in a separate folder and .YAML file.\n",
    "In later versions, you'll be able to do it all in Python APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training MLTable defined locally, with local data to be uploaded\n",
    "my_training_data_input = JobInput(type=AssetTypes.MLTABLE, path=\"./training-mltable-folder\")\n",
    "\n",
    "# Training MLTable defined locally, with local data to be uploaded\n",
    "my_validation_data_input = JobInput(type=AssetTypes.MLTABLE, path=\"./validation-mltable-folder\")\n",
    "\n",
    "# WITH REMOTE PATH\n",
    "# my_training_data_input  = JobInput(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/my-forecasting-mltable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Configure and run the AutoML Forecasting training job\n",
    "In this section we will configure and run the AutoML job, for training the model.\n",
    "\n",
    "## 3.1 Configure the job through the forecasting() factory function\n",
    "\n",
    "### forecasting() function parameters:\n",
    "\n",
    "The `forecasting()` factory function allows user to configure AutoML for the forecasting task for the most common scenarios with the following properties.\n",
    "\n",
    "- `target_column_name` - The name of the column to target for predictions. It must always be specified. This parameter is applicable to 'training_data', 'validation_data' and 'test_data'.\n",
    "- `primary_metric` - The metric that AutoML will optimize for model selection.\n",
    "- `training_data` - The data to be used for training. It should contain both training feature columns and a target column. Optionally, this data can be split for segregating a validation or test dataset. \n",
    "You can use a registered MLTable in the workspace using the format '<mltable_name>:<version>' OR you can use a local file or folder as a MLTable. For e.g JobInput(mltable='my_mltable:1') OR JobInput(mltable=MLTable(local_path=\"./data\"))\n",
    "The parameter 'training_data' must always be provided.\n",
    "- `compute` - The compute on which the AutoML job will run. In this example we are using a compute called 'cpu-cluster' present in the workspace. You can replace it any other compute in the workspace. \n",
    "- `name` - The name of the Job/Run. This is an optional property. If not specified, a random name will be generated.\n",
    "- `experiment_name` - The name of the Experiment. An Experiment is like a folder with multiple runs in Azure ML Workspace that should be related to the same logical machine learning experiment.\n",
    "\n",
    "### set_limits() parameters:\n",
    "This is an optional configuration method to configure limits parameters such as timeouts.     \n",
    "    \n",
    "- timeout_minutes - Maximum amount of time in minutes that the whole AutoML job can take before the job terminates. This timeout includes setup, featurization and training runs but does not include the ensembling and model explainability runs at the end of the process since those actions need to happen once all the trials (children jobs) are done. If not specified, the default job's total timeout is 6 days (8,640 minutes). To specify a timeout less than or equal to 1 hour (60 minutes), make sure your dataset's size is not greater than 10,000,000 (rows times column) or an error results.\n",
    "\n",
    "- trial_timeout_minutes - Maximum time in minutes that each trial (child job) can run for before it terminates. If not specified, a value of 1 month or 43200 minutes is used.\n",
    "    \n",
    "- max_trials - The maximum number of trials/runs each with a different combination of algorithm and hyperparameters to try during an AutoML job. If not specified, the default is 1000 trials. If using 'enable_early_termination' the number of trials used can be smaller.\n",
    "    \n",
    "- max_concurrent_trials - Represents the maximum number of trials (children jobs) that would be executed in parallel. It's a good practice to match this number with the number of nodes your cluster.\n",
    "    \n",
    "- enable_early_termination - Whether to enable early termination if the score is not improving in the short term. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialized Forecasting Parameters\n",
    "To define forecasting parameters for your experiment training, you can leverage the .set_forecast_settings() method. \n",
    "The table below details the forecasting parameters we will be passing into our experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**time_column_name**|The name of your time column.|\n",
    "|**forecast_horizon**|The forecast horizon is how many periods forward you would like to forecast. This integer horizon is in units of the timeseries frequency (e.g. daily, weekly).|\n",
    "|**frequency**|Forecast frequency. This optional parameter represents the period with which the forecast is desired, for example, daily, weekly, yearly, etc. Use this parameter for the correction of time series containing irregular data points or for padding of short time series. The frequency needs to be a pandas offset alias. Please refer to [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Forecasting Training <a id=\"advanced_training\"></a>\n",
    "### Using lags and rolling window features\n",
    "This training is also using the **target lags**, that is the previous values of the target variables, meaning the prediction uses a horizon. We therefore must still specify the `forecast_horizon` that the model will learn to forecast. The `target_lags` keyword specifies how far back we will construct the lags of the target variable, and the `target_rolling_window_size` specifies the size of the rolling window over which we will generate the `max`, `min` and `sum` features.\n",
    "\n",
    "This notebook uses the .set_training(blocked_models=) parameter to exclude some models that take a longer time to train on this dataset.  You can choose to remove models from the blocked_models list but you may need to increase the iteration_timeout_minutes parameter value to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1634852262026
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create the AutoML forecasting job with the related factory-function.\n",
    "\n",
    "forecasting_job = forecasting(\n",
    "                        compute = \"cpu-cluster\",\n",
    "                        # name=\"dpv2-forecasting-job-02\",\n",
    "                        experiment_name = \"dpv2-forecasting-experiment\",\n",
    "                        training_data = my_training_data_input,\n",
    "                        # validation_data = my_validation_data_input,\n",
    "                        target_column_name = \"demand\",\n",
    "                        primary_metric = \"NormalizedRootMeanSquaredError\",\n",
    "                        n_cross_validations=3, # (BUG 1711192) \n",
    "                        enable_model_explainability=True,\n",
    "                        tags={\"my_custom_tag\": \"My custom value\"},\n",
    "\n",
    "                        # These are temporal properties needed in Private Preview\n",
    "                        properties={\n",
    "                            \"_automl_internal_enable_mltable_quick_profile\": True,\n",
    "                            \"_automl_internal_label\": \"latest\",\n",
    "                            \"save_mlflow\": True\n",
    "                        }\n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "forecasting_job.set_limits(timeout = 600, #timeout_minutes\n",
    "                           trial_timeout = 20, #trial_timeout_minutes\n",
    "                           max_trials = 10, \n",
    "                           max_concurrent_trials = 4,\n",
    "                           # max_cores_per_trial: -1,\n",
    "                           enable_early_termination=True)\n",
    "\n",
    "# Specialized properties for Time Series Forecasting training\n",
    "forecasting_job.set_forecast_settings(\n",
    "            time_column_name=\"timeStamp\",\n",
    "            forecast_horizon=48,\n",
    "            frequency=\"H\",\n",
    "            target_lags=[12],\n",
    "            target_rolling_window_size=4,\n",
    "            # ADDITIONAL FORECASTING TRAINING PARAMS ---\n",
    "            # time_series_id_column_names=[\"tid1\", \"tid2\", \"tid2\"],\n",
    "            # short_series_handling_config=ShortSeriesHandlingConfiguration.DROP,\n",
    "            # use_stl=\"season\",\n",
    "            # seasonality=3,\n",
    "        )\n",
    "\n",
    "# Training properties are optional\n",
    "forecasting_job.set_training(blocked_models=[\"ExtremeRandomTrees\"])\n",
    "\n",
    "# Featurization properties are optional\n",
    "# forecasting_job.set_featurization(# drop_columns=[\"not_needed_column\"], # Optional\n",
    "#                                   # enable_dnn_featurization=True         # Enable if there are text columns\n",
    "#                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Run the CommandJob\n",
    "Using the `MLClient` created earlier, we will now run this CommandJob in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1634852267930
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job: ForecastingJob({'log_verbosity': <LogVerbosity.INFO: 'Info'>, 'task_type': <TaskType.FORECASTING: 'Forecasting'>, 'environment_id': None, 'environment_variables': None, 'outputs': {}, 'display_name': 'dpv2-forecasting-job-01', 'type': 'automl', 'status': 'NotStarted', 'log_files': None, 'name': 'dpv2-forecasting-job-01', 'description': None, 'tags': {'owner': 'cesardl'}, 'properties': {'_automl_internal_enable_mltable_quick_profile': 'True', '_automl_internal_scenario': 'non-prod', 'mlflow.source.git.repoURL': 'git@github.com:Azure/azureml-examples.git', 'mlflow.source.git.branch': 'automl-preview', 'mlflow.source.git.commit': '569ecabbb9c402206a8d797eff28bc8adf2bdc65', 'azureml.git.dirty': 'True'}, 'id': '/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-centraluseuap-ws/jobs/dpv2-forecasting-job-01', 'base_path': './', 'creation_context': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.SystemData object at 0x000001D3D8BAD9C8>, 'serialize': <msrest.serialization.Serializer object at 0x000001D3D8B37708>, 'experiment_name': 'dpv2-forecasting-experiment', 'compute': 'cpu-cluster', 'services': {'Tracking': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x000001D3D8BB82C8>, 'Studio': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x000001D3D8BB8048>}, 'resources': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.ResourceConfiguration object at 0x000001D3D8BAD988>, 'data': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.TableVerticalDataSettings object at 0x000001D3D8BADB08>, 'featurization': None, 'limits': <azure.ml.entities._job.automl.tabular.limit_settings.TabularLimitSettings object at 0x000001D3D8BCF588>, 'training': <azure.ml.entities._job.automl.training_settings.TrainingSettings object at 0x000001D3D8BAEAC8>, 'allowed_models': None, 'blocked_models': ['ExtremeRandomTrees'], 'primary_metric': 'NormalizedRootMeanSquaredError', 'forecasting_settings': <azure.ml.entities._job.automl.tabular.forecasting_settings.ForecastingSettings object at 0x000001D3D8B37B08>})\n"
     ]
    }
   ],
   "source": [
    "# Submit the AutoML job (CDLTLL: Is it ml_client.create_or_update(forecasting_job))\n",
    "returned_job = ml_client.jobs.create_or_update(forecasting_job)  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/dpv2-forecasting-job-01?wsid=/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourcegroups/automlpmdemo/workspaces/cesardl-automl-centraluseuap-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: Forecasting predictions and Test Metrics\n",
    "This notebook needs to add the code for using the trained model by forecasting with a .py Script that can be run under the same Environment with a CommandJob to be defined.\n",
    "After that inference logic, an evaluation of the test data inference showing metrics and a plotting chart should be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting predictions<a id=\"forecast\"></a>\n",
    "\n",
    "Now we will retrieve the \"best model\" created by AutoML, so it can be used to make forecasting predictions on test data. We will score on the test dataset which should have the same schema as training dataset.\n",
    "\n",
    "The inference will run on a remote compute. In this example, it will re-use the same training compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "You can see further examples of other AutoML tasks such as Image-Classification, Image-Object-Detection, NLP-Text-Classification, Time-Series-Forcasting, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
