{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy a model served with Triton using a custom container in an online endpoint\n",
    "Learn how to deploy a model using Triton as an online endpoint in Azure Machine Learning.\n",
    "\n",
    "Triton is multi-framework, open-source software that is optimized for inference. It supports popular machine learning frameworks like TensorFlow, ONNX Runtime, PyTorch, NVIDIA TensorRT, and more. It can be used for your CPU or GPU workloads.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* To use Azure Machine Learning, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n",
    "\n",
    "* Install and configure the [Python SDK v2](sdk/setup.sh).\n",
    "\n",
    "* You must have an Azure resource group, and you (or the service principal you use) must have Contributor access to it.\n",
    "\n",
    "* You must have an Azure Machine Learning workspace. \n",
    "\n",
    "* You must have a container registry associated with your workspace. \n",
    "\n",
    "* You must have additional Python packages installed for scoring, install them with this code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --pre azure-mgmt-containerregistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy tritonclient[http] pillow gevent\n",
    "%pip install --pre azure-containerregistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please note, for Triton no-code-deployment, testing via local endpoints is currently not supported, so this tutorial will only show how to set up on online endpoint.\n",
    "\n",
    "## 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Configure workspace details\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace_name = \"<AML_WORKSPACE_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Delete \n",
    "subscription_id = \"ed2cab61-14cc-4fb3-ac23-d72609214cfd\"\n",
    "resource_group = \"inference_turing\"\n",
    "workspace_name = \"tritonex\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Generate an endpoint name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "endpoint_name = f\"endpoint-{random.randint(0, 10000)}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Delete \n",
    "endpoint_name = \"tritonex1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Get a handle to the workspace\n",
    "\n",
    "We use these details above in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../jobs/configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(),\n",
    "    subscription_id,\n",
    "    resource_group,\n",
    "    workspace_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Get the container registry associated with the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = ml_client.workspaces.get(workspace_name)\n",
    "acr_uri = workspace.container_registry\n",
    "acr_name = acr_uri.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Custom Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.containerregistry import ContainerRegistryClient\n",
    "\n",
    "endpoint = f\"https://{acr_name}.azurecr.io\"\n",
    "audience = \"https://management.azure.com\"\n",
    "acr_client = ContainerRegistryClient(endpoint, DefaultAzureCredential(), audience=audience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.mgmt.containerregistry import ContainerRegistryManagementClient\n",
    "acrm_client = ContainerRegistryManagementClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    subscription_id=subscription_id,\n",
    "    base_url=\"https://management.azure.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acr = acrm_client.registries.get(\n",
    "    resource_group_name=resource_group,\n",
    "    registry_name=acr_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acr_client.upload_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/ed2cab61-14cc-4fb3-ac23-d72609214cfd/resourceGroups/inference_turing/providers/Microsoft.ContainerRegistry/registries/tritonexcr',\n",
       " 'name': 'tritonexcr',\n",
       " 'type': 'Microsoft.ContainerRegistry/registries',\n",
       " 'location': 'australiaeast',\n",
       " 'tags': {},\n",
       " 'system_data': {'created_by': 'v-alwallace@microsoft.com',\n",
       "  'created_by_type': 'User',\n",
       "  'created_at': '2022-09-13T20:06:06.569682Z',\n",
       "  'last_modified_by': 'v-alwallace@microsoft.com',\n",
       "  'last_modified_by_type': 'User',\n",
       "  'last_modified_at': '2022-09-13T20:06:06.569682Z'},\n",
       " 'sku': {'name': 'Standard', 'tier': 'Standard'},\n",
       " 'login_server': 'tritonexcr.azurecr.io',\n",
       " 'creation_date': '2022-09-13T20:06:06.569682Z',\n",
       " 'provisioning_state': 'Succeeded',\n",
       " 'admin_user_enabled': True,\n",
       " 'policies': {'quarantine_policy': {'status': 'disabled'},\n",
       "  'trust_policy': {'type': 'Notary', 'status': 'disabled'},\n",
       "  'retention_policy': {'days': 7,\n",
       "   'last_updated_time': '2022-09-13T20:06:11.620909Z',\n",
       "   'status': 'disabled'},\n",
       "  'export_policy': {'status': 'enabled'}},\n",
       " 'encryption': {'status': 'disabled'},\n",
       " 'data_endpoint_enabled': False,\n",
       " 'data_endpoint_host_names': [],\n",
       " 'private_endpoint_connections': [],\n",
       " 'public_network_access': 'Enabled',\n",
       " 'network_rule_bypass_options': 'AzureServices',\n",
       " 'zone_redundancy': 'Disabled'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acrm_client.registries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = acrm_client.builds.list(\n",
    "    resource_group,\n",
    "    acr_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acr_client.upload_blob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set --subscription \"ed2cab61-14cc-4fb3-ac23-d72609214cfd\"\n",
    "!az configure --defaults group=inference_turing\n",
    "!az configure --defaults workspace=tritonex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login --use-device-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mPacking source code into tar to upload...\u001b[0m\n",
      "\u001b[93mUploading archived source code from '/tmp/build_archive_6975d0d8dd0a45a2a625333b0431d29a.tar.gz'...\u001b[0m\n",
      "\u001b[93mSending context (6.405 KiB) to registry: tritonexcr...\u001b[0m\n",
      "\u001b[K - Starting ..\u001b[93mQueued a build with ID: cr1\u001b[0m\n",
      "\u001b[93mWaiting for an agent...\u001b[0m\n",
      "2022/09/13 23:12:22 Downloading source code...\n",
      "2022/09/13 23:12:23 Finished downloading source code\n",
      "2022/09/13 23:12:24 Using acb_vol_ff63a62f-1ea2-4d86-a8ab-4dab4fb9890e as the home volume\n",
      "2022/09/13 23:12:24 Setting up Docker configuration...\n",
      "2022/09/13 23:12:24 Successfully set up Docker configuration\n",
      "2022/09/13 23:12:24 Logging in to registry: tritonexcr.azurecr.io\n",
      "2022/09/13 23:12:25 Successfully logged into tritonexcr.azurecr.io\n",
      "2022/09/13 23:12:25 Executing step ID: build. Timeout(sec): 28800, Working directory: '', Network: ''\n",
      "2022/09/13 23:12:25 Scanning for dependencies...\n",
      "2022/09/13 23:12:26 Successfully scanned dependencies\n",
      "2022/09/13 23:12:26 Launching container with name: build\n",
      "Sending build context to Docker daemon  29.18kB\n",
      "Step 1/2 : FROM nvcr.io/nvidia/tritonserver:21.08-py3\n",
      "21.08-py3: Pulling from nvidia/tritonserver\n",
      "16ec32c2132b: Pulling fs layer\n",
      "2d20fc91ca4c: Pulling fs layer\n",
      "8c1cbfe29823: Pulling fs layer\n",
      "8969bb0f48c6: Pulling fs layer\n",
      "979c937ae0b1: Pulling fs layer\n",
      "54f447dbb869: Pulling fs layer\n",
      "050b9a515d38: Pulling fs layer\n",
      "b47abefddb18: Pulling fs layer\n",
      "9baca5bdde0b: Pulling fs layer\n",
      "8f5d32b6dcb0: Pulling fs layer\n",
      "7eaeb39618ed: Pulling fs layer\n",
      "15c95b7dac39: Pulling fs layer\n",
      "146346f1ce67: Pulling fs layer\n",
      "c78746b2b0ee: Pulling fs layer\n",
      "de960f57ab67: Pulling fs layer\n",
      "a23a010c3f61: Pulling fs layer\n",
      "9bf2920eee68: Pulling fs layer\n",
      "29c67fe2ac6f: Pulling fs layer\n",
      "18c1ec3721d9: Pulling fs layer\n",
      "3ce7af4d5a99: Pulling fs layer\n",
      "e30f539649b1: Pulling fs layer\n",
      "13bc2f7b311a: Pulling fs layer\n",
      "5ffa8d262cd1: Pulling fs layer\n",
      "95a0316283a7: Pulling fs layer\n",
      "bee77548e53a: Pulling fs layer\n",
      "2a4aa7094568: Pulling fs layer\n",
      "0346d37868e2: Pulling fs layer\n",
      "d98a314ccb1a: Pulling fs layer\n",
      "4a3315b4d782: Pulling fs layer\n",
      "762f0b1eddb6: Pulling fs layer\n",
      "05047e660db1: Pulling fs layer\n",
      "0af2a73dc6a9: Pulling fs layer\n",
      "92739fdf9c17: Pulling fs layer\n",
      "fe73389e6b61: Pulling fs layer\n",
      "a849153fa978: Pulling fs layer\n",
      "8122d5d3f645: Pulling fs layer\n",
      "ac0fb9077f17: Pulling fs layer\n",
      "545bb769765f: Pulling fs layer\n",
      "0793f3551159: Pulling fs layer\n",
      "86f95a409372: Pulling fs layer\n",
      "15c95b7dac39: Waiting\n",
      "146346f1ce67: Waiting\n",
      "c78746b2b0ee: Waiting\n",
      "de960f57ab67: Waiting\n",
      "a23a010c3f61: Waiting\n",
      "9bf2920eee68: Waiting\n",
      "29c67fe2ac6f: Waiting\n",
      "18c1ec3721d9: Waiting\n",
      "3ce7af4d5a99: Waiting\n",
      "e30f539649b1: Waiting\n",
      "13bc2f7b311a: Waiting\n",
      "5ffa8d262cd1: Waiting\n",
      "95a0316283a7: Waiting\n",
      "bee77548e53a: Waiting\n",
      "2a4aa7094568: Waiting\n",
      "8969bb0f48c6: Waiting\n",
      "0346d37868e2: Waiting\n",
      "979c937ae0b1: Waiting\n",
      "d98a314ccb1a: Waiting\n",
      "54f447dbb869: Waiting\n",
      "4a3315b4d782: Waiting\n",
      "762f0b1eddb6: Waiting\n",
      "050b9a515d38: Waiting\n",
      "05047e660db1: Waiting\n",
      "b47abefddb18: Waiting\n",
      "0af2a73dc6a9: Waiting\n",
      "9baca5bdde0b: Waiting\n",
      "8f5d32b6dcb0: Waiting\n",
      "7eaeb39618ed: Waiting\n",
      "92739fdf9c17: Waiting\n",
      "fe73389e6b61: Waiting\n",
      "a849153fa978: Waiting\n",
      "8122d5d3f645: Waiting\n",
      "ac0fb9077f17: Waiting\n",
      "545bb769765f: Waiting\n",
      "0793f3551159: Waiting\n",
      "86f95a409372: Waiting\n",
      "16ec32c2132b: Verifying Checksum\n",
      "16ec32c2132b: Download complete\n",
      "8969bb0f48c6: Verifying Checksum\n",
      "8969bb0f48c6: Download complete\n",
      "8c1cbfe29823: Verifying Checksum\n",
      "8c1cbfe29823: Download complete\n",
      "16ec32c2132b: Pull complete\n",
      "2d20fc91ca4c: Verifying Checksum\n",
      "2d20fc91ca4c: Download complete\n",
      "54f447dbb869: Verifying Checksum\n",
      "54f447dbb869: Download complete\n",
      "979c937ae0b1: Verifying Checksum\n",
      "979c937ae0b1: Download complete\n",
      "050b9a515d38: Verifying Checksum\n",
      "050b9a515d38: Download complete\n",
      "9baca5bdde0b: Verifying Checksum\n",
      "9baca5bdde0b: Download complete\n",
      "b47abefddb18: Verifying Checksum\n",
      "b47abefddb18: Download complete\n",
      "8f5d32b6dcb0: Verifying Checksum\n",
      "8f5d32b6dcb0: Download complete\n",
      "7eaeb39618ed: Verifying Checksum\n",
      "7eaeb39618ed: Download complete\n",
      "2d20fc91ca4c: Pull complete\n",
      "146346f1ce67: Verifying Checksum\n",
      "146346f1ce67: Download complete\n",
      "c78746b2b0ee: Verifying Checksum\n",
      "c78746b2b0ee: Download complete\n",
      "de960f57ab67: Verifying Checksum\n",
      "de960f57ab67: Download complete\n",
      "a23a010c3f61: Verifying Checksum\n",
      "a23a010c3f61: Download complete\n",
      "8c1cbfe29823: Pull complete\n",
      "8969bb0f48c6: Pull complete\n",
      "979c937ae0b1: Pull complete\n",
      "54f447dbb869: Pull complete\n",
      "050b9a515d38: Pull complete\n",
      "b47abefddb18: Pull complete\n",
      "9baca5bdde0b: Pull complete\n",
      "8f5d32b6dcb0: Pull complete\n",
      "7eaeb39618ed: Pull complete\n",
      "9bf2920eee68: Verifying Checksum\n",
      "9bf2920eee68: Download complete\n",
      "29c67fe2ac6f: Verifying Checksum\n",
      "29c67fe2ac6f: Download complete\n",
      "18c1ec3721d9: Verifying Checksum\n",
      "18c1ec3721d9: Download complete\n",
      "e30f539649b1: Download complete\n",
      "13bc2f7b311a: Verifying Checksum\n",
      "13bc2f7b311a: Download complete\n",
      "5ffa8d262cd1: Verifying Checksum\n",
      "5ffa8d262cd1: Download complete\n",
      "95a0316283a7: Verifying Checksum\n",
      "95a0316283a7: Download complete\n",
      "3ce7af4d5a99: Verifying Checksum\n",
      "3ce7af4d5a99: Download complete\n",
      "2a4aa7094568: Verifying Checksum\n",
      "2a4aa7094568: Download complete\n",
      "0346d37868e2: Verifying Checksum\n",
      "0346d37868e2: Download complete\n",
      "d98a314ccb1a: Verifying Checksum\n",
      "d98a314ccb1a: Download complete\n",
      "4a3315b4d782: Verifying Checksum\n",
      "4a3315b4d782: Download complete\n",
      "bee77548e53a: Verifying Checksum\n",
      "bee77548e53a: Download complete\n",
      "762f0b1eddb6: Verifying Checksum\n",
      "762f0b1eddb6: Download complete\n",
      "05047e660db1: Download complete\n",
      "0af2a73dc6a9: Verifying Checksum\n",
      "0af2a73dc6a9: Download complete\n",
      "92739fdf9c17: Verifying Checksum\n",
      "92739fdf9c17: Download complete\n",
      "fe73389e6b61: Verifying Checksum\n",
      "fe73389e6b61: Download complete\n",
      "a849153fa978: Download complete\n",
      "8122d5d3f645: Verifying Checksum\n",
      "8122d5d3f645: Download complete\n",
      "ac0fb9077f17: Verifying Checksum\n",
      "ac0fb9077f17: Download complete\n",
      "0793f3551159: Verifying Checksum\n",
      "0793f3551159: Download complete\n",
      "86f95a409372: Verifying Checksum\n",
      "86f95a409372: Download complete\n",
      "\n",
      "15c95b7dac39: Download complete\n",
      "15c95b7dac39: Pull complete\n",
      "146346f1ce67: Pull complete\n",
      "c78746b2b0ee: Pull complete\n",
      "de960f57ab67: Pull complete\n",
      "a23a010c3f61: Pull complete\n",
      "9bf2920eee68: Pull complete\n",
      "29c67fe2ac6f: Pull complete\n",
      "18c1ec3721d9: Pull complete\n",
      "545bb769765f: Verifying Checksum\n",
      "545bb769765f: Download complete\n",
      "3ce7af4d5a99: Pull complete\n",
      "e30f539649b1: Pull complete\n",
      "13bc2f7b311a: Pull complete\n",
      "5ffa8d262cd1: Pull complete\n",
      "95a0316283a7: Pull complete\n",
      "bee77548e53a: Pull complete\n",
      "2a4aa7094568: Pull complete\n",
      "0346d37868e2: Pull complete\n",
      "d98a314ccb1a: Pull complete\n",
      "4a3315b4d782: Pull complete\n",
      "762f0b1eddb6: Pull complete\n",
      "05047e660db1: Pull complete\n",
      "0af2a73dc6a9: Pull complete\n",
      "92739fdf9c17: Pull complete\n",
      "fe73389e6b61: Pull complete\n",
      "a849153fa978: Pull complete\n",
      "8122d5d3f645: Pull complete\n",
      "ac0fb9077f17: Pull complete\n",
      "545bb769765f: Pull complete\n",
      "0793f3551159: Pull complete\n",
      "86f95a409372: Pull complete\n",
      "Digest: sha256:6a1ef84e93327fef53ac11379fa4e53082c9e228de5db24e0abdfc5aff5676cf\n",
      "Status: Downloaded newer image for nvcr.io/nvidia/tritonserver:21.08-py3\n",
      " ---> 3eb9530b33c0\n",
      "Step 2/2 : CMD tritonserver --model-repository=/models --strict-model-config=false\n",
      " ---> Running in b6ee33c6256e\n",
      "Removing intermediate container b6ee33c6256e\n",
      " ---> 1422db808eee\n",
      "Successfully built 1422db808eee\n",
      "Successfully tagged tritonexcr.azurecr.io/azureml-examples/triton-cc:10\n",
      "2022/09/13 23:16:59 Successfully executed container: build\n",
      "2022/09/13 23:16:59 Executing step ID: push. Timeout(sec): 3600, Working directory: '', Network: ''\n",
      "2022/09/13 23:16:59 Pushing image: tritonexcr.azurecr.io/azureml-examples/triton-cc:10, attempt 1\n",
      "The push refers to repository [tritonexcr.azurecr.io/azureml-examples/triton-cc]\n",
      "6ca760c5ef28: Preparing\n",
      "4042a51ce7c5: Preparing\n",
      "28c5b0270c92: Preparing\n",
      "0abe86316da8: Preparing\n",
      "4b047b532d18: Preparing\n",
      "6d820c3932fb: Preparing\n",
      "1bba676a1b60: Preparing\n",
      "810f6f9223b0: Preparing\n",
      "09e531a310e6: Preparing\n",
      "fc7ff3f6e8d8: Preparing\n",
      "56cb87b3d040: Preparing\n",
      "f6008eeed90a: Preparing\n",
      "aea282884860: Preparing\n",
      "8e5c3199c793: Preparing\n",
      "157df127b62d: Preparing\n",
      "5d78ea114987: Preparing\n",
      "efe476b56e19: Preparing\n",
      "8c3d0202c849: Preparing\n",
      "75f761d90f3b: Preparing\n",
      "a632acaf3f47: Preparing\n",
      "d9c26ffe1c13: Preparing\n",
      "0a707fb87820: Preparing\n",
      "d627d760bedf: Preparing\n",
      "4246ff7d9506: Preparing\n",
      "c91a87334476: Preparing\n",
      "6223e500896d: Preparing\n",
      "13e7314b4201: Preparing\n",
      "103ab0c22213: Preparing\n",
      "1a62730e0411: Preparing\n",
      "93576ce8634c: Preparing\n",
      "41db41c49a2e: Preparing\n",
      "4938aec16cb1: Preparing\n",
      "8a86dcb942a0: Preparing\n",
      "df45adac04fd: Preparing\n",
      "c4ac0de61e50: Preparing\n",
      "d9230c3208a1: Preparing\n",
      "e245110f4cd5: Preparing\n",
      "897b016c57ca: Preparing\n",
      "780a3582aff4: Preparing\n",
      "7555a8182c42: Preparing\n",
      "6d820c3932fb: Waiting\n",
      "d627d760bedf: Waiting\n",
      "1bba676a1b60: Waiting\n",
      "4246ff7d9506: Waiting\n",
      "810f6f9223b0: Waiting\n",
      "c91a87334476: Waiting\n",
      "09e531a310e6: Waiting\n",
      "6223e500896d: Waiting\n",
      "fc7ff3f6e8d8: Waiting\n",
      "13e7314b4201: Waiting\n",
      "103ab0c22213: Waiting\n",
      "1a62730e0411: Waiting\n",
      "93576ce8634c: Waiting\n",
      "41db41c49a2e: Waiting\n",
      "4938aec16cb1: Waiting\n",
      "56cb87b3d040: Waiting\n",
      "8a86dcb942a0: Waiting\n",
      "f6008eeed90a: Waiting\n",
      "df45adac04fd: Waiting\n",
      "aea282884860: Waiting\n",
      "c4ac0de61e50: Waiting\n",
      "d9230c3208a1: Waiting\n",
      "e245110f4cd5: Waiting\n",
      "8e5c3199c793: Waiting\n",
      "157df127b62d: Waiting\n",
      "5d78ea114987: Waiting\n",
      "efe476b56e19: Waiting\n",
      "8c3d0202c849: Waiting\n",
      "75f761d90f3b: Waiting\n",
      "a632acaf3f47: Waiting\n",
      "d9c26ffe1c13: Waiting\n",
      "0a707fb87820: Waiting\n",
      "897b016c57ca: Waiting\n",
      "780a3582aff4: Waiting\n",
      "7555a8182c42: Waiting\n",
      "4042a51ce7c5: Pushed\n",
      "6ca760c5ef28: Pushed\n",
      "4b047b532d18: Pushed\n",
      "6d820c3932fb: Pushed\n",
      "810f6f9223b0: Pushed\n",
      "1bba676a1b60: Pushed\n",
      "09e531a310e6: Pushed\n",
      "fc7ff3f6e8d8: Pushed\n",
      "f6008eeed90a: Pushed\n",
      "56cb87b3d040: Pushed\n",
      "aea282884860: Pushed\n",
      "8e5c3199c793: Pushed\n",
      "0abe86316da8: Pushed\n",
      "efe476b56e19: Pushed\n",
      "\n",
      "75f761d90f3b: Pushed\n",
      "a632acaf3f47: Pushed\n",
      "157df127b62d: Pushed\n",
      "0a707fb87820: Pushed\n",
      "8c3d0202c849: Pushed\n",
      "d627d760bedf: Pushed\n",
      "c91a87334476: Pushed\n",
      "5d78ea114987: Pushed\n",
      "6223e500896d: Pushed\n",
      "13e7314b4201: Pushed\n",
      "103ab0c22213: Pushed\n",
      "93576ce8634c: Pushed\n",
      "41db41c49a2e: Pushed\n",
      "4938aec16cb1: Pushed\n",
      "8a86dcb942a0: Pushed\n",
      "df45adac04fd: Pushed\n",
      "c4ac0de61e50: Pushed\n",
      "4246ff7d9506: Pushed\n",
      "d9230c3208a1: Pushed\n",
      "e245110f4cd5: Pushed\n",
      "\n",
      "d9c26ffe1c13: Pushed\n",
      "897b016c57ca: Pushed\n",
      "7555a8182c42: Pushed\n",
      "780a3582aff4: Pushed\n",
      "1a62730e0411: Pushed\n",
      "28c5b0270c92: Pushed\n",
      "10: digest: sha256:67738cb10de0db1b9821385273aa82c94762cf6d18287553e6a84890bfcb406e size: 8705\n",
      "2022/09/13 23:24:17 Successfully pushed image: tritonexcr.azurecr.io/azureml-examples/triton-cc:10\n",
      "2022/09/13 23:24:17 Step ID: build marked as successful (elapsed time in seconds: 273.409290)\n",
      "2022/09/13 23:24:17 Populating digests for step ID: build...\n",
      "2022/09/13 23:24:18 Successfully populated digests for step ID: build\n",
      "2022/09/13 23:24:18 Step ID: push marked as successful (elapsed time in seconds: 438.327068)\n",
      "2022/09/13 23:24:18 The following dependencies were found:\n",
      "2022/09/13 23:24:18 \n",
      "- image:\n",
      "    registry: tritonexcr.azurecr.io\n",
      "    repository: azureml-examples/triton-cc\n",
      "    tag: \"10\"\n",
      "    digest: sha256:67738cb10de0db1b9821385273aa82c94762cf6d18287553e6a84890bfcb406e\n",
      "  runtime-dependency:\n",
      "    registry: nvcr.io\n",
      "    repository: nvidia/tritonserver\n",
      "    tag: 21.08-py3\n",
      "    digest: sha256:6a1ef84e93327fef53ac11379fa4e53082c9e228de5db24e0abdfc5aff5676cf\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cr1 was successful after 11m57s\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "img_tag =f'{acr_name}.azurecr.io/azureml-examples/triton-cc:10'\n",
    "\n",
    "\n",
    "!az acr build -r {acr_name} -t {img_tag} --resource-group {resource_group} -f triton-cc.dockerfile . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure deployment and associated resources\n",
    "\n",
    "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `ManagedOnlineDeployment` class.\n",
    "\n",
    "### Key aspects of deployment \n",
    "- `name` - Name of the deployment.\n",
    "- `endpoint_name` - Name of the endpoint to create the deployment under.\n",
    "- `model` - The model to use for the deployment. This value can be either a reference to an existing versioned model in the workspace or an inline model specification.\n",
    "- `environment` - The environment to use for the deployment. This value can be either a reference to an existing versioned environment in the workspace or an inline environment specification.\n",
    "- `code_configuration` - the configuration for the source code and scoring script\n",
    "    - `path`- Path to the source code directory for scoring the model\n",
    "    - `scoring_script` - Relative path to the scoring file in the source code directory\n",
    "- `instance_type` - The VM size to use for the deployment. For the list of supported sizes, see [Managed online endpoints SKU list](https://docs.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list).\n",
    "- `instance_count` - The number of instances to use for the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Configure online endpoint\n",
    "`endpoint_name`: The name of the endpoint. It must be unique in the Azure region. Naming rules are defined under [managed online endpoint limits](https://docs.microsoft.com/azure/machine-learning/how-to-manage-quotas#azure-machine-learning-managed-online-endpoints-preview).\n",
    "\n",
    "`auth_mode` : Use `key` for key-based authentication. Use `aml_token` for Azure Machine Learning token-based authentication. A `key` does not expire, but `aml_token` does expire. \n",
    "\n",
    "Optionally, you can add description, tags to your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=endpoint_name,\n",
    "    auth_mode=\"key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Configure a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "model = Model(path=\"./models/model_1\", type=\"triton_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Configure an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readiness route vs. liveness route\n",
    "An HTTP server defines paths for both liveness and readiness. A liveness route is used to check whether the server is running. A readiness route is used to check whether the server is ready to do work. In machine learning inference, a server could respond 200 OK to a liveness request before loading a model. The server could respond 200 OK to a readiness request only after the model has been loaded into memory.\n",
    "\n",
    "Review the [Kubernetes documentation](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/) for more information about liveness and readiness probes.\n",
    "\n",
    "Notice that this deployment uses the same path for both liveness and readiness, since TF Serving only defines a liveness route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "enviroment = Environment(\n",
    "    name=\"triton-cc-env\", \n",
    "    inference_config={\n",
    "        \"liveness_route\" : \n",
    "        { \n",
    "            \"path\": \"/v2/health/live\",\n",
    "            \"port\": 8000\n",
    "        },\n",
    "        \"readiness_route\" : \n",
    "        {\n",
    "            \"path\": \"/v2/health/ready\",\n",
    "            \"port\": 8000\n",
    "        },\n",
    "        \"scoring_route\" : {\n",
    "            \"path\": \"/\",\n",
    "            \"port\": 8000\n",
    "        }\n",
    "    }, \n",
    "    image=img_tag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Configure the deployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineDeployment\n",
    "\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    environment=enviroment,\n",
    "    model=model,\n",
    "    instance_type=\"Standard_NC6s_v3\",\n",
    "    instance_count=1,\n",
    "    model_mount_path=\"/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy to Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create the endpoint\n",
    "Using the `MLClient` created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Delete\n",
    "endpoint = ml_client.online_endpoints.get(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `MLClient` created earlier, we will now create the deployment in the workspace. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = ml_client.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Set traffic to 100% for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the endpoint with sample data\n",
    "This version of the triton server requires pre- and post-image processing. Below we show how to invoke the endpoint with this processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Retrieve the scoring URI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_uri = endpoint.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Retrieve the endpoint auth key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ml_client.online_endpoints.list_keys(endpoint_name)\n",
    "auth_key  = keys.primary_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Test the endpoint\n",
    "The below script imports pre- and post-processing functions from `sdk/endpoints/online/triton/scoring_utils/prepost.py`. We first test the model/server readiness and then use those functions to convert the image into a triton readable format and issue the scoring request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the blue deployment with some sample data\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from importlib import util\n",
    "import gevent.ssl\n",
    "import tritonclient.http as tritonhttpclient\n",
    "from importlib import util\n",
    "import sys\n",
    "sys.path.append(\"../../triton/scoring_utils\")\n",
    "import prepost\n",
    "\n",
    "img_url = \"../../triton/scoring_utils/peacock.jpg\"\n",
    "\n",
    "# We remove the scheme from the url\n",
    "scoring_uri = scoring_uri[8:]\n",
    "\n",
    "# Initialize client handler \n",
    "triton_client = tritonhttpclient.InferenceServerClient(\n",
    "        url=scoring_uri,\n",
    "        ssl=True,\n",
    "        ssl_context_factory=gevent.ssl._create_default_https_context,\n",
    "    )\n",
    "\n",
    "# Create headers\n",
    "headers = {}\n",
    "headers[\"Authorization\"] = f\"Bearer {auth_key}\"\n",
    "\n",
    "# Check status of triton server\n",
    "health_ctx = triton_client.is_server_ready(headers=headers)\n",
    "print(\"Is server ready - {}\".format(health_ctx))\n",
    "\n",
    "# Check status of model\n",
    "model_name = \"model_1\"\n",
    "status_ctx = triton_client.is_model_ready(model_name, \"1\", headers)\n",
    "print(\"Is model ready - {}\".format(status_ctx))\n",
    "\n",
    "#img_content = requests.get(img_url).content\n",
    "img_data = prepost.preprocess('peacock-image.png')\n",
    "\n",
    "# Populate inputs and outputs\n",
    "input = tritonhttpclient.InferInput(\"data_0\", img_data.shape, \"FP32\")\n",
    "input.set_data_from_numpy(img_data)\n",
    "inputs = [input]\n",
    "output = tritonhttpclient.InferRequestedOutput(\"fc6_1\")\n",
    "outputs = [output]\n",
    "\n",
    "result = triton_client.infer(model_name, inputs, outputs=outputs, headers=headers)\n",
    "max_label = np.argmax(result.as_numpy(\"fc6_1\"))\n",
    "label_name = prepost.postprocess(max_label)\n",
    "print(label_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Managing endpoints and deployments\n",
    "\n",
    "### 5.1 Get the logs for the new deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=endpoint_name, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_delete(name=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Deploy a custom container as an online endpoint. Use web servers other than the default Python Flask server used by Azure ML without losing the benefits of Azure ML's built-in monitoring, scaling, alerting, and authentication."
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('triton2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb35f1189fc3784569911fd49ab2a440fc44e35cfeb9b311d6717456a6432541"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
