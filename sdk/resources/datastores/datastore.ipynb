{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Azure Machine Learning Datastore\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace. [Check this notebook for creating a workspace](/sdk/resources/workspace/workspace.ipynb) \n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](/sdk/README.md#getting-started)\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Create an Azure Machine Learning datastore from Python SDK for\n",
    "  - Azure Blob Storage container\n",
    "  - Azure File share\n",
    "  - Azure Data Lake Storage Gen1\n",
    "  - Azure Data Lake Storage Gen2\n",
    "- Use a datastore in a CommandJob\n",
    "\n",
    "**Motivations** - Azure Machine Learning datastores securely keep the connection information to your data storage, so you don't have to code it in your scripts. This tutorial will introduce you to create datastores for machine learning from different sources.\n",
    "\n",
    "**Note** - The credentials property in these samples are redacted. Please replace the redacted account_key, sas_token, tenant_id, client_id and client_secret appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the datastore will be created.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from azure.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ml.entities import AzureBlobDatastore, AzureFileDatastore, AzureDataLakeGen1Datastore, AzureDataLakeGen2Datastore\n",
    "from azure.ml.entities import CommandJob, JobInput, Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. More advanced connection methods can be found [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter details of your AML workspace\n",
    "subscription_id = '<SUBSCRIPTION_ID>'\n",
    "resource_group = '<RESOURCE_GROUP>'\n",
    "workspace = '<AML_WORKSPACE_NAME>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a handle to the workspace\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Datastore\n",
    "Datastores are attached to workspaces and are used to store connection information to  storage services so you can refer to them by name and don't need to remember the connection information and secret used to connect to the storage services.\n",
    "\n",
    "## 2.1 Create a datastore for Azure Blob Storage container\n",
    "The `AzureBlobDatastore` can be used to create datastores for Azure blob containers. The key parameters needed to create this type of datastore are:\n",
    "- `name` - Name of the datastore\n",
    "- `account_name` - Name of the Azure storage account.\n",
    "- `container_name` - Name of the container in the storage account\n",
    "- `protocol` - Protocol to use to connect to the container. `https` and `wasbs` are supported. The default is `https`.\n",
    "- `credentials` - Credential-based authentication credentials for connecting to the Azure storage account. You can provide either an `account key` or a shared access signature (`SAS`) token. Credential secrets are stored in the workspace key vault.\n",
    "- `description` - Description of the datastore.\n",
    "\n",
    "### 2.1.1 Create a datastore with account key\n",
    "In this sample we will use an account key to connect to the storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_datastore1 = AzureBlobDatastore(\n",
    "    name='blob-example',\n",
    "    description = 'Datastore pointing to a blob container.',\n",
    "    account_name = 'mytestblobstore',\n",
    "    container_name = 'data-container',\n",
    "    credentials = {'account_key': 'XXXxxxXXXxXXXXxxXXXXXxXXXXXxXxxXxXXXxXXXxXXxxxXXxxXXXxXxXXXxxXxxXXXXxxxxxXXxxxxxxXXXxXXX'})\n",
    "ml_client.create_or_update(blob_datastore1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Create a datastore with SAS token\n",
    "In this sample we will use a shared access signature (`SAS`) token to connect to the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a SAS based blob datastore\n",
    "blob_sas_datastore = AzureBlobDatastore(\n",
    "    name='blob-sas-example',\n",
    "    description = 'Datastore pointing to a blob container using SAS token.',\n",
    "    account_name = 'mytestblobstore',\n",
    "    container_name = 'data-container',\n",
    "    credentials = {'sas_token': '?xx=XXXX-XX-XX&xx=xxxx&xxx=xxx&xx=xxxxxxxxxxx&xx=XXXX-XX-XXXXX:XX:XXX&xx=XXXX-XX-XXXXX:XX:XXX&xxx=xxxxx&xxx=XXxXXXxxxxxXXXXXXXxXxxxXXXXXxxXXXXXxXXXXxXXXxXXxXX'})\n",
    "ml_client.create_or_update(blob_sas_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Create a datastore with account key and wasbs protocol\n",
    "In this sample we will use an account key to connect to the storage using wasbs protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a datastore pointing to a blob container using wasbs protocol\n",
    "blob_wasb_datastore = AzureBlobDatastore(\n",
    "    name='blob-protocol-example',\n",
    "    description = 'Datastore pointing to a blob container using wasbs protocol.',\n",
    "    account_name = 'mytestblobstore',\n",
    "    container_name = 'data-container',\n",
    "    protocol='wasbs',\n",
    "    credentials = {'account_key': 'XXXxxxXXXxXXXXxxXXXXXxXXXXXxXxxXxXXXxXXXxXXxxxXXxxXXXxXxXXXxxXxxXXXXxxxxxXXxxxxxxXXXxXXX'})\n",
    "ml_client.create_or_update(blob_wasb_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Create a datastore without adding any credentials\n",
    "In this sample we will create a datastore without storing any credentials. When this datastore is used in a job, the identity used to run the job will also be used to access the datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a credential-less datastore pointing to a blob container\n",
    "blob_credless_datastore = AzureBlobDatastore(\n",
    "    name='blob-credless-example',\n",
    "    description = 'Credential-less datastore pointing to a blob container.',\n",
    "    account_name = 'mytestblobstore',\n",
    "    container_name = 'data-container')\n",
    "ml_client.create_or_update(blob_credless_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create a datastore for Azure File Share\n",
    "The `AzureFileDatastore` can be used to create datastores for Azure File Share. The key parameters needed to create this type of datastore are:\n",
    "- `name` - Name of the datastore\n",
    "- `account_name` - Name of the Azure storage account.\n",
    "- `file_share_name` - Name of the file share in the storage account\n",
    "- `protocol` - Protocol to use to connect to the file share. Only `https` is supported.\n",
    "- `credentials` - Credential-based authentication credentials for connecting to the Azure storage account. You can provide either an `account key` or a shared access signature (`SAS`) token. Credential secrets are stored in the workspace key vault.\n",
    "- `description` - Description of the datastore.\n",
    "\n",
    "### 2.2.1 Create a datastore with account key\n",
    "In this sample we will use an account key to connect to the storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datastore pointing to an Azure File Share\n",
    "file_datastore = AzureFileDatastore(\n",
    "    name = 'file-example',\n",
    "    description = 'Datastore pointing to an Azure File Share.',\n",
    "    account_name = 'mytestfilestore',\n",
    "    file_share_name = 'my-share',\n",
    "    credentials = {'account_key': 'XXXxxxXXXxXXXXxxXXXXXxXXXXXxXxxXxXXXxXXXxXXxxxXXxxXXXxXxXXXxxXxxXXXXxxxxxXXxxxxxxXXXxXXX'})\n",
    "ml_client.create_or_update(file_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Create a datastore with SAS token\n",
    "In this sample we will use a shared access signature (`SAS`) token to connect to the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datastore pointing to an Azure File Share using SAS token\n",
    "file_sas_datastore = AzureFileDatastore(\n",
    "    name = 'file-sas-example',\n",
    "    description = 'Datastore pointing to an Azure File Share using SAS token.',\n",
    "    account_name = 'mytestfilestore',\n",
    "    file_share_name = 'my-share',\n",
    "    credentials = {'sas_token': '?xx=XXXX-XX-XX&xx=xxxx&xxx=xxx&xx=xxxxxxxxxxx&xx=XXXX-XX-XXXXX:XX:XXX&xx=XXXX-XX-XXXXX:XX:XXX&xxx=xxxxx&xxx=XXxXXXxxxxxXXXXXXXxXxxxXXXXXxxXXXXXxXXXXxXXXxXXxXX'})\n",
    "ml_client.create_or_update(file_sas_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Create a datastore for Azure Data Lake Storage Gen1\n",
    "The `AzureDataLakeGen1Datastore` class can be used to create datastores for Azure Data Lake Storage Gen1. The key parameters needed to create this type of datastore are:\n",
    "- `name` - Name of the datastore\n",
    "- `store_name` - Name of the Azure Data Lake Storage Gen1 account.\n",
    "- `credentials` - Service principal credentials for connecting to the Azure storage account. Credential secrets are stored in the workspace key vault.\n",
    "  - `tenant_id` - \tThe tenant ID of the service principal\n",
    "  - `client_id` - The client ID of the service principal\n",
    "  -  `client_secret` - The client secret of the service principal.\n",
    "- `description` - Description of the datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adlsg1_datastore = AzureDataLakeGen1Datastore(\n",
    "    name = 'adls-gen1-example',\n",
    "    description = 'Datastore pointing to an Azure Data Lake Storage Gen1.',\n",
    "    store_name = 'mytestdatalakegen1', \n",
    "    credentials = {\n",
    "        'tenant_id': 'XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX',\n",
    "        'client_id': 'XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX',\n",
    "        'client_secret': 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'})\n",
    "ml_client.create_or_update(adlsg1_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Create a datastore for Azure Data Lake Storage Gen1\n",
    "The `AzureDataLakeGen2Datastore` class can be used to create datastores for Azure Data Lake Storage Gen2. The key parameters needed to create this type of datastore are:\n",
    "- `name` - Name of the datastore\n",
    "- `account_name` - Name of the Azure Data Lake Gen2 Storage account.\n",
    "- `filesystem` - Name of the file system. The parent directory that contains the files and folders. This is equivalent to a container in Azure Blob storage.\n",
    "- `protocol` - Protocol to use to connect to the file system. `https` and `abfs` are supported. The default is `https`.\n",
    "- `credentials` - Service principal credentials for connecting to the Azure storage account. Credential secrets are stored in the workspace key vault.\n",
    "  - `tenant_id` - \tThe tenant ID of the service principal\n",
    "  - `client_id` - The client ID of the service principal\n",
    "  -  `client_secret` - The client secret of the service principal.\n",
    "- `description` - Description of the datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adlsg2_datastore = AzureDataLakeGen2Datastore(\n",
    "    name = 'adls-gen2-example',\n",
    "    description = 'Datastore pointing to an Azure Data Lake Storage Gen2.',\n",
    "    account_name = 'mytestdatalakegen2',\n",
    "    filesystem = 'my-gen2-container',\n",
    "    credentials = {\n",
    "        'tenant_id': 'XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX',\n",
    "        'client_id': 'XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX',\n",
    "        'client_secret': 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'})\n",
    "ml_client.create_or_update(adlsg2_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using the datastore in a Job\n",
    "A Datastore can be used in a job like a `CommandJob` or a `PipelineJob`. In the below snippet, we will list the contents of a `datastore` in a `CommandJob`. We will use the default datastore `workspaceblobstore` which is created with any Azure Machine Learning Workspace.\n",
    "\n",
    "The datastore can be used as a folder in the format `azureml://datastores/<datastore-name>/paths/<optional-path>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_datastore = CommandJob(\n",
    "    command = 'ls ${{inputs.datastore}}',\n",
    "    inputs = {'datastore': JobInput(folder='azureml://datastores/workspaceblobstore/paths/')},\n",
    "    environment=Environment(image='python:latest'),\n",
    "    compute = \"cpu-cluster\", \n",
    "    display_name=\"using-datastore\"\n",
    ")\n",
    "\n",
    "#submit the command job\n",
    "returned_job = ml_client.create_or_update(explore_datastore)\n",
    "#get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Create datastores and use in a CommandJob"
  },
  "interpreter": {
   "hash": "45ee23ad53d8447c1a4a7f9f605254595f8ee53c2e1723e7948bbd485e96ca91"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('vnext')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
