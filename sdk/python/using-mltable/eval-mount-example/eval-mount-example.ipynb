{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process disparate paths into a single view with `eval_mount`/`eval_download` \n",
    "\n",
    "This example demonstrates how to leverage MLTable to create a table of different storage paths that can then be mounted/download into a single view on the compute target's filesystem with `eval_mount`/`eval_download` modes. You can take specific folders and/or files from the same or different storage accounts/containers and create that view on your compute target's file system by either a mount or download mechanism. For example:\n",
    "\n",
    "<img src=\"./media/eval_mount1.png\" alt=\"evaluate mount\" width=\"600\"/>\n",
    "\n",
    "This avoids having to create multiple inputs in your training jobs when the data is spread across different storage locations. \n",
    "\n",
    "In this notebook, we show a scenario where we want to download to our compute target a folder of images *and* an annotations file. The annotations file is located in the root directory on the storage account. If you were to use the standard `download` mode in your AzureML job, you would either need to create two inputs (one pointing to the folder and one to the annotations file) or you would need to download everything in the root directory. In this case the data is both the images and annotations file, so we want to keep those together."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Install dependencies\n",
    "\n",
    "Ensure you have the latest MLTable library and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../mltable-requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêç Create an MLTable using the Python SDK\n",
    "\n",
    "Here you build your data loading steps using the `mltable` Python SDK. The `show()` method allows you to see the effect of the data loading transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltable\n",
    "\n",
    "# create paths to the data files\n",
    "# NOTE: YOU MUST USE THE SAME URI SCHEMA FOR ALL PATHS (e.g. all wasbs:// or all abfss:// or all azureml://)\n",
    "paths = [\n",
    "    {\"folder\": \"wasbs://data@azuremlexampledata.blob.core.windows.net/pet-images/cat\"},\n",
    "    {\"folder\": \"wasbs://data@azuremlexampledata.blob.core.windows.net/pet-images/dog\"},\n",
    "    {\n",
    "        \"file\": \"wasbs://data@azuremlexampledata.blob.core.windows.net/pet-images-annotations.csv\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# create the mltable\n",
    "tbl = mltable.from_paths(paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Load into a Pandas data frame\n",
    "\n",
    "You can load your Azure ML Table into Pandas using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tbl.to_pandas_dataframe()\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save data loading steps \n",
    "Next, you'll save all your data loading steps into an `MLTable` file. This allows you to *reproduce* your Pandas data frame at a later point in time without having to redefine the data loading steps in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data loading steps in an MLTable file\n",
    "tbl.save(\"./disparate-files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîç View the saved file\n",
    "\n",
    "In the next code cell, we show you the `MLTable` file so you can understand how the data loading steps are serialized into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./disparate-files/MLTable\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ù Create a data asset to aid sharing and reproducibility\n",
    "\n",
    "You'll now create a data asset, which will automatically upload the `MLTable` to cloud storage (the default AzureML datastore) so that others can use it easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace = \"<AML_WORKSPACE_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# set the version number of the data asset to the current UTC time\n",
    "VERSION = time.strftime(\"%Y.%m.%d.%H%M%S\", time.gmtime())\n",
    "\n",
    "# connect to the AzureML workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "my_data = Data(\n",
    "    path=\"./disparate-files\",\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description=\"A sample of cat and dog images with an annotation file.\",\n",
    "    name=\"pets-mltable-example\",\n",
    "    version=VERSION,\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Read the data asset in a job\n",
    "\n",
    "You can also access your Table in a job, using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, command, Input\n",
    "from azure.ai.ml.entities import Environment\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# connect to the AzureML workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "# get the latest version of the data asset\n",
    "# Note: the VERSION was set in a previous cell.\n",
    "data_asset = ml_client.data.get(name=\"pets-mltable-example\", version=VERSION)\n",
    "\n",
    "input = {\n",
    "    \"pets\": Input(\n",
    "        type=AssetTypes.MLTABLE, path=data_asset.id, mode=InputOutputModes.EVAL_DOWNLOAD\n",
    "    )\n",
    "}\n",
    "\n",
    "cmd = \"\"\"\n",
    "    find ${{inputs.pets}}\n",
    "\"\"\"\n",
    "\n",
    "job = command(\n",
    "    command=cmd,\n",
    "    inputs=input,\n",
    "    compute=\"cpu-cluster\",\n",
    "    environment=\"azureml://registries/azureml/environments/sklearn-1.1/versions/4\",\n",
    ")\n",
    "\n",
    "ml_client.jobs.create_or_update(job)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job output\n",
    "\n",
    "This job is very simple - it lists out the downloaded absolute paths on the compute target's filesystem:\n",
    "\n",
    "<img src=\"./media/eval_mount_output.png\" alt=\"evaluate mount job output\" width=\"600\"/>\n",
    "\n",
    "What you'll notice is the data is downloaded into the following directory structure on the filesystem:\n",
    "\n",
    "```\n",
    "/https%3A\n",
    "    ‚îî‚îÄ‚îÄ %2Fazuremlexampledata.blob.core.windows.net\n",
    "        ‚îî‚îÄ‚îÄ data\n",
    "            ‚îú‚îÄ‚îÄ pet-images-annotations.csv\n",
    "            ‚îî‚îÄ‚îÄ pet-images\n",
    "                ‚îú‚îÄ‚îÄ cat\n",
    "                ‚îÇ   ‚îú‚îÄ‚îÄ cat0.jpg\n",
    "                ‚îÇ   ‚îî‚îÄ‚îÄ cat10.jpg\n",
    "                ‚îî‚îÄ‚îÄ dog\n",
    "                    ‚îú‚îÄ‚îÄ dog0.jpg\n",
    "                    ‚îî‚îÄ‚îÄ dog10.jpg\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
