{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Versioning in Azure Machine Learning\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Compute a hash for a dataset.\n",
    "2. Check if a dataset with the same hash already exists in Azure ML.\n",
    "3. If not, upload the dataset to Azure Blob Storage and register it as an asset with a hash tag.\n",
    "4. If it exists, retrieve the asset name, version, and tag.\n",
    "\n",
    "> **Note**: Ensure you update the configuration values before running the notebook.  \n",
    "> **Note**: If you encounter any issues, refer to the troubleshooting section at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-ml\n",
    "!pip install azure-identity\n",
    "!pip install azure-storage-blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "import hashlib\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_SUBSCRIPTION_ID = \"<YOUR_SUBSCRIPTION_ID>\"\n",
    "AZURE_RESOURCE_GROUP = \"<YOUR_RESOURCE_GROUP>\"\n",
    "AZUREML_WORKSPACE = \"<YOUR_WORKSPACE_NAME>\"\n",
    "AZURE_STORAGE_ACCOUNT_NAME = \"<YOUR_STORAGE_ACCOUNT_NAME>\"\n",
    "CONTAINER_NAME = \"<YOUR_CONTAINER_NAME>\"  # Replace with your actual container name in the storage account.\n",
    "ASSET_NAME = \"<YOUR_ASSET_NAME>\"  # Replace with the name you want to give your asset.\n",
    "ASSET_DESCRIPTION = \"<YOUR_ASSET_DESCRIPTION>\"  # Provide a description of your asset.\n",
    "ASSET_PATH = \"<ABSOLUTE_PATH_TO_YOUR_ASSET>\"  # Provide the absolute path to your local asset.\n",
    "ASSET_TYPE = \"dataset\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Azure Machine Learning Workspace\n",
    "\n",
    "Connect to the Azure ML workspace using `MLClient`. Ensure the configuration values in the previous cell are correct before running this code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure ML client\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(),\n",
    "    AZURE_SUBSCRIPTION_ID,\n",
    "    AZURE_RESOURCE_GROUP,\n",
    "    AZUREML_WORKSPACE,\n",
    ")\n",
    "\n",
    "# Initialize the Azure Blob client\n",
    "blob_client = BlobServiceClient(\n",
    "    account_url=f\"https://{AZURE_STORAGE_ACCOUNT_NAME}.blob.core.windows.net\",\n",
    "    credential=DefaultAzureCredential(),\n",
    ").get_container_client(CONTAINER_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Hash for Dataset\n",
    "\n",
    "Compute a hash for the dataset to identify its uniqueness. This will help in checking if the dataset already exists in Azure ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the hash of the asset folder\n",
    "hash_algo = hashlib.sha256()\n",
    "for root, _, files in os.walk(ASSET_PATH):\n",
    "    for file in sorted(files):  # Sort files for consistent hash\n",
    "        file_path = os.path.join(root, file)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_algo.update(chunk)\n",
    "asset_hash = hash_algo.hexdigest()\n",
    "print(f\"Computed hash: {asset_hash}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Existing Asset in Azure ML\n",
    "\n",
    "Check if a dataset with the same hash already exists in the Azure ML workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if an asset with this hash already exists in Azure ML\n",
    "asset_exists = False\n",
    "existing_asset_info = None\n",
    "for asset in ml_client.data.list():\n",
    "    for asset_version_info in ml_client.data.list(name=asset.name):\n",
    "        if asset_version_info.tags.get(\"hash\") == asset_hash:\n",
    "            asset_exists = True\n",
    "            existing_asset_info = {\n",
    "                \"asset_name\": asset_version_info.name,\n",
    "                \"asset_version\": asset_version_info.version,\n",
    "            }\n",
    "            break\n",
    "    if asset_exists:\n",
    "        break\n",
    "\n",
    "if asset_exists:\n",
    "    print(f\"Asset with hash {asset_hash} already exists in the workspace.\")\n",
    "    print(f\"Asset name: {existing_asset_info['asset_name']}, version: {existing_asset_info['asset_version']}\")\n",
    "else:\n",
    "    print(\"No existing asset found with the same hash. Uploading and registering the asset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Azure Blob Storage (If Not Exists)\n",
    "\n",
    "If the dataset doesn't already exist in Azure ML, upload it to Azure Blob Storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not asset_exists:\n",
    "    # Determine the latest version number\n",
    "    try:\n",
    "        latest = ml_client.data._get_latest_version(ASSET_NAME)\n",
    "        latest_version = str(int(latest.version) + 1) if latest else \"1\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting latest version: {e}, setting it to 1.\")\n",
    "        latest_version = \"1\"\n",
    "\n",
    "    # Upload files to Azure Blob Storage\n",
    "    unique_folder_path = f\"{ASSET_NAME}_{latest_version}\"\n",
    "    print(f\"Uploading files from {ASSET_PATH} to {unique_folder_path}\")\n",
    "\n",
    "    for root, _, files in os.walk(ASSET_PATH):\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            blob_path = os.path.join(unique_folder_path, os.path.relpath(file_path, ASSET_PATH))\n",
    "            blob_client_instance = blob_client.get_blob_client(blob_path)\n",
    "            with open(file_path, \"rb\") as data:\n",
    "                blob_client_instance.upload_blob(data, overwrite=True)\n",
    "            print(f\"Uploaded {file_path} to {blob_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the Dataset in Azure ML\n",
    "\n",
    "After uploading to Blob Storage, register the dataset as an asset in Azure ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not asset_exists:\n",
    "    # Register the asset in Azure ML\n",
    "    blob_url = f\"https://{AZURE_STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{CONTAINER_NAME}/{unique_folder_path}\"\n",
    "    data_asset = Data(\n",
    "        path=blob_url,\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        description=ASSET_DESCRIPTION,\n",
    "        name=ASSET_NAME,\n",
    "        tags={\"hash\": asset_hash}, # Tagging the asset with the computed hash\n",
    "    )\n",
    "\n",
    "    registered_asset = ml_client.data.create_or_update(data_asset)\n",
    "    print(f\"New {ASSET_TYPE} registered in the workspace: {ASSET_NAME} with version {registered_asset.version}\")\n",
    "    existing_asset_info = {\n",
    "        f\"asset_name\": registered_asset.name,\n",
    "        f\"asset_version\": registered_asset.version,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "If the asset was uploaded and registered, or if it already existed, the asset name and version are displayed below.\n",
    "\n",
    "**You can use these results to add a tag to the AML job, creating a link to the dataset used.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if existing_asset_info:\n",
    "    print(f\"Asset name: {existing_asset_info['asset_name']}, version: {existing_asset_info['asset_version']} found\")\n",
    "else:\n",
    "    print(\"No action taken.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "\n",
    "1. **Permission Issues:**  \n",
    "   - Ensure that your Azure Active Directory (AAD) account has the appropriate permissions:\n",
    "     - **Azure Machine Learning:** 'Contributor' or 'Owner' role for the resource group containing the Azure ML workspace.\n",
    "     - **Storage Account:** 'Storage Blob Data Contributor' role for the specific storage account used in your operations.\n",
    "\n",
    "2. **Path Error:**  \n",
    "   - The dataset path (`ASSET_PATH`) must be an absolute path. Modify this path based on your environment to point to the correct location of the data files.\n",
    "\n",
    "3. **Asset Registration Issues:**  \n",
    "   - If you encounter an error stating that an asset already exists, ensure that you have a unique asset name or update the existing asset version if necessary.\n",
    "\n",
    "4. **Tagging:**  \n",
    "   - Each dataset is tagged with its computed hash. This tag is used to verify the uniqueness of the dataset in Azure ML. Make sure to include the hash tag when registering a new dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
