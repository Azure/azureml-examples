{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Azure Machine Learning Models\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace with computer cluster - [Configure workspace](../../jobs/configuration.ipynb) \n",
    "\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](../../README.md) - check the getting started section\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Create a model from a local file\n",
    "- Create a model from an mlflow model\n",
    "- Create a model from cloud path\n",
    "- Create a model from a run\n",
    "- Read/write model in a job.\n",
    "\n",
    "**Motivations** - This notebook explains how to register a model in the Azure Machine Learning workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "install",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure.ai.ml --extra-index-url  https://azuremlsdktestpypi.azureedge.net/sdk-cli-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1667854025831
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.constants import AssetTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../jobs/configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1667854026057
    },
    "name": "subscription_id"
   },
   "outputs": [],
   "source": [
    "# Enter details of your AML workspace\n",
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace = \"<AML_WORKSPACE_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1667854026298
    },
    "name": "ml_client"
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a model\n",
    "Azure ML models consist of the binary file(s) that represent a machine learning model and any corresponding metadata. Models can be created from a local file or directory. The created model will be tracked in the workspace under the specified name and version.\n",
    "\n",
    "The `Model` class can be used to create a model. It accepts the following key parameters:\n",
    "- `name` - Name of the model.\n",
    "- `version` - Version of the model. If omitted, Azure ML will autogenerate a version.\n",
    "- `path` - Local path to the model file(s). This can point to either a file or a directory.\n",
    "- `type` - Storage format of the model. Applicable for no-code deployment scenarios. Allowed values are `custom_model`, `mlflow_model`, `triton_model`\n",
    "- `description` - Description of the model.\n",
    "\n",
    "## 2.1 Create a model from a local file\n",
    "In this sample we will create a model from a local `pkl` file and specify the type of the model to be `custom_model`. The model is initialized with the required parameters. It is then created in the Azure Machine Learning workspace using the `MLClient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1667854035349
    },
    "name": "file_model"
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "file_model = Model(\n",
    "    path=\"mlflow-model/model.pkl\",\n",
    "    type=AssetTypes.CUSTOM_MODEL,\n",
    "    name=\"local-file-example\",\n",
    "    description=\"Model created from local file.\",\n",
    ")\n",
    "ml_client.models.create_or_update(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create a model from an mlflow model\n",
    "In this sample we will create a model from a local folder. We will also specify the type of the model to be `mlflow_model`. The model is initialized with the required parameters. It is then created in the Azure Machine Learning workspace using the `MLClient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1667854040340
    },
    "name": "mlflow_model"
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "mlflow_model = Model(\n",
    "    path=\"mlflow-model\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    name=\"local-mlflow-example\",\n",
    "    description=\"MLflow model created from local path\",\n",
    ")\n",
    "ml_client.create_or_update(mlflow_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 2.3 Create a model from cloud path\n",
    "In this sample we will create a model from a cloud path. We will also specify the format of the model to be `custom_model`. The model is initialized with the required parameters. It is then created in the Azure Machine Learning workspace using the `MLClient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1667854049363
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "cloud_model",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "cloud_model = Model(\n",
    "    path=file_model.path,\n",
    "    # The above line basically provides a path in the format \"azureml://subscriptions/XXXXXXXXXXXXXXXX/resourceGroups/XXXXXXXXXXX/workspaces/XXXXXXXXXXX/datastores/workspaceblobstore/paths/model.pkl\"\n",
    "    # Users could also use,\"azureml://datastores/workspaceblobstore/paths/model.pkl\" as a shorthand to the same location\n",
    "    name=\"cloud-path-example\",\n",
    "    type=AssetTypes.CUSTOM_MODEL,\n",
    "    description=\"Model created from cloud path.\",\n",
    ")\n",
    "ml_client.models.create_or_update(cloud_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 2.4 Create a model from a run\n",
    "In this sample we will create a model from a run. We will also specify the type of the model to be `mlflow_model`. The model is initialized with the required parameters. It is then created in the Azure Machine Learning workspace using the `MLClient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1667854235360
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "run_model",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "job_name = \"<JOB_NAME>\"\n",
    "\n",
    "run_model = Model(\n",
    "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n",
    "    name=\"run-model-example\",\n",
    "    description=\"Model created from run.\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    ")\n",
    "# Uncomment after adding required details above\n",
    "# ml_client.models.create_or_update(run_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Loading model as an input to a job\n",
    "\n",
    "In this example we will use the MLflow model trained on the Iris Dataset - ([./mlflow-model](./mlflow-model)) and set-up a command that executes the following python code, that loads the model, test data and scores the model:\n",
    "\n",
    "```python\n",
    "with open(args.input_data) as f:\n",
    "   sample_data = json.load(f)\n",
    "\n",
    "#columns = [\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]\n",
    "\n",
    "sk_model = mlflow.sklearn.load_model(args.input_model)\n",
    "predictions = sk_model.predict(sample_data[\"data\"])\n",
    "```\n",
    "\n",
    "Below is the code for submitting the command to the cloud - note that both the code *and* the data is automatically uploaded to the cloud. Note: The data is only re-uploaded on subsequent job submissions if data has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1667854299357
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "# === Note on path ===\n",
    "# can be can be a local path or a cloud path. AzureML supports `runs:/` and `azureml://` URIs.\n",
    "# Local paths are automatically uploaded to the default datastore in the cloud.\n",
    "# More details on supported paths: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-models?tabs=use-local#supported-paths\n",
    "\n",
    "inputs = {\n",
    "    \"input_data\": Input(\n",
    "        type=AssetTypes.URI_FILE, path=\"./mlflow-model/input_example.json\"\n",
    "    ),\n",
    "    \"input_model\": Input(type=AssetTypes.MLFLOW_MODEL, path=\"./mlflow-model\"),\n",
    "}\n",
    "\n",
    "outputs = {\n",
    "    \"output_folder\": Output(\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        path=f\"azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/workspaces/{workspace}/datastores/workspaceblobstore/paths/predictions\",\n",
    "    )\n",
    "}\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",  # local path where the code is stored\n",
    "    command=\"python load_score.py --input_model ${{inputs.input_model}} --input_data ${{inputs.input_data}} --output_folder ${{outputs.output_folder}}\",\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
    "    compute=\"cpu-cluster\",\n",
    ")\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.jobs.create_or_update(job)\n",
    "# get a URL for the status of the job\n",
    "returned_job.studio_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Reading *and* writing model in a job\n",
    "\n",
    "By design, you cannot *write* to `Inputs` only `Outputs`. The code below creates an `Output` that will mount your AzureML default datastore (Azure Blob) in Read-*Write* mode. The python code simply loads the local mlflow model as input and exports the same model as an output of the job saved in the mounted datastore, i.e.\n",
    "\n",
    "\n",
    "```python\n",
    "sk_model = mlflow.sklearn.load_model(args.input_model)\n",
    "mlflow.sklearn.save_model(sk_model, args.output_folder)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1667854314396
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "inputs = {\"input_model\": Input(type=AssetTypes.MLFLOW_MODEL, path=\"./mlflow-model\")}\n",
    "\n",
    "outputs = {\"custom_model_output\": Output(type=AssetTypes.CUSTOM_MODEL)}\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",  # local path where the code is stored\n",
    "    command=\"python load_write_model.py --input_model ${{inputs.input_model}} --custom_model_output ${{outputs.custom_model_output}}\",\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
    "    compute=\"cpu-cluster\",\n",
    ")\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "# get a URL for the status of the job\n",
    "returned_job.studio_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "- Deploy a model to an Online Inferencing endpoint - [example](../../endpoints/online/managed/online-endpoints-simple-deployment.ipynb) \n",
    "- Deploy a model to a Batch Inferencing endpoint - [example](../../endpoints/batch/mnist-nonmlflow.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Create model from local files, cloud files, Runs"
  },
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
