{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Using batch deployments for image file processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Importing the required libraries. This notebook requires:\n",
    "\n",
    "- `azure-ai-ml`\n",
    "- `mlflow`\n",
    "- `azureml-mlflow`\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `pillow`\n",
    "- `tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.entities import (\n",
    "    BatchEndpoint,\n",
    "    BatchDeployment,\n",
    "    Model,\n",
    "    AmlCompute,\n",
    "    Data,\n",
    "    BatchRetrySettings,\n",
    "    CodeConfiguration,\n",
    "    Environment,\n",
    ")\n",
    "from azure.ai.ml.constants import AssetTypes, BatchDeploymentOutputAction\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Accessing the Azure Machine Learning workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "subscription_id = \"<subscription>\"\n",
    "resource_group = \"<resource-group>\"\n",
    "workspace = \"<workspace>\"\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## About the model\n",
    "\n",
    "Let's review how the model is built. The model was built using TensorFlow along with the RestNet architecture ([Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)). This model has the following constraints that are important to keep in mind for deployment:\n",
    "\n",
    "* In work with images of size 244x244 (tensors of `(224, 224, 3)`).\n",
    "* It requires inputs to be scaled to the range `[0,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        hub.KerasLayer(\n",
    "            \"https://tfhub.dev/google/imagenet/resnet_v2_101/classification/5\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "model.build([None, None, None, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Testing if the model works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "\n",
    "image_file = tf.keras.utils.get_file(\n",
    "    \"image.jpeg\",\n",
    "    \"https://azuremlexampledata.blob.core.windows.net/data/imagenet/goldfish.JPEG\",\n",
    ")\n",
    "img = Image.open(image_file).resize((244, 244))\n",
    "img = np.array(img) / 255.0\n",
    "batch_img = tf.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict(batch_img)\n",
    "pred_class = pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Getting the labels for ImageNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file(\n",
    "    \"ImageNetLabels.txt\",\n",
    "    \"https://azuremlexampledata.blob.core.windows.net/data/imagenet/ImageNetLabels.txt\",\n",
    ")\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "predicted_class_name = [\n",
    "    imagenet_labels[predicted_class] for predicted_class in pred_class\n",
    "]\n",
    "predicted_class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's save this model locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model_local_path = \"imagenet-classifier/model\"\n",
    "model.save(model_local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Deploying the model in a batch endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Registering the model\n",
    "\n",
    "We need to register the model in order to use it with Azure Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"imagenet-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if not any(filter(lambda m: m.name == model_name, ml_client.models.list())):\n",
    "    print(f\"Model {model_name} is not registered. Creating...\")\n",
    "    model = ml_client.models.create_or_update(\n",
    "        Model(name=model_name, path=model_local_path, type=AssetTypes.CUSTOM_MODEL)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's get a reference to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model = ml_client.models.get(name=model_name, label=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Creating an scoring script to work with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%writefile imagenet-classifier/code/imagenet_scorer.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from os.path import basename\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global input_width\n",
    "    global input_height\n",
    "\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment\n",
    "    model_path = os.path.join(os.environ[\"AZUREML_MODEL_DIR\"], \"model\")\n",
    "\n",
    "    # load the model\n",
    "    model = load_model(model_path)\n",
    "    input_width = 244\n",
    "    input_height = 244\n",
    "\n",
    "def run(mini_batch):\n",
    "    results = []\n",
    "\n",
    "    for image in mini_batch:\n",
    "        data = Image.open(image).resize((input_width, input_height)) # Read and resize the image\n",
    "        data = np.array(data)/255.0 # Normalize\n",
    "        data_batch = tf.expand_dims(data, axis=0) # create a batch of size (1, 244, 244, 3)\n",
    "\n",
    "        # perform inference\n",
    "        pred = model.predict(data_batch)\n",
    "\n",
    "        # Compute probabilities, classes and labels\n",
    "        pred_prob = tf.math.reduce_max(tf.math.softmax(pred, axis=-1)).numpy()\n",
    "        pred_class = tf.math.argmax(pred, axis=-1).numpy()\n",
    "\n",
    "        results.append([basename(image), pred_class[0], pred_prob])\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Creating the ednpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "First, let's create the endpoint that is going to host the batch deployments. Remember that each endpoint can host multiple deployments at any time, however, only one of them is the default one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"imagenet-classifier-batch\"\n",
    "endpoint = BatchEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description=\"An batch service to perform imagenet image classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Creating the compute\n",
    "\n",
    "Batch endpoints can run on any Azure ML compute that already exists in the workspace. That means that multiple batch deployments can share the same compute infrastructure. In this example, we are going to work on an AzureML compute cluster called `cpu-cluster`. Let's verify the compute exists on the workspace or create it otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "compute_name = \"cpu-cluster\"\n",
    "if not any(filter(lambda m: m.name == compute_name, ml_client.compute.list())):\n",
    "    print(f\"Compute {compute_name} is not created. Creating...\")\n",
    "    compute_cluster = AmlCompute(\n",
    "        name=compute_name, description=\"amlcompute\", min_instances=0, max_instances=5\n",
    "    )\n",
    "    ml_client.begin_create_or_update(compute_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Compute may take time to be created. Let's wait for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "print(\"Waiting for compute\", end=\"\")\n",
    "while ml_client.compute.get(name=compute_name).provisioning_state == \"Creating\":\n",
    "    sleep(1)\n",
    "    print(\".\", end=\"\")\n",
    "\n",
    "print(\" [DONE]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Creating the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's create the environment. In our case, our model runs on `TensorFlow`. Azure Machine Learning already has an environment with the required software installed, so we can reutilize this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "environment = Environment(\n",
    "    conda_file=\"./imagenet-classifier/environment/conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/tensorflow-2.4-ubuntu18.04-py37-cpu-inference:latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Creating the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's create a deployment under the given endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "deployment = BatchDeployment(\n",
    "    name=\"imagenet-classifier-resnetv2\",\n",
    "    description=\"A ResNetV2 model architecture for performing ImageNet classification in batch\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=model,\n",
    "    environment=environment,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./imagenet-classifier/code/\",\n",
    "        scoring_script=\"imagenet_scorer.py\",\n",
    "    ),\n",
    "    compute=compute_name,\n",
    "    instance_count=2,\n",
    "    max_concurrency_per_instance=1,\n",
    "    mini_batch_size=10,\n",
    "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "    output_file_name=\"predictions.csv\",\n",
    "    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "    logging_level=\"info\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ml_client.batch_deployments.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Setting the default deployment\n",
    "\n",
    "Let's update the default deployment name in the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "endpoint = ml_client.batch_endpoints.get(endpoint_name)\n",
    "endpoint.defaults.deployment_name = deployment.name\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "We can see the endpoint URL as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "endpoint.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Testing the endpoint\n",
    "\n",
    "Once the deployment is created, it is ready to recieve jobs. Let's first register a data asset so we can run the job against it. This data asset is a folder containing 1000 images from the original ImageNet dataset. We are going to download it first and then create the data asset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!wget https://azuremlexampledata.blob.core.windows.net/data/imagenet-1000.zip\n",
    "!unzip imagenet-1000.zip -d /tmp/imagenet-1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/tmp/imagenet-1000\"\n",
    "dataset_name = \"imagenet-sample-unlabeled\"\n",
    "\n",
    "imagenet_sample = Data(\n",
    "    path=data_path,\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=\"A sample of 1000 images from the original ImageNet dataset\",\n",
    "    name=dataset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ml_client.data.create_or_update(imagenet_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's get a reference of the new data asset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "imagenet_sample = ml_client.data.get(name=dataset_name, label=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's use this data as an input for the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "input = Input(type=AssetTypes.URI_FOLDER, path=imagenet_sample.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "job = ml_client.batch_endpoints.invoke(endpoint_name=endpoint.name, input=input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "You can use the returned job object to check the status of the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ml_client.jobs.get(job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## High throughput deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%writefile imagenet-classifier/code/imagenet_scorer_batch.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global input_width\n",
    "    global input_height\n",
    "\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment\n",
    "    model_path = os.path.join(os.environ[\"AZUREML_MODEL_DIR\"], \"model\")\n",
    "\n",
    "    # load the model\n",
    "    model = load_model(model_path)\n",
    "    input_width = 244\n",
    "    input_height = 244\n",
    "\n",
    "def decode_img(file_path):\n",
    "    file = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(file, channels=3)\n",
    "    img = tf.image.resize(img, [input_width, input_height])\n",
    "    return img/255.\n",
    "\n",
    "def run(mini_batch):\n",
    "    images_ds = tf.data.Dataset.from_tensor_slices(mini_batch)\n",
    "    images_ds = images_ds.map(decode_img).batch(64)\n",
    "\n",
    "    # perform inference\n",
    "    pred = model.predict(images_ds)\n",
    "\n",
    "    # Compute probabilities, classes and labels\n",
    "    pred_prob = tf.math.reduce_max(tf.math.softmax(pred, axis=-1)).numpy()\n",
    "    pred_class = tf.math.argmax(pred, axis=-1).numpy()\n",
    "\n",
    "    return pd.DataFrame([mini_batch, pred_prob, pred_class], columns=['file', 'probability', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's use this new scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ht_deployment = BatchDeployment(\n",
    "    name=\"imagenet-classifier-resnetv2-ht\",\n",
    "    description=\"A ResNetV2 model architecture for performing ImageNet classification in batch (High throughput)\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=model,\n",
    "    environment=\"AzureML-tensorflow-2.4-ubuntu18.04-py37-cpu-inference@latest\",\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./imagenet-classifier/code/\",\n",
    "        scoring_script=\"imagenet_scorer_batch.py\",\n",
    "    ),\n",
    "    compute=compute_name,\n",
    "    instance_count=2,\n",
    "    max_concurrency_per_instance=1,\n",
    "    mini_batch_size=10,\n",
    "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "    output_file_name=\"predictions.csv\",\n",
    "    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "    logging_level=\"info\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ml_client.batch_deployments.begin_create_or_update(ht_deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's execute this specific deployment now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint.name, deployment_name=ht_deployment, input=input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Exploring the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ml_client.jobs.download(name=job.name, download_path=\".\", output_name=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = pd.read_csv(\n",
    "    \"named-outputs/score/predictions.csv\",\n",
    "    header=None,\n",
    "    names=[\"file\", \"class\", \"probabilities\"],\n",
    "    sep=\" \",\n",
    ")\n",
    "score[\"label\"] = score[\"class\"].apply(lambda pred: imagenet_labels[pred])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Using MLflow with images\n",
    "\n",
    "When working with MLflow models that processes images, it is important to take into account for all the preprocessing you model requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Resizing(\n",
    "            244, 244, interpolation=\"bilinear\", crop_to_aspect_ratio=False\n",
    "        ),\n",
    "        tf.keras.layers.Rescaling(1 / 255.0),\n",
    "        hub.KerasLayer(\n",
    "            \"https://tfhub.dev/google/imagenet/resnet_v2_101/classification/5\"\n",
    "        ),\n",
    "        tf.keras.layers.Softmax(axis=-1),\n",
    "    ]\n",
    ")\n",
    "model.build([None, None, None, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's save this model in a local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model_local_path = \"imagenet-classifier/model\"\n",
    "model.save(model_local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "We are going to include the labels for the predicted class in the directory so we can use them for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!wget https://azuremlexampledata.blob.core.windows.net/data/imagenet/ImageNetLabels.txt -d imagenet-classifier/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's create a custom loader for the MLflow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%writefile imagenet-classifier-mlflow/code/loader_module.py\n",
    "\n",
    "class TfClassifier():\n",
    "    def __init__(self, model_path: str, labels_path: str):\n",
    "        import tensorflow as tf\n",
    "        import numpy as np\n",
    "        from tensorflow.keras.models import load_model\n",
    "        \n",
    "        self.model = load_model(model_path)\n",
    "        self.imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "\n",
    "    def predict(self, data):\n",
    "        preds = self.model.predict(data)\n",
    "\n",
    "        pred_prob = tf.reduce_max(preds, axis=-1)\n",
    "        pred_class = tf.argmax(preds, axis=-1)\n",
    "        pred_label = [self.imagenet_labels[pred] for pred in pred_class]\n",
    "\n",
    "        return pd.DataFrame([pred_class, pred_prob, pred_label], columns=['class', 'probability', 'label'])\n",
    "\n",
    "def _load_pyfunc(data_path: str):\n",
    "    import os\n",
    "\n",
    "    model_path = os.path.abspath(data_path)\n",
    "    labels_path = os.path.join(model_path, 'ImageNetLabels.txt')\n",
    "\n",
    "    return TfClassifier(model_path, labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Indicating a signature for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "input_schema = Schema(\n",
    "    [\n",
    "        TensorSpec(np.dtype(np.uint8), (-1, -1, -1, 3)),\n",
    "    ]\n",
    ")\n",
    "signature = ModelSignature(inputs=input_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Logging the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow.pyfunc.save_model(\n",
    "    \"model\",\n",
    "    data_path=\"imagenet-classifier/model\",\n",
    "    code_path=[\"imagenet-classifier-mlflow/code/module_loader.py\"],\n",
    "    loader_module=\"module_loader\",\n",
    "    signature=signature,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new model can be used for batch scoring using batch deployments."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "amlv2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 (amlv2)",
   "language": "python",
   "name": "amlv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
