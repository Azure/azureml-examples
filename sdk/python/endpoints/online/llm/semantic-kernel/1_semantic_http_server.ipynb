{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel (SK) Integration into Azure Machine Learning (AzureML)\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "* A basic understanding of Machine Learning and Large Language Models\n",
    "* An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "* An Azure Machine Learning Workspace, Azure Key Vault, and Azure Container Registry\n",
    "* An OpenAI API Key which can be found in User Settings in OpenAI\n",
    "\n",
    "**Motivations** - Semantic kernel has a slightly different approach to LLM agents. It offers an interesting Plan->Execute pattern, where it could use LLM to form a plan first, then human could confirm and execute on the plan. In this notebook, we use the [planner](https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/python/05-using-the-planner.ipynb) example from Semantic Kernel as a base. But additionally, we've made the following modifications:\n",
    "* Created a **python SemanticKernelHttp server** based on Flask.\n",
    "* Deploy SemanticKernelHttp to an **AzureML Managed Online Endpoint**\n",
    "\n",
    "Managed online endpoints provide an easy to manage inferencing server for your ML workload. It's perfect for LLM based applications. Since we need a REST service, we won't use the default endpoint docker image, we will create a custom docker image instead.\n",
    "\n",
    "**Outline** - \n",
    "1. Test SemanticKernelHttpServe locally\n",
    "2. Prepare Dependencies\n",
    "3. Deploy to Managed Online Endpoint\n",
    "4. Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Test SemanticKernelHttpServer Locally\n",
    "Before we proceed, let's startup the server and test locally first. Grab your OpenAI infor and fill in the variables below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_TYPE='azure' # 'azure' or 'openai'\n",
    "OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY') if os.environ.get('OPENAI_API_KEY') else input('OPENAI_API_KEY')\n",
    "\n",
    "# required for OpenAI API\n",
    "OPENAI_ORG_ID=''\n",
    "OPENAI_MODEL_ID='gpt-3.5-turbo'\n",
    "\n",
    "# required for Azure OpenAI API\n",
    "AZURE_OPENAI_API_ENDPOINT='https://<azure-openai-endpoint>.openai.azure.com/'\n",
    "AZURE_OPENAI_API_DEPLOYMENT_NAME='<deployment-name>'\n",
    "\n",
    "# set to true for chat completion API, false for text completion\n",
    "IS_CHAT_COMPLETION=True\n",
    "\n",
    "# setting up env variables for local server\n",
    "%env OPENAI_API_TYPE=$OPENAI_API_TYPE\n",
    "%env OPENAI_API_KEY=$OPENAI_API_KEY\n",
    "%env OPENAI_MODEL_ID=$OPENAI_MODEL_ID\n",
    "%env OPENAI_ORG_ID=$OPENAI_ORG_ID\n",
    "%env AZURE_OPENAI_API_ENDPOINT=$AZURE_OPENAI_API_ENDPOINT\n",
    "%env AZURE_OPENAI_API_DEPLOYMENT_NAME=$AZURE_OPENAI_API_DEPLOYMENT_NAME\n",
    "%env IS_CHAT_COMPLETION=$IS_CHAT_COMPLETION\n",
    "\n",
    "# Install python dependencies\n",
    "%pip install -r ../src/sk/requirements.txt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the server locally\n",
    "# %run -i ../src/sk/app.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Test the server API\n",
    "Now the server is running, since the Jupyter notebook kernal is blocked.\n",
    "You could use postman to test. If you don't have postman, you could also open a terminal and execute the curl commands below to try. \n",
    "```\n",
    "curl -i -X POST -H \"Content-Type: application/json\" -d \"{\\\"value\\\": \\\"Tomorrow is Valentine day. I need to come up with a few date ideas. She speaks French so write it in French.\\\"}\" http://127.0.0.1:5001/planner/createplan\n",
    "```\n",
    "You should be seeing resposes like\n",
    "```\n",
    "{\n",
    "    \"input\": \"Valentine's Day Date Ideas\",\n",
    "    \"subtasks\": [\n",
    "        {\"function\": \"WriterSkill.Brainstorm\"},\n",
    "        {\"function\": \"WriterSkill.EmailTo\", \"args\": {\"to\": \"significant_other\"}},\n",
    "        {\"function\": \"WriterSkill.Translate\", \"args\": {\"language\": \"French\"}}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Then you could execute this plan\n",
    "```\n",
    "curl -i -X POST -H \"Content-Type: application/json\" -d \"{\\\"input\\\": \\\"Valentine's Day Date Ideas\\\",    \\\"subtasks\\\": [{\\\"function\\\": \\\"WriterSkill.Brainstorm\\\"},{\\\"function\\\": \\\"WriterSkill.EmailTo\\\", \\\"args\\\": {\\\"to\\\": \\\"significant_other\\\"}},{\\\"function\\\": \\\"WriterSkill.Translate\\\", \\\"args\\\": {\\\"language\\\": \\\"French\\\"}}]}\" http://127.0.0.1:5001/planner/executeplan\n",
    "```\n",
    "You should see responses like \n",
    "```\n",
    "Assurez-vous d'utiliser uniquement le français.\n",
    "\n",
    "Cher(e) partenaire,\n",
    "\n",
    "Je pensais à des activités amusantes et romantiques que nous pourrions faire ensemble et j'ai eu quelques idées. Nous pourrions avoir un dîner romantique dans un restaurant chic, ou faire un pique-nique dans le parc. Une autre idée est de faire une soirée cinéma à la maison avec du popcorn fait maison, ou aller pour un massage en couple dans un spa. Nous pourrions également essayer une dégustation de vin dans un vignoble local, ou aller patiner sur glace dans une patinoire à proximité. Si nous sommes d'humeur aventureuse, nous pourrions prendre un cours de cuisine ensemble, ou faire un tour en montgolfière au lever ou au coucher du soleil. Pour une expérience plus culturelle, nous pourrions visiter un musée ou une galerie d'art, ou faire une randonnée ou une promenade panoramique.\n",
    "\n",
    "Faites-moi savoir ce que vous en pensez !\n",
    "\n",
    "Merci,\n",
    "[Votre nom]\n",
    "```\n",
    "\n",
    "Great! Now our server and plugin are both working well locally. Let's deploy to AML so our team members could try out too."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Deploy Server to AML Managed Online Endpoint\n",
    "On a high level, we will perform the following tasks:\n",
    "\n",
    "* **Preparation**\n",
    "    * Store Secets in Azure Keyvault\n",
    "    * Create docker image in Azure Container Registry\n",
    "* **Create Managed Online Endpoint**, grant the endpoint permission to access the resources above.\n",
    "* **Deploy to Managed Online Endpoint**, now we are ready deploy the code\n",
    "* **Test**\n",
    "\n",
    "## 2.1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure resources needed for the demo. You can change them to use your own. \n",
    "# If you don't have the resources, you could keep the names as is and we will create them for you in next step.\n",
    "SUBSCRIPTION_ID = \"<subscription-id>\"\n",
    "RESOURCE_GROUP = \"llmops-demo\"\n",
    "REGION = \"westus3\"\n",
    "AML_WORKSPACE_NAME = \"llmops-demo-aml-ws\"\n",
    "\n",
    "# Keyvault information\n",
    "KEYVAULT_NAME = \"aml-llm-demo-kv\"\n",
    "# Key name in keyvault for the OPENAI-AI-KEY\n",
    "KV_OPENAI_KEY = \"OPENAI-API-KEY\"\n",
    "\n",
    "ACR_NAME='amlllmdemoacr'\n",
    "ACR_IMAGE_NAME='serving'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's login first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate clients\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential(additionally_allowed_tenants = ['*'])\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential(additionally_allowed_tenants = ['*'])\n",
    "\n",
    "# If login doesn't work above, uncomment the code below and login using device code\n",
    "# !az login --use-device-code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Store Secrets in Azure Keyvault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_OBJECT_ID = !az ad signed-in-user show --query id -o tsv\n",
    "KEYVAULT_RESOURCE_URI = f\"/subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/{KEYVAULT_NAME}\"\n",
    "\n",
    "need_interactive_auth = False\n",
    "if \"AADSTS530003\".lower() in MY_OBJECT_ID[0].lower():\n",
    "    need_interactive_auth = True\n",
    "    print('\\n'.join(MY_OBJECT_ID))\n",
    "    print(\"\\nYou are geting this error probably because you are using a device login. And this operation needs interactive login. If you can't login interactively, you could simply copy and run the following command in Azure Cloud Shell in Bash mode.\\n\")\n",
    "    print(\"MY_OBJECT_ID=`az ad signed-in-user show --query id -o tsv`\")\n",
    "    print(f\"az role assignment create --role 'Key Vault Administrator' --scope {KEYVAULT_RESOURCE_URI}  --assignee-object-id $MY_OBJECT_ID --assignee-principal-type User\")\n",
    "    print(f\"az keyvault secret set --name {KV_OPENAI_KEY} --vault-name {KEYVAULT_NAME} --value {OPENAI_API_KEY}\")\n",
    "else:\n",
    "    # Let's set OpenAI key as a secret in keyvault\n",
    "    need_interactive_auth = False\n",
    "    !az role assignment create --role \"Key Vault Administrator\" --scope {KEYVAULT_RESOURCE_URI}  --assignee-object-id {MY_OBJECT_ID[0]} --assignee-principal-type User\n",
    "    !az keyvault secret set --name {KV_OPENAI_KEY} --vault-name {KEYVAULT_NAME} --value {OPENAI_API_KEY}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!az acr build --image {ACR_IMAGE_NAME} --registry {ACR_NAME} ./environment/serving/. --subscription {SUBSCRIPTION_ID}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Manage Online Endpoint\n",
    "### 3.1 Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate clients\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential(additionally_allowed_tenants = ['*'])\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "    \n",
    "# create a endpoint\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    ")\n",
    "\n",
    "from azure.ai.ml import (\n",
    "    MLClient,\n",
    ")\n",
    "\n",
    "online_endpoint_name = \"aml-llm-demo-sk-endpoint\"\n",
    "\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(credential, SUBSCRIPTION_ID, RESOURCE_GROUP, AML_WORKSPACE_NAME)\n",
    "\n",
    "try:\n",
    "    endpoint = ml_client.online_endpoints.get(online_endpoint_name)\n",
    "except Exception as ex:\n",
    "    # create an online endpoint\n",
    "    endpoint = ManagedOnlineEndpoint(\n",
    "        name=online_endpoint_name,\n",
    "        description=\"online endpoint for SemanticKernelHttp server\",\n",
    "        auth_mode=\"key\",\n",
    "    )\n",
    "\n",
    "    endpoint = ml_client.begin_create_or_update(endpoint).result()\n",
    "\n",
    "print(endpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Grant Endpoint Permission to Dependencies\n",
    "Endpoint uses AAD to access dependent resources, so you don't have to hardcode secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow the endpoint to access keyvault and acr\n",
    "KEYVAULT_RESOURCE_URI = f\"/subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/{KEYVAULT_NAME}\"\n",
    "ACR_RESOURCE_URI = f\"/subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{RESOURCE_GROUP}/providers/Microsoft.ContainerRegistry/registries/{ACR_NAME}\"\n",
    "\n",
    "need_interactive_auth=True\n",
    "if need_interactive_auth:\n",
    "    print(\"If you can't login interactively, you could run the following command in Azure Cloud Bash Shell.\")\n",
    "    print(f\"az role assignment create --role 'Key Vault Secrets User' --scope {KEYVAULT_RESOURCE_URI}  --assignee {endpoint.identity.principal_id}\")\n",
    "    print(f\"az role assignment create --role 'AcrPull' --scope {ACR_RESOURCE_URI}  --assignee {endpoint.identity.principal_id}\")\n",
    "else:\n",
    "    !az role assignment create --role \"Key Vault Secrets User\" --scope {KEYVAULT_RESOURCE_URI}  --assignee {endpoint.identity.principal_id}\n",
    "    !az role assignment create --role \"AcrPull\" --scope {ACR_RESOURCE_URI}  --assignee {endpoint.identity.principal_id}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Deploy to Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineDeployment,\n",
    "    OnlineRequestSettings,\n",
    "    Model,\n",
    "    Environment,\n",
    ")\n",
    "\n",
    "KEYVAULT_URL = f\"https://{KEYVAULT_NAME}.vault.azure.net\"\n",
    "\n",
    "deployment_name = f\"deploy-{str(datetime.datetime.now().strftime('%m%d%H%M%f'))}\"\n",
    "sk_deployment = ManagedOnlineDeployment(\n",
    "    name = deployment_name,\n",
    "    model=Model(path=\"../src\"),\n",
    "    request_settings=OnlineRequestSettings(\n",
    "        request_timeout_ms= 60000\n",
    "    ),\n",
    "    environment= Environment(\n",
    "        image=f\"{ACR_NAME}.azurecr.io/{ACR_IMAGE_NAME}:latest\",\n",
    "        name=\"serving\",\n",
    "        description=\"A generic serving environment, allowing customer to provide their own entry point to bring up an http server\",\n",
    "        inference_config = {\n",
    "            \"liveness_route\": {\"port\": 5001, \"path\": \"/health\"},\n",
    "            \"readiness_route\": {\"port\": 5001, \"path\": \"/health\"},\n",
    "            \"scoring_route\": {\"port\": 5001, \"path\": \"/\"},\n",
    "        }),\n",
    "    environment_variables={\n",
    "        \"AZUREML_SERVING_ENTRYPOINT\": \"../src/sk/entry.sh\",\n",
    "        \"OPENAI_API_KEY\": f\"keyvaultref:{KEYVAULT_URL}/secrets/{KV_OPENAI_KEY}\",\n",
    "        \"OPENAI_API_TYPE\": OPENAI_API_TYPE,\n",
    "        \"OPENAI_MODEL_ID\": OPENAI_MODEL_ID,\n",
    "        \"OPENAI_ORG_ID\": OPENAI_ORG_ID,\n",
    "        \"AZURE_OPENAI_API_ENDPOINT\": AZURE_OPENAI_API_ENDPOINT,\n",
    "        \"AZURE_OPENAI_API_DEPLOYMENT_NAME\": AZURE_OPENAI_API_DEPLOYMENT_NAME,\n",
    "        \"IS_CHAT_COMPLETION\": True,\n",
    "    },\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    instance_type=\"Standard_F2s_v2\",\n",
    "    instance_count=1\n",
    ")\n",
    "ml_client.online_deployments.begin_create_or_update(sk_deployment).result()\n",
    "\n",
    "endpoint.traffic = {deployment_name: 100}\n",
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test\n",
    "Now endpoint has been deployed, let's test it. We are going to re-use the same request when we test it locally earlier on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "url_parts = urlsplit(endpoint.scoring_uri)\n",
    "url = url_parts.scheme + \"://\" + url_parts.netloc\n",
    "\n",
    "token = ml_client.online_endpoints.get_keys(name=online_endpoint_name).primary_key\n",
    "headers = {'Authorization': 'Bearer ' + token, 'Content-Type': 'application/json'}\n",
    "payload = json.dumps({\n",
    "  \"value\": \"Tomorrow is Valentine's day. I need to come up with a few date ideas. She speaks French so write it in French.\"\n",
    "})\n",
    "\n",
    "response = requests.post(f'{url}/planner/createplan', headers=headers, data=payload)\n",
    "print(f'Created Plan:\\n', response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = response.text\n",
    "response = requests.request(\"POST\", f'{url}/planner/executeplan', headers=headers, data=payload)\n",
    "print(f'Execution Result:\\n', response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
