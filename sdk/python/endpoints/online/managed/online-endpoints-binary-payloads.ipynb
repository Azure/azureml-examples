{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle binary payloads from a Managed Online Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, receiving and sending binary payloads in scoring scripts is demonstrated using the `rawhttp` decorator as well as the `AMLRequest` and `AMLResponse` objects. Without `rawhttp`, the run function is called passed the serialized JSON from the payload. Using `rawhttp`, the run function is instead passed an `AMLRequest` object, which wraps the native Flask request object used internally by the Azure Inference Server. After handling binary payloads, one can either return a JSON-serializable object as usual or use the `AMLResponse` object to have full control over the response, including returning binary payloads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites: \n",
    "* The following additional Python packages should be installed: \n",
    "    * [werkzeug](https://werkzeug.palletsprojects.com/en/2.2.x/) - Used in posting requests\n",
    "    \n",
    "Install the prerequisites with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install werkzeug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure parameters, assets, and clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set workspace details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace_name = \"<AML_WORKSPACE_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"6fe1c377-b645-4e8e-b588-52e57cc856b2\"\n",
    "resource_group = \"alwallace-rg\"\n",
    "workspace_name = \"alwallace\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set endpoint details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand = random.randint(0,10000)\n",
    "\n",
    "endpoint_name = f\"endpt-moe-bp-{rand}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set asset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_path = \"../../../../../cli/endpoints/online/managed/binary-payloads\"\n",
    "code_path = os.path.join(base_path, \"code\")\n",
    "conda_file_path = os.path.join(base_path, \"env.yml\")\n",
    "sample_peacock_path = os.path.join(base_path, \"peacock.jpg\")\n",
    "sample_pecock_resized_path = os.path.join(base_path, \"peacock-resized.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Download sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "url = 'https://aka.ms/peacock-pic'\n",
    "agent = f\"Python Requests/{requests.__version__} (https://github.com/Azure/azureml-examples)\"\n",
    "r = requests.get(url, headers={\"User-Agent\":agent}, allow_redirects=True)\n",
    "open(sample_peacock_path, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Create an MLClient Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    CodeConfiguration,\n",
    "    Environment\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(\n",
    "    credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define and create the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = ManagedOnlineEndpoint(name=endpoint_name)\n",
    "poller = ml_client.online_endpoints.begin_create_or_update(endpoint)\n",
    "poller.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Confirm that creation was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.exceptions import DeploymentException\n",
    "\n",
    "status = poller.status()\n",
    "if status != \"Succeeded\":\n",
    "    raise DeploymentException(status)\n",
    "else:\n",
    "    print(\"Endpoint creation succeeded\")\n",
    "    endpoint = poller.result()\n",
    "    print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a Binary-to-Binary Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Examine the scoring script\n",
    "This script receives an image as a binary file and returns a resized image as a binary file. Both scoring scripts use the `rawhttp` decorator to change the argument passed to the run function from JSON to the entire `AMLRequest` object. This script also uses the `AMLResponse` object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from azureml.contrib.services.aml_request import AMLRequest, rawhttp\n",
    "from azureml.contrib.services.aml_response import AMLResponse\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.image import MIMEImage\n",
    "from PIL import Image\n",
    "import io \n",
    "\n",
    "default_resize = (128, 128)\n",
    "\n",
    "def init(): \n",
    "    pass \n",
    "\n",
    "@rawhttp\n",
    "def run(req : AMLRequest):\n",
    "    try:\n",
    "        data = req.files.getlist(\"file\")[0]\n",
    "    except IndexError:\n",
    "        return AMLResponse(\"No file uploaded\", status_code=422)\n",
    "    \n",
    "    img = Image.open(data.stream)\n",
    "    img = img.resize(default_resize)\n",
    "\n",
    "    output = io.BytesIO()\n",
    "    img.save(output, format=\"JPEG\")\n",
    "    resp = AMLResponse(message = output.getvalue(), status_code=200)\n",
    "    resp.mimetype = \"image/jpg\"\n",
    "\n",
    "    return resp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"binarypayloads\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=Model(path=base_path),\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=code_path, \n",
    "        scoring_script=\"single-file-to-file-score.py\"\n",
    "    ),\n",
    "    environment=Environment(\n",
    "        conda_file=conda_file_path,\n",
    "        image=\"mcr.microsoft.com/azureml/minimal-ubuntu20.04-py38-cpu-inference:latest\",\n",
    "    ),\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1\n",
    ")\n",
    "poller = ml_client.online_deployments.begin_create_or_update(deployment)\n",
    "poller.wait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Confirm the creation was successful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = poller.status()\n",
    "if status != \"Succeeded\":\n",
    "    raise DeploymentException(status)\n",
    "else:\n",
    "    print(\"Endpoint creation succeeded\")\n",
    "    deployment = poller.result()\n",
    "    print(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Update endpoint traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.traffic = {\"binarypayloads\": 100}\n",
    "poller = ml_client.online_endpoints.begin_create_or_update(endpoint)\n",
    "poller.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Get endpoint details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_uri = endpoint.scoring_uri\n",
    "key = ml_client.online_endpoints.get_keys(endpoint_name).primary_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Send a request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from werkzeug.datastructures import MultiDict\n",
    "res = requests.post(\n",
    "    url=scoring_uri,\n",
    "    headers={\"Authorization\" : f\"Bearer {key}\"},\n",
    "    files=(('file', open(sample_peacock_path, 'rb')))\n",
    ")\n",
    "open(sample_pecock_resized_path, \"wb\").write(res.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a Binary-to-JSON Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Examine the scoring script\n",
    "This script accepts multiple image files uploaded as `file[]` and returns the sizes of the images as JSON. Both scoring scripts use the `rawhttp` decorator to change the argument passed to the run function from JSON to the entire `AMLRequest` object. However, unlike the first script this one returns a dictionary rather than an `AMLResponse` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from azureml.contrib.services.aml_request import AMLRequest, rawhttp\n",
    "from PIL import Image\n",
    "\n",
    "def init(): \n",
    "    pass \n",
    "\n",
    "@rawhttp\n",
    "def run(req : AMLRequest):\n",
    "    sizes = [{\"filename\" : f.filename,\n",
    "        \"size\" : Image.open(f.stream).size}\n",
    "        for f in req.files.getlist(\"file[]\")]\n",
    "\n",
    "    return {\"response\" : sizes}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Update the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"binarypayloads\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=Model(path=base_path),\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=code_path, \n",
    "        scoring_script=\"multi-file-to-json-score.py\"\n",
    "    ),\n",
    "    environment=Environment(\n",
    "        conda_file=conda_file_path,\n",
    "        image=\"mcr.microsoft.com/azureml/minimal-ubuntu20.04-py38-cpu-inference:latest\",\n",
    "    ),\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "poller = ml_client.online_deployments.begin_create_or_update(deployment)\n",
    "poller.wait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Confirm the update was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = poller.status()\n",
    "if status != \"Succeeded\":\n",
    "    raise DeploymentException(status)\n",
    "else:\n",
    "    print(\"Deployment creation succeeded\")\n",
    "    deployment = poller.result()\n",
    "    print(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Send a request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post(\n",
    "    url=scoring_uri,\n",
    "    headers={\"Authorization\" : f\"Bearer {key}\"},\n",
    "    files=(('file[]', open(sample_peacock_path, 'rb')),('file[]', open(sample_pecock_resized_path, 'rb')))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Delete assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_delete(\n",
    "    name=endpoint_name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('kv1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "023d9ae598c59591e0d290d91bc7dfa084141c23bf3f1e728ee3e9de1abddc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
