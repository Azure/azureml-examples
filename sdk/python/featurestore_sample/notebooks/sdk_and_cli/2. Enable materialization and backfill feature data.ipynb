{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Tutorial #2: Enable materialization and backfill feature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In this tutorial series you will experience how features seamlessly integrates all the phases of ML lifecycle: Prototyping features, training and operationalizing. \n",
    "\n",
    "In the part 1 of the tutorial you learnt how to create a feature set and use it to generate training data. When you query the featureset, the transformations will be applied on the source on-the-fly to compute the features before returning the values. This is fine for prototyping. However when you run training and inference in production environment, it is recommended that you materialize the features for higher reliability and availability. Materialization is the process of computing the feature values for a given feature window and storing this in an materialization store. All feature queries will now use the values from the materialization store.\n",
    "\n",
    "In this tutorial (part 2 of the series) you will:\n",
    "- Enable offline store on the feature store by creating and attaching an ADLS gen2 container and a user assigned managed identity\n",
    "- Enable offline materialization on the feature sets, and backfill the feature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Important\n",
    "\n",
    "This feature is currently in public preview. This preview version is provided without a service-level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Prerequsite\n",
    "1. Please ensure you have executed part 1 of the tutorial\n",
    "1. An Azure Resource group, in which you (or the service principal you use) need to have `User Access Administrator` role and `Contributor` role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Setup\n",
    "Summary of setup steps you will execute:\n",
    "- In your project workspace, create Azure ML compute to run training pipeline\n",
    "- In your feature store workspace, create a offline materialization store: create a Azure gen2 storage account and a container in it and attach to feature store. Optionally you can use existing storage container.\n",
    "- Create and assign user-assigned managed identity to feature store. Optionally you can use existing one. This will be used by the system managed materialization jobs i.e. recurrent job that will be used in part 3 of the tutorial\n",
    "- Grant required RBAC permissions to the user-assigned managed identity\n",
    "- Grant required RBAC to your AAD identity. Users (like you) need to have read access to (a) sources (b) materialization store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Configure Azure ML spark notebook\n",
    "\n",
    "1. Running the tutorial: You can either create a new notebook, and execute the instructions in this document step by step or open the existing notebook named `2. Enable materialization and backfill feature data.ipynb`, and run it. The notebooks are available in `featurestore_sample/notebooks` directory. You can select from `sdk_only` or `sdk_and_cli`. You may keep this document open and refer to it for additional explanation and documentation links.\n",
    "1. In the \"Compute\" dropdown in the top nav, select \"Serverless Spark Compute\". \n",
    "1. Click on \"configure session\" in top status bar -> click on \"Python packages\" -> click on \"upload conda file\" -> select the file azureml-examples/sdk/python/featurestore-sample/project/env/conda.yml from your local machine; Also increase the session time out (idle time) if you want to avoid running the prerequisites frequently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684207958655
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "start-spark-session",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print(\"started spark session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Setup root directory for the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684208510317
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "root-dir",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# please update the dir to ./Users/{your-alias} (or any custom directory you uploaded the samples to).\n",
    "# You can find the name from the directory structure inm the left nav\n",
    "root_dir = \"./Users/<your user alias>/featurestore_sample\"\n",
    "\n",
    "if os.path.isdir(root_dir):\n",
    "    print(\"The folder exists.\")\n",
    "else:\n",
    "    print(\"The folder does not exist. Please create or fix the path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### (new for sdk/cki track) Setup CLI\n",
    "\n",
    "1. Install azure ml cli extention\n",
    "1. Authenticate\n",
    "1. Set the default subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684208553099
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "install-ml-ext-cli",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Install azure ml cli extention\n",
    "!az extension add --name ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684208689961
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "auth-cli",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Authenticate\n",
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684208694751
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "set-default-subs-cli",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Set the default subscription\n",
    "import os\n",
    "\n",
    "subscription_id = os.environ[\"AZUREML_ARM_SUBSCRIPTION\"]\n",
    "\n",
    "!az account set -s $subscription_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### (new for sdk/cki track) Initialize the project workspace properties\n",
    "This is the current workspace where you will be running the tutorial notebook from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684197959399
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "init-ws-crud-client",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# lookup the subscription id, resource group and workspace name of the current workspace\n",
    "project_ws_sub_id = os.environ[\"AZUREML_ARM_SUBSCRIPTION\"]\n",
    "project_ws_rg = os.environ[\"AZUREML_ARM_RESOURCEGROUP\"]\n",
    "project_ws_name = os.environ[\"AZUREML_ARM_WORKSPACE_NAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### (new for sdk/cki track) Initialize the feature store properties\n",
    "Ensure you update the `featurestore_name` and `featurestore_location` to reflect what you created in part 1 of this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684208846587
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "init-fs-crud-client",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# use the same name from part #1 of the tutorial\n",
    "featurestore_name = \"my-featurestore\"\n",
    "# use the same location from part #1 of the tutorial\n",
    "featurestore_location = \"eastus\"\n",
    "# use the subscription of the project workspace by default\n",
    "featurestore_subscription_id = os.environ[\"AZUREML_ARM_SUBSCRIPTION\"]\n",
    "# use the resource group of the project workspace by default\n",
    "featurestore_resource_group_name = os.environ[\"AZUREML_ARM_RESOURCEGROUP\"]\n",
    "\n",
    "feature_store_arm_id = \"/subscriptions/{sub_id}/resourceGroups/{rg}/providers/Microsoft.MachineLearningServices/workspaces/{ws_name}\".format(\n",
    "    sub_id=featurestore_subscription_id,\n",
    "    rg=featurestore_resource_group_name,\n",
    "    ws_name=featurestore_name,\n",
    ")\n",
    "\n",
    "print(feature_store_arm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Initialize the feature store core sdk client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684197989748
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "init-fs-core-sdk",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# feature store client\n",
    "from azureml.featurestore import FeatureStoreClient\n",
    "from azure.ai.ml.identity import AzureMLOnBehalfOfCredential\n",
    "\n",
    "featurestore = FeatureStoreClient(\n",
    "    credential=AzureMLOnBehalfOfCredential(),\n",
    "    subscription_id=featurestore_subscription_id,\n",
    "    resource_group_name=featurestore_resource_group_name,\n",
    "    name=featurestore_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Setup offline materialization store\n",
    "You can create a new gen2 storage account and a container, or reuse existing one to be used as the offline materilization store for the feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note to docs team: \n",
    "The SDK only track has: `Setup utility functions` and the note below it (\"This code ...\"). This is not applicable in the CLI + SDK track, you can remove it in this track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Set values for the adls gen 2 storage that will be used as materialization store\n",
    "You can optionally override the default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198013967
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "set-offline-store-params",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "## Default Setting\n",
    "# We use the subscription, resource group, region of this active project workspace,\n",
    "# We hard-coded default resource names for creating new resources\n",
    "\n",
    "## Overwrite\n",
    "# You can replace them if you want to create the resources in a different subsciprtion/resourceGroup, or use existing resources\n",
    "\n",
    "storage_subscription_id = os.environ[\"AZUREML_ARM_SUBSCRIPTION\"]\n",
    "storage_resource_group_name = os.environ[\"AZUREML_ARM_RESOURCEGROUP\"]\n",
    "storage_account_name = \"fstorestorage\"\n",
    "# feature store location is used by default. You can change it.\n",
    "storage_location = featurestore_location\n",
    "storage_file_system_name = \"offlinestore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Storage container (option 1): create new storage and container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198050922
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "create-new-storage",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# create new storage account\n",
    "!az storage account create --name $storage_account_name --enable-hierarchical-namespace true --resource-group $storage_resource_group_name --location $storage_location --subscription $storage_subscription_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198081290
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "create-new-storage-container",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# create new storage container\n",
    "!az storage fs create --name $storage_file_system_name --account-name $storage_account_name --subscription $storage_subscription_id --auth-mode login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198089900
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "set-container-arm-id-cli",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# set the container arm id\n",
    "gen2_container_arm_id = \"/subscriptions/{sub_id}/resourceGroups/{rg}/providers/Microsoft.Storage/storageAccounts/{account}/blobServices/default/containers/{container}\".format(\n",
    "    sub_id=storage_subscription_id,\n",
    "    rg=storage_resource_group_name,\n",
    "    account=storage_account_name,\n",
    "    container=storage_file_system_name,\n",
    ")\n",
    "\n",
    "print(gen2_container_arm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Storage container (option 2): If you have an existing storage container that you want to reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198094208
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "use-existing-storage",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# set the container arm id\n",
    "gen2_container_arm_id = \"/subscriptions/{sub_id}/resourceGroups/{rg}/providers/Microsoft.Storage/storageAccounts/{account}/blobServices/default/containers/{container}\".format(\n",
    "    sub_id=storage_subscription_id,\n",
    "    rg=storage_resource_group_name,\n",
    "    account=storage_account_name,\n",
    "    container=storage_file_system_name,\n",
    ")\n",
    "\n",
    "print(gen2_container_arm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Setup user assigned managed identity (UAI)\n",
    "This will be used by the system managed materialization jobs i.e. recurrent job that will be used in part 3 of the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Set values for UAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198104193
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "set-uai-params",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# User assigned managed identity values. Optionally you may change the values.\n",
    "uai_subscription_id = os.environ[\"AZUREML_ARM_SUBSCRIPTION\"]\n",
    "uai_resource_group_name = os.environ[\"AZUREML_ARM_RESOURCEGROUP\"]\n",
    "uai_name = \"fstoreuai\"\n",
    "# feature store location is used by default. You can change it.\n",
    "uai_location = featurestore_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### User-assigned managed identity (option 1): create new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683418554848
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "create-new-uai",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!az identity create --subscription $uai_subscription_id --resource-group $uai_resource_group_name --location $uai_location --name $uai_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### User-assigned managed identity (option 2): If you have an existing one that you want to reuse\n",
    "Run `az identity show` to get the UAI information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683421366072
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "use-existing-uai",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!az identity show --resource-group $uai_resource_group_name --subscription $uai_subscription_id --name $uai_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Retrieve UAI properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198195891
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "retrieve-uai-properties",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.mgmt.msi import ManagedServiceIdentityClient\n",
    "from azure.mgmt.msi.models import Identity\n",
    "\n",
    "msi_client = ManagedServiceIdentityClient(\n",
    "    AzureMLOnBehalfOfCredential(), uai_subscription_id\n",
    ")\n",
    "managed_identity = msi_client.user_assigned_identities.get(\n",
    "    resource_name=uai_name, resource_group_name=uai_resource_group_name\n",
    ")\n",
    "\n",
    "uai_principal_id = managed_identity.principal_id\n",
    "uai_client_id = managed_identity.client_id\n",
    "uai_arm_id = managed_identity.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Grant RBAC permission to the user assigned managed identity (UAI)\n",
    "\n",
    "This UAI will be assigned to the feature store shortly. It requires the following permissions:\n",
    "\n",
    "|Scope|\tAction/Role|\n",
    "|--|--|\n",
    "|Feature store\t|AzureML Data Scientist role|\n",
    "|Storage account of feature store offline store\t|Blob storage data contributor role|\n",
    "|Storage accounts of source data\t|Blob storage data reader role|\n",
    "\n",
    "The below cli commands will assign the first two roles to the UAI. In this example \"Storage accounts of source data\" is not applicable since we are reading the sample data from a public access blob storage. If you have your own data sources then you want to assign the required roles to the UAI. To learn more about access control, see access control document in the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "grant-rbac-to-uai-fs",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!az role assignment create --role \"AzureML Data Scientist\" --assignee-object-id $uai_principal_id --assignee-principal-type ServicePrincipal --scope $feature_store_arm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "grant-rbac-to-uai-offline-store",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!az role assignment create --role \"Storage Blob Data Contributor\" --assignee-object-id $uai_principal_id --assignee-principal-type ServicePrincipal --scope $gen2_container_arm_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Grant your user account \"Blob data reader\" role on the offline store\n",
    "If feature data is materialized, then you need this role to read feature data from offline materialization store.\n",
    "\n",
    "Get your AAD object id from Azure portal following this instruction: https://learn.microsoft.com/en-us/partner-center/find-ids-and-domain-names#find-the-user-object-id\n",
    "\n",
    "To learn more about access control, see access control document in the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198291857
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "grant-rbac-to-user-identity",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# This utility function is created for ease of use in the docs tutorials. It uses standard azure API's. You can optionally inspect it `featurestore/setup/setup_storage_uai.py`\n",
    "your_aad_objectid = \"<your_aad_objectId>\"\n",
    "\n",
    "!az role assignment create --role \"Storage Blob Data Reader\" --assignee-object-id $your_aad_objectid --assignee-principal-type User --scope $gen2_container_arm_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 1: Enable offline store on the feature store by attaching offline materialization store and UAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(todo) (new for sdk+cli track)__ Action: inspect the file `xxxx`. The below command will update the feature store by attaching the offline store and UAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198312818
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "dump_featurestore_yaml",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# The below code creeates a feature stor\n",
    "import yaml\n",
    "\n",
    "config = {\n",
    "    \"$schema\": \"http://azureml/sdk-2-0/FeatureStore.json\",\n",
    "    \"name\": featurestore_name,\n",
    "    \"location\": featurestore_location,\n",
    "    \"compute_runtime\": {\"spark_runtime_version\": \"3.2\"},\n",
    "    \"offline_store\": {\"type\": \"azure_data_lake_gen2\", \"target\": gen2_container_arm_id},\n",
    "    \"materialization_identity\": {\"client_id\": uai_client_id, \"resource_id\": uai_arm_id},\n",
    "}\n",
    "\n",
    "feature_store_yaml = root_dir + \"/featurestore/featurestore_with_offline_setting.yaml\"\n",
    "\n",
    "with open(feature_store_yaml, \"w\") as outfile:\n",
    "    yaml.dump(config, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683421376728
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "name": "enable-offline-store",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!az ml feature-store update --file $feature_store_yaml --resource-group $featurestore_resource_group_name --name $featurestore_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 2: Enable offline materialization on transactions featureset\n",
    "Once materialization is enabled on a featureset, you can perform backfill (this tutorial) or schedule recurrent materialization jobs (next part of the tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(todo) (new for sdk+cli track)__ Action: inspect the file `xxxx`. The below command will update the transaction feature set to enable offline materilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198473486
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "enable-offline-mat-txns-fset",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "transaction_asset_mat_yaml = (\n",
    "    root_dir\n",
    "    + \"/featurestore/featuresets/transactions/featureset_asset_offline_enabled.yaml\"\n",
    ")\n",
    "\n",
    "!az ml feature-set update --file $transaction_asset_mat_yaml --resource-group $featurestore_resource_group_name --workspace-name $featurestore_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 3: Backfill data for transactions featureset\n",
    "As explained in the beginning of this tutorial, materialization is the process of computing the feature values for a given feature window and storing this in an materialization store. Materializing the features will increase its reliability and availability. All feature queries will now use the values from the materialization store. In this step you perform a one-time backfill for a feature window of __three months__.\n",
    "\n",
    "#### Note\n",
    "How to determine the window of backfill data needed? It has to match with the window of your training data. For e.g. if you want to train with two years of data, then you will want to be able to retrieve features for the same window, so you will backfill for a two year window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684208874891
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "backfill-txns-fset",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "feature_window_start_time = \"2023-01-01T00:00.000Z\"\n",
    "feature_window_end_time = \"2023-04-01T00:00.000Z\"\n",
    "\n",
    "!az ml feature-set backfill --name transactions --version 1 --workspace-name $featurestore_name --resource-group $featurestore_resource_group_name --feature-window-start-time $feature_window_start_time --feature-window-end-time $feature_window_end_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Lets print sample data from the featureset. You can notice from the output information that the data was retrieved from the materilization store. `get_offline_features()` method that is used to retrieve training/inference data will also use the materialization store by default ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1684198545115
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "sample-txns-fset-data",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# look up the featureset by providing name and version\n",
    "transactions_featureset = featurestore.feature_sets.get(\"transactions\", \"1\")\n",
    "display(transactions_featureset.to_spark_dataframe().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Cleanup\n",
    "Part 4 of the tutorial has instructions for deleting the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Next steps\n",
    "* Part 3 of tutorial: Experiment and train models using features"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
