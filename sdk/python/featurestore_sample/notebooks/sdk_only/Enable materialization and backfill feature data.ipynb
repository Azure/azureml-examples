{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Tutorial #2: Enable materialization and backfill feature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In this tutorial series you will experience how features seamlessly integrates all the phases of ML lifecycle: Prototyping features, training and operationalizing. \n",
    "\n",
    "In the part 1 of the tutorial you learnt how to create a feature set and use it to generate training data. When you query the featureset, the transformations will be applied on the source on-the-fly to compute the features before returning the values. This is fine for prototyping. However when you run training and inference in production environment, it is recommended that you materialize the features for higher reliability and availability. Materialization is the process of computing the feature values for a given feature window and storing this in an materialization store. All feature queries will now use the values from the materialization store.\n",
    "\n",
    "In this tutorial (part 2 of the series) you will:\n",
    "- Enable offline store on the feature store by creating and attaching an ADLS gen2 container and a user assigned managed identity\n",
    "- Enable offline materialization on the feature sets, and backfill the feature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Important\n",
    "\n",
    "This feature is currently in public preview. This preview version is provided without a service-level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Prerequsite\n",
    "1. Please ensure you have executed part 1 of the tutorial\n",
    "1. An Azure Resource group, in which you (or the service principal you use) need to have `User Access Administrator` role and `Contributor` role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Setup\n",
    "Summary of setup steps you will execute:\n",
    "- In your project workspace, create Azure ML compute to run training pipeline\n",
    "- In your feature store workspace, create a offline materialization store: create a Azure gen2 storage account and a container in it and attach to feature store. Optionally you can use existing storage container.\n",
    "- Create and assign user-assigned managed identity to feature store. Optionally you can use existing one. This will be used by the system managed materialization jobs i.e. recurrent job that will be used in part 3 of the tutorial\n",
    "- Grant required RBAC permissions to the user-assigned managed identity\n",
    "- Grant required RBAC to your AAD identity. Users (like you) need to have read access to (a) sources (b) materialization store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Configure Azure ML spark notebook\n",
    "\n",
    "1. In the \"Compute\" dropdown in the top nav, select \"Serverless Spark Compute\". \n",
    "1. Click on \"configure session\" in top status bar -> click on \"Python packages\" -> click on \"upload conda file\" -> select the file azureml-examples/sdk/python/featurestore-sample/project/env/conda.yml from your local machine; Also increase the session time out (idle time) if you want to avoid running the prerequisites frequently\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422232605
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "start-spark-session",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print(\"started spark session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Setup root directory for the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422281498
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "root-dir",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# please update the dir to ./Users/{your-alias} (or any custom directory you uploaded the samples to).\n",
    "# You can find the name from the directory structure inm the left nav\n",
    "root_dir = \"./Users/<your_user_alias>/featurestore_sample\"\n",
    "\n",
    "if os.path.isdir(root_dir):\n",
    "    print(\"The folder exists.\")\n",
    "else:\n",
    "    print(\"The folder does not exist. Please create or fix the path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Initialize the project workspace CRUD client\n",
    "This is the current workspace where you will be running the tutorial notebook from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422293418
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "init-ws-crud-client",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "### Initialize the MLClient of this project workspace\n",
    "import os\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.identity import AzureMLOnBehalfOfCredential\n",
    "\n",
    "project_ws_sub_id = os.environ[\"AZUREML_ARM_SUBSCRIPTION\"]\n",
    "project_ws_rg = os.environ[\"AZUREML_ARM_RESOURCEGROUP\"]\n",
    "project_ws_name = os.environ[\"AZUREML_ARM_WORKSPACE_NAME\"]\n",
    "\n",
    "# connect to the project workspace\n",
    "ws_client = MLClient(\n",
    "    AzureMLOnBehalfOfCredential(), project_ws_sub_id, project_ws_rg, project_ws_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Initialize the feature store CRUD client\n",
    "Ensure you update the `featurestore_name` to reflect what you created in part 1 of this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422298466
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "init-fs-crud-client",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.identity import AzureMLOnBehalfOfCredential\n",
    "\n",
    "# feature store\n",
    "featurestore_name = \"my-featurestore\"  # use the same name from part #1 of the tutorial\n",
    "featurestore_subscription_id = os.environ[\"AZUREML_ARM_SUBSCRIPTION\"]\n",
    "featurestore_resource_group_name = os.environ[\"AZUREML_ARM_RESOURCEGROUP\"]\n",
    "\n",
    "# feature store ml client\n",
    "fs_client = MLClient(\n",
    "    AzureMLOnBehalfOfCredential(),\n",
    "    featurestore_subscription_id,\n",
    "    featurestore_resource_group_name,\n",
    "    featurestore_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Initialize the feature store core sdk client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422304506
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "init-fs-core-sdk",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# feature store client\n",
    "from azureml.featurestore import FeatureStoreClient\n",
    "from azure.ai.ml.identity import AzureMLOnBehalfOfCredential\n",
    "\n",
    "featurestore = FeatureStoreClient(\n",
    "    credential=AzureMLOnBehalfOfCredential(),\n",
    "    subscription_id=featurestore_subscription_id,\n",
    "    resource_group_name=featurestore_resource_group_name,\n",
    "    name=featurestore_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Setup offline materialization store\n",
    "You can create a new gen2 storage account and a container, or reuse existing one to be used as the offline materilization store for the feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Setup utility functions\n",
    "Note: The below code  sets up utility functions to create storage and user assigned identity. These utility functions use standard azure SDKs. These are provided to keep the tutorial concise. However do not use this for production purposes as it might not implement best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422311529
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "setup-utility-fns",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, root_dir + \"/featurestore/setup\")\n",
    "from setup_storage_uai import (\n",
    "    create_gen2_storage_container,\n",
    "    create_user_assigned_managed_identity,\n",
    "    grant_rbac_permissions,\n",
    "    grant_user_aad_storage_data_reader_role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Set values for the adls gen 2 storage that will be used as materialization store\n",
    "You can optionally override the default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422350826
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "set-offline-store-params",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.identity import AzureMLOnBehalfOfCredential\n",
    "\n",
    "## Default Setting\n",
    "# We use the subscription, resource group, region of this active project workspace,\n",
    "# We hard-coded resource names for creating new resources\n",
    "\n",
    "## Overwrite\n",
    "# You can replace them if you want to create the resources in a different subsciprtion/resourceGroup, or use existing resources\n",
    "\n",
    "ws_location = ws_client.workspaces.get(ws_client.workspace_name).location\n",
    "\n",
    "# storage\n",
    "storage_subscription_id = os.environ[\"AZUREML_ARM_SUBSCRIPTION\"]\n",
    "storage_resource_group_name = os.environ[\"AZUREML_ARM_RESOURCEGROUP\"]\n",
    "storage_account_name = \"<FEATURE_STORAGE_ACCOUNT_NAME>\"\n",
    "storage_location = ws_location\n",
    "storage_file_system_name = \"offlinestore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Storage container (option 1): create new storage container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683418495136
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "create-new-storage",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "gen2_container_arm_id = create_gen2_storage_container(\n",
    "    AzureMLOnBehalfOfCredential(),\n",
    "    storage_subscription_id=storage_subscription_id,\n",
    "    storage_resource_group_name=storage_resource_group_name,\n",
    "    storage_account_name=storage_account_name,\n",
    "    storage_location=storage_location,\n",
    "    storage_file_system_name=storage_file_system_name,\n",
    ")\n",
    "\n",
    "print(gen2_container_arm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Storage container (option 2): If you have an existing storage container that you want to reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683421319637
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "use-existing-storage",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "gen2_container_arm_id = \"/subscriptions/{sub_id}/resourceGroups/{rg}/providers/Microsoft.Storage/storageAccounts/{account}/blobServices/default/containers/{container}\".format(\n",
    "    sub_id=storage_subscription_id,\n",
    "    rg=storage_resource_group_name,\n",
    "    account=storage_account_name,\n",
    "    container=storage_file_system_name,\n",
    ")\n",
    "\n",
    "print(gen2_container_arm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Setup user assigned managed identity (UAI)\n",
    "This will be used by the system managed materialization jobs i.e. recurrent job that will be used in part 3 of the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Set values for UAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683421358493
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "set-uai-params",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# User assigned managed identity values. Optionally you may change the values.\n",
    "uai_subscription_id = os.environ[\"AZUREML_ARM_SUBSCRIPTION\"]\n",
    "uai_resource_group_name = os.environ[\"AZUREML_ARM_RESOURCEGROUP\"]\n",
    "uai_name = \"fstoreuai\"\n",
    "uai_location = ws_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### User-assigned managed identity (option 1): create new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683418554848
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "create-new-uai",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "uai_principal_id, uai_client_id, uai_arm_id = create_user_assigned_managed_identity(\n",
    "    AzureMLOnBehalfOfCredential(),\n",
    "    uai_subscription_id=uai_subscription_id,\n",
    "    uai_resource_group_name=uai_resource_group_name,\n",
    "    uai_name=uai_name,\n",
    "    uai_location=uai_location,\n",
    ")\n",
    "\n",
    "print(\"uai_principal_id:\" + uai_principal_id)\n",
    "print(\"uai_client_id:\" + uai_client_id)\n",
    "print(\"uai_arm_id:\" + uai_arm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### User-assigned managed identity (option 2): If you have an existing one that you want to reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683421366072
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "use-existing-uai",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.mgmt.msi import ManagedServiceIdentityClient\n",
    "\n",
    "msi_client = ManagedServiceIdentityClient(\n",
    "    AzureMLOnBehalfOfCredential(), uai_subscription_id\n",
    ")\n",
    "\n",
    "managed_identity = msi_client.user_assigned_identities.get(\n",
    "    uai_resource_group_name, uai_name\n",
    ")\n",
    "\n",
    "uai_principal_id = managed_identity.principal_id\n",
    "uai_client_id = managed_identity.client_id\n",
    "uai_arm_id = managed_identity.id\n",
    "\n",
    "print(\"uai_principal_id:\" + uai_principal_id)\n",
    "print(\"uai_client_id:\" + uai_client_id)\n",
    "print(\"uai_arm_id:\" + uai_arm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Grant RBAC permission to the user assigned managed identity (UAI)\n",
    "\n",
    "This UAI will be assigned to the feature store shortly. It requires the following permissions:\n",
    "\n",
    "|Scope|\tAction/Role|\n",
    "|--|--|\n",
    "|Feature store\t|AzureML Data Scientist role|\n",
    "|Storage account of feature store offline store\t|Blob storage data contributor role|\n",
    "|Storage accounts of source data\t|Blob storage data reader role|\n",
    "\n",
    "The below code utility function will assign the first two roles to the UAI. In this example \"Storage accounts of source data\" is not applicable since we are reading the sample data from a public access blob storage. If you have your own data sources then you want to assign the required roles to the UAI. To learn more about access control, see access control document in the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683418605920
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "grant-rbac-to-uai",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# This utility function is created for ease of use in the docs tutorials. It uses standard azure API's. You can optionally inspect it `featurestore/setup/setup_storage_uai.py`\n",
    "grant_rbac_permissions(\n",
    "    AzureMLOnBehalfOfCredential(),\n",
    "    uai_principal_id,\n",
    "    storage_subscription_id=storage_subscription_id,\n",
    "    storage_resource_group_name=storage_resource_group_name,\n",
    "    storage_account_name=storage_account_name,\n",
    "    featurestore_subscription_id=featurestore_subscription_id,\n",
    "    featurestore_resource_group_name=featurestore_resource_group_name,\n",
    "    featurestore_name=featurestore_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Grant your user account \"Blob data reader\" role on the offline store\n",
    "If feature data is materialized, then you need this role to read feature data from offline materialization store.\n",
    "\n",
    "Get your AAD object id from Azure portal following this instruction: https://learn.microsoft.com/en-us/partner-center/find-ids-and-domain-names#find-the-user-object-id\n",
    "\n",
    "To learn more about access control, see access control document in the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683126235070
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "grant-rbac-to-user-identity",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# This utility function is created for ease of use in the docs tutorials. It uses standard azure API's. You can optionally inspect it `featurestore/setup/setup_storage_uai.py`\n",
    "your_aad_objectid = \"<USER_AAD_OBJECTID>\"\n",
    "\n",
    "grant_user_aad_storage_data_reader_role(\n",
    "    AzureMLOnBehalfOfCredential(),\n",
    "    your_aad_objectid,\n",
    "    storage_subscription_id,\n",
    "    storage_resource_group_name,\n",
    "    storage_account_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 1: Enable offline store on the feature store by attaching offline materialization store and UAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683421376728
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "name": "enable-offline-store",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedIdentityConfiguration,\n",
    "    FeatureStore,\n",
    "    MaterializationStore,\n",
    ")\n",
    "\n",
    "offline_store = MaterializationStore(\n",
    "    type=\"azure_data_lake_gen2\",\n",
    "    target=gen2_container_arm_id,\n",
    ")\n",
    "\n",
    "materialization_identity1 = ManagedIdentityConfiguration(\n",
    "    client_id=uai_client_id, principal_id=uai_principal_id, resource_id=uai_arm_id\n",
    ")\n",
    "\n",
    "fs = FeatureStore(\n",
    "    name=featurestore_name,\n",
    "    offline_store=offline_store,\n",
    "    materialization_identity=materialization_identity1,\n",
    ")\n",
    "\n",
    "fs_poller = fs_client.feature_stores.begin_update(fs, update_dependent_resources=True)\n",
    "\n",
    "print(fs_poller.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 2: Enable offline materialization on transactions featureset\n",
    "Once materialization is enabled on a featureset, you can perform backfill (this tutorial) or schedule recurrent materialization jobs(next part of the tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422398454
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "enable-offline-mat-txns-fset",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    MaterializationSettings,\n",
    "    MaterializationComputeResource,\n",
    ")\n",
    "\n",
    "transactions_fset_config = fs_client._featuresets.get(name=\"transactions\", version=\"1\")\n",
    "\n",
    "transactions_fset_config.materialization_settings = MaterializationSettings(\n",
    "    offline_enabled=True,\n",
    "    resource=MaterializationComputeResource(instance_type=\"standard_e8s_v3\"),\n",
    "    spark_configuration={\n",
    "        \"spark.driver.cores\": 4,\n",
    "        \"spark.driver.memory\": \"36g\",\n",
    "        \"spark.executor.cores\": 4,\n",
    "        \"spark.executor.memory\": \"36g\",\n",
    "        \"spark.executor.instances\": 2,\n",
    "    },\n",
    "    schedule=None,\n",
    ")\n",
    "\n",
    "fs_poller = fs_client.feature_sets.begin_create_or_update(transactions_fset_config)\n",
    "print(fs_poller.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Optionally, you can save the the above feature set asset as yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422407359
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "dump-txn-fset-yaml",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "## uncomment to run\n",
    "# transactions_fset_config.dump(root_dir + \"/featurestore/featuresets/transactions/featureset_asset_offline_enabled.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 3: Backfill data for transactions featureset\n",
    "As explained in the beginning of this tutorial, materialization is the process of computing the feature values for a given feature window and storing this in an materialization store. Materializing the features will increase its reliability and availability. All feature queries will now use the values from the materialization store. In this step you perform a one-time backfill for a feature window of __three months__.\n",
    "\n",
    "#### Note\n",
    "How to determine the window of backfill data needed? It has to match with the window of your training data. For e.g. if you want to train with two years of data, then you will want to be able to retrieve features for the same window, so you will backfill for a two year window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422440549
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "name": "backfill-txns-fset",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "st = datetime(2023, 1, 1, 0, 0, 0, 0)\n",
    "ed = datetime(2023, 4, 1, 0, 0, 0, 0)\n",
    "\n",
    "poller = fs_client.feature_sets.begin_backfill(\n",
    "    name=\"transactions\",\n",
    "    version=\"1\",\n",
    "    feature_window_start_time=st,\n",
    "    feature_window_end_time=ed,\n",
    ")\n",
    "print(poller.result().job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the job URL, and stream the job logs\n",
    "fs_client.jobs.stream(poller.result().job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Lets print sample data from the featureset. You can notice from the output information that the data was retrieved from the materilization store. `get_offline_features()` method that is used to retrieve training/inference data will also use the materialization store by default ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1683422850258
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "sample-txns-fset-data",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# look up the featureset by providing name and version\n",
    "transactions_featureset = featurestore.feature_sets.get(\"transactions\", \"1\")\n",
    "display(transactions_featureset.to_spark_dataframe().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Cleanup\n",
    "Part 4 of the tutorial has instructions for deleting the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Next steps\n",
    "* Part 3 of tutorial: Experiment and train models using features"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
