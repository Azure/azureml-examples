{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml\n",
    "%pip install -U 'azureml-rag[faiss]>=0.1.11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038912d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If `import win32file` fails with a DLL error then run the following and restart kernel:\n",
    "# %pip uninstall -y pywin32\n",
    "# %conda install -y --force-reinstall pywin32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b26c69",
   "metadata": {},
   "source": [
    "# Create a FAISS based Vector Index for DBCopilot with AzureML\n",
    "We'll walk through setting up an AzureML Pipeline which grounding a DataBase into a LangChain-compatible FAISS Vector Index and create the promptflow to consume this index to serve as a DBCopilot chatbot."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a99955c",
   "metadata": {},
   "source": [
    "## Get client for AzureML Workspace\n",
    "\n",
    "The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "Enter your Workspace details below, running this still will write a `workspace.json` file to the current folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63178816",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile workspace.json\n",
    "{\n",
    "    \"subscription_id\": \"<subscription_id>\",\n",
    "    \"resource_group\": \"<resource_group_name>\",\n",
    "    \"workspace_name\": \"<workspace_name>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb5c8f0",
   "metadata": {},
   "source": [
    "`MLClient` is how you interact with AzureML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azureml.core import Workspace\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential=credential, path=\"workspace.json\")\n",
    "except Exception as ex:\n",
    "    raise Exception(\n",
    "        \"Failed to create MLClient from config file. Please modify and then run the above cell with your AzureML Workspace details.\"\n",
    "    ) from ex\n",
    "\n",
    "ws = Workspace(\n",
    "    subscription_id=ml_client.subscription_id,\n",
    "    resource_group=ml_client.resource_group_name,\n",
    "    workspace_name=ml_client.workspace_name,\n",
    ")\n",
    "print(ml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade6080e",
   "metadata": {},
   "source": [
    "## Create a Datastore\n",
    "1. Go to workspace in Azure Portal\n",
    "2. Click **Data** -> **Datastore** -> **+ Create**\n",
    "3. Fill in the datastore form\n",
    "\n",
    "\n",
    "### SQL Server Datastore\n",
    "| Field | Value |\n",
    "| --- | --- |\n",
    "| Datastore name | the name for the datastore |\n",
    "| Datastore type | Azure SQL Database |\n",
    "| Account information| could be found in the Azure SQL Database overview page |\n",
    "| Authentication type | SQL Authentication/ Service principal |\n",
    "| Authentication info | SQL Authentication: username and password; Service principal: tenant id, client id, client secret |\n",
    "### Kusto / Cosmos / ClickHouse Datastore\n",
    "| Field | Value |\n",
    "| --- | --- |\n",
    "| Datastore name | the name for the datastore |\n",
    "| Datastore type | Custom(preview) |\n",
    "| Custom Datastore type | could fill in the custom type |\n",
    "| Credential value | Datastore credential, an optional field that can be updated later.<br>Value will be stored securely in Azure Key Vault |\n",
    "| Properties |Add any additional properties required for this datastore |\n",
    "##### Additional properties required by Kusto / Cosmos / ClickHouse\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td> \n",
    "        <td colspan=\"2\"><b>Kusto</b></td> \n",
    "        <td colspan=\"2\"><b>ClickHouse</b></td> \n",
    "        <td colspan=\"2\"><b>Cosmos</b></td> \n",
    "   </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"6\"><b>Required</b> <br/><b>properties</b></td>     \n",
    "         <td>Property</td> \n",
    "      \t <td>Value</td> \n",
    "         <td>Property</td> \n",
    "      \t <td>Value</td> \n",
    "         <td>Property</td> \n",
    "      \t <td>Value</td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>connection</td> \n",
    "        <td>connect to external data sources for training</td>\n",
    "        <td>host</td>\n",
    "        <td>host name or IP address of the ClickHouse database server</td>\n",
    "        <td>url</td>\n",
    "        <td>url of Azure Cosmos DB services</td>      \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>connection_string</td> \n",
    "        <td>the string that contains the information needed to connect <br>to an external data source for training</td>\n",
    "        <td>user</td>\n",
    "        <td>user name used to authenticate the database user for the connection</td>\n",
    "        <td>key</td>\n",
    "        <td> access key used for authorizing access and operations to <br>an Azure Cosmos DB account</td>      \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>database</td> \n",
    "        <td>database name</td>\n",
    "        <td>port</td>\n",
    "        <td>The port on which the ClickHouse server listens. By default, ClickHouse <br>uses port number 8123 as the client connection port</td>\n",
    "        <td>container</td>\n",
    "        <td>logical unit used to organize and store documents</td>      \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>tenant_id</td> \n",
    "        <td>unique identifier for your Azure Active Directory tenant</td>\n",
    "        <td>password</td>\n",
    "        <td>secret string that the user uses to verify their identity</td>\n",
    "        <td>database</td>\n",
    "        <td>database name</td>      \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>client_id</td> \n",
    "        <td>the identifier for a managed identity that is used to retrieve <br>a credential for accessing resources within the code for a <br>submitted job</td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>      \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b906d",
   "metadata": {},
   "source": [
    "Use the datastore you created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c25d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = \"<test_db_datastore_name>\"\n",
    "db_datastore_uri = f\"azureml://datastores/{datastore_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e953ac19",
   "metadata": {},
   "source": [
    "## Create a Data assets\n",
    "1. Go to workspace in Azure Portal\n",
    "2. Click **Data** -> **Data assets** -> **+ Create**\n",
    "3. Fill in the Data assets form\n",
    "### SQLite/Sheet Data assets\n",
    "| Field | Value |\n",
    "| --- | --- |\n",
    "| Data assets name | the name for the Data assets |\n",
    "| Data assets type | File(uri_file) / Folder(uri_folder) |\n",
    "| Data source | From a URI / From Azure storage / From local files |\n",
    "\n",
    "##### Different data source, Different parameters\n",
    "<table>\n",
    "    <tr> \n",
    "        <td colspan=\"2\"><b>From a URL</b></td> \n",
    "        <td colspan=\"2\"><b>From Azure storage</b></td> \n",
    "        <td colspan=\"2\"><b>From local</b></td> \n",
    "   </tr>\n",
    "    <tr>     \n",
    "         <td>Field</td> \n",
    "      \t <td>Value</td> \n",
    "         <td>Field</td> \n",
    "      \t <td>Value</td> \n",
    "         <td>Field</td> \n",
    "      \t <td>Value</td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>URI</td>\n",
    "        <td>path parameter that points to the data location. Three formats are supported: <br>1. A path on a public http(s) server <br>2. A path on Azure storage<br>3. A path on a datastore</td>\n",
    "        <td>Source storage type</td>\n",
    "        <td>Azure Blob Storage / Azure file share / Azure Data Lake Storage Gen1 /<br> Azure Data Lake Storage Gen2</td>\n",
    "        <td>Destination storage type</td> \n",
    "        <td>Azure Blob Storage / Azure Data Lake Storage Gen2</td>     \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td>Storage path</td>\n",
    "        <td>storage path you want to use for this data asset</td>\n",
    "        <td>File selection</td>\n",
    "        <td>Upload file</td>     \n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e055e2",
   "metadata": {},
   "source": [
    "<H3>Example for Tabular Data</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install -U mltable azureml-dataprep[pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b23be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test.csv\n",
    "id,text\n",
    "0,Hello world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7348ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import mltable\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "tbl = mltable.from_delimited_files([{\"file\": \"test.csv\"}])\n",
    "# Convert tabular data to sqlite db\n",
    "df = tbl.to_pandas_dataframe()\n",
    "conn = sqlite3.connect(\"test.db\")\n",
    "df.to_sql(\"test_table\", conn, if_exists=\"replace\")\n",
    "conn.close()\n",
    "# Upload sqlite db to AzureML\n",
    "my_data = Data(\n",
    "    name=\"test_db\",\n",
    "    description=\"test db\",\n",
    "    version=\"1\",\n",
    "    path=\"test.db\",\n",
    "    type=AssetTypes.URI_FILE,\n",
    ")\n",
    "my_data = ml_client.data.create_or_update(my_data)\n",
    "print(f\"Data asset created. Name: {my_data.name}, version: {my_data.version}\")\n",
    "db_datastore_uri = my_data.path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30906d39",
   "metadata": {},
   "source": [
    "## Azure OpenAI\n",
    "\n",
    "We recommend using gpt-35-turbo model to get good quality QAs. [Follow these instructions](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) to setup an Azure OpenAI Instance and deploy the model. Once you have the model deployed in AOAI you can specify your Model name and Deployment name below.\n",
    "\n",
    "We will use the automatically created `Default_AzureOpenAI` connection, change `aoai_connection_name` to use your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_connection_name = \"Default_AzureOpenAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ac0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.rag.utils.connections import (\n",
    "    get_connection_by_name_v2,\n",
    "    create_connection_v2,\n",
    ")\n",
    "\n",
    "try:\n",
    "    aoai_connection = get_connection_by_name_v2(ws, aoai_connection_name)\n",
    "except Exception as ex:\n",
    "    # Create New Connection\n",
    "    # Modify the details below to match the `Endpoint` and API key of your AOAI resource, these details can be found in Azure Portal\n",
    "    raise RuntimeError(\n",
    "        \"Have you entered your AOAI resource details below? If so, delete me!\"\n",
    "    )\n",
    "    aoai_connection = create_connection_v2(\n",
    "        workspace=ws,\n",
    "        name=aoai_connection,\n",
    "        category=\"AzureOpenAI\",\n",
    "        # 'Endpoint' from Azure OpenAI resource overview\n",
    "        target=\"https://<endpoint_name>.openai.azure.com/\",\n",
    "        auth_type=\"ApiKey\",\n",
    "        credentials={\n",
    "            # Either `Key` from the `Keys and Endpoint` tab of your Azure OpenAI resource, will be stored in your Workspace associated Azure Key Vault.\n",
    "            \"key\": \"<api-key>\"\n",
    "        },\n",
    "        metadata={\"ApiType\": \"azure\", \"ApiVersion\": \"2023-05-15\"},\n",
    "    )\n",
    "\n",
    "aoai_connection_id = aoai_connection[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c4ece4",
   "metadata": {},
   "source": [
    "Now that your Workspace has a connection to Azure OpenAI we will make sure the `gpt-35-turbo` model has been deployed ready for inference. This cell will fail if there is not deployment for the embeddings model, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a model with Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.rag.utils.deployment import infer_deployment\n",
    "\n",
    "aoai_embedding_model_name = \"text-embedding-ada-002\"\n",
    "try:\n",
    "    aoai_embedding_deployment_name = infer_deployment(\n",
    "        aoai_connection, aoai_embedding_model_name\n",
    "    )\n",
    "    print(\n",
    "        f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is '{aoai_embedding_deployment_name}'\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Deployment name in AOAI workspace for model '{model_name}' is not found.\")\n",
    "    print(\n",
    "        f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e5cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.rag.utils.deployment import infer_deployment\n",
    "\n",
    "aoai_completion_model_name = \"gpt-35-turbo\"\n",
    "\n",
    "try:\n",
    "    aoai_completion_deployment_name = infer_deployment(\n",
    "        aoai_connection, aoai_completion_model_name\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"Deployment name in AOAI workspace for model '{aoai_completion_model_name}' is not found.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Deployment name in AOAI workspace for model '{aoai_completion_model_name}' is '{aoai_completion_deployment_name}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40ff04",
   "metadata": {},
   "source": [
    "Finally we will combine the deployment and model information into a uri form which the AzureML embeddings components expect as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_completion_config = f'{{\"type\":\"azure_open_ai\",\"model_name\":\"{aoai_completion_model_name}\",\"deployment_name\":\"{aoai_completion_deployment_name}\",\"temperature\":0,\"max_tokens\":\"1500\"}}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56878876",
   "metadata": {},
   "source": [
    "### Setup Pipeline\n",
    "\n",
    "The Components are published to a [Registry](https://learn.microsoft.com/azure/machine-learning/how-to-manage-registries?view=azureml-api-2&tabs=cli), `azureml`, which should have access to by default, it can be accessed from any Workspace.\n",
    "In the below cell we get the Component Definitions from the `azureml` registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a3752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_registry = MLClient(credential=credential, registry_name=\"azureml\")\n",
    "\n",
    "db_copilot_component = ml_registry.components.get(\n",
    "    \"llm_ingest_db_to_faiss\", label=\"latest\"\n",
    ")\n",
    "\n",
    "print(db_copilot_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209700d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "\n",
    "\n",
    "@pipeline(name=f\"db_copilot_vector_pipeline_faiss\", default_compute=\"serverless\")\n",
    "def db_copilot_vector_pipeline_faiss(\n",
    "    aoai_connection: str,\n",
    "    db_datastore: str,\n",
    "    embeddings_model: str,\n",
    "    chat_aoai_deployment_name: str,\n",
    "    embedding_aoai_deployment_name: str,\n",
    "    mlindex_dataset_name: str,\n",
    "    selected_tables: str = None,\n",
    "    max_sampling_rows: int = 3,\n",
    "):\n",
    "    db_copilot_component(\n",
    "        db_datastore=db_datastore,\n",
    "        embeddings_model=embeddings_model,\n",
    "        chat_aoai_deployment_name=chat_aoai_deployment_name,\n",
    "        embedding_aoai_deployment_name=embedding_aoai_deployment_name,\n",
    "        embeddings_dataset_name=mlindex_dataset_name,\n",
    "        embedding_connection=aoai_connection,\n",
    "        llm_connection=aoai_connection,\n",
    "        selected_tables=selected_tables,\n",
    "        max_sampling_rows=max_sampling_rows,\n",
    "    )\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6682ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = \"<test_db_datastore_name>\"\n",
    "aoai_embedding_model_name = \"text-embedding-ada-002\"\n",
    "asset_name = \"llm_index_db_dataset\"\n",
    "pipeline_job = db_copilot_vector_pipeline_faiss(\n",
    "    aoai_connection=aoai_connection_id,\n",
    "    db_datastore=f\"azureml://datastores/{datastore_name}\",\n",
    "    embeddings_model=f\"azure_open_ai://deployment/{aoai_embedding_deployment_name}/model/{aoai_completion_model_name}\",\n",
    "    chat_aoai_deployment_name=aoai_completion_deployment_name,\n",
    "    embedding_aoai_deployment_name=aoai_embedding_deployment_name,\n",
    "    mlindex_dataset_name=asset_name,\n",
    "    selected_tables='[\"[dbo].[jobs]\"]',\n",
    "    max_sampling_rows=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are added so that in progress index generations can be listed in UI, this tagging is done automatically by UI.\n",
    "pipeline_job.properties[\"azureml.mlIndexAssetName\"] = asset_name\n",
    "pipeline_job.properties[\"azureml.mlIndexAssetKind\"] = \"faiss\"\n",
    "pipeline_job.properties[\"azureml.mlIndexAssetSource\"] = \"Database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"db_copilot_pipeline\"\n",
    ")\n",
    "running_pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.stream(running_pipeline_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098fccd",
   "metadata": {},
   "source": [
    "## Use DBCopilot with Promptflow\n",
    "After the pipeline complete, it will create a promptflow which could be used to chat with the db."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to MIR Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Endpoint\n",
    "\n",
    "1. **Go to the Workspace**: Log in to the Azure Portal and navigate to your Azure Machine Learning workspace.\n",
    "\n",
    "2. **Access Endpoints**: In the left-hand menu, find and click on \"Endpoints\".\n",
    "\n",
    "3. **Create Real-time Endpoint**: In the Endpoints page, click on \"Real-time endpoints\", then click on \"+ Create\".\n",
    "\n",
    "4. **Select a Model**: In the create endpoint form, you need to select a registered model. If you have not registered a model yet, you will need to do this in the \"Models\" page first.\n",
    "\n",
    "5. **Fill in the Endpoint Form**: In the form, you need to provide the following information:\n",
    "   1. **Select Endpoint**: An endpoint is used to deploy and score your models. From the Azure Portal, navigate to your Azure Machine Learning workspace and select \"Endpoints\" from the sidebar.\n",
    "\n",
    "   2. **Endpoint Details**:\n",
    "      - **Endpoint Name**: Provide a unique identifier for your endpoint.\n",
    "      - **Description**: Write a brief note about the endpoint's purpose.\n",
    "      - **Compute Type**: Select the type of compute the endpoint will run on.\n",
    "      - **Authentication Type**: Choose the type of authentication for the endpoint (Key-based or Token-based).\n",
    "      - **Endpoint Tags**: Add tags to your endpoint for better organization and identification of your resources.\n",
    "\n",
    "   3. **Deployment**:\n",
    "      - **Deployment Name**: Provide a name for your deployment.\n",
    "      - **Scoring Timeout (seconds)**: Specify the timeout for scoring in seconds.\n",
    "\n",
    "   4. **Code and Environment for Inferencing**: For the selected model, you need to provide at least one scoring Python script and an environment. \n",
    "      - **Select a Scoring Script for Inferencing**: Choose the Python script that will be used for scoring.\n",
    "      - **Optional Script(s)**: If you have any additional scripts, add them here.\n",
    "      - **Select an Environment for Inferencing**: Choose the environment that will be used for scoring.\n",
    "\n",
    "   5. **Compute**\n",
    "      - **Virtual Machine**: Select the type of virtual machine. For example, \"Standard_DS3_v2\" which includes 4 Cores, 14 GB RAM, 28 GB Disk, and costs \\$0.29/hr.\n",
    "      - **Instance Count**: Specify the number of instances for your deployment.\n",
    "\n",
    "   6. **Live Traffic**: Ensure that the allocated live traffic between all deployments adds up to either 0% or 100%.\n",
    "\n",
    "After filling in all the necessary information, click on the \"Create\" button. Azure ML will begin creating your endpoint, and you can monitor the progress on the Endpoints page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy to your Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Components are published to a [Registry](https://learn.microsoft.com/azure/machine-learning/how-to-manage-registries?view=azureml-api-2&tabs=cli), `azureml`, which should have access to by default, it can be accessed from any Workspace.\n",
    "In the below cell we get the Component Definitions from the `azureml` registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_registry = MLClient(credential=credential, registry_name=\"azureml\")\n",
    "\n",
    "db_copilot_component = ml_registry.components.get(\n",
    "    \"llm_ingest_dbcopilot_faiss_e2e\", label=\"latest\"\n",
    ")\n",
    "\n",
    "print(db_copilot_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    name=f\"test_db_copilot_e2e_pipeline_faiss_{component_version}\",\n",
    "    version=component_version,\n",
    ")\n",
    "def db_copilot_e2e_pipeline_faiss(\n",
    "    aoai_connection: str,\n",
    "    db_datastore: str,\n",
    "    embeddings_model: str,\n",
    "    chat_aoai_deployment_name: str,\n",
    "    embedding_aoai_deployment_name: str,\n",
    "    mir_environment: str,\n",
    "    endpoint_name: str,\n",
    "    sample_data: Input = None,\n",
    "    deployment_name: str = \"blue\",\n",
    "    selected_tables: str = None,\n",
    "    max_sampling_rows: int = 3,\n",
    "    tools: str = None,\n",
    "):\n",
    "    db_copilot_component(\n",
    "        db_datastore=db_datastore,\n",
    "        embeddings_model=embeddings_model,\n",
    "        chat_aoai_deployment_name=chat_aoai_deployment_name,\n",
    "        embedding_aoai_deployment_name=embedding_aoai_deployment_name,\n",
    "        embedding_connection=aoai_connection,\n",
    "        llm_connection=aoai_connection,\n",
    "        sample_data=sample_data,\n",
    "        endpoint_name=endpoint_name,\n",
    "        deployment_name=deployment_name,\n",
    "        mir_environment=mir_environment,\n",
    "        selected_tables=selected_tables,\n",
    "        max_sampling_rows=max_sampling_rows,\n",
    "        tools=tools,\n",
    "    )\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = \"<test_db_datastore_name>\"\n",
    "aoai_embedding_model_name = \"text-embedding-ada-002\"\n",
    "deployment_name = f\"{deployment_name}-faiss\"\n",
    "mir_environment = (\n",
    "    \"azureml://registries/registry-name/environments/llm-dbcopilot-mir/versions/\"\n",
    ")\n",
    "endpoint_name = \"dbcopilot-mir\"\n",
    "sample_data = Input(type=\"uri_folder\", path=example_data.path)\n",
    "pipeline_job = db_copilot_e2e_pipeline_faiss(\n",
    "    aoai_connection=aoai_connection_id,\n",
    "    db_datastore=f\"azureml://datastores/{datastore_name}\",\n",
    "    embeddings_model=f\"azure_open_ai://deployment/{aoai_embedding_deployment_name}/model/{aoai_completion_model_name}\",\n",
    "    chat_aoai_deployment_name=aoai_completion_deployment_name,\n",
    "    embedding_aoai_deployment_name=aoai_embedding_deployment_name,\n",
    "    mir_environment=mir_environment,\n",
    "    endpoint_name=endpoint_name,\n",
    "    sample_data=sample_data,\n",
    "    deployment_name=deployment_name,\n",
    "    selected_tables='[\"[dbo].[jobs]\"]',\n",
    "    max_sampling_rows=3,\n",
    "    tools=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"db_copilot_pipeline\"\n",
    ")\n",
    "running_pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.stream(running_pipeline_job.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}