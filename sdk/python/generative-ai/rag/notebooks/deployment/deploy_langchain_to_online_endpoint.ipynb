{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml\n",
    "%pip install azureml-rag[hugging_face]\n",
    "# mlflow==2.5.0 added support for RetrievalQA in mlflow.langchain\n",
    "%pip install mlflow>=2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\smamgain\\msft\\azureml-examples\\sdk\\python\\generative-ai\\rag\\notebooks\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x0000021FDEC551B0>,\n",
      "         subscription_id=381b38e9-9840-4719-a5a0-61d9585e1e91,\n",
      "         resource_group_name=smamgain-rg,\n",
      "         workspace_name=smamgain-eastus-ws)\n",
      "Workspace.create(name='smamgain-eastus-ws', subscription_id='381b38e9-9840-4719-a5a0-61d9585e1e91', resource_group='smamgain-rg')\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azureml.core import Workspace\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
    "print(ml_client)\n",
    "\n",
    "ws = Workspace(\n",
    "    subscription_id=ml_client.subscription_id,\n",
    "    resource_group=ml_client.resource_group_name,\n",
    "    workspace_name=ml_client.workspace_name,\n",
    ")\n",
    "print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_connection_name = \"azure-openai-creds\"  # TODO(shivam)\n",
    "aoai_connection_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.rag.utils.connections import (\n",
    "    get_connection_by_name_v2,\n",
    "    create_connection_v2,\n",
    ")\n",
    "\n",
    "try:\n",
    "    aoai_connection = get_connection_by_name_v2(ws, aoai_connection_name)\n",
    "except Exception as ex:\n",
    "    # Create New Connection\n",
    "    # Modify the details below to match the `Endpoint` and API key of your AOAI resource, these details can be found in Azure Portal\n",
    "    raise RuntimeError(\n",
    "        \"Have you entered your AOAI resource details below? If so, delete me!\"\n",
    "    )\n",
    "    target = \"<target>\"  # example: 'https://<endpoint>.openai.azure.com/'\n",
    "    key = \"<key>\"\n",
    "    apiVersion = \"2023-03-15-preview\"\n",
    "    if key == \"<key>\":\n",
    "        raise RuntimeError(f\"Please provide a valid key for the Azure OpenAI service\")\n",
    "    if target == \"<target>\":\n",
    "        raise RuntimeError(\n",
    "            f\"Please provide a valid target for the Azure OpenAI service\"\n",
    "        )\n",
    "    if apiVersion == \"<api_version>\":\n",
    "        raise RuntimeError(\n",
    "            f\"Please provide a valid api-version for the Azure OpenAI service\"\n",
    "        )\n",
    "    aoai_connection_id = create_connection_v2(\n",
    "        workspace=ws,\n",
    "        name=aoai_connection_name,\n",
    "        category=\"AzureOpenAI\",\n",
    "        target=target,\n",
    "        auth_type=\"ApiKey\",\n",
    "        credentials={\"key\": key},\n",
    "        metadata={\"ApiType\": \"azure\", \"ApiVersion\": apiVersion},\n",
    "    )[\"id\"]\n",
    "\n",
    "aoai_connection_id = aoai_connection[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlindex_dir = \"./mlindex\"\n",
    "asset_name = \"rustdocs_aoai_faiss_mlindex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "\n",
    "mlindex_data = ml_client.data.get(asset_name, label=\"latest\")\n",
    "fs, _ = fsspec.core.url_to_fs(mlindex_data.path)\n",
    "fs.download(mlindex_data.path, mlindex_dir, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smamgain\\AppData\\Local\\anaconda3\\envs\\baker\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['# Defining an Enum\\n\\n',\n",
       " '# Concise Control Fl',\n",
       " '# Defining an Enum\\n\\n',\n",
       " '# Storing Lists of V']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.rag.mlindex import MLIndex\n",
    "\n",
    "mlindex = MLIndex(mlindex_dir)\n",
    "retriever = mlindex.as_langchain_retriever()\n",
    "question = \"What makes Rust Enums so awesome?\"\n",
    "[doc.page_content[:20] for doc in retriever.get_relevant_documents(question)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-03-15-preview'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Rust Enums are awesome because they allow you to encode possibilities as a single type. Enums are especially useful when you need to work with values that can only be one of a set of possible variants. They also allow you to define methods on them, making them a powerful tool for creating custom types.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"text-davinci-003\",\n",
    "    model=\"text-davinci-003\",\n",
    "    max_tokens=1500,\n",
    "    openai_api_base=aoai_connection[\"properties\"][\"target\"],\n",
    "    openai_api_key=aoai_connection[\"properties\"][\"credentials\"][\"key\"],\n",
    "    openai_api_version=aoai_connection[\"properties\"][\"metadata\"][\"ApiVersion\"],\n",
    ")\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever\n",
    ")\n",
    "qa.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = ml_client.subscription_id\n",
    "resource_group_name = ml_client.resource_group_name\n",
    "workspace_name = ml_client.workspace_name\n",
    "\n",
    "def load_retriever(persist_dir):\n",
    "    \"\"\"Function to load the retriever during mlflow's load_model().\n",
    "    Additionally, it fetches AOAI workspace connection to set OPENAI_API_* environment variables that will be used by LLM. \n",
    "    \"\"\"\n",
    "    from azureml.rag.mlindex import MLIndex\n",
    "    from mlflow_code.utils import set_openai_env_vars\n",
    "\n",
    "    set_openai_env_vars(subscription_id, resource_group_name, workspace_name)\n",
    "\n",
    "    mlindex = MLIndex(persist_dir)\n",
    "    retriever = mlindex.as_langchain_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/25 14:51:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\smamgain\\msft\\azureml-examples\\sdk\\python\\generative-ai\\rag\\notebooks\\deployment\\mlflow-model, flavor: langchain), fall back to return ['langchain==0.0.202']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "\n",
    "model_dir = \"./mlflow-model\"\n",
    "\n",
    "saved_model = mlflow.langchain.save_model(\n",
    "    qa,\n",
    "    model_dir,\n",
    "    loader_fn=load_retriever,\n",
    "    persist_dir=mlindex_dir,\n",
    "    code_paths=[\"./code/mlflow_code\"],\n",
    "    extra_pip_requirements=[\n",
    "        \"azureml-rag[hugging_face,faiss]\",\n",
    "        \"mlflow>=2.5.0\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aoai_connection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: RetrievalQA = mlflow.pyfunc.load_model(model_dir)\n",
    "# model.predict([{\"query\": question}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "import openai\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.loading import load_chain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.vectorstores.azuresearch import AzureSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SETTING ENVIRONMENT VARIABLES_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting openai creds as env vars\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://<azure-openai-endpoint-name>.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<azure-openai-api-key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the embeddings\n",
    "def load_embeddings():\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        deployment=\"text-embedding-ada-002\",\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        chunk_size=1,\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# function to load the vectorstore\n",
    "def load_vectorstore(embeddings):\n",
    "    # using azure cognitive search as the vector store\n",
    "    vectorstore = AzureSearch(\n",
    "        azure_search_endpoint=os.getenv(\"VECTOR_STORE_ADDRESS\"),\n",
    "        azure_search_key=os.getenv(\"VECTOR_STORE_PASSWORD\"),\n",
    "        index_name=os.getenv(\"INDEX_NAME\"),\n",
    "        embedding_function=embeddings.embed_query,\n",
    "    )\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ADDING TEXTS AND METADATA TO THE VECTORSTORE_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"./stateoftheunion.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "vector_store = load_vectorstore(load_embeddings())\n",
    "_ = vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SAVING THE MODEL_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The president said that Ketanji Brown Jackson is one of our nation's top legal minds and that she will continue Justice Breyerâ€™s legacy of excellence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RM\\.conda\\envs\\aml-lc_env\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\RM\\.conda\\envs\\aml-lc_env\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_LOADING THE MODEL_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" The president said that Ketanji Brown Jackson is one of the nation's top legal minds and that she will continue Justice Breyer's legacy of excellence.\"]\n"
     ]
    }
   ],
   "source": [
    "model: RetrievalQA = mlflow.pyfunc.load_model(local_dir)\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "input_row = {\"query\": query}\n",
    "answer = model.predict([input_row])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Below is the code to deploy the model in azureml_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_CREATING AN INSTANCE OF MLCLIENT_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .\\config.json\n"
     ]
    }
   ],
   "source": [
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
    "print(ml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_REGISTERING THE MODEL_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading mlflow_model (0.0 MBs): 100%|##########| 4317/4317 [00:02<00:00, 1697.71it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    ")\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "model_name = \"aml-langchain-model\"\n",
    "model_local_path = \"./mlflow_model\"\n",
    "model = ml_client.models.create_or_update(\n",
    "    Model(name=model_name, path=model_local_path, type=AssetTypes.MLFLOW_MODEL)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SETTING UP ENVIRONMENT VARIABLES FOR OPENAI AND AZURE COGNITIVE SEARCH_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_env_vars = {\n",
    "    \"OPENAI_API_TYPE\": os.getenv(\"OPENAI_API_TYPE\"),\n",
    "    \"OPENAI_API_VERSION\": os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    \"OPENAI_API_BASE\": os.getenv(\"OPENAI_API_BASE\") ,\n",
    "    \"OPENAI_API_KEY\": os.getenv(\"OPENAI_API_KEY\")\n",
    "}\n",
    "\n",
    "acs_env_vars = {\n",
    "    \"VECTOR_STORE_ADDRESS\": os.getenv(\"VECTOR_STORE_ADDRESS\"),\n",
    "    \"VECTOR_STORE_PASSWORD\": os.getenv(\"VECTOR_STORE_PASSWORD\"),\n",
    "    \"INDEX_NAME\": os.getenv(\"INDEX_NAME\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_CREATING THE ENDPOINT WHERE THE MODEL WILL BE DEPLOYED_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x147717891b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = \"aml-langchain-\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "endpoint_name = endpoint_name + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(name=endpoint_name, auth_mode=\"key\")\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SETTING UP DEPLOYMENT PARAMETERS_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_NAME = \"aml-langchain-deployment\"\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    environment_variables={\n",
    "        **openai_env_vars,\n",
    "        **acs_env_vars,\n",
    "    },\n",
    "    instance_type=\"Standard_DS3_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_DEPLOYING TO THE ENDPOINT_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint aml-langchain-07191453558955 exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x147778ff1c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................."
     ]
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_UPDATING TRAFFIC TO THE ENDPOINT_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x14777912380>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic = {DEPLOYMENT_NAME: 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TESTING THE RESULTS_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\" The president said that she is a Circuit Court of Appeals Judge and one of our nation\\\\u2019s top legal minds who will continue Justice Breyer\\\\u2019s legacy of excellence.\"]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    request_file=\"request.json\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (baker)",
   "language": "python",
   "name": "baker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
