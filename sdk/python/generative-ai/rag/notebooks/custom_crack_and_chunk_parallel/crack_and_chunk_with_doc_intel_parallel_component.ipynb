{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create component of crack_and_chunk_with_doc_intel_parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1712725306438
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U azure-ai-ml>=1.23.1  # versions may change later\n",
    "%pip install azure-identity\n",
    "%pip install -U 'azureml-rag[azure,cognitive_search]>=0.2.28'\n",
    "%pip install promptflow-rag==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1714021712485
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.entities import Environment\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml.parallel import parallel_run_function, RunFunction\n",
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "microsoft": {
     "language": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile config.json\n",
    "{\n",
    "    \"subscription_id\": \"<subscription id>\",\n",
    "    \"resource_group\": \"<resource_group>\",\n",
    "    \"workspace_name\": \"<workspace_name>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1714021712810
    }
   },
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "identity = None\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1714025250575
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from azure.ai.ml.entities import BuildContext, Environment\n",
    "\n",
    "\"\"\"\n",
    "llm_rag_embeddings_doc_intel_environment = Environment(\n",
    "    name=\"llm_rag_embeddings_doc_intel\",\n",
    "    description=\"AzureML RAGs base crack_and_chunk environment with azure-ai-formrecognizer installed.\",\n",
    "    build=BuildContext(path=Path.cwd() / \"doc_intel_env\"),\n",
    ")\n",
    "\"\"\"\n",
    "llm_rag_embeddings_doc_intel_environment = ml_client.environments.get(\n",
    "    name=\"llm_rag_embeddings_doc_intel\", version=\"6\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Define the crack_and_chunk_with_doc_intel_component_parallel which can be used in place of the crack_and_chunk_parallel Component in Vector Index creation Pipelines.\n",
    "\n",
    "Please reference this article for parallel job setup of ML pipeline. https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-parallel-job-in-pipeline?view=azureml-api-2&tabs=python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the connections to Azure OpenAI (for embeddings with `text-embedding-ada-002`) and Azure Cognitive Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1714021713747
    }
   },
   "outputs": [],
   "source": [
    "aoai_connection = ml_client.connections.get(\"AOAI-westus\")\n",
    "acs_connection = ml_client.connections.get(\"cog-serch-westus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Custom Connection with details for an Azure AI Document Intelligence Service.\n",
    "[Setup instructions for Azure AI Document Intelligence](https://learn.microsoft.com/azure/ai-services/document-intelligence/create-document-intelligence-resource?view=doc-intel-3.1.0)\n",
    "\n",
    "Use the Connections UI in an AzureML Workspace, under the Promptflow tab, to create a connection with these fields: ![custom_doc_intel_connection.png](./assets/custom_doc_intel_connection.png)\n",
    "\n",
    "It's not yet supported to create/retrieve Custom Connections using SDK, so you will need to create it using the UI and we'll use string replacement below to get the ID for this custom connection to pass to our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1714021713891
    }
   },
   "outputs": [],
   "source": [
    "document_intelligence_connection_id = aoai_connection.id.replace(\n",
    "    \"AOAI-westus\", \"doc-intelligence\"\n",
    ")\n",
    "document_intelligence_connection_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Please reference this article for setting up optimum parameters of parallel job https://microsoft.github.io/azureml-ops-accelerator/4-Migrate/3-PerformanceTunePRS.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1714021767247
    }
   },
   "outputs": [],
   "source": [
    "crack_and_chunk_with_doc_intel_component_parallel = parallel_run_function(\n",
    "    version=\"0.0.1\",\n",
    "    name=\"crack_and_chunk_with_doc_intel_parallel\",\n",
    "    display_name=\"crack_and_chunk_with_doc_intel_parallel\",\n",
    "    description=\"\"\"Creates chunks from source data leveraging Azure AI Document Intelligence for PDFs in parallel.\n",
    "\n",
    "    Supported formats: md, txt, html/htm, pdf, ppt(x), doc(x), xls(x), py\"\"\",\n",
    "    inputs={\n",
    "        # Input AzureML Data\n",
    "        \"input_data\": Input(type=\"uri_folder\", mode=\"ro_mount\"),\n",
    "        # Files to handle from source\n",
    "        \"input_glob\": Input(\n",
    "            type=\"string\",\n",
    "            default=\"/**/*\",\n",
    "            description=\"Limit files opened from `input_data`, defaults to '**/*'\",\n",
    "        ),\n",
    "        \"allowed_extensions\": Input(\n",
    "            type=\"string\",\n",
    "            optional=True,\n",
    "            description=\"Comma separated list of extensions to include, if not provided the default list of supported extensions will be used. e.g. '.md,.txt,.html,.py,.pdf'\",\n",
    "        ),\n",
    "        # Chunking options\n",
    "        \"chunk_size\": Input(\n",
    "            type=\"integer\",\n",
    "            default=768,\n",
    "            description=\"Maximum number of tokens per chunk.\",\n",
    "        ),\n",
    "        \"chunk_overlap\": Input(\n",
    "            type=\"integer\",\n",
    "            default=0,\n",
    "            description=\"Number of tokens to overlap between chunks.\",\n",
    "        ),\n",
    "        \"use_rcts\": Input(\n",
    "            type=\"boolean\",\n",
    "            default=True,\n",
    "            description=\"Use langchain RecursiveTextSplitter to split chunks.\",\n",
    "        ),\n",
    "        # Augmentation options\n",
    "        \"data_source_url\": Input(\n",
    "            type=\"string\",\n",
    "            optional=True,\n",
    "            description=\"Base URL to join with file paths to create full source file URL for chunk metadata.\",\n",
    "        ),\n",
    "        \"document_path_replacement_regex\": Input(\n",
    "            type=\"string\",\n",
    "            optional=True,\n",
    "            description=\"A JSON string with two fields, 'match_pattern' and 'replacement_pattern' to be used with re.sub on the source url. e.g. '{\\\"match_pattern\\\": \\\"(.*)/articles/(.*)\\\", \\\"replacement_pattern\\\": \\\"\\\\1/\\\\2\\\"}' would remove '/articles' from the middle of the url.\",\n",
    "        ),\n",
    "        \"doc_intel_connection_id\": Input(\n",
    "            type=\"string\",\n",
    "            default=document_intelligence_connection_id,\n",
    "            description=\"AzureML Connection ID for Custom Workspace Connection containing the `endpoint` key and `api_key` secret for an Azure AI Document Intelligence Service.\",\n",
    "        ),\n",
    "        \"use_layout\": Input(\n",
    "            type=\"boolean\",\n",
    "            default=True,\n",
    "            description=\"Use 'prebuilt-layout' model from Azure AI Document Intelligence, more expensive and slower but maintains more structure from original doc.\",\n",
    "        ),\n",
    "    },\n",
    "    outputs={\n",
    "        \"output_chunks\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    input_data=\"${{inputs.input_data}}\",\n",
    "    instance_count=4,\n",
    "    max_concurrency_per_instance=4,\n",
    "    mini_batch_size=\"1\",\n",
    "    mini_batch_error_threshold=-1,\n",
    "    item_error_treshold=-1,\n",
    "    retry_settings=dict(max_retries=2, timeout=1200),\n",
    "    progress_update_timeout=259200,\n",
    "    logging_level=\"DEBUG\",\n",
    "    task=RunFunction(\n",
    "        code=Path.cwd() / \"crack_and_chunk_with_doc_intel\",\n",
    "        entry_script=\"crack_and_chunk_parallel.py\",\n",
    "        program_arguments=\"--input_data ${{inputs.input_data}}\\\n",
    "        --input_glob '${{inputs.input_glob}}'\\\n",
    "        $[[--allowed_extensions ${{inputs.allowed_extensions}}]]\\\n",
    "        --output_chunks ${{outputs.output_chunks}}\\\n",
    "        --chunk_size ${{inputs.chunk_size}}\\\n",
    "        --chunk_overlap ${{inputs.chunk_overlap}}\\\n",
    "        --use_rcts ${{inputs.use_rcts}}\\\n",
    "        $[[--data_source_url ${{inputs.data_source_url}}]]\\\n",
    "        $[[--document_path_replacement_regex '${{inputs.document_path_replacement_regex}}']]\\\n",
    "        --doc_intel_connection_id '${{inputs.doc_intel_connection_id}}'\\\n",
    "        --use_layout ${{inputs.use_layout}}\\ \",\n",
    "        environment=llm_rag_embeddings_doc_intel_environment,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1714021774212
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Now we register the component to the workspace\n",
    "crack_and_chunk_workspace = ml_client.create_or_update(\n",
    "    crack_and_chunk_with_doc_intel_component_parallel.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {crack_and_chunk_workspace.name} with Version {crack_and_chunk_workspace.version} is registered\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "categories": [
   "SDK v2",
   "sdk",
   "python",
   "generative-ai",
   "rag",
   "notebooks"
  ],
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
