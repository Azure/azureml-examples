{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a022eff",
   "metadata": {},
   "source": [
    "# Speculative Decoding\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f71c77",
   "metadata": {},
   "source": [
    "## Pre-requisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install huggingface_hub\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f165ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4300f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "\n",
    "\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7341c0a",
   "metadata": {},
   "source": [
    "## Create draft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_name = \"test_centralus\"\n",
    "comp_name = \"eagle3_chat_completion_pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_ml_client = MLClient(credential=credential, registry_name=registry_name)\n",
    "eagle3_comp = registry_ml_client.components.get(name=comp_name, label=\"latest\")\n",
    "eagle3_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45149cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_model_config = {\n",
    "  \"architectures\": [\n",
    "    \"LlamaForCausalLMEagle3\"\n",
    "  ],\n",
    "  \"bos_token_id\": 128000,\n",
    "  \"eos_token_id\": 128001,\n",
    "  \"hidden_act\": \"silu\",\n",
    "  \"hidden_size\": 4096,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 14336,\n",
    "  \"max_position_embeddings\": 2048,\n",
    "  \"model_type\": \"llama\",\n",
    "  \"num_attention_heads\": 32,\n",
    "  \"num_key_value_heads\": 8,\n",
    "  \"num_hidden_layers\": 1,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"rms_norm_eps\": 1e-05,\n",
    "  \"tie_word_embeddings\": False,\n",
    "  \"torch_dtype\": \"float16\",\n",
    "  \"transformers_version\": \"4.28.1\",\n",
    "  \"use_cache\": True,\n",
    "  \"vocab_size\": 128256,\n",
    "  \"draft_vocab_size\": 32000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_config_path = \"./data/config/draft_model_config.json\"\n",
    "input_data_path = \"./data/train/sharegpt_train_small.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(draft_config_path, \"w\") as f:\n",
    "    json.dump(draft_model_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c41e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities._inputs_outputs import Input\n",
    "from azure.ai.ml.constants._common import AssetTypes\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def speculative_decoding_pipeline():\n",
    "    node = eagle3_comp(\n",
    "        mlflow_model_path=Input(type=AssetTypes.MLFLOW_MODEL, path=\"azureml://registries/azureml-meta/models/Meta-Llama-3-8B-Instruct/versions/9\"),\n",
    "        dataset_train_split=Input(type=AssetTypes.URI_FILE, path=input_data_path),\n",
    "        dataset_validation_split=Input(type=AssetTypes.URI_FILE, path=input_data_path),\n",
    "        draft_model_config=Input(type=AssetTypes.URI_FILE, path=draft_config_path),\n",
    "        # resume_from_checkpoint=None,\n",
    "    )\n",
    "    return {\n",
    "        \"output_model\": node.outputs.output_model_path\n",
    "    }\n",
    "\n",
    "\n",
    "spec_dec_job = speculative_decoding_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd53398",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dec_job = ml_client.jobs.create_or_update(\n",
    "    spec_dec_job, experiment_name=\"speculative-decoding-exp\"\n",
    ")\n",
    "spec_dec_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd103d9",
   "metadata": {},
   "source": [
    "## Download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"nvidia/Llama-3.1-8B-Instruct-FP8\"\n",
    "# draft_model_name = \"lmsys/sglang-EAGLE3-LLaMA3.1-Instruct-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07764253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "\n",
    "base_model_dir = \"./models/base\"\n",
    "draft_model_dir = \"./models/draft\"\n",
    "\n",
    "snapshot_download(repo_id=base_model_name, local_dir=base_model_dir)\n",
    "# snapshot_download(repo_id=draft_model_name, local_dir=draft_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aac890",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.download(name=spec_dec_job.name, output_name=\"output_model\", download_path=draft_model_dir, all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2cc3f0",
   "metadata": {},
   "source": [
    "## Change config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "draft_config = json.load(open(f\"{draft_model_dir}/config.json\"))\n",
    "\n",
    "draft_config = {\n",
    "    **draft_config,\n",
    "    \"max_position_embeddings\": 131072,\n",
    "    \"rope_scaling\": {\n",
    "        \"factor\": 8,\n",
    "        \"high_freq_factor\": 4,\n",
    "        \"low_freq_factor\": 1,\n",
    "        \"original_max_position_embeddings\": 8192,\n",
    "        \"rope_type\": \"llama3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{draft_model_dir}/config.json\", \"w\") as f:\n",
    "    json.dump(draft_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285fc89e",
   "metadata": {},
   "source": [
    "## Upload model as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    path=\"./models\", # Path to your model files\n",
    "    name=\"llama-3-1-speculative\",\n",
    ")\n",
    "ml_client.models.create_or_update(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c2272",
   "metadata": {},
   "source": [
    "## Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae73a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "\n",
    "\n",
    "env = Environment(\n",
    "    build=BuildContext(path=\"./environment\"),\n",
    "    name=\"speculative-env\",\n",
    "    description=\"Environment for speculative decoding inference using sglang.\",\n",
    "    inference_config={\n",
    "        \"liveness_route\": {\n",
    "            \"port\": 30000,\n",
    "            \"path\": \"/health\"\n",
    "        },\n",
    "        \"readiness_route\": {\n",
    "            \"port\": 30000,\n",
    "            \"path\": \"/health_generate\"\n",
    "        },\n",
    "        \"scoring_route\": {\n",
    "            \"port\": 30000,\n",
    "            \"path\": \"/\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "ml_client.environments.create_or_update(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4abbd",
   "metadata": {},
   "source": [
    "## Create an online endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e720944",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"llama-3-1-speculative-endpoint-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b3fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
    "\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "   name=endpoint_name,\n",
    "   auth_mode=\"key\" # Use \"aml_token\" for token-based authentication\n",
    ")\n",
    "\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c699bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name = \"llama-3-1-speculative-deployment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640bd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineDeployment, ProbeSettings\n",
    "from azure.ai.ml.entities._deployment.deployment_settings import OnlineRequestSettings\n",
    "\n",
    "\n",
    "liveness_probe = ProbeSettings(\n",
    "    initial_delay=2000,\n",
    "    period=10,\n",
    "    timeout=2,\n",
    "    success_threshold=1,\n",
    "    failure_threshold=30,\n",
    ")\n",
    "\n",
    "readiness_probe = ProbeSettings(\n",
    "    initial_delay=2000,\n",
    "    period=10,\n",
    "    timeout=2,\n",
    "    success_threshold=1,\n",
    "    failure_threshold=30,\n",
    ")\n",
    "\n",
    "env_vars = {\n",
    "    \"BASE_MODEL\": \"/var/model-mount/models/base\",\n",
    "    \"DRAFT_MODEL\": \"/var/model-mount/models/draft\",\n",
    "    \"SGLANG_ARGS\": \"--tp-size 1 --max-running-requests 32 --mem-fraction-static 0.8 --speculative-algorithm EAGLE3 --speculative-num-steps 3 --speculative-eagle-topk 2 --speculative-num-draft-tokens 4 --dtype float16 --attention-backend fa3 --host 0.0.0.0 --port 30000 --enable-torch-compile\",\n",
    "    \"SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN\": \"1\",\n",
    "    \"SGL_HOST\": \"0.0.0.0\",\n",
    "    \"SGL_PORT\": \"30000\",\n",
    "}\n",
    "\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    model_mount_path=\"/var/model-mount\",\n",
    "    environment=env,\n",
    "    environment_variables=env_vars,\n",
    "    # instance_type=\"Standard_NC40ads_H100_v5\",\n",
    "    instance_type=\"STANDARD_ND96ISRF_H100_V5\",\n",
    "    instance_count=1,\n",
    "    liveness_probe=liveness_probe,\n",
    "    readiness_probe=readiness_probe,\n",
    "    request_settings=OnlineRequestSettings(\n",
    "        request_timeout_ms=60000,\n",
    "        max_concurrent_requests_per_instance=32,\n",
    "    )\n",
    ")\n",
    "\n",
    "ml_client.online_deployments.begin_create_or_update(deployment).wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611a82f",
   "metadata": {},
   "source": [
    "## Invoke endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be249d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "api_key = ml_client.online_endpoints.get_keys(name=endpoint_name).primary_key\n",
    "base_url = ml_client.online_endpoints.get(name=endpoint_name).scoring_uri.replace(\"/score\", \"/v1\")  # replace with /v1/chat/completions when using requests library\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"\",  # This is a no-op, the actual model is defined in your deployment\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Come up with a joke on AI\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
