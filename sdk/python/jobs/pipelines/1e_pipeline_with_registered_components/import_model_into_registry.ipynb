{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d8471b",
   "metadata": {},
   "source": [
    "## Import models from Hugging Face hub\n",
    "This sample shows how to import and register models from [HuggingFace hub](https://huggingface.co/models). \n",
    "\n",
    "### How does import work?\n",
    "The import process runs as a job in your AzureML workspace using components from the `azureml` system registry. The models are downloaded and converted to MLflow packaged format. You can then register the models to your AzureML Workspace or Registry that makes them available for inference or fine tuning. \n",
    "\n",
    "### What models are supported for import?\n",
    "Any model from Hugging Face hub can be downloaded using the `download_model` component. Only the following set of tasks are supported for MLflow conversion:\n",
    "* fill-mask\n",
    "* token-classification\n",
    "* question-answering\n",
    "* summarization\n",
    "* text-generation\n",
    "* text-classification\n",
    "* translation\n",
    "* image-classification\n",
    "* text-to-image\n",
    "\n",
    "Conversion to MLflow will fail if you attempt to download a model that has a task type other than the above.\n",
    "\n",
    "### Why convert to MLflow?\n",
    "MLflow is AzureML's recommended model packaging format. \n",
    "* **Inference benefits**: AzureML supports no-code-deployment for models packaged as MLflow that enables a seamless inference experience for the models. Learn more about [MLflow model packaging](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow-models) and [no-code-deployment](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-mlflow-models-online-endpoints?tabs=sdk). \n",
    "* **Fine tuning benefits**: Foundation models imported and converted to MLflow format can be fine tuned using AzureML's fine tuning pipelines. You can use the no-code UI wizards, or the code based job submission with the SDK or CLI/YAML. AzureML's fine tuning pipelines are built using components. This gives you the flexibility to compose your own fine tuning pipelines containing your own jobs for data transformation, post processing and the AzureML fine tuning components. Learn more about pipelines using [sdk](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipeline-python) or [CLI](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipelines-cli).\n",
    "\n",
    "### What happens if I just download model and register models without converting to MLflow? That's because the task of the model I'm interested in is not among the supported list of tasks.\n",
    "You can still download and register the model using the outputs of the `download_model` job. You need to [write your own inference code](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-online-endpoints?tabs=python) in this case. It also means that fine tuning is not yet supported if the task type of the model you are interested in is not in the supported list.\n",
    "\n",
    "### Outline\n",
    "* Setup pre-requisites such as compute.\n",
    "* Pick a model to import.\n",
    "* Configure the import job.\n",
    "* Run the fine tuning job.\n",
    "* Register the fine tuned model. \n",
    "\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription - [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace with computer cluster - [Configure workspace](../../configuration.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](../../../README.md) - check the getting started section\n",
    "\n",
    "\n",
    "**Motivations** - This notebook explains how to create model importing/publishing pipeline job in workspace using pipeline component registered in a registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba6a51",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section, we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1 Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85623da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, ClientSecretCredential\n",
    "from azure.ai.ml import UserIdentityConfiguration\n",
    "\n",
    "from azure.ai.ml import MLClient, Input, Output\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import load_component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180bc1d",
   "metadata": {},
   "source": [
    "## 1.2 Configure credential\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to the workspace. \n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "\n",
    "Reference for more available credentials if it does not work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9800ab1",
   "metadata": {},
   "source": [
    "## 1.3 Get a handle to the workspace and the registry\n",
    "\n",
    "We use the config file to connect to a workspace. The Azure ML workspace should be configured with a computer cluster. [Check this notebook for configure a workspace](../../configuration.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7159db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a handle to workspace from config file\n",
    "try:\n",
    "    ml_client_ws = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    ml_client_ws = MLClient(\n",
    "            credential,\n",
    "            subscription_id =  \"<SUBSCRIPTION_ID>\",\n",
    "            resource_group_name =  \"<RESOURCE_GROUP>\",\n",
    "            workspace_name =  \"<WORKSPACE_NAME>\"\n",
    "    )\n",
    "\n",
    "ml_client_registry = MLClient(credential, registry_name=\"azureml\")\n",
    "\n",
    "# Retrieve an already attached Azure Machine Learning Compute.\n",
    "cluster_name = \"cpu-cluster\"\n",
    "print(ml_client_ws.compute.get(cluster_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb705c33",
   "metadata": {},
   "source": [
    "# 2. Load pipeline component from the registry to create a pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb9810",
   "metadata": {},
   "source": [
    "## 2.1 Use registry handle to load the components in workspace\n",
    "\n",
    "### Components\n",
    "- import_model - Pipeline component which downloads the model, converts it into mlflow, validates locally and then register it respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_model = ml_client_registry.components.get(\n",
    "    name=\"import_model\", version=\"0.1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e53eb8",
   "metadata": {},
   "source": [
    "# 3. Create a pipeline job using the pipeline component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1c389",
   "metadata": {},
   "source": [
    "## 3.1 Create pipeline object using necessary parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5862d95e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3497695939.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [10], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    - compute - Compute cluster on which pipeline job will run\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#### Important parameters to pass\n",
    "- model_id                                \n",
    "- compute - Compute cluster on which pipeline job will run\n",
    "- registry_name - This needs to be passed only when you want to register the model in the registry else ignore\n",
    "\n",
    "#### model_id \n",
    "\n",
    "\"Browse models on [HuggingFace hub](https://huggingface.co/models) and identify a model to import. Make sure the task type of the model is among the supported tasks as explained in the introduction section. Copy the model id which is available in the URI of the page or can be copied using the copy icon next to the model name and assign it to the variable `MODEL_ID`.\"\n",
    "\n",
    "\n",
    "![model-id-screen-shot.png](attachment:model-id-screen-shot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"bert-base-cased\"\n",
    "COMPUTE = cluster_name\n",
    "REGISTRY_NAME = None # Set this value only if you want to register the model in registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7178a91",
   "metadata": {},
   "source": [
    "## Check if model already exists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ea15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if REGISTRY_NAME:\n",
    "        models = ml_client_registry.models.list(name = MODEL_ID)\n",
    "        if models:\n",
    "            max_version = (max(models_list, key=lambda x: x.version)).version\n",
    "            model_version = str(int(max_version) + 1)\n",
    "        print(f\"Model already exists in {REGISTRY_NAME} with name {MODEL_ID} and version {model_version}\")\n",
    "    else:\n",
    "        model = ml_client_ws.models.get(name = MODEL_ID, label = \"latest\")\n",
    "        print(f\"Model already exists in your workspace with name {MODEL_ID} and version {model.version}\")\n",
    "except:\n",
    "    print(\"Model does not exist ! Import the model using pipeline component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d854f",
   "metadata": {},
   "source": [
    "## Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_object = import_model(\n",
    "                    model_id = MODEL_ID,\n",
    "                    compute = COMPUTE,\n",
    "                    task_name =\"cdcdcd\"\n",
    "                    # registry_name = \"azureml-preview-test1\", pass only if you want to register model in registry\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293357d",
   "metadata": {},
   "source": [
    "## 3.2 Setting pipeline computes,identity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1391afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings of compute and Identity\n",
    "pipeline_object.settings.force_rerun = True\n",
    "pipeline_object.settings.default_compute  = cluster_name\n",
    "pipeline_object.identity = UserIdentityConfiguration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32bb8d9",
   "metadata": {},
   "source": [
    "# 4. Submit the import job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the pipeline job\n",
    "pipeline_job = ml_client_ws.jobs.create_or_update(pipeline_object, experiment_name=f\"bert-base-cased import\")\n",
    "# wait for the pipeline job to complete\n",
    "ml_client_ws.jobs.stream(pipeline_job.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
