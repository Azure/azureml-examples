{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTuning LLM with Model-As-Service\n",
    "\n",
    "This sample shows how use create a standalone FineTuning job to fine tune a model to summarize a dialog between 2 people using samsum dataset.\n",
    "\n",
    "#### Training data\n",
    "We use sample data placed along with the notebook for our finetuning in files \"train.jsonl\" and \"validation.jsonl\".\n",
    "\n",
    "#### Model\n",
    "We will use the Phi-3-mini-4k-instruct model to show how user can finetune a model for chat-completion task. If you opened this notebook from a specific model card, remember to replace the specific model name. \n",
    "\n",
    "#### Outline\n",
    "1. Setup pre-requisites\n",
    "2. Pick a model to fine-tune.\n",
    "3. Create training and validation datasets.\n",
    "4. Configure the fine tuning job.\n",
    "5. Submit the fine tuning job.\n",
    "6. Create serverless deployment using finetuned model and sample inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup pre-requisites\n",
    "* Install dependencies\n",
    "* Connect to AzureML Workspace. Learn more at [set up SDK authentication](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk). Replace  `<WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` below.\n",
    "* Connect to `azureml` system registry\n",
    "* Set an optional experiment name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install dependencies by running below cell. This is not an optional step if running in a new environment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml\n",
    "%pip install azure-identity\n",
    "\n",
    "%pip install mlflow\n",
    "%pip install azureml-mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AzureML Workspace connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    workspace_ml_client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "        resource_group_name=\"<RESOURCE_GROUP_NAME>\",\n",
    "        workspace_name=\"<PROJECT_NAME OR WORKSPACE_NAME>\",\n",
    "    )\n",
    "\n",
    "# the models, fine tuning pipelines and environments are available in various AzureML system registries,\n",
    "# Example: Phi family of models are in \"azureml\", Llama family of models are in \"azureml-meta\" registry.\n",
    "registry_ml_client = MLClient(credential, registry_name=\"azureml\")\n",
    "\n",
    "# Get AzureML workspace object.\n",
    "workspace = workspace_ml_client._workspaces.get(workspace_ml_client.workspace_name)\n",
    "workspace.id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pick a model to fine tune\n",
    "\n",
    "Phi-4-mini-instruct is a lightweight open model built upon synthetic data and filtered publicly available websites - with a focus on high-quality, reasoning dense data. The model belongs to the Phi-4 model family and supports 128K token context length. The model underwent an enhancement process, incorporating both supervised fine-tuning and direct preference optimization to support precise instruction adherence and robust safety measures. You can browse these models in the Model Catalog in the Azure AI Studio, filtering by the `chat-completion` task. In this example, we use the `Phi-3-mini-4k-instruct` model. If you have opened this notebook for a different model, replace the model name and version accordingly.\n",
    "\n",
    "Note the model id property of the model. This will be passed as input to the fine tuning job. This is also available as the `Asset ID` field in model details page in Azure AI Studio Model Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Phi-4-mini-instruct\"\n",
    "model_to_finetune = registry_ml_client.models.get(model_name, label=\"latest\")\n",
    "print(\n",
    "    \"\\n\\nUsing model name: {0}, version: {1}, id: {2} for fine tuning\".format(\n",
    "        model_to_finetune.name, model_to_finetune.version, model_to_finetune.id\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sample data\n",
    "The chat-completion dataset entry using the following schema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    {\n",
    "        \"prompt\": \"Create a fully-developed protagonist who is challenged to survive within a dystopian society under the rule of a tyrant. ...\",\n",
    "        \"messages\":[\",\n",
    "            {\",\n",
    "                \"content\": \"Create a fully-developed protagonist who is challenged to survive within a dystopian society under the rule of a tyrant. ...\",\n",
    "                \"role\": \"user\",\n",
    "            },\n",
    "            {\",\n",
    "                \"content\": \"Name: Ava\\n Ava was just 16 years old when the world as she knew it came crashing down. The government had collapsed, leaving behind a chaotic and lawless society. ...\",\n",
    "                \"role\": \"assistant\",\n",
    "            },\n",
    "            {\",\n",
    "                \"content\": \"Wow, Ava's story is so intense and inspiring! Can you provide me with more details.  ...\",\n",
    "                \"role\": \"user\",\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"Certainly! ....\",\n",
    "                \"role\": \"assistant\"\",\n",
    "            }\n",
    "        ],\n",
    "        \"prompt_id\": \"d938b65dfe31f05f80eb8572964c6673eddbd68eff3db6bd234d7f1e3b86c2af\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Data\n",
    "\n",
    "dataset_version = \"1\"\n",
    "train_dataset_name = \"chat_training_small\"\n",
    "try:\n",
    "    train_data_asset = workspace_ml_client.data.get(\n",
    "        train_dataset_name, version=dataset_version\n",
    "    )\n",
    "    print(f\"Dataset {train_dataset_name} already exists\")\n",
    "except:\n",
    "    print(\"creating dataset\")\n",
    "    train_data = Data(\n",
    "        path=f\"./train.jsonl\",\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        description=\"Training dataset\",\n",
    "        name=train_dataset_name,\n",
    "        version=\"1\",\n",
    "    )\n",
    "    train_data_asset = workspace_ml_client.data.create_or_update(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "\n",
    "dataset_version = \"1\"\n",
    "validation_dataset_name = \"chat_validation_small\"\n",
    "try:\n",
    "    validation_data_asset = workspace_ml_client.data.get(\n",
    "        validation_dataset_name, version=dataset_version\n",
    "    )\n",
    "    print(f\"Dataset {validation_dataset_name} already exists\")\n",
    "except:\n",
    "    print(\"creating dataset\")\n",
    "    validation_data = Data(\n",
    "        path=f\"./validation.jsonl\",\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        description=\"Validation dataset\",\n",
    "        name=validation_dataset_name,\n",
    "        version=\"1\",\n",
    "    )\n",
    "    validation_data_asset = workspace_ml_client.data.create_or_update(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create marketplace subscription for 3P models\n",
    "**Note:** Skip this step for 1P(Microsoft) models that are offered on Azure. Example: Phi family of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_to_subscribe = \"/\".join(model_to_finetune.id.split(\"/\")[:-2])\n",
    "print(model_id_to_subscribe)\n",
    "\n",
    "normalized_model_name = model_name.replace(\".\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import MarketplaceSubscription\n",
    "\n",
    "\n",
    "subscription_name = f\"{normalized_model_name}-sub\"\n",
    "\n",
    "marketplace_subscription = MarketplaceSubscription(\n",
    "    model_id=model_id_to_subscribe,\n",
    "    name=subscription_name,\n",
    ")\n",
    "\n",
    "# note: this will throw exception if the subscription already exists or subscription is not required (for example, if the model is not in the marketplace like Phi family)\n",
    "try:\n",
    "    marketplace_subscription = (\n",
    "        workspace_ml_client.marketplace_subscriptions.begin_create_or_update(\n",
    "            marketplace_subscription\n",
    "        ).result()\n",
    "    )\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Submit the fine tuning job using the the model and data as inputs\n",
    " \n",
    "Create FineTuning job using all the data that we have so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define finetune parameters\n",
    "\n",
    "##### There are following set of parameters that are required.\n",
    "\n",
    "1. `model` - Base model to finetune.\n",
    "2. `training_data` - Training data for finetuning the base model.\n",
    "3. `validation_data` - Validation data for finetuning the base model.\n",
    "4. `task` - FineTuning task to perform. eg. CHAT_COMPLETION for chat-completion finetuning jobs.\n",
    "5. `outputs`- Output registered model name.\n",
    "\n",
    "##### Following parameters are optional:\n",
    "\n",
    "1. `hyperparameters` - Parameters that control the FineTuning behavior at runtime.\n",
    "2. `name`- FineTuning job name\n",
    "3. `experiment_name` - Experiment name for FineTuning job.\n",
    "4. `display_name` - FineTuning job display name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.finetuning import FineTuningTaskType, create_finetuning_job\n",
    "import uuid\n",
    "\n",
    "guid = uuid.uuid4()\n",
    "short_guid = str(guid)[:8]\n",
    "display_name = f\"{model_name}-display-name-{short_guid}-from-sdk\"\n",
    "name = f\"{model_name}t-{short_guid}-from-sdk\"\n",
    "output_model_name_prefix = f\"{model_name}-{short_guid}-from-sdk-finetuned\"\n",
    "experiment_name = f\"{model_name}-from-sdk\"\n",
    "\n",
    "finetuning_job = create_finetuning_job(\n",
    "    task=FineTuningTaskType.CHAT_COMPLETION,\n",
    "    training_data=train_data_asset.id,\n",
    "    validation_data=validation_data_asset.id,\n",
    "    hyperparameters={\n",
    "        \"per_device_train_batch_size\": \"1\",\n",
    "        \"learning_rate\": \"0.00002\",\n",
    "        \"num_train_epochs\": \"1\",\n",
    "    },\n",
    "    model=model_to_finetune.id,\n",
    "    display_name=display_name,\n",
    "    name=name,\n",
    "    experiment_name=experiment_name,\n",
    "    tags={\"foo_tag\": \"bar\"},\n",
    "    properties={\"my_property\": \"my_value\"},\n",
    "    output_model_name_prefix=output_model_name_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_job = workspace_ml_client.jobs.create_or_update(finetuning_job)\n",
    "workspace_ml_client.jobs.get(created_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for the above job to complete successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = workspace_ml_client.jobs.get(created_job.name).status\n",
    "\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    status = workspace_ml_client.jobs.get(created_job.name).status\n",
    "    print(f\"Current job status: {status}\")\n",
    "    if status in [\"Failed\", \"Completed\", \"Canceled\"]:\n",
    "        print(\"Job has finished with status: {0}\".format(status))\n",
    "        break\n",
    "    else:\n",
    "        print(\"Job is still running. Checking again in 30 seconds.\")\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model_name = created_job.outputs[\"registered_model\"][\"name\"]\n",
    "finetune_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model as a serverless endpoint\n",
    "\n",
    "endpoint_name = f\"{normalized_model_name}-ft-{short_guid}\"  # Name must be unique\n",
    "model_id = f\"azureml://locations/{workspace.location}/workspaces/{workspace._workspace_id}/models/{finetune_model_name}/versions/1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create serverless endpoint using the finetuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Option 1: Create serverless endpoint in the same project where it was finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ServerlessEndpoint\n",
    "\n",
    "serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_id)\n",
    "\n",
    "created_endpoint = workspace_ml_client.serverless_endpoints.begin_create_or_update(\n",
    "    serverless_endpoint\n",
    ").result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 2: Create Serverless endpoint in a different Region/Subscription/Project\n",
    "\n",
    " **Scenario**: User wants to create deployment in a different project/region/subscription under same tenant and avoid retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Current support matrix for FT deployments:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Supported Models          | eastus2 | eastus | northcentralus | westus3 | westus | southcentralus | swedencentral |\n",
    "|---------------------------|---------|--------|----------------|---------|--------|----------------|---------------|\n",
    "| Mistral-3B               | ✅      | ✅     | ✅             | ✅      | ✅     | ✅             | ❌            |\n",
    "| Mistral-Nemo             | ✅      | ✅     | ✅             | ✅      | ✅     | ✅             | ❌            |\n",
    "| Mistral-Large-2411       | ✅      | ✅     | ✅             | ✅      | ✅     | ✅             | ❌            |\n",
    "| tsuzumi-7b | ✅      | ✅     | ✅             | ✅      | ✅     | ✅              | ❌            |\n",
    "| Phi-4-mini-instruct      | ✅      | ✅     | ✅             | ✅      | ✅     | ✅             | ❌            |\n",
    "| Phi-3.5-mini-instruct    | ✅      | ✅     | ✅             | ✅      | ✅     | ✅             | ❌            |\n",
    "| Phi-3.5-MOE-instruct     | ✅      | ✅     | ✅             | ✅      | ✅     | ✅             | ❌            |\n",
    "| Phi-3-mini-4k-instruct   | ✅      | ❌      | ❌             | ❌      | ❌     | ❌            | ❌            |\n",
    "| Phi-3-mini-128k-instruct   | ✅      | ❌      | ❌             | ❌      | ❌     | ❌      | ❌            |\n",
    "| Phi-3-medium-4k-instruct | ✅      | ❌      | ❌             | ❌      | ❌     | ❌               | ❌            |\n",
    "| Phi-3-medium-128k-instruct     | ✅      | ❌      | ❌             | ❌      | ❌     | ❌             | ✅               |\n",
    "| Llama-3.1-8b-instruct | ❌     | ❌      | ❌             | ✅    | ❌     | ❌               | ❌            |\n",
    "| Llama-3.1-70b-instruct | ❌     | ❌      | ❌             | ✅    | ❌     | ❌               | ❌            |\n",
    "| Llama-2-7b | ❌     | ❌      | ❌             | ✅    | ❌     | ❌               | ❌            |\n",
    "| Llama-2-13b | ❌     | ❌      | ❌             | ✅    | ❌     | ❌               | ❌            |\n",
    "| Llama-2-70b | ❌     | ❌      | ❌             | ✅    | ❌     | ❌               | ❌            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create MLClient with target Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Cross region FT deployment client\n",
    "from azure.ai.ml.entities import ServerlessEndpoint\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "try:\n",
    "    workspace_ml_client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        subscription_id=\"<TARGET_SUBSCRIPTION_ID>\",\n",
    "        resource_group_name=\"<TARGET_RESOURCE_GROUP_NAME>\",\n",
    "        workspace_name=\"<TARGET_PROJECT_NAME>\",\n",
    "    )\n",
    "\n",
    "workspace = workspace_ml_client._workspaces.get(workspace_ml_client.workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create marketplace subscription in the target project (SKIP this step for Microsoft 1P models like Phi-family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import MarketplaceSubscription\n",
    "\n",
    "\n",
    "subscription_name = f\"{normalized_model_name}-sub\"\n",
    "\n",
    "marketplace_subscription = MarketplaceSubscription(\n",
    "    model_id=model_id_to_subscribe,\n",
    "    name=subscription_name,\n",
    ")\n",
    "\n",
    "# note: this will throw exception if the subscription already exists or subscription is not required (for example, if the model is not in the marketplace like Phi family)\n",
    "try:\n",
    "    marketplace_subscription = (\n",
    "        workspace_ml_client.marketplace_subscriptions.begin_create_or_update(\n",
    "            marketplace_subscription\n",
    "        ).result()\n",
    "    )\n",
    "except Exception as ex:\n",
    "    print(str(ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create deployment in the target region/subscription/project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_region = workspace.location\n",
    "model_to_finetune.tags\n",
    "supported_regions = model_to_finetune.tags[\"maas-finetuning-deploy-regions\"]\n",
    "supported_regions\n",
    "if workspace_region in supported_regions:\n",
    "    print(f\"Creating endpoint in the region:{workspace_region}\")\n",
    "    serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_id)\n",
    "    created_endpoint = workspace_ml_client.serverless_endpoints.begin_create_or_update(\n",
    "        serverless_endpoint\n",
    "    ).result()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"For the model : {model_to_finetune}, the target region: {workspace_region} is not supported for deployment, the supported regions: {supported_regions}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Inference on the Finetuned Serverless Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = workspace_ml_client.serverless_endpoints.get(endpoint_name)\n",
    "endpoint_keys = workspace_ml_client.serverless_endpoints.get_keys(endpoint_name)\n",
    "auth_key = endpoint_keys.primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"{endpoint.scoring_uri}/v1/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"max_tokens\": 1024,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"This script is great so far. Can you add more dialogue between Amanda and Thierry to build up their chemistry and connection?\",\n",
    "            \"role\": \"user\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"{auth_key}\"}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Delete the Finetuned Serverless Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_ml_client.serverless_endpoints.begin_delete(endpoint_name).result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
