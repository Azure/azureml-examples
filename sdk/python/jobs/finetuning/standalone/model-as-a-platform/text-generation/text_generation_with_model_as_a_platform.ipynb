{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTuning LLM with Model-As-Platform - TextGeneration\n",
    "\n",
    "This sample shows how to create a standalone FineTuning job to fine tune a model to summarize the input text provided in the training data.\n",
    "\n",
    "#### Training data\n",
    "We use the [samsum]((https://huggingface.co/datasets/samsum)) dataset. For simplicity we preprocessed the data and have only fraction of the data put here along with the notebook. The dataset, suitable for:\n",
    "* Supervised fine-tuning (sft).\n",
    "* Generation ranking (gen).\n",
    "\n",
    "Note that sample data is only useful for demo purposes. Also terms 'text-generation/text-completion' are used interchangebly and mean same task of finetuning.\n",
    "\n",
    "#### Model\n",
    "We will use the Meta-Llama-3-8B model to show how user can finetune a model for Text-Generation task. If you opened this notebook from a specific model card, remember to replace the specific model name. \n",
    "\n",
    "#### Outline\n",
    "1. Setup pre-requisites\n",
    "2. Pick a model to fine-tune.\n",
    "3. Create training and validation datasets.\n",
    "4. Configure the fine tuning job.\n",
    "5. Submit the fine tuning job.\n",
    "6. Deploy the fine tuned model for real time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup pre-requisites\n",
    "* Install dependencies\n",
    "* Connect to AzureML Workspace. Learn more at [set up SDK authentication](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk). Replace  `<WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` below.\n",
    "* Connect to `azureml` system registry\n",
    "* Set an optional experiment name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install dependencies by running below cell. This is not an optional step if running in a new environment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml\n",
    "%pip install azure-identity\n",
    "\n",
    "%pip install mlflow\n",
    "%pip install azureml-mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AzureML Workspace connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    workspace_ml_client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "        resource_group_name=\"<RESOURCE_GROUP>\",\n",
    "        workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    )\n",
    "\n",
    "# the models, fine tuning pipelines and environments are available in various AzureML system registries,\n",
    "# Example: Phi family of models are in \"azureml\", Llama family of models are in \"azureml-meta\" registry.\n",
    "registry_ml_client = MLClient(credential, registry_name=\"azureml-meta\")\n",
    "\n",
    "# Get AzureML workspace object.\n",
    "workspace = workspace_ml_client._workspaces.get(workspace_ml_client.workspace_name)\n",
    "workspace.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pick a model to fine tune\n",
    "\n",
    "`Meta-Llama-3-8B` is a 3.8B parameters, lightweight, state-of-the-art open model built by `Meta`. The model belongs to the Meta model family. You can browse these models in the Model Catalog in the Azure AI Studio, filtering by the `text-completion` task.\n",
    "\n",
    "Note the model id property of the model. This will be passed as input to the fine tuning job. This is also available as the `Asset ID` field in model details page in Azure AI Studio Model Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Meta-Llama-3-8B\"\n",
    "model_to_finetune = registry_ml_client.models.get(model_name, label=\"latest\")\n",
    "print(\n",
    "    \"\\n\\nUsing model name: {0}, version: {1}, id: {2} for fine tuning\".format(\n",
    "        model_to_finetune.name, model_to_finetune.version, model_to_finetune.id\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use either compute cluster or provide instance type which is compatible with below list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_to_finetune.properties[\"finetune-recommended-sku\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sample data\n",
    "\n",
    "The text-generation dataset is stored in this format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    {\n",
    "        \"text\": \"Summarize the dialog.\\n<dialog>: Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\\n<summary>: \",\n",
    "        \"ground_truth\":\"Amanda baked cookies and will bring Jerry some tomorrow.\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Data\n",
    "\n",
    "dataset_version = \"1\"\n",
    "train_dataset_name = \"text_generation_train_small\"\n",
    "try:\n",
    "    train_data_asset = workspace_ml_client.data.get(\n",
    "        train_dataset_name, version=dataset_version\n",
    "    )\n",
    "    print(f\"Dataset {train_dataset_name} already exists\")\n",
    "except:\n",
    "    print(\"creating dataset\")\n",
    "    train_data = Data(\n",
    "        path=f\"./train.jsonl\",\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        description=\"Training dataset\",\n",
    "        name=train_dataset_name,\n",
    "        version=\"1\",\n",
    "    )\n",
    "    train_data_asset = workspace_ml_client.data.create_or_update(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_asset.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "\n",
    "dataset_version = \"1\"\n",
    "validation_dataset_name = f\"text_generation_validation_small\"\n",
    "try:\n",
    "    validation_data_asset = workspace_ml_client.data.get(\n",
    "        validation_dataset_name, version=dataset_version\n",
    "    )\n",
    "    print(f\"Dataset {validation_dataset_name} already exists\")\n",
    "except:\n",
    "    print(\"creating dataset\")\n",
    "    validation_data = Data(\n",
    "        path=f\"./validation.jsonl\",\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        description=\"Validation dataset\",\n",
    "        name=validation_dataset_name,\n",
    "        version=\"1\",\n",
    "    )\n",
    "    validation_data_asset = workspace_ml_client.data.create_or_update(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data_asset.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Submit the fine tuning job using the the model and data as inputs\n",
    " \n",
    "Create FineTuning job using all the data that we have so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define finetune parameters\n",
    "\n",
    "##### There are following set of parameters that are required.\n",
    "\n",
    "1. `model` - Base model to finetune.\n",
    "2. `training_data` - Training data for finetuning the base model.\n",
    "3. `validation_data` - Validation data for finetuning the base model.\n",
    "4. `task` - FineTuning task to perform. eg. TEXT_COMPLETION for text-generation/text-generation finetuning jobs.\n",
    "5. `outputs`- Output registered model name.\n",
    "\n",
    "##### Following parameters are optional:\n",
    "\n",
    "1. `hyperparameters` - Parameters that control the FineTuning behavior at runtime.\n",
    "2. `name`- FineTuning job name\n",
    "3. `experiment_name` - Experiment name for FineTuning job.\n",
    "4. `display_name` - FineTuning job display name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.finetuning import FineTuningTaskType, create_finetuning_job\n",
    "import uuid\n",
    "\n",
    "guid = uuid.uuid4()\n",
    "short_guid = str(guid)[:8]\n",
    "display_name = f\"{model_name}-display-name-{short_guid}\"\n",
    "name = f\"finetuned-model-{short_guid}\"\n",
    "output_model_name_prefix = f\"finetuned-model-{short_guid}\"\n",
    "experiment_name = f\"finetuning-llm\"\n",
    "compute = \"nc96-lowpri-eastus\"\n",
    "\n",
    "finetuning_job = create_finetuning_job(\n",
    "    task=FineTuningTaskType.TEXT_COMPLETION,\n",
    "    training_data=train_data_asset.id,\n",
    "    validation_data=validation_data_asset.id,\n",
    "    hyperparameters={\n",
    "        \"per_device_train_batch_size\": \"1\",\n",
    "        \"learning_rate\": \"0.00002\",\n",
    "        \"num_train_epochs\": \"1\",\n",
    "    },\n",
    "    model=model_to_finetune.id,\n",
    "    display_name=display_name,\n",
    "    name=name,\n",
    "    experiment_name=experiment_name,\n",
    "    # compute=compute,\n",
    "    instance_types=[\"Standard_ND96amsr_A100_v4\", \"Standard_E4s_v3\"],\n",
    "    tags={\"foo_tag\": \"bar\"},\n",
    "    properties={\"my_property\": \"my_value\"},\n",
    "    output_model_name_prefix=output_model_name_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_job = workspace_ml_client.jobs.create_or_update(finetuning_job)\n",
    "workspace_ml_client.jobs.get(created_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for the above job to complete successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = workspace_ml_client.jobs.get(created_job.name).status\n",
    "\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    status = workspace_ml_client.jobs.get(created_job.name).status\n",
    "    print(f\"Current job status: {status}\")\n",
    "    if status in [\"Failed\", \"Completed\", \"Canceled\"]:\n",
    "        print(\"Job has finished with status: {0}\".format(status))\n",
    "        break\n",
    "    else:\n",
    "        print(\"Job is still running. Checking again in 30 seconds.\")\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if status in [\"Failed\", \"Canceled\"]:\n",
    "    print(\n",
    "        \"Job did not finish successfully. So no model to deploy. JobStatus: {0}\".format(\n",
    "            status\n",
    "        )\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model_output = created_job.outputs[\"registered_model\"]\n",
    "registered_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registered_model = workspace_ml_client.models.get(\n",
    "    name=registered_model_output.name, version=\"1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registered_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deploy the fine tuned model to an online endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create OnlineEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys, re\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    ProbeSettings,\n",
    "    OnlineRequestSettings,\n",
    ")\n",
    "\n",
    "sanitized_model_name_for_deployment = re.sub(r\"[^a-zA-Z0-9-]\", \"-\", model_name)\n",
    "online_endpoint_name = f\"{sanitized_model_name_for_deployment}\" + short_guid\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"Online endpoint for \"\n",
    "    + registered_model_output.name\n",
    "    + \", fine tuned model for samsum textgen\",\n",
    "    auth_mode=\"key\",\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can find the SKUS supported by the model for deployment with below command. You can choose one of the sku for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_to_finetune.properties[\"inference-recommended-sku\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=\"demo\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_NC24ads_A100_v4\",\n",
    "    instance_count=1,\n",
    "    liveness_probe=ProbeSettings(initial_delay=600),\n",
    "    request_settings=OnlineRequestSettings(request_timeout_ms=90000),\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {\"demo\": 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"{endpoint.scoring_uri}/v1/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0,\n",
    "    \"model\": \"llama-2\",\n",
    "    \"prompt\": \"The Seattle Seahawks\",\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"{auth_key}\"}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
