{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTuning LLM with Model-As-Platform.\n",
    "\n",
    "This sample shows how to create a standalone FineTuning job to fine tune a model to summarize a dialog between 2 people using samsum dataset. This notebook expects user will provide compute in the form of aml compute cluster or compute sku.\n",
    "\n",
    "#### Training data\n",
    "We use sample data placed along with the notebook for our finetuning in files \"train.jsonl\" and \"validation.jsonl\"\n",
    "\n",
    "#### Model\n",
    "We will use the Phi-3-mini-4k-instruct model to show how user can finetune a model for chat-completion task. If you opened this notebook from a specific model card, remember to replace the specific model name. \n",
    "\n",
    "#### Outline\n",
    "1. Setup pre-requisites\n",
    "2. Pick a model to fine-tune.\n",
    "3. Create training and validation datasets.\n",
    "4. Configure the fine tuning job.\n",
    "5. Submit the fine tuning job.\n",
    "6. Create online endpoint deployment using finetuned model and sample inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup pre-requisites\n",
    "* Install dependencies\n",
    "* Connect to AzureML Workspace. Learn more at [set up SDK authentication](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk). Replace  `<WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` below.\n",
    "* Connect to `azureml` system registry\n",
    "* Set an optional experiment name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install dependencies by running below cell. This is not an optional step if running in a new environment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml\n",
    "%pip install azure-identity\n",
    "\n",
    "%pip install mlflow\n",
    "%pip install azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "from azure.ai.ml.constants._common import AssetTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AzureML Workspace connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    workspace_ml_client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "        resource_group_name=\"<RESOURCE_GROUP>\",\n",
    "        workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    )\n",
    "\n",
    "# the models, fine tuning pipelines and environments are available in various AzureML system registries,\n",
    "# Example: Phi family of models are in \"azureml\"\n",
    "registry_ml_client = MLClient(credential, registry_name=\"azureml\")\n",
    "\n",
    "# Get AzureML workspace object.\n",
    "workspace = workspace_ml_client._workspaces.get(workspace_ml_client.workspace_name)\n",
    "workspace.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pick a model to fine tune\n",
    "\n",
    "`Phi-3-mini-4k-instruct` is a 3.8B parameters, lightweight, state-of-the-art open model built upon datasets used for Phi-2. The model belongs to the Phi-3 model family, and the Mini version comes in two variants 4K and 128K which is the context length (in tokens) it can support. You can browse these models in the Model Catalog in the Azure AI Studio, filtering by the `chat-completion` task. In this example, we use the `Phi-3-mini-4k-instruct` model. If you have opened this notebook for a different model, replace the model name and version accordingly.\n",
    "\n",
    "Note the model id property of the model. This will be passed as input to the fine tuning job. This is also available as the `Asset ID` field in model details page in Azure AI Studio Model Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Phi-3-mini-4k-instruct\"\n",
    "model_to_finetune = registry_ml_client.models.get(model_name, label=\"latest\")\n",
    "print(\n",
    "    \"\\n\\nUsing model name: {0}, version: {1}, id: {2} for fine tuning\".format(\n",
    "        model_to_finetune.name, model_to_finetune.version, model_to_finetune.id\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use either compute cluster or provide instance type which is compatible with below list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_to_finetune.properties[\"finetune-recommended-sku\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sample data\n",
    "\n",
    "The chat-completion dataset is stored in parquet format with each entry using the following schema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    {\n",
    "        \"messages\":[\",\n",
    "            {\",\n",
    "                \"content\": \"Create a fully-developed protagonist who is challenged to survive within a dystopian society under the rule of a tyrant. ...\",\n",
    "                \"role\": \"user\",\n",
    "            },\n",
    "            {\",\n",
    "                \"content\": \"Name: Ava\\n Ava was just 16 years old when the world as she knew it came crashing down. The government had collapsed, leaving behind a chaotic and lawless society. ...\",\n",
    "                \"role\": \"assistant\",\n",
    "            },\n",
    "            {\",\n",
    "                \"content\": \"Wow, Ava's story is so intense and inspiring! Can you provide me with more details.  ...\",\n",
    "                \"role\": \"user\",\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"Certainly! ....\",\n",
    "                \"role\": \"assistant\"\",\n",
    "            }\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Data\n",
    "\n",
    "dataset_version = \"1\"\n",
    "train_dataset_name = \"chat_training_small\"\n",
    "try:\n",
    "    train_data_asset = workspace_ml_client.data.get(\n",
    "        train_dataset_name, version=dataset_version\n",
    "    )\n",
    "    print(f\"Dataset {train_dataset_name} already exists\")\n",
    "except:\n",
    "    print(\"creating dataset\")\n",
    "    train_data = Data(\n",
    "        path=f\"./train.jsonl\",\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        description=\"Training dataset\",\n",
    "        name=train_dataset_name,\n",
    "        version=\"1\",\n",
    "    )\n",
    "    train_data_asset = workspace_ml_client.data.create_or_update(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_asset.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "\n",
    "dataset_version = \"1\"\n",
    "validation_dataset_name = \"chat_validation_small\"\n",
    "try:\n",
    "    validation_data_asset = workspace_ml_client.data.get(\n",
    "        validation_dataset_name, version=dataset_version\n",
    "    )\n",
    "    print(f\"Dataset {validation_dataset_name} already exists\")\n",
    "except:\n",
    "    print(\"creating dataset\")\n",
    "    validation_data = Data(\n",
    "        path=f\"./validation.jsonl\",\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        description=\"Validation dataset\",\n",
    "        name=validation_dataset_name,\n",
    "        version=\"1\",\n",
    "    )\n",
    "    validation_data_asset = workspace_ml_client.data.create_or_update(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data_asset.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Submit the fine tuning job using the the model and data as inputs\n",
    " \n",
    "Create FineTuning job using all the data that we have so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create marketplace subscription for 3P models\n",
    "Note: Skip this step for 1P(Microsoft) models that are offered on Azure. Example: Phi family of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define finetune parameters\n",
    "\n",
    "##### There are following set of parameters that are required.\n",
    "\n",
    "1. `name`- FineTuning job name\n",
    "2. `model` - Base model to finetune.\n",
    "3. `training_data` - Training data for finetuning the base model.\n",
    "4. `task` - FineTuning task to perform. eg. TEXT_COMPLETION for text-generation/text-generation finetuning jobs.\n",
    "5. `outputs`- Output registered model name.\n",
    "\n",
    "##### Following parameters are optional:\n",
    "\n",
    "1. `hyperparameters` - Parameters that control the FineTuning behavior at runtime.\n",
    "2. `validation_data` - Validation data for finetuning the base model.\n",
    "3. `experiment_name` - Experiment name for FineTuning job.\n",
    "4. `display_name` - FineTuning job display name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.finetuning import FineTuningTaskType, create_finetuning_job\n",
    "import uuid\n",
    "\n",
    "guid = uuid.uuid4()\n",
    "short_guid = str(guid)[:8]\n",
    "display_name = f\"{model_name}-display-name-{short_guid}\"\n",
    "name = f\"finetuned-model-{short_guid}\"\n",
    "output_model_name_prefix = f\"finetuned-model-{short_guid}\"\n",
    "experiment_name = f\"finetuning-llm\"\n",
    "compute = \"gpu-compute-low-pri\"\n",
    "\n",
    "finetuning_job = create_finetuning_job(\n",
    "    task=FineTuningTaskType.CHAT_COMPLETION,\n",
    "    training_data=train_data_asset.id,\n",
    "    validation_data=validation_data_asset.id,\n",
    "    hyperparameters={\n",
    "        \"per_device_train_batch_size\": \"1\",\n",
    "        \"learning_rate\": \"0.00002\",\n",
    "        \"num_train_epochs\": \"1\",\n",
    "    },\n",
    "    model=model_to_finetune.id,\n",
    "    display_name=display_name,\n",
    "    name=name,\n",
    "    experiment_name=experiment_name,\n",
    "    # compute=compute,\n",
    "    instance_types=[\"Standard_ND96amsr_A100_v4\", \"Standard_E4s_v3\"],\n",
    "    tags={\"foo_tag\": \"bar\"},\n",
    "    properties={\"my_property\": \"my_value\"},\n",
    "    output_model_name_prefix=output_model_name_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_job = workspace_ml_client.jobs.create_or_update(finetuning_job)\n",
    "workspace_ml_client.jobs.get(created_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for the above job to complete successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = workspace_ml_client.jobs.get(created_job.name).status\n",
    "\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    status = workspace_ml_client.jobs.get(created_job.name).status\n",
    "    print(f\"Current job status: {status}\")\n",
    "    if status in [\"Failed\", \"Completed\", \"Canceled\"]:\n",
    "        print(\"Job has finished with status: {0}\".format(status))\n",
    "        break\n",
    "    else:\n",
    "        print(\"Job is still running. Checking again in 30 seconds.\")\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if status in [\"Failed\", \"Canceled\"]:\n",
    "    print(\n",
    "        \"Job did not finish successfully. So no model to deploy. JobStatus: {0}\".format(\n",
    "            status\n",
    "        )\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model_output = created_job.outputs[\"registered_model\"]\n",
    "registered_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model = workspace_ml_client.models.get(\n",
    "    name=registered_model_output.name, version=\"1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deploy the fine tuned model to an online endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys, re\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    ProbeSettings,\n",
    "    OnlineRequestSettings,\n",
    ")\n",
    "\n",
    "sanitized_model_name_for_deployment = re.sub(r\"[^a-zA-Z0-9-]\", \"-\", model_name)\n",
    "online_endpoint_name = f\"{sanitized_model_name_for_deployment}-\" + short_guid\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"Online endpoint for \"\n",
    "    + registered_model_output.name\n",
    "    + \", fine tuned model for samsum textgen\",\n",
    "    auth_mode=\"key\",\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create a deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can find the SKUS supported by the model for deployment with below command. You can choose one of the sku for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundation_model.properties[\"inference-recommended-sku\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=\"demo\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_NC24ads_A100_v4\",\n",
    "    instance_count=1,\n",
    "    liveness_probe=ProbeSettings(initial_delay=600),\n",
    "    request_settings=OnlineRequestSettings(request_timeout_ms=90000),\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {\"demo\": 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"{endpoint.scoring_uri}/v1/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"max_tokens\": 1024,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"This script is great so far. Can you add more dialogue between Amanda and Thierry to build up their chemistry and connection?\",\n",
    "            \"role\": \"user\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"{auth_key}\"}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
