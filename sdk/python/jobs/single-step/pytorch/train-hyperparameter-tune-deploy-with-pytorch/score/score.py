import os
import torch
import torch.nn as nn
from torchvision import transforms
import json
import logging


def init():
    """
    This function is called when the container is initialized/started, typically after create/update of the deployment.
    You can write the logic here to perform init operations like caching the model in memory
    """
    global model
    # AZUREML_MODEL_DIR is an environment variable created during deployment.
    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)
    model_path = os.path.join(os.getenv("AZUREML_MODEL_DIR"), "outputs", "model.pt")
    # deserialize the model file back into a sklearn model
    model = torch.load(model_path, map_location=lambda storage, loc: storage)
    logging.info("Init complete")


def run(input_data):
    input_data = torch.tensor(json.loads(input_data)["data"])

    # get prediction
    with torch.no_grad():
        output = model(input_data)
        classes = ["chicken", "turkey"]
        softmax = nn.Softmax(dim=1)
        pred_probs = softmax(output).numpy()[0]
        index = torch.argmax(output, 1)

    result = {"label": classes[index], "probability": str(pred_probs[index])}
    return result
