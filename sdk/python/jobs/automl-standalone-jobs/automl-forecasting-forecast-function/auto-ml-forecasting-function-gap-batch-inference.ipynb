{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates the full interface of the `forecast()` function. \n",
    "\n",
    "The best known and most frequent usage of `forecast` enables forecasting on test sets that immediately follows training data. \n",
    "\n",
    "However, in many use cases it is necessary to continue using the model for some time before retraining it. This happens especially in **high frequency forecasting** when forecasts need to be made more frequently than the model can be retrained. Examples are in Internet of Things and predictive cloud resource scaling.\n",
    "\n",
    "Here we show how to use the `forecast()` function when a time gap exists between training data and prediction period.\n",
    "\n",
    "Terminology:\n",
    "* forecast origin: the last period when the target value is known\n",
    "* forecast periods(s): the period(s) for which the value of the target is desired.\n",
    "* lookback: how many past periods (before forecast origin) the model function depends on. The larger of number of lags and length of rolling window.\n",
    "* prediction context: `lookback` periods immediately preceding the forecast origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Model**  \n",
    "   We will need the MLflow model, which is downloaded at the end of the training notebook. Follow any training notebook to get the model. The MLflow model is usually downloaded to the folder: `./artifact_downloads/outputs/mlflow-model`.\n",
    "\n",
    "2. **Environment**  \n",
    "   We will need the environment to load the model. Please run the following commands to create the environment (the conda file is usually downloaded to: `./artifact_downloads/outputs/mlflow-model/conda.yaml`):\n",
    "   - `conda env create --file <path_to_conda_yaml>`\n",
    "   - `conda activate project_environment`\n",
    "\n",
    "3. **Register environment as kernel**  \n",
    "   - Please run the following command to register the environment as a kernel:  \n",
    "     ```bash\n",
    "     python -m ipykernel install --user --name project_environment --display-name \"model-inference\"\n",
    "     ```\n",
    "   - Refresh the kernel and then select the newly created kernel named `model-inference` from the kernel dropdown.\n",
    "   \n",
    "   Now we are good to run this notebook in the newly created kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TIME_COLUMN_NAME = \"date\"\n",
    "TIME_SERIES_ID_COLUMN_NAME = \"time_series_id\"\n",
    "TARGET_COLUMN_NAME = \"y\"\n",
    "lags = [1, 2, 3]\n",
    "forecast_horizon = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_parquet('./data/training-mltable-folder/df_train.parquet') # We stored the training and test data during training\n",
    "df_test = pd.read_parquet('./data/testing-mltable-folder/df_test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/72c03bf3-4e69-41af-9532-dfcdc3eefef4/resourceGroups/aml-benchmarking/providers/Microsoft.MachineLearningServices/workspaces/aml-benchmarking-rd\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "\n",
    "subscription_id = \"72c03bf3-4e69-41af-9532-dfcdc3eefef4\"#\"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"aml-benchmarking\"#\"<RESOURCE_GROUP>\"\n",
    "workspace = \"aml-benchmarking-rd\"#\"<AML_WORKSPACE_NAME>\"\n",
    "\n",
    "ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
    "    name=ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current tracking uri: azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/72c03bf3-4e69-41af-9532-dfcdc3eefef4/resourceGroups/aml-benchmarking/providers/Microsoft.MachineLearningServices/workspaces/aml-benchmarking-rd\n"
     ]
    }
   ],
   "source": [
    "# Set the MLFLOW TRACKING URI\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))\n",
    "\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.artifacts import download_artifacts\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Run: \n",
      "<Run: data=<RunData: metrics={'explained_variance': 0.9910013504019911,\n",
      " 'mean_absolute_error': 0.29282333566680235,\n",
      " 'mean_absolute_percentage_error': 1.118067051888466,\n",
      " 'median_absolute_error': 0.3040329750308685,\n",
      " 'normalized_mean_absolute_error': 0.011402639389141949,\n",
      " 'normalized_median_absolute_error': 0.011167830489974646,\n",
      " 'normalized_root_mean_squared_error': 0.013701302313198613,\n",
      " 'normalized_root_mean_squared_log_error': 0.00621450456108454,\n",
      " 'r2_score': 0.9863519731383007,\n",
      " 'root_mean_squared_error': 0.35499956438249874,\n",
      " 'root_mean_squared_log_error': 0.01294906396693142,\n",
      " 'spearman_correlation': 1.0}, params={}, tags={'automl_best_child_run_id': 'yellow_camera_1n84g0vcwp_4',\n",
      " 'fit_time_000': '0.891015;0.8447906666666666;0.880821;0.8549053333333333;0.9084923333333333;1.1095196666666667;1.1935733333333334;0.029423;0.4111286666666667;0.007625666666666667;0.009171;0.008983;0.008941333333333334;0.05766866666666667;0.008226666666666667;0.008711666666666666;0.008384;0.008851333333333334;0.041659;0.006776;0.008079333333333334;7',\n",
      " 'iteration_000': '0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21',\n",
      " 'mlflow.rootRunId': 'yellow_camera_1n84g0vcwp',\n",
      " 'mlflow.runName': 'yellow_camera_1n84g0vcwp',\n",
      " 'mlflow.user': 'Sampurna Goswami',\n",
      " 'model_explain_best_run_child_id': 'yellow_camera_1n84g0vcwp_4',\n",
      " 'model_explain_run': 'best_run',\n",
      " 'pipeline_id_000': '__AutoML_Naive__;__AutoML_SeasonalNaive__;__AutoML_Average__;__AutoML_SeasonalAverage__;__AutoML_ExponentialSmoothing__;__AutoML_Arimax__;__AutoML_Prophet__;faf12f74cf9bbd358ca5525682c5030d36f7be7c;4bc4ec47eb8df2d5d68b361cd60120e65196f757;2dc95d8bafd84221b8de309021c722b4fa570e77;25f83b241b8941c8c1f896a8338015dbab159f71;1ee8bbdda30f414fb76bee47d543cd5e109dcdf8;86f7c6ce026522eff88f32e647e3e27450da2679;6ea29a0b9fd1f634678397a456aaf8d4d853f689;7839ca66a0ff9be386363c852f0384a7b2a1c93f;4379608887dc335ce8c4ec4afbec7da03177d166;ae729f09378486945c70eb2a2306f8aa8f4e30a7;13907c2227a8ccd337dcfb9775a6091b777331e0;65d7c43a91915b98bea837d39e652767814c8983;3840ebb82b060782c0c1aaabbe352751ed0cb999;322472bb82968b4f37e85efa3a44571fd0e0a889;__AutoML_Ensemble__',\n",
      " 'predicted_cost_000': '0;0;0;0;0;0;0;0.5;0.5;0.5;0.5;0.5;0.5;0.5;0.5;0.5;0.5;0.5;0.5;0.5;0.0033159163343357283;0',\n",
      " 'run_algorithm_000': 'Naive;SeasonalNaive;Average;SeasonalAverage;ExponentialSmoothing;Arimax;ProphetModel;LightGBM;XGBoostRegressor;ElasticNet;ElasticNet;ElasticNet;ElasticNet;RandomForest;ElasticNet;ElasticNet;ElasticNet;ElasticNet;RandomForest;DecisionTree;DecisionTree;VotingEnsemble',\n",
      " 'run_preprocessor_000': ';;;;;;;StandardScalerWrapper;StandardScalerWrapper;MaxAbsScaler;RobustScaler;MinMaxScaler;StandardScalerWrapper;MinMaxScaler;MaxAbsScaler;StandardScalerWrapper;MaxAbsScaler;StandardScalerWrapper;MinMaxScaler;MinMaxScaler;RobustScaler;',\n",
      " 'score_000': '0.1527892437179229;0.3877640499212947;0.5201172235322448;0.5201172235322448;0.013701302313198613;0.01537853655489462;0.015032226562868933;0.16274812858535784;0.15504394673889124;0.23810221088799155;0.18780239394892953;0.21542307677493008;0.08846608782906884;0.25673134717003016;0.2908252684446397;0.027851739691573202;0.3277470047089184;0.0862038499678548;0.21687753509291793;0.1796310888210276;0.21672419545452093;0.015362224737705881',\n",
      " 'training_percent_000': '100;100;100;100;100;100;100;100;100;100;100;100;100;100;100;100;100;100;100;100;100;100'}>, info=<RunInfo: artifact_uri='azureml://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/72c03bf3-4e69-41af-9532-dfcdc3eefef4/resourceGroups/aml-benchmarking/providers/Microsoft.MachineLearningServices/workspaces/aml-benchmarking-rd/experiments/100950b6-552b-46ed-bc24-f80ac6d7c5e0/runs/yellow_camera_1n84g0vcwp/artifacts', end_time=1729236829546, experiment_id='100950b6-552b-46ed-bc24-f80ac6d7c5e0', lifecycle_stage='active', run_id='yellow_camera_1n84g0vcwp', run_name='yellow_camera_1n84g0vcwp', run_uuid='yellow_camera_1n84g0vcwp', start_time=1729235779545, status='FINISHED', user_id='8332a4ed-85df-4112-826d-a35a00b59d05'>, inputs=<RunInputs: dataset_inputs=[]>>\n"
     ]
    }
   ],
   "source": [
    "# job_name = returned_job.name\n",
    "# Example if providing an specific Job name/ID\n",
    "job_name = \"yellow_camera_1n84g0vcwp\"\n",
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
    "\n",
    "print(\"Parent Run: \")\n",
    "print(mlflow_parent_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best child run id:  yellow_camera_1n84g0vcwp_4\n",
      "Best child run: \n",
      "<Run: data=<RunData: metrics={'explained_variance': 0.9910013504019911,\n",
      " 'mean_absolute_error': 0.29282333566680235,\n",
      " 'mean_absolute_percentage_error': 1.118067051888466,\n",
      " 'median_absolute_error': 0.3040329750308685,\n",
      " 'normalized_mean_absolute_error': 0.011402639389141949,\n",
      " 'normalized_median_absolute_error': 0.011167830489974646,\n",
      " 'normalized_root_mean_squared_error': 0.013701302313198613,\n",
      " 'normalized_root_mean_squared_log_error': 0.00621450456108454,\n",
      " 'r2_score': 0.9863519731383007,\n",
      " 'root_mean_squared_error': 0.35499956438249874,\n",
      " 'root_mean_squared_log_error': 0.01294906396693142,\n",
      " 'spearman_correlation': 1.0}, params={}, tags={'mlflow.parentRunId': 'yellow_camera_1n84g0vcwp',\n",
      " 'mlflow.rootRunId': 'yellow_camera_1n84g0vcwp',\n",
      " 'mlflow.runName': 'ivory_bear_5j8y7myk',\n",
      " 'mlflow.user': 'Sampurna Goswami',\n",
      " 'model_explain_run_id': 'yellow_camera_1n84g0vcwp_ModelExplain',\n",
      " 'model_explanation': 'True'}>, info=<RunInfo: artifact_uri='azureml://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/72c03bf3-4e69-41af-9532-dfcdc3eefef4/resourceGroups/aml-benchmarking/providers/Microsoft.MachineLearningServices/workspaces/aml-benchmarking-rd/experiments/100950b6-552b-46ed-bc24-f80ac6d7c5e0/runs/yellow_camera_1n84g0vcwp_4/artifacts', end_time=1729236072867, experiment_id='100950b6-552b-46ed-bc24-f80ac6d7c5e0', lifecycle_stage='active', run_id='yellow_camera_1n84g0vcwp_4', run_name='ivory_bear_5j8y7myk', run_uuid='yellow_camera_1n84g0vcwp_4', start_time=1729236034603, status='FINISHED', user_id='8332a4ed-85df-4112-826d-a35a00b59d05'>, inputs=<RunInputs: dataset_inputs=[]>>\n"
     ]
    }
   ],
   "source": [
    "# Get the best model's child run\n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Found best child run id: \", best_child_run_id)\n",
    "\n",
    "best_run = mlflow_client.get_run(best_child_run_id)\n",
    "\n",
    "print(\"Best child run: \")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from azure.ai.ml.entities import (\n",
    "    Environment,\n",
    "    BatchEndpoint,\n",
    "    BatchDeployment,\n",
    "    BatchRetrySettings,\n",
    "    Model,\n",
    ")\n",
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "\n",
    "model_name = \"test-gap-batch-endpoint\"\n",
    "batch_endpoint_name = \"gap-batch-\" + datetime.datetime.now().strftime(\n",
    "    \"%m%d%H%M%f\"\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    path=f\"azureml://jobs/{best_run.info.run_id}/outputs/artifacts/outputs/model.pkl\",\n",
    "    name=model_name,\n",
    "    description=\"Gap prediction sample best model\",\n",
    ")\n",
    "registered_model = ml_client.models.create_or_update(model)\n",
    "\n",
    "env = Environment(\n",
    "    name=\"automl-tabular-env\",\n",
    "    description=\"environment for automl inference\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    conda_file=\"artifact_downloads/outputs/conda_env_v_1_0_0.yml\",\n",
    ")\n",
    "\n",
    "endpoint = BatchEndpoint(\n",
    "    name=batch_endpoint_name,\n",
    "    description=\"this is a sample batch endpoint\",\n",
    ")\n",
    "ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cluster_name = \"gap-cluster\"\n",
    "\n",
    "try:\n",
    "    # Retrieve an already attached Azure Machine Learning Compute.\n",
    "    compute = ml_client.compute.get(cluster_name)\n",
    "except ResourceNotFoundError as e:\n",
    "    compute = AmlCompute(\n",
    "        name=cluster_name,\n",
    "        size=\"STANDARD_DS12_V2\",\n",
    "        type=\"amlcompute\",\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        idle_time_before_scale_down=120,\n",
    "    )\n",
    "    poller = ml_client.begin_create_or_update(compute)\n",
    "    poller.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gap-batch-10241739762384'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"forecast.csv\"\n",
    "batch_deployment = BatchDeployment(\n",
    "    name=\"oj-non-mlflow-deployment\",\n",
    "    description=\"this is a sample non-mlflow deployment\",\n",
    "    endpoint_name=batch_endpoint_name,\n",
    "    model=registered_model,\n",
    "    code_path=\"./forecasting_script\",\n",
    "    scoring_script=\"forecasting_script.py\",\n",
    "    environment=env,\n",
    "    environment_variables={\n",
    "        \"TARGET_COLUMN_NAME\": TARGET_COLUMN_NAME,\n",
    "    },\n",
    "    compute=cluster_name,\n",
    "    instance_count=1, #2\n",
    "    max_concurrency_per_instance=1, #2\n",
    "    mini_batch_size=1, #10\n",
    "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "    output_file_name=output_file,\n",
    "    retry_settings=BatchRetrySettings(max_retries=3, timeout=30),\n",
    "    logging_level=\"info\",\n",
    "    properties={\"include_output_header\": \"true\"},\n",
    "    tags={\"include_output_header\": \"true\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.begin_create_or_update(batch_deployment).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "my_test_data_input = Input(\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    path=\"./data/testing-mltable-folder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x0000029EE13BDB20>,\n",
       "         subscription_id=72c03bf3-4e69-41af-9532-dfcdc3eefef4,\n",
       "         resource_group_name=aml-benchmarking,\n",
       "         workspace_name=aml-benchmarking-rd)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gap-batch-10241739762384'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'uri_folder', 'path': './data/testing-mltable-folder'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_test_data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=batch_endpoint_name,\n",
    "    input=my_test_data_input,\n",
    "    deployment_name=\"oj-non-mlflow-deployment\",  # name is required as default deployment is not set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n",
      "RunId: batchjob-f47ea9fe-132f-4b91-b038-ca19fb71c9be\n",
      "Web View: https://ml.azure.com/runs/batchjob-f47ea9fe-132f-4b91-b038-ca19fb71c9be?wsid=/subscriptions/72c03bf3-4e69-41af-9532-dfcdc3eefef4/resourcegroups/aml-benchmarking/workspaces/aml-benchmarking-rd\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2024-10-24 12:12:27Z] Submitting 1 runs, first five are: 16057eb9:658e18fb-67ae-4a36-bbdf-fd8db589f027\n",
      "[2024-10-24 12:20:40Z] Execution of experiment failed, update experiment status and cancel running nodes.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: batchjob-f47ea9fe-132f-4b91-b038-ca19fb71c9be\n",
      "Web View: https://ml.azure.com/runs/batchjob-f47ea9fe-132f-4b91-b038-ca19fb71c9be?wsid=/subscriptions/72c03bf3-4e69-41af-9532-dfcdc3eefef4/resourcegroups/aml-benchmarking/workspaces/aml-benchmarking-rd\n"
     ]
    },
    {
     "ename": "JobException",
     "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2024-10-24T12:20:40.0429Z\",\n    \"component_name\": \"\"\n} ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJobException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_job\u001b[38;5;241m.\u001b[39mstatus)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# stream the job logs\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sagoswami\\.conda\\envs\\sdkv2-test1\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\sagoswami\\.conda\\envs\\sdkv2-test1\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:289\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[0;32m    287\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[0;32m    288\u001b[0m         ):\n\u001b[1;32m--> 289\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "File \u001b[1;32mc:\\Users\\sagoswami\\.conda\\envs\\sdkv2-test1\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:818\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[38;5;241m=\u001b[39mjob_object\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m--> 818\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sagoswami\\.conda\\envs\\sdkv2-test1\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_ops_helper.py:334\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[1;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[0;32m    332\u001b[0m         file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[0;32m    335\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)),\n\u001b[0;32m    336\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[0;32m    337\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised on failed job.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    338\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[0;32m    339\u001b[0m         )\n\u001b[0;32m    341\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    342\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[1;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2024-10-24T12:20:40.0429Z\",\n    \"component_name\": \"\"\n} "
     ]
    }
   ],
   "source": [
    "job_name = job.name\n",
    "batch_job = ml_client.jobs.get(name=job_name)\n",
    "print(batch_job.status)\n",
    "# stream the job logs\n",
    "ml_client.jobs.stream(name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local inferencing from model pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml.training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m fitted_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlflow_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sagoswami\\.conda\\envs\\sdkv2-test1\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:638\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_uri, dst_path)\u001b[0m\n\u001b[0;32m    636\u001b[0m sklearn_model_artifacts_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(local_model_path, flavor_conf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickled_model\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    637\u001b[0m serialization_format \u001b[38;5;241m=\u001b[39m flavor_conf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_format\u001b[39m\u001b[38;5;124m\"\u001b[39m, SERIALIZATION_FORMAT_PICKLE)\n\u001b[1;32m--> 638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_local_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msklearn_model_artifacts_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialization_format\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sagoswami\\.conda\\envs\\sdkv2-test1\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:453\u001b[0m, in \u001b[0;36m_load_model_from_local_file\u001b[1;34m(path, serialization_format)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# Models serialized with Cloudpickle cannot necessarily be deserialized using Pickle;\u001b[39;00m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;66;03m# That's why we check the serialization format of the model before deserializing\u001b[39;00m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m serialization_format \u001b[38;5;241m==\u001b[39m SERIALIZATION_FORMAT_PICKLE:\n\u001b[1;32m--> 453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m serialization_format \u001b[38;5;241m==\u001b[39m SERIALIZATION_FORMAT_CLOUDPICKLE:\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcloudpickle\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azureml.training'"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import mlflow.sklearn\n",
    "# Please ensure that the training artifacts are downloaded. For more details refer to the training notebook\n",
    "mlflow_dir = \"./artifact_downloads/outputs/mlflow-model\"\n",
    "fitted_model = mlflow.sklearn.load_model(mlflow_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[df_train['time_series_id']==\"ts1\"].tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test[df_test['time_series_id']==\"ts1\"].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting from the trained model\n",
    "\n",
    "In this section we will review the forecast interface for two main scenarios: forecasting right after the training data, and the more complex interface for forecasting when there is a gap (in the time sense) between training and testing data.\n",
    "\n",
    "## X_train is directly followed by the X_test\n",
    "Let's first consider the case when the prediction period immediately follows the training data. This is typical in scenarios where we have the time to retrain the model every time we wish to forecast. Forecasts that are made on daily and slower cadence typically fall into this category. Retraining the model every time benefits the accuracy because the most recent data is often the most informative.\n",
    "\n",
    "\n",
    "<img src=\"./images/forecast_function_at_train.png\" alt=\"Description\" width=\"50%\">\n",
    "\n",
    "We use X_test as a forecast request to generate the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = df_test.copy()\n",
    "y_test = X_test.pop(TARGET_COLUMN_NAME).values.astype(float)\n",
    "\n",
    "y_pred_no_gap, xy_nogap = fitted_model.forecast(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confidence Intervals\n",
    "Forecasting model may be used for the prediction of forecasting intervals by running forecast_quantiles(). This method accepts the same parameters as forecast()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantiles = fitted_model.forecast_quantiles(X_test)\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Distribution forecasts\n",
    "Often the figure of interest is not just the point prediction, but the prediction at some quantile of the distribution. This arises when the forecast is used to control some kind of inventory, for example of grocery items or virtual machines for a cloud service. In such case, the control point is usually something like \"we want the item to be in stock and not run out 99% of the time\". This is called a \"service level\". Here is how you get quantile forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify which quantiles you would like\n",
    "fitted_model.quantiles = [0.01, 0.5, 0.95]\n",
    "\n",
    "# use forecast_quantiles function, not the forecast() one\n",
    "y_pred_quantiles = fitted_model.forecast_quantiles(X_test)\n",
    "\n",
    "# quantile forecasts returned in a Dataframe along with the time and time series id columns\n",
    "y_pred_quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting away from training data\n",
    "Suppose we trained a model, some time passed, and now we want to apply the model without re-training. If the model \"looks back\" -- uses previous values of the target -- then we somehow need to provide those values to the model.\n",
    "\n",
    "<img src=\"./images/forecast_function_away_from_train.png\" alt=\"Description\" width=\"50%\">\n",
    "\n",
    "The notion of forecast origin comes into play: **the forecast origin is the last period for which we have seen the target value.** This applies per time-series, so each time-series can have a different forecast origin.\n",
    "\n",
    "The part of data before the forecast origin is the **prediction context**. To provide the context values the model needs when it looks back, we pass definite values in y_test (aligned with corresponding times in X_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate the same kind of test data we trained on, but now make the train set much longer, so that the test set will be in the future\n",
    "from helper import get_timeseries, make_forecasting_query\n",
    "X_context, y_context, X_away, y_away = get_timeseries(\n",
    "    train_len=42,  # train data was 30 steps long\n",
    "    test_len=4,\n",
    "    time_column_name=TIME_COLUMN_NAME,\n",
    "    target_column_name=TARGET_COLUMN_NAME,\n",
    "    time_series_id_column_name=TIME_SERIES_ID_COLUMN_NAME,\n",
    "    time_series_number=2,\n",
    ")\n",
    "\n",
    "print(\"End of the data we trained on:\")\n",
    "print(df_train.groupby(TIME_SERIES_ID_COLUMN_NAME)[TIME_COLUMN_NAME].max())\n",
    "\n",
    "print(\"\\nStart of the data we want to predict on:\")\n",
    "print(X_away.groupby(TIME_SERIES_ID_COLUMN_NAME)[TIME_COLUMN_NAME].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a gap of 12 hours between end of training and beginning of X_away. (It looks like 13 because all timestamps point to the start of the one hour periods.) Using only X_away will fail without adding context data for the model to consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    y_pred_away, xy_away = fitted_model.forecast(X_away)\n",
    "    xy_away\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "How should we read that eror message? The forecast origin is at the last time the model saw an actual value of y (the target). That was at the end of the training data! The model is attempting to forecast from the end of training data. But the requested forecast periods are past the forecast horizon. We need to provide a define y value to establish the forecast origin.\n",
    "\n",
    "We will use the helper function to take the required amount of context from the data preceding the testing data. It's definition is intentionally simplified to keep the idea in the clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where the context data ends - it ends, by construction, just before the testing data starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    X_context.groupby(TIME_SERIES_ID_COLUMN_NAME)[TIME_COLUMN_NAME].agg(\n",
    "        [\"min\", \"max\", \"count\"]\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    X_away.groupby(TIME_SERIES_ID_COLUMN_NAME)[TIME_COLUMN_NAME].agg(\n",
    "        [\"min\", \"max\", \"count\"]\n",
    "    )\n",
    ")\n",
    "X_context.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "How should we read that eror message? The forecast origin is at the last time the model saw an actual value of y (the target). That was at the end of the training data! The model is attempting to forecast from the end of training data. But the requested forecast periods are past the forecast horizon. We need to provide a define y value to establish the forecast origin.\n",
    "\n",
    "We will use this helper function to take the required amount of context from the data preceding the testing data. It's definition is intentionally simplified to keep the idea in the clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since the length of the lookback is 3, we need to add 3 periods from the context to the request so that the model has the data it needs\n",
    "\n",
    "# Put the X and y back together for a while. They like each other and it makes them happy.\n",
    "X_context[TARGET_COLUMN_NAME] = y_context\n",
    "X_away[TARGET_COLUMN_NAME] = y_away\n",
    "fulldata = pd.concat([X_context, X_away])\n",
    "\n",
    "# Forecast origin is the last point of data, which is one 1-hr period before test\n",
    "forecast_origin = X_away[TIME_COLUMN_NAME].min() - pd.DateOffset(hours=1)\n",
    "# it is indeed the last point of the context\n",
    "assert forecast_origin == X_context[TIME_COLUMN_NAME].max()\n",
    "print(\"Forecast origin: \" + str(forecast_origin))\n",
    "\n",
    "# The model uses lags and rolling windows to look back in time\n",
    "n_lookback_periods = max(lags) # n_lookback_periods = max(max(lags), forecast_horizon) # If target_rolling_window_size is used\n",
    "lookback = pd.DateOffset(hours=n_lookback_periods)\n",
    "horizon = pd.DateOffset(hours=forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now make the forecast query from context (refer to figure)\n",
    "X_pred, y_pred = make_forecasting_query(\n",
    "    fulldata, TIME_COLUMN_NAME, TARGET_COLUMN_NAME, forecast_origin, horizon, lookback\n",
    ")\n",
    "\n",
    "# show the forecast request aligned\n",
    "X_show = X_pred.copy()\n",
    "X_show[TARGET_COLUMN_NAME] = y_pred\n",
    "X_show[X_show['time_series_id']==\"ts0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_pred['data_type']=\"unknown\"   # Our trining had an additional column called data_type, hence, adding it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now everything should work\n",
    "y_pred_away, xy_away = fitted_model.forecast(X_pred, y_pred)\n",
    "\n",
    "# show the forecast aligned without the generated features\n",
    "X_show = xy_away.reset_index()\n",
    "X_show[[\"date\", \"time_series_id\", \"ext_predictor\", \"_automl_target_col\"]] # prediction is in _automl_target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let us look at the tail of training data and the head of the test data for one grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[df_train['time_series_id']==\"ts1\"].tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a gap between the train and the test data, and the test data uses lags/ rolling forecasts, we need to append the context data such that the test data has access to the lags\n",
    "In the above case, train_data ends at 2000-01-02 05:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_show[X_show['time_series_id'] == \"ts1\"][[\"date\", \"time_series_id\", \"ext_predictor\", \"_automl_target_col\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting using batch endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "jialiu"
   }
  ],
  "category": "tutorial",
  "compute": [
   "Remote"
  ],
  "datasets": [
   "None"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Azure ML AutoML"
  ],
  "friendly_name": "Forecasting away from training data",
  "index_order": 3,
  "kernelspec": {
   "display_name": "sdkv2-test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "tags": [
   "Forecasting",
   "Confidence Intervals"
  ],
  "task": "Forecasting"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
