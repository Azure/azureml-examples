{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609, 15)   (122, 15)\n",
      "2012-08-31 00:00:00   2012-09-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "full_df = pd.read_csv(os.getcwd()+\"/data/bike-no.csv\")\n",
    "full_df['new_date'] = pd.to_datetime(full_df['date'], format = \"%m/%d/%Y\")\n",
    "\n",
    "# Filter by date\n",
    "train_df = full_df.loc[full_df['new_date'] < '2012-09-1'].copy()\n",
    "test_df = full_df.loc[(full_df['new_date'] >= '2012-09-1')].copy()\n",
    "print(train_df.shape,\" \",test_df.shape)\n",
    "print(train_df['new_date'].max(),\" \",test_df['new_date'].min())\n",
    "\n",
    "train_df['date'] = train_df['new_date'].dt.strftime('%Y-%m-%d')\n",
    "test_df['date'] = test_df['new_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "train_df.drop(columns=['new_date'],inplace = True)\n",
    "test_df.drop(columns=['new_date'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.getcwd()+\"/data/training-mltable-folder/bike-no-train.csv\",index = False)\n",
    "test_df.to_csv(os.getcwd()+\"/data/test-mltable-folder/bike-no-test.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/forecasting-bike-share/auto-ml-forecasting-bike-share.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning\n",
    "**BikeShare Demand Forecasting**\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Compute](#Compute)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Featurization](#Featurization)\n",
    "1. [Evaluate](#Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates demand forecasting for a bike-sharing service using AutoML.\n",
    "\n",
    "AutoML highlights here include built-in holiday featurization, accessing engineered feature names, and working with the `forecast` function. Please also look at the additional forecasting notebooks, which document lagging, rolling windows, forecast quantiles, other ways to use the forecast function, and forecaster deployment.\n",
    "\n",
    "Make sure you have executed the [configuration notebook](../../../configuration.ipynb) before running this notebook.\n",
    "\n",
    "Notebook synopsis:\n",
    "1. Creating an Experiment in an existing Workspace\n",
    "2. Configuration and local run of AutoML for a time-series model with lag and holiday features \n",
    "3. Viewing the engineered names for featurized data and featurization summary for all raw features\n",
    "4. Evaluating the fitted model using a rolling test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import automl\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is compatible with Azure ML SDK version 1.35.0 or later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the setup you have already created a <b>Workspace</b>. To run AutoML, you also need to create an <b>Experiment</b>. An Experiment corresponds to a prediction problem you are trying to solve, while a Run corresponds to a specific approach to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We could not find config.json in: . or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n"
     ]
    }
   ],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"381b38e9-9840-4719-a5a0-61d9585e1e91\" #\"<SUBSCRIPTION_ID>\"\n",
    "    resource_group =  \"sagoswami_southcentralus_rg\" #<RESOURCE_GROUP>\"\n",
    "    workspace =  'test'#'amlb69723617'#\"sagoswami_ws\" #<AML_WORKSPACE_NAME>\"\n",
    "    \n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Azure ML Workspace information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>381b38e9-9840-4719-a5a0-61d9585e1e91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>sagoswami_southcentralus_rg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>eastus2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     \n",
       "Workspace                                        test\n",
       "Subscription ID  381b38e9-9840-4719-a5a0-61d9585e1e91\n",
       "Resource Group            sagoswami_southcentralus_rg\n",
       "Location                                      eastus2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "workspace = ml_client.workspaces.get(name=ml_client.workspace_name)\n",
    "\n",
    "output = {}\n",
    "output[\"Workspace\"] = ml_client.workspace_name\n",
    "output[\"Subscription ID\"] = ml_client.connections._subscription_id\n",
    "output[\"Resource Group\"] = workspace.resource_group\n",
    "output[\"Location\"] = workspace.location\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "outputDf = pd.DataFrame(data=output, index=[\"\"])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute) for your AutoML run. In this tutorial, you create AmlCompute as your training compute resource.\n",
    "\n",
    "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist.\n",
    "\n",
    "#### Creation of AmlCompute takes approximately 5 minutes. \n",
    "If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "\n",
    "The [Machine Learning service workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-workspace) is paired with the storage account, which contains the default data store. We will use it to upload the bike share data and create [tabular dataset](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py) for training. A tabular dataset defines a series of lazily-evaluated, immutable operations to load data from the data source into tabular representation.\n",
    "\n",
    "With Azure Machine Learning MLTables you can keep a single copy of data in your storage, easily access data during model training, share data and collaborate with other users. \n",
    "Below, we will upload the data by creating an MLTable to be used for training.\n",
    "\n",
    "**NOTE:** In this PRIVATE PREVIEW we're defining the MLTable in a separate folder and .YAML file.\n",
    "In later versions, you'll be able to do it all in Python APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training MLTable defined locally, with local data to be uploaded\n",
    "my_training_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, path=\"./data/training-mltable-folder\"\n",
    ")\n",
    "\n",
    "# WITH REMOTE PATH\n",
    "# my_training_data_input  = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/my-forecasting-mltable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "os.makedirs(\"test_dataset\", exist_ok=True)\n",
    "shutil.copy(\n",
    "    \"data/test-mltable-folder/bike-no-test.csv\",\n",
    "    \"test_dataset/bike-no-test.csv\",\n",
    ")\n",
    "\n",
    "my_test_data_input = Input(\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    path=\"test_dataset/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will upload the dirrectory with the test set so that further we will be able to run the inferencing on the batch endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'mltable', 'path': './data/training-mltable-folder'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_training_data_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create or Attach existing AmlCompute.\n",
    "[Azure Machine Learning Compute](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute) is a managed-compute infrastructure that allows the user to easily create a single or multi-node compute. In this tutorial, you create AmlCompute as your training compute resource.\n",
    "\n",
    "#### Creation of AmlCompute takes approximately 5 minutes. \n",
    "If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cluster_name = \"bike-share-v2\"\n",
    "\n",
    "try:\n",
    "    # Retrieve an already attached Azure Machine Learning Compute.\n",
    "    compute = ml_client.compute.get(cluster_name)\n",
    "except ResourceNotFoundError as e:\n",
    "    compute = AmlCompute(\n",
    "        name=cluster_name,\n",
    "        size=\"STANDARD_DS12_V2\",\n",
    "        type=\"amlcompute\",\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        idle_time_before_scale_down=120,\n",
    "    )\n",
    "    poller = ml_client.begin_create_or_update(compute)\n",
    "    poller.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure and run the AutoML Forecasting training job\n",
    "In this section we will configure and run the AutoML job, for training the model.\n",
    "\n",
    "### 4.1 Configure the job through the forecasting() factory function\n",
    "\n",
    "#### forecasting() function parameters:\n",
    "\n",
    "The `forecasting()` factory function allows user to configure AutoML for the forecasting task for the most common scenarios with the following properties.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**target_column_name**|The name of the label column.|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n",
    "|**training_data**|The training data to be used within the experiment. You can use a registered MLTable in the workspace using the format '&lt;mltable_name&gt;:&lt;version\\&gt;' OR you can use a local file or folder as a MLTable. For e.g Input(mltable='my_mltable:1') OR Input(mltable=MLTable(local_path=\"./data\")) The parameter 'training_data' must always be provided.|\n",
    "|**compute**|The compute on which the AutoML job will run. In this example we are using a compute called 'cpu-cluster' present in the workspace. You can replace it any other compute in the workspace.|\n",
    "|**n_cross_validations**|Number of cross-validation folds to use for model/pipeline selection. The default value is \"auto\", in which case AutoMl determines the number of cross-validations automatically, if a validation set is not provided. Or users could specify an integer value.|\n",
    "|**name**|The name of the Job/Run. This is an optional property. If not specified, a random name will be generated.\n",
    "|**experiment_name**|The name of the Experiment. An Experiment is like a folder with multiple runs in Azure ML Workspace that should be related to the same logical machine learning experiment.|\n",
    "|**enable_model_explainability**|If set to true, the explanations for the best model will be generated.|\n",
    "\n",
    "### set_limits() parameters:\n",
    "This is an optional configuration method to configure limits parameters such as timeouts.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**timeout_minutes**|Maximum amount of time in minutes that the whole AutoML job can take before the job terminates. This timeout includes setup, featurization and training runs but does not include the ensembling and model explainability runs at the end of the process since those actions need to happen once all the trials (children jobs) are done. If not specified, the default job's total timeout is 6 days (8,640 minutes). To specify a timeout less than or equal to 1 hour (60 minutes), make sure your dataset's size is not greater than 10,000,000 (rows times column) or an error results.|\n",
    "|**trial_timeout_minutes**|Maximum time in minutes that each trial (child job) can run for before it terminates. If not specified, a value of 1 month or 43200 minutes is used.|\n",
    "|**max_trials**|The maximum number of trials/runs each with a different combination of algorithm and hyperparameters to try during an AutoML job. If not specified, the default is 1000 trials. If using 'enable_early_termination' the number of trials used can be smaller.|\n",
    "|**max_concurrent_trials**|Represents the maximum number of trials (children jobs) that would be executed in parallel. It's a good practice to match this number with the number of nodes your cluster.|\n",
    "|**enable_early_termination**|Whether to enable early termination if the score is not improving in the short term.|\n",
    "\n",
    "### Specialized Forecasting Parameters\n",
    "To define forecasting parameters for your experiment training, you can leverage the .set_forecast_settings() method. \n",
    "The table below details the forecasting parameters we will be passing into our experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**time_column_name**|The name of your time column.|\n",
    "|**forecast_horizon**|The forecast horizon is how many periods forward you would like to forecast. This integer horizon is in units of the timeseries frequency (e.g. daily, weekly).|\n",
    "|**frequency**|Forecast frequency. This optional parameter represents the period with which the forecast is desired, for example, daily, weekly, yearly, etc. Use this parameter for the correction of time series containing irregular data points or for padding of short time series. The frequency needs to be a pandas offset alias. Please refer to [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects) for more information.\n",
    "|**cv_step_size**|Number of periods between two consecutive cross-validation folds. The default value is \"auto\", in which case AutoMl determines the cross-validation step size automatically, if a validation set is not provided. Or users could specify an integer value.|\n",
    "|**target_lags**|The target_lags specifies how far back we will construct the lags of the target variable.|\n",
    "|**target_rolling_window_size**|The target_rolling_window_size specifies the size of a rolling window for aggregated lookback features.|\n",
    "\n",
    "### Using lags and rolling window features\n",
    "This training is also using the **target lags**, that is the previous values of the target variables, meaning the prediction uses a horizon. We therefore must still specify the `forecast_horizon` that the model will learn to forecast. The `target_lags` keyword specifies how far back we will construct the lags of the target variable, and the `target_rolling_window_size` specifies the size of the rolling window over which we will generate the `max`, `min` and `sum` features.\n",
    "\n",
    "This notebook uses the .set_training(blocked_training_algorithms=...) parameter to exclude some models that take a longer time to train on this dataset.  You can choose to remove models from the blocked_training_algorithms list but you may need to increase the trial_timeout_minutes parameter value to get results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up what we know about the dataset. \n",
    "\n",
    "**Target column** is what we want to forecast.\n",
    "\n",
    "**Time column** is the time axis along which to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general job parameters\n",
    "max_trials = 5\n",
    "exp_name = \"dpv2-bike-test\"#forecasting-experiment\"\n",
    "target_column_name = \"cnt\"\n",
    "time_column_name = \"date\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting forecaster maximum horizon \n",
    "\n",
    "The forecast horizon is the number of periods into the future that the model should predict. Here, we set the horizon to 14 periods (i.e. 14 days). Notice that this is much shorter than the number of days in the test set; we will need to use a rolling test to evaluate the performance on the whole test set. For more discussion of forecast horizons and guiding principles for setting them, please see the [energy demand notebook](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/automated-machine-learning/forecasting-energy-demand).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class ForecastingJob: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "# Create the AutoML forecasting job with the related factory-function.\n",
    "#######################mising param#############\n",
    "#country_or_region_for_holidays=\"US\",  # set country_or_region will trigger holiday featurizer\n",
    "#cv_step_size=\"auto\",\n",
    "#n_cross_validations=\"auto\", \n",
    "# Force the target column, to be integer type.\n",
    "\n",
    "##########################################\n",
    "forecasting_job = automl.forecasting(\n",
    "    compute=cluster_name,\n",
    "    # name=\"dpv2-forecasting-job-02\",\n",
    "    experiment_name=exp_name,\n",
    "    training_data=my_training_data_input,\n",
    "    # validation_data = my_validation_data_input,\n",
    "    target_column_name=target_column_name,\n",
    "    primary_metric=\"NormalizedRootMeanSquaredError\",\n",
    "    n_cross_validations=3,\n",
    "    enable_model_explainability=True,\n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "forecasting_job.set_limits(\n",
    "    timeout_minutes=60,\n",
    "    trial_timeout_minutes=20, #20 change\n",
    "    max_trials=max_trials,\n",
    "    enable_early_termination=True,\n",
    "    max_concurrent_trials=4,\n",
    ")\n",
    "\n",
    "# Specialized properties for Time Series Forecasting training\n",
    "forecasting_job.set_forecast_settings(\n",
    "    time_column_name=time_column_name,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    frequency=\"D\",\n",
    "    # target_lags=\"auto\", #it is [12] in Nikolay \n",
    "    country_or_region_for_holidays=\"US\",\n",
    "    #enable_stack_ensemble=False,\n",
    "    #target_rolling_window_size=4,\n",
    "    #cv_step_size=1,# it should be auto\n",
    ")\n",
    "\n",
    "# Training properties are optional\n",
    "forecasting_job.set_training(blocked_training_algorithms=[\"ExtremeRandomTrees\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Run the Command\n",
    "Using the `MLClient` created earlier, we will now run this Command in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading training-mltable-folder (0.14 MBs): 100%|##########| 136269/136269 [00:01<00:00, 68295.22it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job: ForecastingJob({'log_verbosity': <LogVerbosity.INFO: 'Info'>, 'target_column_name': 'cnt', 'weight_column_name': None, 'validation_data_size': None, 'cv_split_column_names': None, 'n_cross_validations': 3, 'test_data_size': None, 'task_type': <TaskType.FORECASTING: 'Forecasting'>, 'training_data': {'type': 'mltable', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/1c805cddcc0530df1fc249107d8c6d02/training-mltable-folder'}, 'validation_data': {'type': 'mltable'}, 'test_data': None, 'environment_id': None, 'environment_variables': None, 'outputs': {}, 'type': 'automl', 'status': 'NotStarted', 'log_files': None, 'name': 'helpful_clock_sxgnphy4vg', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/Azure/azureml-examples.git', 'mlflow.source.git.branch': 'sagoswami/update_bike_share_v2', 'mlflow.source.git.commit': '5de802c1e9f94feececb6faf5dd7f1bad0c63433', 'azureml.git.dirty': 'True'}, 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sagoswami_southcentralus_rg/providers/Microsoft.MachineLearningServices/workspaces/test/jobs/helpful_clock_sxgnphy4vg', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\sagoswami\\\\projects\\\\azureml-examples\\\\sdk\\\\python\\\\jobs\\\\automl-standalone-jobs\\\\automl-forecasting-task-bike-share', 'creation_context': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.SystemData object at 0x0000025500B01AF0>, 'serialize': <msrest.serialization.Serializer object at 0x0000025500B01370>, 'inputs': {}, 'display_name': 'helpful_clock_sxgnphy4vg', 'experiment_name': 'dpv2-bike-test', 'compute': 'bike-share-v2', 'services': {'Tracking': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x0000025500B015B0>, 'Studio': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x0000025500B015E0>}, 'resources': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobResourceConfiguration object at 0x0000025500B01280>, 'identity': None, 'featurization': None, 'limits': <azure.ai.ml.entities._job.automl.tabular.limit_settings.TabularLimitSettings object at 0x000002556CB20400>, 'training': <azure.ai.ml.entities._job.automl.training_settings.ForecastingTrainingSettings object at 0x000002556CB20250>, 'primary_metric': <ForecastingPrimaryMetrics.NORMALIZED_ROOT_MEAN_SQUARED_ERROR: 'NormalizedRootMeanSquaredError'>, 'forecasting_settings': <azure.ai.ml.entities._job.automl.tabular.forecasting_settings.ForecastingSettings object at 0x00000255007F74F0>})\n"
     ]
    }
   ],
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    forecasting_job\n",
    ")  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: helpful_clock_sxgnphy4vg\n",
      "Web View: https://ml.azure.com/runs/helpful_clock_sxgnphy4vg?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/sagoswami_southcentralus_rg/workspaces/test\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: helpful_clock_sxgnphy4vg\n",
      "Web View: https://ml.azure.com/runs/helpful_clock_sxgnphy4vg?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/sagoswami_southcentralus_rg/workspaces/test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wait until AutoML training runs are finished\n",
    "ml_client.jobs.stream(returned_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieve the Best Trial (Best Model's trial/run)\n",
    "Use the MLFLowClient to access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Initialize MLFlow Client\n",
    "The models and artifacts that are produced by AutoML can be accessed via the MLFlow interface. \n",
    "Initialize the MLFlow client here, and set the backend as Azure ML, via. the MLFlow Client.\n",
    "\n",
    "*IMPORTANT*, you need to have installed the latest MLFlow packages with:\n",
    "\n",
    "    pip install azureml-mlflow\n",
    "\n",
    "    //pip install mlflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain the tracking URI for MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sagoswami_southcentralus_rg/providers/Microsoft.MachineLearningServices/workspaces/test\n",
      "\n",
      "Current tracking uri: azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sagoswami_southcentralus_rg/providers/Microsoft.MachineLearningServices/workspaces/test\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
    "    name=ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)\n",
    "\n",
    "# Set the MLFLOW TRACKING URI\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the AutoML parent Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Run: \n",
      "<Run: data=<RunData: metrics={'explained_variance': 0.1114027759125406,\n",
      " 'mean_absolute_error': 661.0210884353742,\n",
      " 'mean_absolute_percentage_error': 10.931066218715648,\n",
      " 'median_absolute_error': 450.93333333333356,\n",
      " 'normalized_mean_absolute_error': 0.08334649961358898,\n",
      " 'normalized_median_absolute_error': 0.056857058798806405,\n",
      " 'normalized_root_mean_squared_error': 0.11385744861162471,\n",
      " 'normalized_root_mean_squared_log_error': 0.04995799377339727,\n",
      " 'r2_score': 0.10792264429026525,\n",
      " 'root_mean_squared_error': 903.0034249387954,\n",
      " 'root_mean_squared_log_error': 0.1480328746365164,\n",
      " 'spearman_correlation': 0.36915099580121574}, params={}, tags={'_azureml.ComputeTargetType': 'STANDARD_DS12_V2',\n",
      " 'automl_best_child_run_id': 'helpful_clock_sxgnphy4vg_4',\n",
      " 'fit_time': '<0.05379433333333333>;<0.041014666666666665>;<0.05559466666666666>;<0.04250933333333332>;<3>;',\n",
      " 'iteration': '<1>;<0>;<2>;<3>;<4>;',\n",
      " 'mlflow.rootRunId': 'helpful_clock_sxgnphy4vg',\n",
      " 'mlflow.runName': 'helpful_clock_sxgnphy4vg',\n",
      " 'mlflow.user': 'Sampurna Goswami',\n",
      " 'model_explain_best_run_child_id': 'helpful_clock_sxgnphy4vg_4',\n",
      " 'model_explain_run': 'best_run',\n",
      " 'pipeline_id': '<__AutoML_SeasonalNaive__>;<__AutoML_Naive__>;<__AutoML_Average__>;<__AutoML_SeasonalAverage__>;<__AutoML_Ensemble__>;',\n",
      " 'predicted_cost': '<0>;<0>;<0>;<0>;<0>;',\n",
      " 'run_algorithm': '<SeasonalNaive>;<Naive>;<Average>;<SeasonalAverage>;<VotingEnsemble>;',\n",
      " 'run_preprocessor': '<>;<>;<>;<>;<>;',\n",
      " 'score': '<0.11669651439395544>;<0.13636973162301635>;<0.36056973908167533>;<0.12192637204203947>;<0.11385744861162471>;',\n",
      " 'training_percent': '<100>;<100>;<100>;<100>;<100>;'}>, info=<RunInfo: artifact_uri='azureml://experiments/dpv2-bike-test/runs/helpful_clock_sxgnphy4vg/artifacts', end_time=1665415582573, experiment_id='e033e2a5-abda-4d5d-888e-a81f94780443', lifecycle_stage='active', run_id='helpful_clock_sxgnphy4vg', run_uuid='helpful_clock_sxgnphy4vg', start_time=1665415154636, status='FINISHED', user_id='8332a4ed-85df-4112-826d-a35a00b59d05'>>\n"
     ]
    }
   ],
   "source": [
    "job_name = returned_job.name\n",
    "\n",
    "# Example if providing an specific Job name/ID\n",
    "# job_name = \"591640e8-0f88-49c5-adaa-39b9b9d75531\"\n",
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
    "\n",
    "print(\"Parent Run: \")\n",
    "print(mlflow_parent_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_explain_run': 'best_run', '_azureml.ComputeTargetType': 'STANDARD_DS12_V2', 'pipeline_id': '<__AutoML_SeasonalNaive__>;<__AutoML_Naive__>;<__AutoML_Average__>;<__AutoML_SeasonalAverage__>;<__AutoML_Ensemble__>;', 'score': '<0.11669651439395544>;<0.13636973162301635>;<0.36056973908167533>;<0.12192637204203947>;<0.11385744861162471>;', 'predicted_cost': '<0>;<0>;<0>;<0>;<0>;', 'fit_time': '<0.05379433333333333>;<0.041014666666666665>;<0.05559466666666666>;<0.04250933333333332>;<3>;', 'training_percent': '<100>;<100>;<100>;<100>;<100>;', 'iteration': '<1>;<0>;<2>;<3>;<4>;', 'run_preprocessor': '<>;<>;<>;<>;<>;', 'run_algorithm': '<SeasonalNaive>;<Naive>;<Average>;<SeasonalAverage>;<VotingEnsemble>;', 'automl_best_child_run_id': 'helpful_clock_sxgnphy4vg_4', 'model_explain_best_run_child_id': 'helpful_clock_sxgnphy4vg_4', 'mlflow.rootRunId': 'helpful_clock_sxgnphy4vg', 'mlflow.runName': 'helpful_clock_sxgnphy4vg', 'mlflow.user': 'Sampurna Goswami'}\n"
     ]
    }
   ],
   "source": [
    "# Print parent run tags. 'automl_best_child_run_id' tag should be there.\n",
    "print(mlflow_parent_run.data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the AutoML best child run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best child run id:  helpful_clock_sxgnphy4vg_4\n",
      "Best child run: \n",
      "<Run: data=<RunData: metrics={'explained_variance': 0.1114027759125406,\n",
      " 'mean_absolute_error': 661.0210884353742,\n",
      " 'mean_absolute_percentage_error': 10.931066218715648,\n",
      " 'median_absolute_error': 450.93333333333356,\n",
      " 'normalized_mean_absolute_error': 0.08334649961358898,\n",
      " 'normalized_median_absolute_error': 0.056857058798806405,\n",
      " 'normalized_root_mean_squared_error': 0.11385744861162471,\n",
      " 'normalized_root_mean_squared_log_error': 0.04995799377339727,\n",
      " 'r2_score': 0.10792264429026525,\n",
      " 'root_mean_squared_error': 903.0034249387954,\n",
      " 'root_mean_squared_log_error': 0.1480328746365164,\n",
      " 'spearman_correlation': 0.36915099580121574}, params={}, tags={'mlflow.parentRunId': 'helpful_clock_sxgnphy4vg',\n",
      " 'mlflow.rootRunId': 'helpful_clock_sxgnphy4vg',\n",
      " 'mlflow.runName': 'goofy_cheese_7nchp071',\n",
      " 'mlflow.source.name': 'automl_driver.py',\n",
      " 'mlflow.source.type': 'JOB',\n",
      " 'mlflow.user': 'Sampurna Goswami',\n",
      " 'model_explain_run_id': 'helpful_clock_sxgnphy4vg_ModelExplain',\n",
      " 'model_explanation': 'True'}>, info=<RunInfo: artifact_uri='azureml://experiments/dpv2-bike-test/runs/helpful_clock_sxgnphy4vg_4/artifacts', end_time=1665415580908, experiment_id='e033e2a5-abda-4d5d-888e-a81f94780443', lifecycle_stage='active', run_id='helpful_clock_sxgnphy4vg_4', run_uuid='helpful_clock_sxgnphy4vg_4', start_time=1665415538909, status='FINISHED', user_id='8332a4ed-85df-4112-826d-a35a00b59d05'>>\n"
     ]
    }
   ],
   "source": [
    "# Get the best model's child run\n",
    "\n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Found best child run id: \", best_child_run_id)\n",
    "\n",
    "best_run = mlflow_client.get_run(best_child_run_id)\n",
    "\n",
    "print(\"Best child run: \")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Get best model run's metrics\n",
    "\n",
    "Access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_log_error</th>\n",
       "      <td>0.148033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_median_absolute_error</th>\n",
       "      <td>0.056857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>661.021088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_correlation</th>\n",
       "      <td>0.369151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_root_mean_squared_log_error</th>\n",
       "      <td>0.049958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explained_variance</th>\n",
       "      <td>0.111403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_mean_absolute_error</th>\n",
       "      <td>0.083346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_absolute_error</th>\n",
       "      <td>450.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_root_mean_squared_error</th>\n",
       "      <td>0.113857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <td>10.931066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_score</th>\n",
       "      <td>0.107923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <td>903.003425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0\n",
       "root_mean_squared_log_error               0.148033\n",
       "normalized_median_absolute_error          0.056857\n",
       "mean_absolute_error                     661.021088\n",
       "spearman_correlation                      0.369151\n",
       "normalized_root_mean_squared_log_error    0.049958\n",
       "explained_variance                        0.111403\n",
       "normalized_mean_absolute_error            0.083346\n",
       "median_absolute_error                   450.933333\n",
       "normalized_root_mean_squared_error        0.113857\n",
       "mean_absolute_percentage_error           10.931066\n",
       "r2_score                                  0.107923\n",
       "root_mean_squared_error                 903.003425"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(best_run.data.metrics, index=[0]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model evaluation and deployemnt.\n",
    "### 6.1 Download the best model locally\n",
    "\n",
    "Access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local folder\n",
    "import os\n",
    "\n",
    "local_dir = \"./artifact_downloads\"\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts downloaded in: c:\\Users\\sagoswami\\projects\\azureml-examples\\sdk\\python\\jobs\\automl-standalone-jobs\\automl-forecasting-task-bike-share\\artifact_downloads\\outputs\n",
      "Artifacts: ['conda_env_v_1_0_0.yml', 'engineered_feature_names.json', 'env_dependencies.json', 'featurization_summary.json', 'internal_cross_validated_models.pkl', 'mlflow-model', 'model.pkl', 'pipeline_graph.json', 'run_id.txt', 'scoring_file_pbi_v_1_0_0.py', 'scoring_file_v_1_0_0.py', 'scoring_file_v_2_0_0.py']\n"
     ]
    }
   ],
   "source": [
    "# Download run's artifacts/outputs\n",
    "local_path = mlflow_client.download_artifacts(\n",
    "    best_run.info.run_id, \"outputs\", local_dir\n",
    ")\n",
    "print(\"Artifacts downloaded in: {}\".format(local_path))\n",
    "print(\"Artifacts: {}\".format(os.listdir(local_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conda.yaml', 'MLmodel', 'model.pkl', 'python_env.yaml', 'requirements.txt']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the contents of the MLFlow model folder\n",
    "os.listdir(\"./artifact_downloads/outputs/mlflow-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization\n",
    "We can look at the engineered feature names generated in time-series featurization via. the JSON file named 'engineered_feature_names.json' under the run outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instant',\n",
       " 'season',\n",
       " 'yr',\n",
       " 'mnth',\n",
       " 'weekday',\n",
       " 'weathersit',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'hum',\n",
       " 'windspeed',\n",
       " 'casual',\n",
       " 'registered',\n",
       " '_automl_target_col_WASNULL',\n",
       " 'instant_WASNULL',\n",
       " 'season_WASNULL',\n",
       " 'yr_WASNULL',\n",
       " 'mnth_WASNULL',\n",
       " 'weekday_WASNULL',\n",
       " 'weathersit_WASNULL',\n",
       " 'temp_WASNULL',\n",
       " 'atemp_WASNULL',\n",
       " 'hum_WASNULL',\n",
       " 'windspeed_WASNULL',\n",
       " 'casual_WASNULL',\n",
       " 'registered_WASNULL',\n",
       " '_automl_year',\n",
       " '_automl_year_iso',\n",
       " '_automl_half',\n",
       " '_automl_quarter',\n",
       " '_automl_month',\n",
       " '_automl_day',\n",
       " '_automl_wday',\n",
       " '_automl_qday',\n",
       " '_automl_week',\n",
       " '_automl_IsPaidTimeOff',\n",
       " '_automl_Holiday_1 day after Christmas Day',\n",
       " '_automl_Holiday_1 day after Columbus Day',\n",
       " '_automl_Holiday_1 day after Independence Day',\n",
       " '_automl_Holiday_1 day after Labor Day',\n",
       " '_automl_Holiday_1 day after Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_1 day after Memorial Day',\n",
       " \"_automl_Holiday_1 day after New Year's Day\",\n",
       " '_automl_Holiday_1 day after Thanksgiving',\n",
       " '_automl_Holiday_1 day after Veterans Day',\n",
       " \"_automl_Holiday_1 day after Washington's Birthday\",\n",
       " '_automl_Holiday_1 day before Christmas Day',\n",
       " '_automl_Holiday_1 day before Columbus Day',\n",
       " '_automl_Holiday_1 day before Independence Day',\n",
       " '_automl_Holiday_1 day before Labor Day',\n",
       " '_automl_Holiday_1 day before Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_1 day before Memorial Day',\n",
       " '_automl_Holiday_1 day before Thanksgiving',\n",
       " '_automl_Holiday_1 day before Veterans Day',\n",
       " \"_automl_Holiday_1 day before Washington's Birthday\",\n",
       " '_automl_Holiday_10 days after Thanksgiving',\n",
       " '_automl_Holiday_10 days before Christmas Day',\n",
       " '_automl_Holiday_2 days after Christmas Day',\n",
       " '_automl_Holiday_2 days after Columbus Day',\n",
       " '_automl_Holiday_2 days after Independence Day',\n",
       " '_automl_Holiday_2 days after Labor Day',\n",
       " '_automl_Holiday_2 days after Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_2 days after Memorial Day',\n",
       " \"_automl_Holiday_2 days after New Year's Day\",\n",
       " '_automl_Holiday_2 days after Thanksgiving',\n",
       " '_automl_Holiday_2 days after Veterans Day',\n",
       " \"_automl_Holiday_2 days after Washington's Birthday\",\n",
       " '_automl_Holiday_2 days before Christmas Day',\n",
       " '_automl_Holiday_2 days before Columbus Day',\n",
       " '_automl_Holiday_2 days before Independence Day',\n",
       " '_automl_Holiday_2 days before Labor Day',\n",
       " '_automl_Holiday_2 days before Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_2 days before Memorial Day',\n",
       " '_automl_Holiday_2 days before Thanksgiving',\n",
       " '_automl_Holiday_2 days before Veterans Day',\n",
       " \"_automl_Holiday_2 days before Washington's Birthday\",\n",
       " '_automl_Holiday_3 days after Christmas Day',\n",
       " '_automl_Holiday_3 days after Columbus Day',\n",
       " '_automl_Holiday_3 days after Independence Day',\n",
       " \"_automl_Holiday_3 days after New Year's Day\",\n",
       " '_automl_Holiday_3 days after Thanksgiving',\n",
       " '_automl_Holiday_3 days after Veterans Day',\n",
       " '_automl_Holiday_3 days before Christmas Day',\n",
       " '_automl_Holiday_3 days before Columbus Day',\n",
       " '_automl_Holiday_3 days before Independence Day',\n",
       " '_automl_Holiday_3 days before Thanksgiving',\n",
       " '_automl_Holiday_3 days before Veterans Day',\n",
       " '_automl_Holiday_4 days after Christmas Day',\n",
       " '_automl_Holiday_4 days after Columbus Day',\n",
       " '_automl_Holiday_4 days after Independence Day',\n",
       " \"_automl_Holiday_4 days after New Year's Day\",\n",
       " '_automl_Holiday_4 days after Thanksgiving',\n",
       " '_automl_Holiday_4 days after Veterans Day',\n",
       " '_automl_Holiday_4 days before Christmas Day',\n",
       " '_automl_Holiday_4 days before Columbus Day',\n",
       " '_automl_Holiday_4 days before Independence Day',\n",
       " '_automl_Holiday_4 days before Thanksgiving',\n",
       " '_automl_Holiday_4 days before Veterans Day',\n",
       " '_automl_Holiday_5 days after Christmas Day',\n",
       " '_automl_Holiday_5 days after Columbus Day',\n",
       " '_automl_Holiday_5 days after Independence Day',\n",
       " \"_automl_Holiday_5 days after New Year's Day\",\n",
       " '_automl_Holiday_5 days after Thanksgiving',\n",
       " '_automl_Holiday_5 days after Veterans Day',\n",
       " '_automl_Holiday_5 days before Christmas Day',\n",
       " '_automl_Holiday_5 days before Columbus Day',\n",
       " '_automl_Holiday_5 days before Independence Day',\n",
       " '_automl_Holiday_5 days before Thanksgiving',\n",
       " '_automl_Holiday_5 days before Veterans Day',\n",
       " '_automl_Holiday_6 days after Christmas Day',\n",
       " '_automl_Holiday_6 days after Thanksgiving',\n",
       " '_automl_Holiday_6 days before Christmas Day',\n",
       " '_automl_Holiday_6 days before Thanksgiving',\n",
       " '_automl_Holiday_7 days after Thanksgiving',\n",
       " '_automl_Holiday_7 days before Christmas Day',\n",
       " '_automl_Holiday_7 days before Thanksgiving',\n",
       " '_automl_Holiday_8 days after Thanksgiving',\n",
       " '_automl_Holiday_8 days before Christmas Day',\n",
       " '_automl_Holiday_9 days after Thanksgiving',\n",
       " '_automl_Holiday_9 days before Christmas Day',\n",
       " '_automl_Holiday_Christmas Day',\n",
       " '_automl_Holiday_Columbus Day',\n",
       " '_automl_Holiday_Independence Day',\n",
       " '_automl_Holiday_Labor Day',\n",
       " '_automl_Holiday_Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_Memorial Day',\n",
       " \"_automl_Holiday_New Year's Day\",\n",
       " '_automl_Holiday_Thanksgiving',\n",
       " '_automl_Holiday_Veterans Day',\n",
       " \"_automl_Holiday_Washington's Birthday\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(local_path, \"engineered_feature_names.json\"), \"r\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization\n",
    "\n",
    "We can look at the engineered feature names generated in time-series featurization via. the JSON file named 'engineered_feature_names.json' under the run outputs. Note that a number of named holiday periods are represented. We recommend that you have at least one year of data when using this feature to ensure that all yearly holidays are captured in the training featurization.\n",
    "\n",
    "#### View featurization summary\n",
    "You can also see what featurization steps were performed on different raw features in the user data. For each raw feature in the user data, the following information is displayed:\n",
    "\n",
    "+ Raw feature name\n",
    "+ Number of engineered features formed out of this raw feature\n",
    "+ Type detected\n",
    "+ If feature was dropped\n",
    "+ List of feature transformations for the raw feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RawFeatureName</th>\n",
       "      <th>TypeDetected</th>\n",
       "      <th>Dropped</th>\n",
       "      <th>EngineeredFeatureCount</th>\n",
       "      <th>Transformations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>instant</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>season</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yr</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mnth</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weekday</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weathersit</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>temp</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>atemp</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hum</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>windspeed</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>casual</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>registered</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>_automl_target_col</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>[ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>date</td>\n",
       "      <td>DateTime</td>\n",
       "      <td>No</td>\n",
       "      <td>104</td>\n",
       "      <td>[DateTimeTransformer, DateTimeTransformer-OneHotEncoder]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RawFeatureName TypeDetected Dropped  EngineeredFeatureCount  \\\n",
       "0              instant      Numeric      No                       2   \n",
       "1               season      Numeric      No                       2   \n",
       "2                   yr      Numeric      No                       2   \n",
       "3                 mnth      Numeric      No                       2   \n",
       "4              weekday      Numeric      No                       2   \n",
       "5           weathersit      Numeric      No                       2   \n",
       "6                 temp      Numeric      No                       2   \n",
       "7                atemp      Numeric      No                       2   \n",
       "8                  hum      Numeric      No                       2   \n",
       "9            windspeed      Numeric      No                       2   \n",
       "10              casual      Numeric      No                       2   \n",
       "11          registered      Numeric      No                       2   \n",
       "12  _automl_target_col      Numeric      No                       1   \n",
       "13                date     DateTime      No                     104   \n",
       "\n",
       "                                             Transformations  \n",
       "0                          [MedianImputer, ImputationMarker]  \n",
       "1                          [MedianImputer, ImputationMarker]  \n",
       "2                          [MedianImputer, ImputationMarker]  \n",
       "3                          [MedianImputer, ImputationMarker]  \n",
       "4                          [MedianImputer, ImputationMarker]  \n",
       "5                          [MedianImputer, ImputationMarker]  \n",
       "6                          [MedianImputer, ImputationMarker]  \n",
       "7                          [MedianImputer, ImputationMarker]  \n",
       "8                          [MedianImputer, ImputationMarker]  \n",
       "9                          [MedianImputer, ImputationMarker]  \n",
       "10                         [MedianImputer, ImputationMarker]  \n",
       "11                         [MedianImputer, ImputationMarker]  \n",
       "12                                        [ImputationMarker]  \n",
       "13  [DateTimeTransformer, DateTimeTransformer-OneHotEncoder]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Render the JSON as a pandas DataFrame\n",
    "with open(os.path.join(local_path, \"featurization_summary.json\"), \"r\") as f:\n",
    "    records = json.load(f)\n",
    "fs = pd.DataFrame.from_records(records)\n",
    "\n",
    "# View a summary of the featurization\n",
    "fs[\n",
    "    [\n",
    "        \"RawFeatureName\",\n",
    "        \"TypeDetected\",\n",
    "        \"Dropped\",\n",
    "        \"EngineeredFeatureCount\",\n",
    "        \"Transformations\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.ai.ml.entities import (\n",
    "#     Environment,\n",
    "#     BatchEndpoint,\n",
    "#     BatchDeployment,\n",
    "#     BatchRetrySettings,\n",
    "#     Model,\n",
    "# )\n",
    "# from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "# fitted_model = joblib.load(\"./artifact_downloads/outputs/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Forecasting using batch endpoint<a id=\"forecast\"></a>\n",
    "\n",
    "Now that we have retrieved the best pipeline/model, it can be used to make predictions on test data. We will do batch scoring on the test dataset which should have the same schema as training dataset.\n",
    "\n",
    "The inference will run on a remote compute. In this example, it will re-use the training compute.\n",
    "Fisrt we will load model and environment from the local file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model endpoint\n",
    "First we need to register the model, environment and batch endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchEndpoint({'scoring_uri': 'https://bike-share.eastus2.inference.ml.azure.com/jobs', 'swagger_uri': None, 'provisioning_state': 'Succeeded', 'name': 'bike-share', 'description': 'this is a sample batch endpoint', 'tags': {}, 'properties': {'BatchEndpointCreationApiVersion': '2022-05-01', 'azureml.onlineendpointid': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/sagoswami_southcentralus_rg/providers/microsoft.machinelearningservices/workspaces/test/onlineendpoints/bike-share', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/be:104cbf67-baa5-4a37-bc93-451a3fa51799:3b054981-4fc6-45bd-ba18-fb3a26a5e6e9?api-version=2022-05-01'}, 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sagoswami_southcentralus_rg/providers/Microsoft.MachineLearningServices/workspaces/test/batchEndpoints/bike-share', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\sagoswami\\\\projects\\\\azureml-examples\\\\sdk\\\\python\\\\jobs\\\\automl-standalone-jobs\\\\automl-forecasting-task-bike-share', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000025510DEEEE0>, 'auth_mode': 'aad_token', 'location': 'eastus2', 'defaults': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.BatchEndpointDefaults object at 0x0000025510DEE2E0>})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    Environment,\n",
    "    BatchEndpoint,\n",
    "    BatchDeployment,\n",
    "    BatchRetrySettings,\n",
    "    Model,\n",
    ")\n",
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "\n",
    "model_name = \"bike-share\"\n",
    "batch_endpoint_name = \"bike-share\"\n",
    "\n",
    "model = Model(\n",
    "    path=f\"azureml://jobs/{best_run.info.run_id}/outputs/artifacts/outputs/model.pkl\",\n",
    "    name=model_name,\n",
    "    description=\"Bike share model.\",\n",
    ")\n",
    "registered_model = ml_client.models.create_or_update(model)\n",
    "\n",
    "env = Environment(\n",
    "    name=\"automl-tabular-env\",\n",
    "    description=\"environment for automl inference\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210727.v1\",\n",
    "    conda_file=\"artifact_downloads/outputs/conda_env_v_1_0_0.yml\",\n",
    ")\n",
    "\n",
    "endpoint = BatchEndpoint(\n",
    "    name=batch_endpoint_name,\n",
    "    description=\"this is a sample batch endpoint\",\n",
    ")\n",
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a batch deployment we will use the forecasting_script.py which will load the model and will call forecast each time we will envoke the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"forecast.json\"\n",
    "batch_deployment = BatchDeployment(\n",
    "    name=\"non-mlflow-deployment-1\",\n",
    "    description=\"this is a sample non-mlflow deployment\",\n",
    "    endpoint_name=batch_endpoint_name,\n",
    "    model=registered_model,\n",
    "    code_path=\"./forecast\",\n",
    "    scoring_script=\"forecasting_script.py\",\n",
    "    environment=env,\n",
    "    environment_variables={\n",
    "        \"TARGET_COLUMN_NAME\": target_column_name,\n",
    "    },\n",
    "    compute=cluster_name,\n",
    "    instance_count=2,\n",
    "    max_concurrency_per_instance=2,\n",
    "    mini_batch_size=10,\n",
    "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "    output_file_name=output_file,\n",
    "    retry_settings=BatchRetrySettings(max_retries=3, timeout=30),\n",
    "    logging_level=\"info\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, start a model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchDeployment({'endpoint_name': 'bike-share', 'type': None, 'name': 'non-mlflow-deployment-1', 'description': 'this is a sample non-mlflow deployment', 'tags': {}, 'properties': {}, 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sagoswami_southcentralus_rg/providers/Microsoft.MachineLearningServices/workspaces/test/batchEndpoints/bike-share/deployments/non-mlflow-deployment-1', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\sagoswami\\\\projects\\\\azureml-examples\\\\sdk\\\\python\\\\jobs\\\\automl-standalone-jobs\\\\automl-forecasting-task-bike-share', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000025510DDCC70>, 'model': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sagoswami_southcentralus_rg/providers/Microsoft.MachineLearningServices/workspaces/test/models/bike-share/versions/13', 'code_configuration': <azure.ai.ml.entities._deployment.code_configuration.CodeConfiguration object at 0x0000025510DDC160>, 'environment': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sagoswami_southcentralus_rg/providers/Microsoft.MachineLearningServices/workspaces/test/environments/automl-tabular-env/versions/15', 'environment_variables': {'TARGET_COLUMN_NAME': 'cnt'}, 'compute': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/sagoswami_southcentralus_rg/providers/Microsoft.MachineLearningServices/workspaces/test/computes/bike-share-v2', 'resources': {'instance_count': 2, 'properties': {}}, 'output_action': 'append_row', 'output_file_name': 'forecast.json', 'error_threshold': -1, 'retry_settings': <azure.ai.ml.entities._deployment.deployment_settings.BatchRetrySettings object at 0x0000025510DDC6A0>, 'logging_level': 'Info', 'mini_batch_size': 10, 'max_concurrency_per_instance': 2})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(batch_deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create the Input, representing URI folder, because the batch endpoint is intended to process multiple files at a time. In this example we will use only one test file, we have uploaded to the blob storage before. This file must be available through the url link.\n",
    "\n",
    "Create an inference job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading test_dataset (0.06 MBs): 100%|##########| 63760/63760 [00:01<00:00, 40672.32it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=batch_endpoint_name,\n",
    "    input=my_test_data_input,\n",
    "    deployment_name=\"non-mlflow-deployment-1\",  # name is required as default deployment is not set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will stream the job output to monitor the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n",
      "RunId: 86c59301-15fe-4842-98a8-c4b62c09e921\n",
      "Web View: https://ml.azure.com/runs/86c59301-15fe-4842-98a8-c4b62c09e921?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/sagoswami_southcentralus_rg/workspaces/test\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2022-10-10 15:29:34Z] Submitting 1 runs, first five are: 7ae63bb9:dfcd7410-8e26-41f3-a243-3f582a02e395\n",
      "[2022-10-10 15:38:25Z] Execution of experiment failed, update experiment status and cancel running nodes.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: 86c59301-15fe-4842-98a8-c4b62c09e921\n",
      "Web View: https://ml.azure.com/runs/86c59301-15fe-4842-98a8-c4b62c09e921?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/sagoswami_southcentralus_rg/workspaces/test\n"
     ]
    },
    {
     "ename": "JobException",
     "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has some failed steps. See child run or execution logs for more details.\",\n        \"message_format\": \"Pipeline has some failed steps. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus2\",\n    \"location\": \"eastus2\",\n    \"time\": \"2022-10-10T15:38:25.813264Z\",\n    \"component_name\": \"\"\n} ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJobException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sagoswami\\projects\\azureml-examples\\sdk\\python\\jobs\\automl-standalone-jobs\\automl-forecasting-task-bike-share\\auto-ml-forecasting-bike-share.ipynb Cell 63\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sagoswami/projects/azureml-examples/sdk/python/jobs/automl-standalone-jobs/automl-forecasting-task-bike-share/auto-ml-forecasting-bike-share.ipynb#Y126sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(batch_job\u001b[39m.\u001b[39mstatus)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sagoswami/projects/azureml-examples/sdk/python/jobs/automl-standalone-jobs/automl-forecasting-task-bike-share/auto-ml-forecasting-bike-share.ipynb#Y126sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# stream the job logs\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sagoswami/projects/azureml-examples/sdk/python/jobs/automl-standalone-jobs/automl-forecasting-task-bike-share/auto-ml-forecasting-bike-share.ipynb#Y126sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49mjobs\u001b[39m.\u001b[39;49mstream(name\u001b[39m=\u001b[39;49mjob_name)\n",
      "File \u001b[1;32mc:\\Users\\sagoswami\\Miniconda3\\envs\\platv2\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:260\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    259\u001b[0m     \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[1;32m--> 260\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sagoswami\\Miniconda3\\envs\\platv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:548\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[39mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[39m=\u001b[39mjob_object\u001b[39m.\u001b[39mid)\n\u001b[0;32m    547\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 548\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream_logs_until_completion(\n\u001b[0;32m    549\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_runs_operations, job_object, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datastore_operations, requests_pipeline\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requests_pipeline\n\u001b[0;32m    550\u001b[0m     )\n\u001b[0;32m    551\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sagoswami\\Miniconda3\\envs\\platv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_ops_helper.py:297\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[1;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[0;32m    295\u001b[0m         file_handle\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    296\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m         \u001b[39mraise\u001b[39;00m JobException(\n\u001b[0;32m    298\u001b[0m             message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException : \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(json\u001b[39m.\u001b[39mdumps(error, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)),\n\u001b[0;32m    299\u001b[0m             target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[0;32m    300\u001b[0m             no_personal_data_message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException raised on failed job.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    301\u001b[0m             error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mSYSTEM_ERROR,\n\u001b[0;32m    302\u001b[0m         )\n\u001b[0;32m    304\u001b[0m file_handle\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    305\u001b[0m file_handle\u001b[39m.\u001b[39mflush()\n",
      "\u001b[1;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has some failed steps. See child run or execution logs for more details.\",\n        \"message_format\": \"Pipeline has some failed steps. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus2\",\n    \"location\": \"eastus2\",\n    \"time\": \"2022-10-10T15:38:25.813264Z\",\n    \"component_name\": \"\"\n} "
     ]
    }
   ],
   "source": [
    "job_name = job.name\n",
    "batch_job = ml_client.jobs.get(name=job_name)\n",
    "print(batch_job.status)\n",
    "# stream the job logs\n",
    "ml_client.jobs.stream(name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the prediction result for metrics calculation\n",
    "The output of prediction is saved in JSON format. You can download it and calculation some error metrics for the forecasts and vizualize the predictions vs. the actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.download(job_name, download_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_df = pd.read_json(output_file, orient=\"table\")\n",
    "fcst_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics_helper import calculate_metrics\n",
    "calculate_metrics(fcst_df[target_column_name], fcst_df[\"predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecast versus actuals plot.\n",
    "We will join the last three forecast horizons of history data with the predictions to evaluate the forecast quality on forecast vs versus actuals plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_data = pd.read_csv(\n",
    "    \"./data/training-mltable-folder/nyc_energy_training_clean.csv\",\n",
    "    parse_dates=[time_column_name],\n",
    ")\n",
    "history_data.sort_values(by=time_column_name, inplace=True)\n",
    "history_data = history_data.iloc[-3 * forecast_horizon :]\n",
    "# Merge predictions to historic data.\n",
    "df = pd.concat([history_data, fcst_df], sort=False, ignore_index=True)\n",
    "df.set_index(time_column_name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(df[[target_column_name, \"predicted\"]])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f\"Predicted vs. Actuals\")\n",
    "plt.legend([\"actual\", \"forecast\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################### old #########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the best fitted model from the AutoML Run to make forecasts for the test set. We will do batch scoring on the test dataset which should have the same schema as training dataset.\n",
    "\n",
    "The scoring will run on a remote compute. In this example, it will reuse the training compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_experiment = Experiment(ws, experiment_name + \"_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving forecasts from the model\n",
    "To run the forecast on the remote compute we will use a helper script: forecasting_script. This script contains the utility methods which will be used by the remote estimator. We copy the script to the project folder to upload it to remote compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "script_folder = os.path.join(os.getcwd(), \"forecast\")\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "shutil.copy(\"forecasting_script.py\", script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For brevity, we have created a function called run_forecast that submits the test data to the best model determined during the training run and retrieves forecasts. The test set is longer than the forecast horizon specified at train time, so the forecasting script uses a so-called rolling evaluation to generate predictions over the whole test set. A rolling evaluation iterates the forecaster over the test set, using the actuals in the test set to make lag features as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_forecast import run_rolling_forecast\n",
    "\n",
    "remote_run = run_rolling_forecast(\n",
    "    test_experiment, compute_target, best_run, test, target_column_name\n",
    ")\n",
    "remote_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the prediction result for metrics calculation\n",
    "The test data with predictions are saved in artifact outputs/predictions.csv. You can download it and calculation some error metrics for the forecasts and vizualize the predictions vs. the actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.download_file(\"outputs/predictions.csv\", \"predictions.csv\")\n",
    "df_all = pd.read_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.automl.core.shared import constants\n",
    "from azureml.automl.runtime.shared.score import scoring\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# use automl metrics module\n",
    "scores = scoring.score_regression(\n",
    "    y_test=df_all[target_column_name],\n",
    "    y_pred=df_all[\"predicted\"],\n",
    "    metrics=list(constants.Metric.SCALAR_REGRESSION_SET),\n",
    ")\n",
    "\n",
    "print(\"[Test data scores]\\n\")\n",
    "for key, value in scores.items():\n",
    "    print(\"{}:   {:.3f}\".format(key, value))\n",
    "\n",
    "# Plot outputs\n",
    "%matplotlib inline\n",
    "test_pred = plt.scatter(df_all[target_column_name], df_all[\"predicted\"], color=\"b\")\n",
    "test_test = plt.scatter(\n",
    "    df_all[target_column_name], df_all[target_column_name], color=\"g\"\n",
    ")\n",
    "plt.legend(\n",
    "    (test_pred, test_test), (\"prediction\", \"truth\"), loc=\"upper left\", fontsize=8\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details on what metrics are included and how they are calculated, please refer to [supported metrics](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml#regressionforecasting-metrics). You could also calculate residuals, like described [here](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml#residuals).\n",
    "\n",
    "\n",
    "Since we did a rolling evaluation on the test set, we can analyze the predictions by their forecast horizon relative to the rolling origin. The model was initially trained at a forecast horizon of 14, so each prediction from the model is associated with a horizon value from 1 to 14. The horizon values are in a column named, \"horizon_origin,\" in the prediction set. For example, we can calculate some of the error metrics grouped by the horizon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics_helper import MAPE, APE\n",
    "\n",
    "df_all.groupby(\"horizon_origin\").apply(\n",
    "    lambda df: pd.Series(\n",
    "        {\n",
    "            \"MAPE\": MAPE(df[target_column_name], df[\"predicted\"]),\n",
    "            \"RMSE\": np.sqrt(\n",
    "                mean_squared_error(df[target_column_name], df[\"predicted\"])\n",
    "            ),\n",
    "            \"MAE\": mean_absolute_error(df[target_column_name], df[\"predicted\"]),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drill down more, we can look at the distributions of APE (absolute percentage error) by horizon. From the chart, it is clear that the overall MAPE is being skewed by one particular point where the actual value is of small absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_APE = df_all.assign(APE=APE(df_all[target_column_name], df_all[\"predicted\"]))\n",
    "APEs = [\n",
    "    df_all_APE[df_all[\"horizon_origin\"] == h].APE.values\n",
    "    for h in range(1, forecast_horizon + 1)\n",
    "]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.boxplot(APEs)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"horizon\")\n",
    "plt.ylabel(\"APE (%)\")\n",
    "plt.title(\"Absolute Percentage Errors by Forecast Horizon\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# full_df.sort_values(\n",
    "#     by = ['new_date'],\n",
    "#     axis = 0, \n",
    "#     ascending = True,\n",
    "#     inplace=  True)\n",
    "# # # Get the date from pad.Date\n",
    "# # full_df['month'] = pd.DatetimeIndex(full_df['new_date']).month \n",
    "# # full_df['day'] = pd.DatetimeIndex(full_df['new_date']).day \n",
    "# # full_df['year'] = pd.DatetimeIndex(full_df['new_date']).year\n",
    "\n",
    "# # For timestamp\n",
    "# # for index, row in full_df.iterrows():\n",
    "# #     year = row['year']\n",
    "# #     month = row['month']\n",
    "# #     day = row['day']\n",
    "# #     print(year,\" \",month,\" \",day)\n",
    "# #     full_df['date_stamp'][index]= pd.Timestamp(year=year, month=month, day=day, hour=12)\n",
    "\n",
    "# # train_df['date'] = train_df['date_stamp'] \n",
    "# # test_df['date'] = test_df['date_stamp'] "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "jialiu"
   }
  ],
  "category": "tutorial",
  "compute": [
   "Remote"
  ],
  "datasets": [
   "BikeShare"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "file_extension": ".py",
  "framework": [
   "Azure ML AutoML"
  ],
  "friendly_name": "Forecasting BikeShare Demand",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.8.13 ('platv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "tags": [
   "Forecasting"
  ],
  "task": "Forecasting",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "7db8a53542ba35b01ae7762868d8d16c0f1f14c2eb043bc8fff69addb7ba1f0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
