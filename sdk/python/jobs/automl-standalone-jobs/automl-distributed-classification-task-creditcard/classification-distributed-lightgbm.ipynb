{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AutoML - distributed training for classification"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Requirements** - In order to benefit from this tutorial, you will need:\r\n",
    "- A basic understanding of Machine Learning\r\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\r\n",
    "- An Azure ML workspace. [Check this notebook for creating a workspace](../../../resources/workspace/workspace.ipynb) \r\n",
    "- A Compute Cluster. [Check this notebook to create a compute cluster](../../../resources/compute/compute.ipynb)\r\n",
    "- A python environment\r\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](../../../README.md) - check the getting started section"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Connect to Azure Machine Learning Workspace\r\n",
    "\r\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\r\n",
    "\r\n",
    "#### 1.1. Import the required libraries"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import automl\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1685545471374
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2. Configure workspace details and get a handle to the workspace\r\n",
    "\r\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Found the config file in: /config.json\n"
    }
   ],
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1685545478371
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Show Azure ML Workspace information"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "workspace = ml_client.workspaces.get(name=ml_client.workspace_name)\n",
    "\n",
    "output = {}\n",
    "output[\"Workspace\"] = ml_client.workspace_name\n",
    "output[\"Subscription ID\"] = ml_client.connections._subscription_id\n",
    "output[\"Resource Group\"] = workspace.resource_group\n",
    "output[\"Location\"] = workspace.location\n",
    "output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 3,
     "data": {
      "text/plain": "{'Workspace': 'nivmishra_workspace3',\n 'Subscription ID': '381b38e9-9840-4719-a5a0-61d9585e1e91',\n 'Resource Group': 'nivmishra-eastus-rg',\n 'Location': 'eastus'}"
     },
     "metadata": {}
    }
   ],
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1685545518452
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data\r\n",
    "\r\n",
    "We will download the data and save it in the respective folders, created at the same location (in the repo) as this notebook.\r\n",
    "For large data we recommend that the dataset be registered in your workspace."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "\n",
    "train_mltable_path = \"./data/training-mltable-folder\"\n",
    "valid_mltable_path = \"./data/valid-mltable-folder\"\n",
    "\n",
    "# Download dataset files and copy them in data path\n",
    "\n",
    "training_download_url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/creditcard.csv\"\n",
    "training_data_file = os.path.join(train_mltable_path, \"training_data.csv\")\n",
    "urllib.request.urlretrieve(training_download_url, filename=training_data_file)\n",
    "\n",
    "valid_download_url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/creditcard_validate.csv\"\n",
    "valid_data_file = os.path.join(valid_mltable_path, \"validation_data.csv\")\n",
    "urllib.request.urlretrieve(valid_download_url, filename=valid_data_file)\n",
    "\n",
    "print(\"Dataset files downloaded...\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684844704572
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Create the Azure Machine Learning MLTable"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With Azure Machine Learning MLTables you can keep a single copy of data in your storage, easily access data during model training, share data and collaborate with other users. \r\n",
    "Please make use of the MLTable files present within the data folder at the same location (in the repo) as this notebook."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Training MLTable defined locally, with local data to be uploaded\n",
    "my_training_data_input = Input(type=AssetTypes.MLTABLE, path=train_mltable_path)\n",
    "\n",
    "# Validation MLTable defined locally, with local data to be uploaded\n",
    "my_validation_data_input = Input(type=AssetTypes.MLTABLE, path=valid_mltable_path)\n",
    "\n",
    "# WITH REMOTE PATH: If available already in the cloud/workspace-blob-store\n",
    "# my_training_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/my_training_mltable\")\n",
    "# my_validation_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/my_validation_mltable\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684844838777
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For documentation on creating your own MLTable assets for jobs beyond this notebook:\r\n",
    "- https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-mltable details how to write MLTable YAMLs (required for each MLTable asset).\r\n",
    "- https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-data-assets?tabs=Python-SDK covers how to work with them in the v2 CLI/SDK."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Create or Attach existing AmlCompute\r\n",
    "\r\n",
    "[Azure Machine Learning Compute](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute) is a managed-compute infrastructure that allows the user to easily create a single or multi-node compute. In this tutorial, you will create and an AmlCompute cluster as your training compute resource.\r\n",
    "\r\n",
    "<b>Creation of AmlCompute takes approximately 5 minutes.</b>\r\n",
    "\r\n",
    "If the AmlCompute with that name is already in your workspace this code will skip the creation process.\r\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cluster_name = \"automl-distributed-cluster\"\n",
    "\n",
    "try:\n",
    "    # Retrieve an already attached Azure Machine Learning Compute.\n",
    "    compute = ml_client.compute.get(cluster_name)\n",
    "except ResourceNotFoundError as e:\n",
    "    compute = AmlCompute(\n",
    "        name=cluster_name,\n",
    "        size=\"STANDARD_DS12_V2\",\n",
    "        type=\"amlcompute\",\n",
    "        min_instances=4,\n",
    "        max_instances=6,\n",
    "        idle_time_before_scale_down=120,\n",
    "    )\n",
    "    poller = ml_client.begin_create_or_update(compute)\n",
    "    poller.wait()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684844847439
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Configure and run the Distributed Classification training job\r\n",
    "\r\n",
    "In this section we will configure and run the AutoML job to train the model.\r\n",
    "\r\n",
    "#### 4.1 Configure the job through the classification() factory function\r\n",
    "\r\n",
    "##### classification() function parameters:\r\n",
    "\r\n",
    "The `classification()` factory function allows user to configure AutoML for the classification task for the most common scenarios with the following properties.\r\n",
    "\r\n",
    "|Property|Description|\r\n",
    "|-|-|\r\n",
    "|**target_column_name**|The name of the label column.|\r\n",
    "|**primary_metric**|This is the metric that you want to optimize. In case this parameter is set to `None`, `accuaracy` is used.|\r\n",
    "|**training_data**|The training data to be used for this experiment. You can use a registered MLTable in the workspace using the format `<mltable_name>:<version>` OR you can use a local file or folder as a MLTable. For e.g `Input(mltable='my_mltable:1')` OR `Input(mltable=MLTable(local_path=\"./data\"))` The parameter 'training_data' must always be provided.|\r\n",
    "|**compute**|The compute on which the AutoML job will run. In this example we are using a compute called 'cpu-cluster' present in the workspace. You can replace it with any other compute in the workspace.|\r\n",
    "|**name**|The name of the Job/Run. This is an optional property. If not specified, a random name will be generated.|\r\n",
    "|**experiment_name**|The name of the Experiment. An Experiment is like a folder with multiple runs in Azure ML Workspace that should be related to the same logical machine learning experiment. For example, if a user runs this notebook multiple times, there will be multiple runs associated with the same Experiment name.|\r\n",
    "|**positive_label**|Positive label for binary metrics calculation, defaults to` None`|\r\n",
    "\r\n",
    "\r\n",
    "##### set_limits() parameters:\r\n",
    "This is an optional configuration method to configure limits parameters such as timeouts.\r\n",
    "\r\n",
    "|Property|Description|\r\n",
    "|-|-|\r\n",
    "|**timeout_minutes**|Maximum amount of time in minutes that the whole AutoML job can take before the job terminates. This timeout includes setup, featurization and training runs but does not include the ensembling and model explainability runs at the end of the process since those actions need to happen once all the trials (children jobs) are done. If not specified, the default job's total timeout is 6 days (8,640 minutes). To specify a timeout less than or equal to 1 hour (60 minutes), make sure your dataset's size is not greater than 10,000,000 (rows times column) or an error results. It is hard to say what the timeout limit should be because the runtimes depend on multiple factors such as number of unique time series in the dataset, length of time series, statistical properties of the data, etc. If your dataset is less than 10,000,000 observations, you can try to set the experiment to 1 hour. If you are seeing less than 30 child jobs completed in this time frame, increase the timeout limit and re-run the experiment.|\r\n",
    "|**trial_timeout_minutes**|Maximum time in minutes that each trial (child job) can run for before it terminates. If not specified, a value of 1 month or 43200 minutes is used.|\r\n",
    "|**max_trials**|The maximum number of trials/runs each with a different combination of algorithm and hyperparameters to try during an AutoML job. If not specified, the default is 1000 trials. If you are setting the `enable_early_termination=True` the number of trials will be smaller.|\r\n",
    "|**max_concurrent_trials**|Represents the maximum number of trials (children jobs) that would be executed in parallel. It's a good practice to set this number equal to the number of nodes in your cluster.|\r\n",
    "|**enable_early_termination**|Whether to enable early termination if the score is not improving over 10 iterations. Early stopping window starts only after first 20 iterations. This means that the first iteration where stopping can occur is the 31st.|\r\n",
    "|**max_nodes**|The maximum number of nodes to use for `distributed` training. For classification/regression tasks, the minimum value that needs to be set is 4.|\r\n",
    "\r\n",
    "\r\n",
    "##### set_training() parameters:\r\n",
    "This is an optional configuration method to configure training parameters.\r\n",
    "\r\n",
    "|Property|Description|\r\n",
    "|-|-|\r\n",
    "|**allowed_training_algorithms**|A list of Regression algorithms to try out as base model for model training in an experiment. If it is omitted or set to None, then all supported algorithms are used during experiment|\r\n",
    "|**enable_model_explainability**|A flag to turn on model explainability like feature importance, of best model evaluated by Automated ML system.|\r\n",
    "|**training_mode**|[Experimental] The training mode to use. The possible values are-<ul>`distributed`- enables distributed training for supported algorithms.<ul>`non_distributed`- disables distributed training.<ul>`auto`- Currently, it is same as non_distributed. In future, this might change.<br><i>*Note*: This parameter is in public preview and may change in future.</i>|\r\n",
    "\r\n"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# General job parameters.\n",
    "max_trials = 5\n",
    "max_nodes = 6\n",
    "exp_name = \"classification_task_distributed_lightgbm\"\n",
    "target_column_name = \"Class\"\n",
    "primary_metric = \"accuracy\""
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684844854618
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2 Create the AutoML classification job"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create the AutoML job with the related factory-function\n",
    "classification_job = automl.classification(\n",
    "    compute=cluster_name,\n",
    "    experiment_name=exp_name,\n",
    "    training_data=my_training_data_input,\n",
    "    validation_data=my_validation_data_input,\n",
    "    target_column_name=target_column_name,\n",
    "    primary_metric=primary_metric,\n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "classification_job.set_limits(\n",
    "    timeout_minutes=120,\n",
    "    trial_timeout_minutes=60,\n",
    "    enable_early_termination=True,\n",
    "    max_cores_per_trial=-1,\n",
    "    max_trials=max_trials,\n",
    "    max_concurrent_trials=4,\n",
    "    max_nodes=6,\n",
    ")\n",
    "\n",
    "# set training configrations\n",
    "classification_job.set_training(\n",
    "    allowed_training_algorithms=[\"LightGBM\"],\n",
    "    enable_model_explainability=False,\n",
    "    training_mode=\"distributed\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684844860802
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3 Train the AutoML model\r\n",
    "\r\n",
    "Using the `MLClient` created earlier, we will execute the following commands to train the model."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    classification_job, experiment_name=exp_name\n",
    ")  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684844881827
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Wait until AutoML training runs are finished\n",
    "ml_client.jobs.stream(returned_job.name)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684846003381
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# print job name\n",
    "print(returned_job.name)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684850479576
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684850496535
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Retrieve the Best Trial (Best Model's trial/run)\r\n",
    "\r\n",
    "Use the MLFLowClient to access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Trial."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5.1 Initialize MLFlow Client\r\n",
    "The models and artifacts that are produced by AutoML can be accessed via the MLFlow interface. \r\n",
    "Initialize the MLFlow client here, and set the backend as Azure ML, via. the MLFlow Client.\r\n",
    "\r\n",
    "*IMPORTANT*, you need to have installed the latest MLFlow packages with:\r\n",
    "\r\n",
    "    pip install azureml-mlflow\r\n",
    "\r\n",
    "    pip install mlflow"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5.2 Obtain the tracking URI for MLFlow"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
    "    name=ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856487135
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the MLFLOW TRACKING URI\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856490266
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856506245
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5.3 Get the AutoML parent Job"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "job_name = returned_job.name\n",
    "\n",
    "# Example if providing an specific Job name/ID\n",
    "# job_name = \"b4e95546-0aa1-448e-9ad6-002e3207b4fc\"\n",
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
    "\n",
    "print(\"Parent Run: \")\n",
    "print(mlflow_parent_run)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856510090
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Print parent run tags. 'automl_best_child_run_id' tag should be there.\n",
    "print(mlflow_parent_run.data.tags)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856515894
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5.4 Get the AutoML best child run"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the best model's child run\n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Found best child run id: \", best_child_run_id)\n",
    "\n",
    "best_run = mlflow_client.get_run(best_child_run_id)\n",
    "\n",
    "print(\"Best child run: \")\n",
    "print(best_run)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856577110
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Model Evaluation"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.1 Get best model run's metrics\r\n",
    "\r\n",
    "Access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Run."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "best_run.data.metrics"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856582975
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.2 Download the best model"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create local folder\n",
    "local_dir = \"./artifact_downloads\"\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)\n",
    "# Download run's artifacts/outputs\n",
    "local_path = mlflow_client.download_artifacts(\n",
    "    best_run.info.run_id, \"outputs\", local_dir\n",
    ")\n",
    "print(\"Artifacts downloaded in: {}\".format(local_path))\n",
    "print(\"Artifacts: {}\".format(os.listdir(local_path)))\n",
    "\n",
    "# Show the contents of the MLFlow model folder\n",
    "os.listdir(\"./artifact_downloads/outputs/mlflow-model\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856595646
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Feaurization Summary\r\n",
    "We can look at the engineered feature names generated in time-series featurization via the JSON file named 'engineered_feature_names.json' under the run outputs."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(local_path, \"engineered_feature_names.json\"), \"r\") as f:\n",
    "    records = json.load(f)\n",
    "records"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### View featurization summary\r\n",
    "You can also see what featurization steps were performed on different raw features in the user data. For each raw feature in the user data, the following information is displayed:\r\n",
    "\r\n",
    "+ Raw feature name\r\n",
    "+ Number of engineered features formed out of this raw feature\r\n",
    "+ Type detected\r\n",
    "+ If feature was dropped\r\n",
    "+ List of feature transformations for the raw feature"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with open(os.path.join(local_path, \"featurization_summary.json\"), \"r\") as f:\n",
    "    records = json.load(f)\n",
    "fs = pd.DataFrame.from_records(records)\n",
    "\n",
    "# View a summary of the featurization\n",
    "fs[\n",
    "    [\n",
    "        \"RawFeatureName\",\n",
    "        \"TypeDetected\",\n",
    "        \"Dropped\",\n",
    "        \"EngineeredFeatureCount\",\n",
    "        \"Transformations\",\n",
    "    ]\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.3 Prediction using managed batch endpoint\r\n",
    "\r\n",
    "Now that we have retrieved the best pipeline/model, it can be used to make predictions on test data. We will do batch inferencing on the test dataset which must have the same schema as training dataset.\r\n",
    "\r\n",
    "The inference will run on a remote compute. In this example, it will re-use the training compute."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 6.3.1 Create a model endpoint\r\n",
    "First, we need to register the model, environment and the batch endpoint."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    "    ProbeSettings,\n",
    ")\n",
    "from azure.ai.ml.constants import ModelType\n",
    "\n",
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"distributed-classification-model\"\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is a sample online endpoint for mlflow model\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")\n",
    "\n",
    "ml_client.begin_create_or_update(endpoint).wait()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856703619
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 6.3.2 Register best model"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"distributed-classification-model01\"\n",
    "model = Model(\n",
    "    path=f\"azureml://jobs/{best_run.info.run_id}/outputs/artifacts/outputs/mlflow-model/\",\n",
    "    name=model_name,\n",
    "    description=\"my sample regression model\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    ")\n",
    "\n",
    "# for downloaded file\n",
    "# model = Model(path=\"artifact_downloads/outputs/model.pkl\", name=model_name)\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(model)\n",
    "\n",
    "print(registered_model.id)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856720104
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.3.3 Deploy the registered model"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"credit-card-default-deploy\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_DS3_V2\",\n",
    "    instance_count=1,\n",
    "    liveness_probe=ProbeSettings(\n",
    "        failure_threshold=30,\n",
    "        success_threshold=1,\n",
    "        timeout=2,\n",
    "        period=10,\n",
    "        initial_delay=2000,\n",
    "    ),\n",
    "    readiness_probe=ProbeSettings(\n",
    "        failure_threshold=10,\n",
    "        success_threshold=1,\n",
    "        timeout=10,\n",
    "        period=10,\n",
    "        initial_delay=2000,\n",
    "    ),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684856729016
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ml_client.online_deployments.begin_create_or_update(deployment).result()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684859185678
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# deployment to take 100% traffic\n",
    "endpoint.traffic = {\"credit-card-default-deploy\": 100}\n",
    "ml_client.begin_create_or_update(endpoint).result()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684859219057
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.3.4 Test the deployment"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_download_url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/creditcard_test.csv\"\n",
    "test_data_file = \"./data/test_data.csv\"\n",
    "urllib.request.urlretrieve(test_data_file, filename=test_data_file)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# test the blue deployment with some sample data\n",
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv(test_data_file)\n",
    "\n",
    "test_data = test_data.drop(target_column_name, axis=1)\n",
    "\n",
    "test_data_json = test_data.to_json(orient=\"records\", indent=4)\n",
    "data = (\n",
    "    '{ \\\r\n",
    "          \"input_data\": {\"data\": '\n",
    "    + test_data_json\n",
    "    + \"}}\"\n",
    ")\n",
    "\n",
    "request_file_name = \"sample-request-credit-card-default.json\"\n",
    "\n",
    "with open(request_file_name, \"w\") as request_file:\n",
    "    request_file.write(data)\n",
    "# test the blue deployment with some sample data\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=\"credit-card-default-deploy\",\n",
    "    request_file=request_file_name,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684860207960
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1684860276594
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.3.5 Delete the deployment and endpoint"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next Step: Load the best model and try predictions\r\n",
    "\r\n",
    "Loading the models locally assume that you are running the notebook in an environment compatible with the model. The list of dependencies that is expected by the model is specified in the MLFlow model produced by AutoML (in the 'conda.yaml' file within the mlflow-model folder).\r\n",
    "\r\n",
    "Since the AutoML model was trained remotelly in a different environment with different dependencies to your current local conda environment where you are running this notebook, if you want to load the model you have several options:\r\n",
    "\r\n",
    "1. A recommended way to locally load the model in memory and try predictions is to create a new/clean conda environment with the dependencies specified in the conda.yaml file within the MLFlow model's folder, then use MLFlow to load the model and call .predict() as explained in the notebook **mlflow-model-local-inference-test.ipynb** in this same folder.\r\n",
    "\r\n",
    "2. You can install all the packages/dependencies specified in conda.yaml into your current conda environment you used for using Azure ML SDK and AutoML. MLflow SDK also have a method to install the dependencies in the current environment. However, this option could have risks of package version conflicts depending on what's installed in your current environment.\r\n",
    "\r\n",
    "3. You can also use: mlflow models serve -m 'xxxxxxx'"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python310-sdkv2",
   "language": "python",
   "display_name": "Python 3.10 - SDK v2"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   },
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}