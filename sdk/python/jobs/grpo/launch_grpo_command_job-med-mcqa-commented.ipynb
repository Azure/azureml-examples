{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8348fe9",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:0.8em;\">üìù Plan of Action</span>\n",
    "\n",
    "This notebook guides you through the end-to-end process of fine-tuning the **Qwen2.5-7B-Instruct** model into a **reasoning model** using medical data on **Azure ML**. Qwen2.5-7B-Instruct is an instruction-tuned large language model developed by Alibaba Cloud, based on their Qwen2.5-7B foundation model. It is optimized for following human instructions across a wide range of tasks, such as question answering, code generation, and language understanding. In this walkthrough, one will learn how to enhance the model's reasoning capabilities using **Reinforced Fine-Tuning (RFT)** techniques, with a focus on **GRPO (**G**roup **R**elative **P**olicy **O**ptimization)**.\n",
    "\n",
    "<img src=\"images/agenda.png\" alt=\"image.png\" width=\"1000\"/>\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3348434",
   "metadata": {},
   "source": [
    "# <span style=\"font-size:0.8em;\">‚öôÔ∏è Section 1: Setup - AML Resources</span>\n",
    "\n",
    "Install the necessary packages and CLI tools to get started with Azure Machine Learning:\n",
    "\n",
    "- **azure-core**: Provides core utilities and HTTP infrastructure used by all Azure SDKs for Python.\n",
    "- **azure-ai-ml**: The Python SDK used to interact with Azure Machine Learning for managing and running ML workflows.\n",
    "- **rich**: A library for rendering richly formatted text, tables, and progress bars directly in the terminal.\n",
    "- **huggingface_hub**: Lets you download, upload, and manage models and datasets from the Hugging Face Hub.\n",
    "- **AzureCLI**: The `az` command-line interface used to manage Azure resources and services from your terminal.\n",
    "\n",
    "‚úÖ These tools form the foundation for orchestrating scalable and efficient ML workloads on Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Installing Azure cli and Azure SDK for Python.\n",
    "! pip install azure-core azure-ai-ml rich huggingface_hub\n",
    "! curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793aea2",
   "metadata": {},
   "source": [
    "In this example, a **Hugging Face access token** is used to download the **Qwen2.5-7B-Instruct model**. This token is required only for the initial run to access the gated model; subsequent runs will use the cached copy of the model from the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f85ed9",
   "metadata": {
    "gather": {
     "logged": 1747816782954
    }
   },
   "outputs": [],
   "source": [
    "# Set your Hugging Face token here (generate one at https://huggingface.co/settings/tokens)\n",
    "# This token is required the first time you run the script, to download gated models from Hugging Face.\n",
    "! export HF_TOKEN=\"hf_xxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f43523-ccbf-422a-b694-2ba267f45ef5",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "The Azure Machine Learning (AML) **setup process is encapsulated** into a script that provisions all required resources in the workspace. \\\n",
    "By the end of the setup, the AML workspace will be fully configured with the below resources: \n",
    "\n",
    "- **Dataset** : [MedMCQA](https://medmcqa.github.io): A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering. We use a modified version of the MedMCQA dataset, restricting our experiments to question/answer pairs having only a single correct answer. The modified dataset used in the demo can be found in `datasets/med_mcqa`\n",
    "- **Model** : [Qwen2_5-7B-Instruct_base](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)\n",
    "- **Compute Cluster**: STANDARD_ND96ISR_H100_V5 cluster with at least 2 nodes \n",
    "- **Environment**: Is designed for GRPO specific large-scale, distributed training and inference of reasoning models using Azure Machine Learning, TRL, DeepSpeed, vLLM, and LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41ca80",
   "metadata": {
    "gather": {
     "logged": 1747816824407
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from aml_setup import (\n",
    "    setup,\n",
    ")  # This script sets up the Azure ML client, model, and environment.\n",
    "\n",
    "ml_client, med_mcqa_data, model, compute, environment = setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd924e",
   "metadata": {},
   "source": [
    "The complete dataset can be found in datasets/med_mcqa. Here is a sample of the dataset :\n",
    "\n",
    "## <span style=\"font-size:0.8em;\"> Sample DataSet</span>\n",
    "\n",
    "üìò When solving a multiple-choice question, we ask the LLM to follow this structure:\n",
    "\n",
    "**Think out loud**: Explain your reasoning step by step. Wrap this part in tags.  \n",
    "**Give your final answer**: Clearly state your chosen option (A, B, C, or D) and explain why it's correct. Wrap this part in tags.<br>\n",
    "**Final Answer line**: On a new line, write Final Answer: followed by just one letter ‚Äî A, B, C, or D. \n",
    "\n",
    "‚úÖ **Example Question**: \n",
    "\n",
    "```text\n",
    "CSF Rhinorrhea occurs due to damage of:\n",
    "\n",
    "Options:\n",
    "\n",
    "A. Roof of orbit \n",
    "B. Cribriform plate of ethmoidal bone \n",
    "C. Frontal sinus \n",
    "D. Sphenoid bone\n",
    "```\n",
    "**Ideal reasoning model response:**\n",
    "```text\n",
    "<think>\n",
    "\n",
    "Start by identifying the anatomical structure most commonly associated with CSF (cerebrospinal fluid) leakage. CSF rhinorrhea typically results from a breach in the skull base, especially the cribriform plate of the ethmoid bone, which is thin and located near the nasal cavity.\n",
    "\n",
    "</think>\n",
    "\n",
    "The cribriform plate of the ethmoid bone is the most common site of CSF leakage into the nasal cavity, leading to CSF rhinorrhea. This makes option B the correct answer. \n",
    "\n",
    "<answer>B</answer>\n",
    "\n",
    "Final Answer: B\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71ed6c",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5497f1aa-513e-48ec-8c46-812f169c2975",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# <span style=\"font-size:0.8em;\">üß© Section 2: How to train a Reasoning Model on AML Using GRPO Trainer</span>\n",
    "\n",
    "<div style=\"display: flex; align-items: flex-start; gap: 32px;\">\n",
    "  <div style=\"flex: 1;\">\n",
    "    <p>The reasoning model training process typically includes three key components:</p>\n",
    "    <ul>\n",
    "      <li><strong>Sampler</strong> ‚Äì Generates multiple candidate responses from the model</li>\n",
    "      <li><strong>Reward Function</strong> ‚Äì Evaluates and scores each response based on criteria like accuracy or structure</li>\n",
    "      <li><strong>Trainer</strong> ‚Äì Updates the model to reinforce high-quality outputs</li>\n",
    "    </ul>\n",
    "    <p>\n",
    "      In this example we use the <strong>GRPO Trainer</strong> for training Qwen2.5-7B-Instruct model into a reasoning model. We use the GRPO implementation from TRL library.\n",
    "    </p>\n",
    "    <br>\n",
    "    <p>\n",
    "      <strong>GRPO</strong> (<strong>G</strong>roup <strong>R</strong>elative <strong>P</strong>olicy <strong>O</strong>ptimization) is a reinforcement learning technique that:\n",
    "    </p>\n",
    "    <ul>\n",
    "      <li><em>Compares</em> multiple answers within a group</li>\n",
    "      <li><em>Rewards</em> the best-performing outputs</li>\n",
    "      <li><em>Penalizes</em> poor ones</li>\n",
    "      <li>Applies careful updates to <em>avoid sudden changes</em></li>\n",
    "    </ul>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; display: flex; justify-content: center;\">\n",
    "    <img src=\"images/training_loop.png\" alt=\"Training Loop\" style=\"max-width:100%; width: 600px;\"/>\n",
    "  </div>\n",
    "</div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25545006-ab16-4641-87d7-96128ad6da6a",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## <span style=\"font-size:0.8em;\">Why does training reasoning models become easy in Azure ML?</span>  \n",
    "\n",
    "\n",
    "- **AzureML natively supports reasoning model training**, with seamless integration of vLLM and scalable training workflows.\n",
    "\n",
    "- **DeepSpeed scales effortlessly on AML**, enabling multi-node training by sharding model states across GPUs.\n",
    "\n",
    "- **LoRA support makes fine-tuning large models lightweight and cost-efficient**, even on smaller setups.\n",
    "\n",
    "- **Robust tracking, metrics, and debugging tools** make experimentation on AML smooth and production-ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0947a-3fcc-4809-a02f-8b5b7848e6d2",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## <span style=\"font-size:0.8em;\"> GRPO Trainer Configuration</span>  \n",
    "\n",
    "There are 4 main configs and scripts to train a reasoning model using TRL. \n",
    "\n",
    "\n",
    "**1. BldDemo_Reasoning_Train.py**\n",
    "\n",
    "This is the main script for running GRPO training. Here is a section, where one can control the **_base model (current policy)_**, **_reward function_**, **_dataset_** and **_LoRA_** configuration for PEFT (Parameter-Efficient Fine-Tuning). \n",
    "\n",
    "It's **important to note that the sampler, trainer and grader are abstracted** within the GRPO trainer implementation.\n",
    "\n",
    "\n",
    "<img src=\"images/grpo_trainer.png\" alt=\"image.png\" width=\"1050\"/>\n",
    "\n",
    "**2. grpo_trainer_rewards.py**\n",
    "\n",
    "This file defines a set of reward functions **_used to evaluate model outputs_** during training for reasoning tasks. \n",
    "\n",
    "For example, a format_reward function **_encourages the mode_** to follow the correct output structure, while an accuracy_reward function **_promotes correct answers_**‚Äîboth rewarding desired behavior and penalizing deviations. \n",
    "\n",
    "_format_reward_: \n",
    "\n",
    "\n",
    "<img src=\"images/reward_func.png\" alt=\"image.png\" width=\"1050\"/>\n",
    "\n",
    "\n",
    "**3. grpo_trainer_config.yaml**\n",
    "\n",
    "This file defines the training configuration. Some of the key trainer config parameters are discussed below:\n",
    "\n",
    "a. **_vllm_mode_** - TRL leverages vLLM to accelerate sampling during reasoning model training.\n",
    "\n",
    "It is supported in two modes:\n",
    "\n",
    "- **Server Mode**\n",
    "    - vLLM runs on _dedicated_ nodes/GPUs\n",
    "    - Ideal for large-scale, high-throughput sampling\n",
    "\n",
    "- **Colocate Mode**\n",
    "    - vLLM and trainer _share_ the same GPU\n",
    "    - Useful for smaller setups or resource-constrained environments\n",
    "\n",
    "<img src=\"images/vllm.png\" alt=\"image.png\" width=\"1050\"/>\n",
    "\n",
    "b. **_reward_functions_**: The reward functions to **_use by the grader_**, we define the format and accuracy reward. \\\n",
    "c. **_reward_weights_**: Weight of each reward function. We give **_more weight_** to the accuracy reward. \\\n",
    "d. **_report_to_**: To integrate the **_logs and metrics_** into Azure ML.\n",
    "\n",
    "\n",
    "<img src=\"images/reward_weights.png\" alt=\"image.png\" width=\"1050\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b471827",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**4. Deepspeed ZeRO config**\n",
    "\n",
    "Azure ML simplifies hardware scaling with built-in support for distributed training. Use DeepSpeed to maximize hardware efficiency across GPU clusters.\n",
    "\n",
    "In this example, ZeRO Stage3 config has been used where - The **model**, **Gradients** and **Optimizer States** are partitioned across the GPUs. \n",
    "\n",
    "This drastically reduces memory requirements per GPU and without ZeRO Stage 3, larger models would need significantly more GPUs.\n",
    "\n",
    "**Efficient scaling = Lower costs + ability to train much larger models**\n",
    "\n",
    "\n",
    "<img src=\"images/deepspeed_config_explain.png\" alt=\"image.png\" width=\"600\"/>\n",
    "\n",
    "\n",
    "a. _offload_optimizer_device = cpu_ : allows to offload optimizer states computations to be made on CPU. \\\n",
    "b. _zero_stage_: Stage 3 optimization, **helps scale training horizontally** for bigger models. \\\n",
    "c. _train_micro_batch_size_per_gpu_: **Batch size that a single GPU** processes in one forward/backward pass. \n",
    "\n",
    "A small train_micro_batch_size_per_gpu with offload_optimizer_device: cpu one can **fit bigger models** or **train on fewer GPUs** at the cost of slightly longer training times.\n",
    "\n",
    "\n",
    "<img src=\"images/deepspeed.png\" alt=\"image.png\" Width=\"1050\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47a690-4461-4306-9534-68d49a560374",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# <span style=\"font-size:0.8em;\"> üöÄ Section 3: Launch the job! </span> \n",
    "The below section shows how to kick off the pytorch distributed command job and rut it across multiple nodes. \\\n",
    "For this command job we pass the **GRPO trainer config, base model, dataset, DeepSpeed configuration** as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60b13c",
   "metadata": {
    "gather": {
     "logged": 1747817752135
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from aml_setup import N_NODES\n",
    "\n",
    "# Below is a command job that takes grpo config, deepspeed config, the dataset and the model parameters as inputs.\n",
    "# This kicks off a distributed job on a gpu cluster with 2 nodes (8XH100 on each).\n",
    "command_str = f\"\"\"python BldDemo_Reasoning_Train.py \\\n",
    "    --config {\"grpo_trainer_config.yaml\" if N_NODES==2 else \"grpo_trainer_config_single_node.yaml\"} \\\n",
    "    --model_name_or_path ${{inputs.model_dir}} \\\n",
    "    --dataset_name ${{inputs.dataset}} \\\n",
    "    --output_dir ${{outputs.checkpoint_folder}} \\\n",
    "    --final_model_save_path ${{outputs.mlflow_model_folder}} \\\n",
    "    --deepspeed {\"deepspeed_stage3_zero_config.json\" if N_NODES==2 else \"deepspeed_stage3_zero_config_single_node.json\"} \\\n",
    "    --mlflow_task_type \"chat-completion\" \\\n",
    "    --base_model_name \"{model.name}\"\n",
    "\"\"\"\n",
    "\n",
    "# Model directory and dataset as job inputs.\n",
    "job_input = {\n",
    "    \"model_dir\": Input(\n",
    "        path=model.path,\n",
    "        type=AssetTypes.CUSTOM_MODEL,\n",
    "    ),\n",
    "    \"dataset\": Input(\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        path=med_mcqa_data.path,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# The job outputs the finetuned model in mlflow format and the intermediate checkpoints.\n",
    "job_output = {\n",
    "    \"mlflow_model_folder\": Output(\n",
    "        type=AssetTypes.CUSTOM_MODEL,\n",
    "        mode=\"rw_mount\",\n",
    "    ),\n",
    "    \"checkpoint_folder\": Output(\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        mode=\"rw_mount\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Setting up the distributed training job.\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    inputs=job_input,\n",
    "    command=command_str,\n",
    "    environment=environment,\n",
    "    compute=compute.name,\n",
    "    instance_count=N_NODES,\n",
    "    outputs=job_output,\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        # set process count to the number of gpus per node\n",
    "        \"process_count_per_instance\": 8,\n",
    "    },\n",
    "    experiment_name=\"build-demo-reasoning-training-jobs\",\n",
    "    display_name=f\"build-demo-reasoning-train-batchsize-{N_NODES*8}\",\n",
    "    properties={\"_azureml.LogTrainingMetricsToAzMon\": \"true\"},\n",
    "    # Environment variables to enable profiling\n",
    "    environment_variables={\n",
    "        \"KINETO_USE_DAEMON\": \"1\",\n",
    "        \"ENABLE_AZUREML_TRAINING_PROFILER\": \"true\",\n",
    "        \"AZUREML_PROFILER_WAIT_DURATION_SECOND\": \"2\",\n",
    "        \"AZUREML_PROFILER_RUN_DURATION_MILLISECOND\": \"500\",\n",
    "        \"AZUREML_COMMON_RUNTIME_USE_APPINSIGHTS_CAPABILITY\": \"true\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad54d9-b35f-4f84-bf8c-0d9bcb393b1f",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "The below block will submit a machine learning job to Azure Machine Learning (AML) for execution.\n",
    "\n",
    "After submission, the returned **train_job object contains metadata and status information** about the job, such as its ID, current state, and output location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8ff68",
   "metadata": {
    "gather": {
     "logged": 1747817763878
    }
   },
   "outputs": [],
   "source": [
    "# üöÄ Submit the job\n",
    "train_job = ml_client.jobs.create_or_update(job)\n",
    "train_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4072cec0",
   "metadata": {},
   "source": [
    "## ‚è≥ **Wait** for the job to finish successfully, To move to next section..\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138ca1a-50fc-4847-8af2-dbcb9d152567",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Register and deploy the fine tuned model\n",
    "\n",
    "The output of the training is a set of files representing the weights of the trained model. To use it for inferencing, we will register the files as a model and then create an endpoint and a deployment for it. An endpoint provides security, url and traffic-splitting aspects of inferencing, whereas a deployment actually hosts and runs the registered model.\n",
    "\n",
    "You can find the assets registered in this section in the AzureML portal ([ml.azure.com](ml.azure.com)). Navigate to your resource group and workspace and click on the models or endpoints tab on the left panel. Deployments are sub-entities of endpoints and they can be found on the detailed view page of a particular endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424bc234-5f4e-4cf0-91d1-9c1fb50226c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering the model is necessary to deploy the model to an online endpoint.\n",
    "\n",
    "model_output_path = f\"azureml://jobs/{train_job.name}/outputs/mlflow_model_folder\"\n",
    "run_model = Model(\n",
    "    path=model_output_path,  # model output path from the job\n",
    "    name=\"grpo-finetuned-model\",  # registered model name\n",
    "    description=f\"Model created from run {train_job.name}.\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,  # registering as mlflow model\n",
    ")\n",
    "\n",
    "ft_model = ml_client.models.create_or_update(run_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d47a1-620a-4591-a539-06420e7846b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_endpoint_name = \"grpo-ft-model-endpoint\"\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,  # name for the endpoint\n",
    "    description=\"Online endpoint for the GRPO fine-tuned model\",\n",
    "    auth_mode=\"key\",\n",
    ")\n",
    "endpoint = ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca9675-72eb-42fb-ae62-d75e0613d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A deployment will be created in the online endpoint.\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"grpo-ft-model-deployment\",  # name for the deployment\n",
    "    endpoint_name=online_endpoint_name,  # endpoint name where model will be deployed\n",
    "    model=ft_model,  # finetuned and registered model\n",
    "    instance_type=\"Standard_ND96amsr_A100_v4\",\n",
    "    instance_count=1,\n",
    ")\n",
    "ml_client.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640cf63",
   "metadata": {},
   "source": [
    "## Results and metrics\n",
    "\n",
    "This job has a truncated dataset and fewer iterations than needed to see a significant principle for managing job runtime. But with over 100 iterations and the full dataset (takes about 6 hours on 16 H100s), you may see an improvement in the accuracy metric.\n",
    "\n",
    "As training progresses, the length of completions may increase with more iterations. Ideally, the mean completion length should stabilize over time, indicating that responses are not being capped and are of reasonable size. These metrics are of interest: \n",
    "\n",
    "- eval_rewards/accuracy/mean: This represents the mean of accuracy reward over the eval dataset as the training progresses. Note that we calculate this over the eval dataset but dont use the information from it to change our training.\n",
    "- eval_completions/mean_length: This represents the mean of the completions over the eval dataset. We should see this metric increasing as the model beigns to reason, which usually takes more tokens.\n",
    "- eval_reward: This represents how the overall reward (80% accuracy + 20% format) moved as the training progressed. We should see this increasing over longer runs.\n",
    "- reward: This is the training version of the net reward. This should increase as well as the training progresses. This information is used to inform the training process.\n",
    "\n",
    "You can view this in AzureML portal under the metrics Tab of the job. Expand the panel to the left which says \"Select metrics\" and search for the above listed metrics."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "aip-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
