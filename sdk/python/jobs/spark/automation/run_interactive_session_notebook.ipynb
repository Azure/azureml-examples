{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a serverless Spark compute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have an attached Synapse Spark pool available in your workspace. Please see documentation page: [Attach and manage a Synapse Spark pool in Azure Machine Learning (preview)](https://learn.microsoft.com/azure/machine-learning/how-to-manage-synapse-spark-pool) for more details.\n",
    "\n",
    "**Note** - To ensure successful execution of Spark job, the identity being used for the Spark job should be assigned **Contributor** and **Storage Blob Data Contributor** roles on the Azure storage account used for data input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, spark\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import time\n",
    "\n",
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "spark_job = spark(\n",
    "    display_name=\"interactive_data_wrangling\",\n",
    "    code=\"../../../data-wrangling\",\n",
    "    entry={\"file\": \"interactive_data_wrangling.py\"},\n",
    "    driver_cores=1,\n",
    "    driver_memory=\"2g\",\n",
    "    executor_cores=2,\n",
    "    executor_memory=\"2g\",\n",
    "    executor_instances=2,\n",
    "    resources={\n",
    "        \"instance_type\": \"Standard_E8S_V3\",\n",
    "        \"runtime_version\": \"3.4.0\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create or update the Spark job\n",
    "returned_spark_job = ml_client.jobs.create_or_update(spark_job)\n",
    "\n",
    "print(returned_spark_job.id)\n",
    "# Wait until the job completes\n",
    "job_name = returned_spark_job.name\n",
    "while True:\n",
    "    job = ml_client.jobs.get(job_name)\n",
    "    print(f\"Current job status: {job.status}\")\n",
    "    if job.status in [\"Completed\", \"Failed\", \"Canceled\"]:\n",
    "        break\n",
    "    time.sleep(10)\n",
    "\n",
    "print(f\"Final job status: {job.status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
