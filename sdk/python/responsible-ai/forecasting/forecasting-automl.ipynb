{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b8ff36",
   "metadata": {},
   "source": [
    "# Evaluate Time-Series Forecasting AutomatedML Models with  the Responsible AI Dashboard\n",
    "\n",
    "This notebook will allow you to use the Responsible AI components in AzureML to assess a time-series forecasting model trained with AutoML.\n",
    "\n",
    "To use this workbook, you must have:\n",
    "\n",
    "    1. a valid AzureML subscription ID, workspace, and resource group\n",
    "    2. a trained AutoML time-series forecasting model\n",
    "    3. a running compute cluster on AzureML\n",
    "\n",
    "If you have not trained an AutoML model yet, please use the forecasting-data-preprocessing notebook to prepare your data to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b08d0",
   "metadata": {},
   "source": [
    "### 1. Workspace Details\n",
    "\n",
    "Enter the details of your AzureML workspace below. If the provided compute name does not exist, it will be created for you later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b41247",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "compute_name = \"rai-cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cfb78f",
   "metadata": {},
   "source": [
    "### 2. Model Details\n",
    "Enter the name of your model. You can obtain the name of your model from under the **\"Output name: best model\"** section in the **Outputs** section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"azureml_plucky_shelf_lgrt16cy1f_40_output_mlflow_log_model_261482756:1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f67543",
   "metadata": {},
   "source": [
    "### 3. Data Details\n",
    "\n",
    "Enter the details of the data you used to train your AutoML model. If you created your data from the forecasting-data-preprocessing notebook, the dataset names and versions should be the same across the two notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = \"1\"\n",
    "input_train_data = \"forecasting_train_mltable\"\n",
    "input_test_data = \"forecasting_test_mltable\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827aa88",
   "metadata": {},
   "source": [
    "### 4. Get a handle to the workspace\n",
    "\n",
    "We will use the information provided in the Workspace Details section to get a handle to the required Azure Machine Learning workspace. No additional input is required for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c178005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from azure.ai.ml import Input, MLClient, Output, dsl, load_job\n",
    "from azure.ai.ml.entities import PipelineJob\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eca644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLClient object\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace,\n",
    ")\n",
    "print(ml_client)\n",
    "\n",
    "# Get handle to azureml registry for the RAI built in components\n",
    "\n",
    "registry_name = \"azureml\"\n",
    "ml_client_registry = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    registry_name=registry_name,\n",
    ")\n",
    "print(ml_client_registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "all_compute_names = [x.name for x in ml_client.compute.list()]\n",
    "\n",
    "if compute_name in all_compute_names:\n",
    "    print(f\"Found existing compute: {compute_name}\")\n",
    "else:\n",
    "    my_compute = AmlCompute(\n",
    "        name=compute_name,\n",
    "        size=\"Standard_D2_v2\",\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        idle_time_before_scale_down=3600,\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(my_compute).result()\n",
    "    print(\"Initiated compute creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53178dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
    "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    assert created_job is not None\n",
    "\n",
    "    print(\"Pipeline job can be accessed in the following URL:\")\n",
    "    display(HTML('<a href=\"{0}\">{0}</a>'.format(created_job.studio_url)))\n",
    "\n",
    "    while created_job.status not in [\n",
    "        \"Completed\",\n",
    "        \"Failed\",\n",
    "        \"Canceled\",\n",
    "        \"NotResponding\",\n",
    "    ]:\n",
    "        time.sleep(30)\n",
    "        created_job = ml_client.jobs.get(created_job.name)\n",
    "        print(\"Latest status : {0}\".format(created_job.status))\n",
    "    assert created_job.status == \"Completed\"\n",
    "    return created_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2790f",
   "metadata": {},
   "source": [
    "### 5. Run the RAI Dashboard Pipeline\n",
    "\n",
    "We will now define and start the pipeline to generate an RAI Dashboard from your model. There are four parameters that need to be adjusted here.\n",
    "\n",
    "1. **target_column** should be the name of the column that you want your model to predict over time. \n",
    "\n",
    "2. **datetime_column** should be the name of the column in your dataset with datetime features.\n",
    "\n",
    "3. **time_series_id_column** should be the column in your dataset which represents the group IDs that describe which time-series in your dataset each row belongs to. If your dataset contains a single time-series, then the value in this column should be the same in every row. See forecasting-data-preprocessing.ipynb for more details.\n",
    "\n",
    "4. **categorical_columns** should include a list of all the columns in your data **except** for the three columns you already provided. These columns will be the features that you can perturb with What-If Analysis once the Dashboard is launched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e324f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"demand\"\n",
    "datetime_column = \"datetime\"\n",
    "time_series_id_column = \"group_id\"\n",
    "categorical_columns = [\"precip\", \"temp\", \"group_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cf76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't touch any of this\n",
    "d = {}\n",
    "d[\"datetime_features\"] = [datetime_column]\n",
    "d[\"time_series_id_features\"] = [time_series_id_column]\n",
    "feature_metadata = json.dumps(d)\n",
    "categorical_columns.append(time_series_id_column)\n",
    "categorical_column_names = json.dumps(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecasting_rai_dashboard():\n",
    "\n",
    "    rai_constructor_component = ml_client_registry.components.get(\n",
    "        name=\"microsoft_azureml_rai_tabular_insight_constructorr\", label=\"latest\"\n",
    "    )\n",
    "\n",
    "    rai_gather_component = ml_client_registry.components.get(\n",
    "        name=\"microsoft_azureml_rai_tabular_insight_gather\", label=\"latest\"\n",
    "    )\n",
    "\n",
    "    train_data = Input(\n",
    "        type=\"mltable\",\n",
    "        path=f\"azureml:{input_train_data}:{data_version}\",\n",
    "        mode=\"download\",\n",
    "    )\n",
    "    test_data = Input(\n",
    "        type=\"mltable\",\n",
    "        path=f\"{input_test_data}:{data_version}\",\n",
    "        mode=\"download\",\n",
    "    )\n",
    "\n",
    "    # Pipeline skips on analysis; relies on the constructor component verifying the model works\n",
    "    @dsl.pipeline(\n",
    "        compute=compute_name,\n",
    "        description=\"Create RAI Dashboard for Forecasting\",\n",
    "        experiment_name=f\"create_rai_dashboard_forecasting{version_string}\",\n",
    "    )\n",
    "    def construct_dashboard(train_data, test_data):\n",
    "        construct_job = rai_constructor_component(\n",
    "            title=\"RAI Forecasting Dashboard\",\n",
    "            task_type=\"forecasting\",\n",
    "            model_info=model_id,\n",
    "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=f\"azureml:{model_id}\"),\n",
    "            train_dataset=train_data,\n",
    "            test_dataset=test_data,\n",
    "            target_column_name=target_column,\n",
    "            feature_metadata=feature_metadata,\n",
    "            categorical_column_names=categorical_column_names,\n",
    "            maximum_rows_for_test_dataset=5000,\n",
    "            classes=\"[]\",  # Should be default value\n",
    "            use_model_dependency=True,\n",
    "        )\n",
    "        construct_job.set_limits(timeout=1800)\n",
    "\n",
    "        rai_gather_job = rai_gather_component(\n",
    "            constructor=construct_job.outputs.rai_insights_dashboard\n",
    "        )\n",
    "        rai_gather_job.set_limits(timeout=1800)\n",
    "\n",
    "    insights_pipeline_job = construct_dashboard(\n",
    "        train_data=train_data,\n",
    "        test_data=test_data,\n",
    "    )\n",
    "\n",
    "    # Send it\n",
    "    insights_pipeline_job = submit_and_wait(ml_client, insights_pipeline_job)\n",
    "    assert insights_pipeline_job is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting_rai_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
