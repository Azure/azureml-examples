{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_string = '0.0.4.preview'\n",
    "compute_name = \"cpucluster\"\n",
    "rai_example_version_string = '6'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell will specify the version of RAI components for the workspace as wellas the compute cluster to utilize in AzureML. The rai string is to specify a version for teh data and components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib \n",
    "import os\n",
    "import sys\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "try:\n",
    "    from urllib import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "def download_mscoco_dataset(data_path, annotations_file):\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "    base_url = \"https://publictestdatasets.blob.core.windows.net/\"\n",
    "    coco = 'computervision/smallMSCOCO/'\n",
    "    data_url = base_url+coco+annotations_file\n",
    "\n",
    "    data_output_path = os.path.join(data_path, annotations_file)\n",
    "    urlretrieve(data_url, filename=data_output_path)\n",
    "\n",
    "annotations = \"msCOCOValExample.jsonl\"\n",
    "\n",
    "data_path = \"./dataMSCOCO\"\n",
    "\n",
    "\n",
    "download_mscoco_dataset(data_path, annotations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell of code, this is downloading the json file from the azure blob storage. Plus it will create a directory call dataMSCOCO and place the ms coco json file. Note that this is just 25 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ml_table_file(filename):\n",
    "    return (\"$schema: http://azureml/sdk-2-0/MLTable.json\\n\"\n",
    "            \"type: mltable\\n\"\n",
    "            \"paths:\\n\"\n",
    "            \" - file: ./{0}\\n\"\n",
    "            \"transformations:\\n\"\n",
    "            \"  - read_json_lines:\\n\"\n",
    "            \"        encoding: utf8\\n\"\n",
    "            \"        invalid_lines: error\\n\"\n",
    "            \"        include_path_column: false\\n\").format(filename)\n",
    "\n",
    "def save_ml_table_file(output_path, ml_table_data):\n",
    "    mltable_file_contents = create_ml_table_file(ml_table_data)\n",
    "    with open(os.path.join(output_path, \"MLTable\"), \"w\") as f:\n",
    "        f.write(mltable_file_contents)\n",
    "\n",
    "save_ml_table_file(data_path, annotations )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above creates the ML table using the json file that we downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltable\n",
    "\n",
    "tbl = mltable.load(data_path)\n",
    "\n",
    "val_df : pd.DataFrame = tbl.to_pandas_dataframe()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the mltable and putting it to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = \"label\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth of the bounding boxes, this will be used for the dashboard and other components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential=DefaultAzureCredential(exclude_shared_token_cache_credential=True),\n",
    "                                     logging_enable=True)\n",
    "except Exception:\n",
    "    # In case of exception due to config missing, try to get and create config, which may work if in compute instance\n",
    "    from azureml.core import Workspace\n",
    "    workspace = Workspace.from_config()\n",
    "    workspace.write_config()\n",
    "    ml_client = MLClient.from_config(credential=DefaultAzureCredential(exclude_shared_token_cache_credential=True),\n",
    "                                     logging_enable=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To upload the dataset (mltable) so we create an MLClinet with AzureML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': ['./msCOCOValExample.jsonl'], 'type': 'mltable', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'MSCOCO_Test_MLTable_OD18', 'description': 'RAI MSCOCO data', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/a75ae43f-9f72-4699-ba66-d3a173cfe082/resourceGroups/MAIDAP-RG/providers/Microsoft.MachineLearningServices/workspaces/maidap_cv_ws/data/MSCOCO_Test_MLTable_OD18/versions/6', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\cjbarberan\\\\raiDPV2\\\\responsibleai\\\\notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000001E4019329A0>, 'serialize': <msrest.serialization.Serializer object at 0x000001E40194F130>, 'version': '6', 'latest_version': None, 'path': 'azureml://subscriptions/a75ae43f-9f72-4699-ba66-d3a173cfe082/resourcegroups/MAIDAP-RG/workspaces/maidap_cv_ws/datastores/workspaceblobstore/paths/LocalUpload/cfc9e1d7ed455921f13ab6f531c920a8/dataMSCOCO/', 'datastore': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "input_test_data = \"MSCOCO_Test_MLTable_OD18\"\n",
    "\n",
    "test_data = Data(\n",
    "    path=data_path,\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description=\"RAI MSCOCO data\",\n",
    "    name=input_test_data,\n",
    "    version=rai_example_version_string,\n",
    ")\n",
    "ml_client.data.create_or_update(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLClinet will upload the data to AzureML. One typical error is the name of input_test_data, if you have used that string name, an error will occur saying that it has been used. To remedy this error change the input_test_data string name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('mscoco_component_src', exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create directory to place the script file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mscoco_component_src/model_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mscoco_component_src/model_script.py\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "#from fastai.learner import load_learner\n",
    "import torchvision\n",
    "\n",
    "from raiutils.common.retries import retry_function\n",
    "\n",
    "try:\n",
    "    from urllib import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "_logger = logging.getLogger(__file__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "MSCOCO_MODEL_NAME = 'mscoco_model'\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\n",
    "        \"--model_output_path\", type=str, help=\"Path to write model info JSON\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_base_name\", type=str, help=\"Name of the registered model\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name_suffix\", type=int, help=\"Set negative to use epoch_secs\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", type=int, help=(\n",
    "            \"Device for CPU/GPU supports. Setting this to -1 will leverage \"\n",
    "            \"CPU, >=0 will run the model on the associated CUDA device id.\")\n",
    "    )\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    current_experiment = Run.get_context().experiment\n",
    "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\n",
    "    _logger.info(\"tracking_uri: {0}\".format(tracking_uri))\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(current_experiment.name)\n",
    "\n",
    "    _logger.info(\"Getting device\")\n",
    "    device = args.device\n",
    "\n",
    "    _logger.info(\"Loading parquet input\")\n",
    "\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) \n",
    "\n",
    "    if device >= 0:\n",
    "        model = model.cuda()\n",
    "\n",
    "    if args.model_name_suffix < 0:\n",
    "        suffix = int(time.time())\n",
    "    else:\n",
    "        suffix = args.model_name_suffix\n",
    "    registered_name = \"{0}_{1}\".format(args.model_base_name, suffix)\n",
    "    _logger.info(f\"Registering model as {registered_name}\")\n",
    "\n",
    "    # Saving model with mlflow\n",
    "    _logger.info(\"Saving with mlflow\")\n",
    "\n",
    "    mlflow.pytorch.log_model(\n",
    "        model,\n",
    "        artifact_path=registered_name,\n",
    "        registered_model_name=registered_name\n",
    "    )\n",
    "\n",
    "    _logger.info(\"Writing JSON\")\n",
    "    dict = {\"id\": \"{0}:1\".format(registered_name)}\n",
    "    output_path = os.path.join(args.model_output_path, \"model_info.json\")\n",
    "    with open(output_path, \"w\") as of:\n",
    "        json.dump(dict, fp=of)\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create the python file to load the pretrained pytorch fasterrcnn model that was trained on MS COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_base_name=\"mscoco_model\"\n",
    "model_name_suffix=\"12972\"\n",
    "device=-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is to specify what type of model and model name for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading mscoco_component_src (0.01 MBs): 100%|##########| 5562/5562 [00:00<00:00, 33423.38it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(UserError) Failed to update component mscoco_component since fields \"1: code, 2: command\" are immutable, try specifying a new version.\nCode: UserError\nMessage: Failed to update component mscoco_component since fields \"1: code, 2: command\" are immutable, try specifying a new version.\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"eb3beedb0fde9a6daba7cc5b3be9fe8b\",\n        \"request\": \"a93f785ed2a152ee\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"eastus2\"\n}Type: Location\nInfo: {\n    \"value\": \"eastus2\"\n}Type: Time\nInfo: {\n    \"value\": \"2023-05-15T03:35:12.4544746+00:00\"\n}Type: InnerError\nInfo: {\n    \"value\": {\n        \"code\": \"BadArgument\",\n        \"innerError\": {\n            \"code\": \"ArgumentInvalid\",\n            \"innerError\": {\n                \"code\": \"UpdateComponentFailed\",\n                \"innerError\": null\n            }\n        }\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cjbarberan\\raiDPV2\\responsibleai\\notebooks\\MSCOCO_dpv2.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cjbarberan/raiDPV2/responsibleai/notebooks/MSCOCO_dpv2.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     f\u001b[39m.\u001b[39mwrite(yaml_contents)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cjbarberan/raiDPV2/responsibleai/notebooks/MSCOCO_dpv2.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m test_component_definition \u001b[39m=\u001b[39m load_component(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cjbarberan/raiDPV2/responsibleai/notebooks/MSCOCO_dpv2.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     source\u001b[39m=\u001b[39myaml_filename\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cjbarberan/raiDPV2/responsibleai/notebooks/MSCOCO_dpv2.ipynb#X14sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cjbarberan/raiDPV2/responsibleai/notebooks/MSCOCO_dpv2.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49mcomponents\u001b[39m.\u001b[39;49mcreate_or_update(test_component_definition)\n",
      "File \u001b[1;32mc:\\Users\\cjbarberan\\AppData\\Local\\anaconda3\\envs\\dpv2\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[0;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[1;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[0;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[0;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[1;32mc:\\Users\\cjbarberan\\AppData\\Local\\anaconda3\\envs\\dpv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_component_operations.py:370\u001b[0m, in \u001b[0;36mComponentOperations.create_or_update\u001b[1;34m(self, component, version, skip_validation, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m             result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_version_operation\u001b[39m.\u001b[39mcreate_or_update(\n\u001b[0;32m    362\u001b[0m                 name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    363\u001b[0m                 version\u001b[39m=\u001b[39mversion,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_args,\n\u001b[0;32m    368\u001b[0m             )\n\u001b[0;32m    369\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 370\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[0;32m    373\u001b[0m     component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(name\u001b[39m=\u001b[39mcomponent\u001b[39m.\u001b[39mname, version\u001b[39m=\u001b[39mcomponent\u001b[39m.\u001b[39mversion)\n",
      "File \u001b[1;32mc:\\Users\\cjbarberan\\AppData\\Local\\anaconda3\\envs\\dpv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_component_operations.py:361\u001b[0m, in \u001b[0;36mComponentOperations.create_or_update\u001b[1;34m(self, component, version, skip_validation, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m             result \u001b[39m=\u001b[39m _create_or_update_autoincrement(\n\u001b[0;32m    352\u001b[0m                 name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    353\u001b[0m                 body\u001b[39m=\u001b[39mrest_component_resource,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_args,\n\u001b[0;32m    359\u001b[0m             )\n\u001b[0;32m    360\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 361\u001b[0m             result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_version_operation\u001b[39m.\u001b[39;49mcreate_or_update(\n\u001b[0;32m    362\u001b[0m                 name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    363\u001b[0m                 version\u001b[39m=\u001b[39;49mversion,\n\u001b[0;32m    364\u001b[0m                 resource_group_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resource_group_name,\n\u001b[0;32m    365\u001b[0m                 workspace_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_workspace_name,\n\u001b[0;32m    366\u001b[0m                 body\u001b[39m=\u001b[39;49mrest_component_resource,\n\u001b[0;32m    367\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_args,\n\u001b[0;32m    368\u001b[0m             )\n\u001b[0;32m    369\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    370\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\cjbarberan\\AppData\\Local\\anaconda3\\envs\\dpv2\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\cjbarberan\\AppData\\Local\\anaconda3\\envs\\dpv2\\lib\\site-packages\\azure\\ai\\ml\\_restclient\\v2022_10_01\\operations\\_component_versions_operations.py:546\u001b[0m, in \u001b[0;36mComponentVersionsOperations.create_or_update\u001b[1;34m(self, resource_group_name, workspace_name, name, version, body, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m     map_error(status_code\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code, response\u001b[39m=\u001b[39mresponse, error_map\u001b[39m=\u001b[39merror_map)\n\u001b[0;32m    545\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize\u001b[39m.\u001b[39mfailsafe_deserialize(_models\u001b[39m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[1;32m--> 546\u001b[0m     \u001b[39mraise\u001b[39;00m HttpResponseError(response\u001b[39m=\u001b[39mresponse, model\u001b[39m=\u001b[39merror, error_format\u001b[39m=\u001b[39mARMErrorFormat)\n\u001b[0;32m    548\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m    549\u001b[0m     deserialized \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize(\u001b[39m'\u001b[39m\u001b[39mComponentVersion\u001b[39m\u001b[39m'\u001b[39m, pipeline_response)\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: (UserError) Failed to update component mscoco_component since fields \"1: code, 2: command\" are immutable, try specifying a new version.\nCode: UserError\nMessage: Failed to update component mscoco_component since fields \"1: code, 2: command\" are immutable, try specifying a new version.\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"eb3beedb0fde9a6daba7cc5b3be9fe8b\",\n        \"request\": \"a93f785ed2a152ee\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"eastus2\"\n}Type: Location\nInfo: {\n    \"value\": \"eastus2\"\n}Type: Time\nInfo: {\n    \"value\": \"2023-05-15T03:35:12.4544746+00:00\"\n}Type: InnerError\nInfo: {\n    \"value\": {\n        \"code\": \"BadArgument\",\n        \"innerError\": {\n            \"code\": \"ArgumentInvalid\",\n            \"innerError\": {\n                \"code\": \"UpdateComponentFailed\",\n                \"innerError\": null\n            }\n        }\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import load_component\n",
    "\n",
    "yaml_contents = f\"\"\"\n",
    "$schema: http://azureml/sdk-2-0/CommandComponent.json\n",
    "name: mscoco_component\n",
    "display_name: MSCOCO component for RAI example\n",
    "version: {rai_example_version_string}\n",
    "type: command\n",
    "inputs:\n",
    "  model_base_name:\n",
    "    type: string\n",
    "  model_name_suffix: # Set negative to use epoch_secs\n",
    "    type: integer\n",
    "    default: -1\n",
    "  device: # set to >= 0 to use GPU\n",
    "    type: integer\n",
    "    default: 0\n",
    "outputs:\n",
    "  model_output_path:\n",
    "    type: path\n",
    "code: ./mscoco_component_src/\n",
    "environment: azureml://registries/azureml/environments/responsibleai-vision-ubuntu20.04-py38-cpu/versions/17\n",
    "command: >-\n",
    "  python model_script.py\n",
    "  --model_base_name ${{{{inputs.model_base_name}}}}\n",
    "  --model_name_suffix ${{{{inputs.model_name_suffix}}}}\n",
    "  --device ${{{{inputs.device}}}}\n",
    "  --model_output_path ${{{{outputs.model_output_path}}}}\n",
    "\"\"\"\n",
    "\n",
    "yaml_filename = \"test_mscoco.yaml\"\n",
    "\n",
    "\n",
    "with open(yaml_filename, 'w') as f:\n",
    "    f.write(yaml_contents)\n",
    "    \n",
    "test_component_definition = load_component(\n",
    "    source=yaml_filename\n",
    ")\n",
    "\n",
    "ml_client.components.create_or_update(test_component_definition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yaml file to send it as an ML component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute: cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "all_compute_names = [x.name for x in ml_client.compute.list()]\n",
    "\n",
    "if compute_name in all_compute_names:\n",
    "    print(f\"Found existing compute: {compute_name}\")\n",
    "else:\n",
    "    my_compute = AmlCompute(\n",
    "        name=compute_name,\n",
    "        size=\"STANDARD_DS3_V2\",\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        idle_time_before_scale_down=3600\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(my_compute)\n",
    "    print(\"Initiated compute creation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find compute target to run the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import dsl, Input\n",
    "\n",
    "test_model_component = ml_client.components.get(\n",
    "    name=\"mscoco_component\", version=rai_example_version_string\n",
    ")\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=compute_name,\n",
    "    description=\"Register Model for RAI MSCOCO example\",\n",
    "    experiment_name=f\"RAI_MSCOCO_Example_Model_{model_name_suffix}\",\n",
    ")\n",
    "def my_pipeline(model_base_name, model_name_suffix, device):\n",
    "    test_model = test_component_definition(\n",
    "        model_base_name=model_base_name,\n",
    "        model_name_suffix=model_name_suffix,\n",
    "        device=device\n",
    "    )\n",
    "    test_model.set_limits(timeout=120)\n",
    "\n",
    "    return {}\n",
    "\n",
    "model_registration_pipeline_job = my_pipeline(model_base_name, model_name_suffix, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pipeline to load the model and register it, this is needed to create the RAI vision insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Completed\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import PipelineJob\n",
    "\n",
    "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
    "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    assert created_job is not None\n",
    "\n",
    "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\n",
    "        time.sleep(30)\n",
    "        created_job = ml_client.jobs.get(created_job.name)\n",
    "        print(\"Latest status : {0}\".format(created_job.status))\n",
    "    assert created_job.status == 'Completed'\n",
    "    return created_job\n",
    "\n",
    "# This is the actual submission\n",
    "testing_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once submitted we can monitor the progress of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_model_id = f'{model_base_name}_{model_name_suffix}:1'\n",
    "azureml_model_id = f'azureml:{expected_model_id}'\n",
    "#need these ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the name of the id, we will need for rai vision insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mscoco_test_mltable = Input(\n",
    "    type=\"mltable\", path=f\"{input_test_data}:{rai_example_version_string}\", mode=\"download\"\n",
    ")\n",
    "\n",
    "registry_name = \"azureml-preview\"\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "ml_client_registry = MLClient(\n",
    "        credential=credential,\n",
    "        subscription_id=ml_client.subscription_id,\n",
    "        resource_group_name=ml_client.resource_group_name,\n",
    "        registry_name=registry_name\n",
    ")\n",
    "\n",
    "rai_vision_insights_component = ml_client_registry.components.get(\n",
    "    name=\"rai_vision_insights\", version=version_string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "@dsl.pipeline(\n",
    "        compute=compute_name,\n",
    "        description=\"Example RAI computation on MSCOCO data\",\n",
    "        experiment_name=f\"RAI_MSCOCO_Example_RAIInsights_Computation_{model_name_suffix}\",\n",
    "    )\n",
    "def rai_mscoco_object_detection_pipeline(\n",
    "        target_column_name,\n",
    "        test_data,\n",
    "        classes\n",
    "    ):\n",
    "        # Initiate the RAIInsights\n",
    "        rai_image_job = rai_vision_insights_component(\n",
    "            task_type=\"object_detection\",\n",
    "            model_info=expected_model_id,\n",
    "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n",
    "            test_dataset=test_data,\n",
    "            target_column_name=target_column_name,\n",
    "            classes=classes,\n",
    "            model_type=\"pytorch\",\n",
    "            enable_error_analysis=False\n",
    "\n",
    "        )\n",
    "        rai_image_job.set_limits(timeout=120)\n",
    "\n",
    "        rai_image_job.outputs.dashboard.mode = \"upload\"\n",
    "        rai_image_job.outputs.ux_json.mode = \"upload\"\n",
    "\n",
    "        return {\n",
    "            \"dashboard\": rai_image_job.outputs.dashboard,\n",
    "            \"ux_json\": rai_image_job.outputs.ux_json\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from azure.ai.ml import Output\n",
    "\n",
    "insights_pipeline_job = rai_mscoco_object_detection_pipeline(\n",
    "    target_column_name=target_column_name,\n",
    "    test_data=mscoco_test_mltable,\n",
    "    classes='[\"person\", \"bicycle\", \"car\", \"motorcycle\",\"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\",\"street sign\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\",\"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"hat\", \"backpack\",\"umbrella\", \"shoe\", \"eye glasses\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\",\"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\",\"surfboard\", \"tennis racket\", \"bottle\", \"plate\", \"wine glass\", \"cup\", \"fork\", \"knife\",\"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\",\"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"mirror\", \"dining table\",\"window\", \"desk\", \"toilet\", \"door\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\",\"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"blender\",\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]'\n",
    ")\n",
    "\n",
    "rand_path = str(uuid.uuid4())\n",
    "insights_pipeline_job.outputs.dashboard = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\"\n",
    ")\n",
    "insights_pipeline_job.outputs.ux_json = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing a pipeline of RAI object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Completed\n"
     ]
    }
   ],
   "source": [
    "insights_job = submit_and_wait(ml_client, insights_pipeline_job)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor the progress, since this is on 25 ms coco images and to compute D-Rise this may take around 30-60 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit https://ml.azure.com/model/mscoco_model_12972:1/model_analysis?wsid=/subscriptions/a75ae43f-9f72-4699-ba66-d3a173cfe082/resourcegroups/MAIDAP-RG/workspaces/maidap_cv_ws to see your analysis\n"
     ]
    }
   ],
   "source": [
    "sub_id = ml_client._operation_scope.subscription_id\n",
    "rg_name = ml_client._operation_scope.resource_group_name\n",
    "ws_name = ml_client.workspace_name\n",
    "\n",
    "expected_uri = f\"https://ml.azure.com/model/{expected_model_id}/model_analysis?wsid=/subscriptions/{sub_id}/resourcegroups/{rg_name}/workspaces/{ws_name}\"\n",
    "\n",
    "print(f\"Please visit {expected_uri} to see your analysis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor the progress on azureml "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
