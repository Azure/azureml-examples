{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deploying and Using MedImageParse model for Inference using Batch Endpoints\n",
    "This example illustrates how to deploy MedImageParse, a state-of-the-art segmentation model tailored for biomedical imaging. For this Notebook, we use Python 3.10, AzureML v2.\n",
    "\n",
    "### Task\n",
    "The primary task is semantic segmentation, where the goal is to identify and label specific regions within an image based on their semantic meaning using a submitted image and a text prompt.\n",
    " \n",
    "### Model\n",
    "MedImageParse is powered by a transformer-based architecture, fine-tuned for segmentation tasks on extensive biomedical image datasets. It is designed to excel in handling complex segmentation challenges across diverse imaging modalities. \n",
    "\n",
    "### Inference data\n",
    "For this demonstration, we will use histopathology images stained with HE (Hematoxylin and Eosin) and focus on cell phenotyping, segmenting and identifying different types of cells in the tissue sample.\n",
    "\n",
    "### Outline\n",
    "1. Setup pre-requisites\n",
    "2. Pick a model to deploy\n",
    "3. Deploy the model to an batch endpoint\n",
    "4. Test the endpoint\n",
    "5. Clean up resources - delete the endpoint\n"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup pre-requisites\n",
    "* Install [Azure ML Client library for Python](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-ml-readme?view=azure-python)\n",
    "* Connect to AzureML Workspace and authenticate."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.entities import (\n",
    "    BatchEndpoint,\n",
    "    ModelBatchDeployment,\n",
    "    ModelBatchDeploymentSettings,\n",
    "    Model,\n",
    "    AmlCompute,\n",
    "    Data,\n",
    "    BatchRetrySettings,\n",
    "    CodeConfiguration,\n",
    "    Environment,\n",
    ")\n",
    "from azure.ai.ml.constants import AssetTypes, BatchDeploymentOutputAction\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import pandas as pd\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_workspace = MLClient.from_config(credential)\n",
    "print(\"Workspace:\", ml_workspace)\n",
    "ml_registry = MLClient(credential, registry_name=\"azureml\")\n",
    "print(\"Registry:\", ml_registry)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741730097817
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Pick a model to deploy\n",
    "\n",
    "In this example, we use the `MedImageParse` model. If you have opened this notebook for a different model, replace the model name accordingly."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = ml_registry.models.get(name=\"MedImageParse\", label=\"latest\")\n",
    "model"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741730098160
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Deploy the model to an online endpoint for real time inference\n",
    "Online endpoints give a durable REST API that can be used to integrate with applications that need to use the model.\n",
    "\n",
    "The steps below show how to deploy an endpoint programmatically. You can skip the steps in this section if you just want to test an existing endpoint. "
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create compute cluster"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "compute_name = \"mip-batch-cluster\"\n",
    "if not any(filter(lambda m: m.name == compute_name, ml_workspace.compute.list())):\n",
    "    compute_cluster = AmlCompute(\n",
    "        name=compute_name,\n",
    "        description=\"GPU cluster compute for MedImageParse inference\",\n",
    "        min_instances=0,\n",
    "        max_instances=1,\n",
    "        size=\"Standard_NC6s_v3\",\n",
    "    )\n",
    "    ml_workspace.compute.begin_create_or_update(compute_cluster).result()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741730105601
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create batch endpoint"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "endpoint_prefix = \"mip-batch\"\n",
    "endpoint_list = list(\n",
    "    filter(\n",
    "        lambda m: m.name.startswith(endpoint_prefix),\n",
    "        ml_workspace.batch_endpoints.list(),\n",
    "    )\n",
    ")\n",
    "\n",
    "if endpoint_list:\n",
    "    endpoint = endpoint_list and endpoint_list[0]\n",
    "    print(\"Found existing endpoint:\", endpoint.name)\n",
    "else:\n",
    "    # Creating a unique endpoint name by including a random suffix\n",
    "    allowed_chars = string.ascii_lowercase + string.digits\n",
    "    endpoint_suffix = \"\".join(random.choice(allowed_chars) for x in range(5))\n",
    "    endpoint_name = f\"{endpoint_prefix}-{endpoint_suffix}\"\n",
    "    endpoint = BatchEndpoint(\n",
    "        name=endpoint_name,\n",
    "        description=\"A batch endpoint for scoring images from MedImageParse.\",\n",
    "        tags={\"type\": \"medimageparse\"},\n",
    "    )\n",
    "    ml_workspace.begin_create_or_update(endpoint).result()\n",
    "    print(f\"Created new endpoint: {endpoint_name}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741730108434
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deploy MedImageParse to batch endpoint\n",
    "\n",
    "- **max_concurrency_per_instance**: Determines the number of worker process to spawn. Each worker process loads the model into GPU. We want to use multiple worker process to maximize GPU utilization, but not exceed available GPU memory.\n",
    "- **retry_settings**: Timeout may need to be adjusted based on batch size. Larger batch size requires longer timeout; otherwise, worker process may end prematurely."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "deployment = ModelBatchDeployment(\n",
    "    name=\"mip-dpl\",\n",
    "    description=\"A deployment for model MedImageParse\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=model,\n",
    "    compute=compute_name,\n",
    "    settings=ModelBatchDeploymentSettings(\n",
    "        max_concurrency_per_instance=4,\n",
    "        mini_batch_size=1,\n",
    "        instance_count=1,\n",
    "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "        output_file_name=\"predictions.csv\",\n",
    "        retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "        logging_level=\"info\",\n",
    "    ),\n",
    ")\n",
    "ml_workspace.begin_create_or_update(deployment).result()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741731514224
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ml_workspace.batch_endpoints.get_logs()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "endpoint = ml_workspace.batch_endpoints.get(endpoint.name)\n",
    "endpoint.defaults.deployment_name = deployment.name\n",
    "ml_workspace.batch_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(f\"The default deployment is {endpoint.defaults.deployment_name}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740784549318
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4 Test the endpoint - base64 encoded image and text"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load test dataset\n",
    "Download the test dataset using command `azcopy copy --recursive https://azuremlexampledata.blob.core.windows.net/data/healthcare-ai/ /home/azureuser/data/`"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import glob\n",
    "\n",
    "root_dir = \"/home/azureuser/data/healthcare-ai/medimageinsight-examparameter/pngs\"\n",
    "\n",
    "png_files = glob.glob(f\"{root_dir}/**/*.png\", recursive=True)\n",
    "print(f\"Found {len(png_files)} PNG files\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740784549462
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the input CSV file"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "\n",
    "def read_base64_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "data = []\n",
    "for f in png_files:\n",
    "    base64_image = read_base64_image(f)\n",
    "    data.append([base64_image, \"abnormality\"])\n",
    "\n",
    "csv_path = os.path.join(os.getcwd(), \"batch_input.csv\")\n",
    "df_input = pd.DataFrame(data, columns=[\"image\", \"text\"])\n",
    "df_input.to_csv(csv_path)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740784550103
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the test dataset into AzureML"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_name = \"mip-png-dataset\"\n",
    "\n",
    "png_dataset = Data(\n",
    "    path=csv_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"An unlabeled dataset for heart classification\",\n",
    "    name=dataset_name,\n",
    ")\n",
    "\n",
    "ml_workspace.data.create_or_update(png_dataset)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740784552092
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verify the test dataset is uploaded successfully"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ml_workspace.data.get(name=dataset_name, label=\"latest\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740784552223
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Submit a job to the batch endpoint"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "input = Input(type=AssetTypes.URI_FILE, path=png_dataset.path)\n",
    "input"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740784552341
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "job = ml_workspace.batch_endpoints.invoke(endpoint_name=endpoint.name, input=input)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740784560413
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Monitor job progress\n",
    "ml_workspace.jobs.stream(job.name)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740785453165
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download the job output\n",
    "MedImageParse embeddings can be found in file `named-outputs/score/predictions.csv`"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scoring_job = list(ml_workspace.jobs.list(parent_job_name=job.name))[0]\n",
    "scoring_job"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740785702373
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ml_workspace.jobs.download(\n",
    "    name=scoring_job.name, download_path=\".\", output_name=\"score\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740785706092
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load job result"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pred_csv_path = os.path.join(\"named-outputs\", \"score\", \"predictions.csv\")\n",
    "df_result = pd.read_csv(pred_csv_path, header=None)\n",
    "print(\"df_result.shape:\", df_result.shape)\n",
    "print(df_result.iloc[0])  # print first row"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740785710091
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display job result"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import base64\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_image(json_encoded):\n",
    "    \"\"\"Decode an image pixel data array in JSON.\n",
    "    Return image pixel data as an array.\n",
    "    \"\"\"\n",
    "    # Parse the JSON string\n",
    "    array_metadata = json.loads(json_encoded)\n",
    "    # Extract Base64 string, shape, and dtype\n",
    "    base64_encoded = array_metadata[\"data\"]\n",
    "    shape = tuple(array_metadata[\"shape\"])\n",
    "    dtype = np.dtype(array_metadata[\"dtype\"])\n",
    "    # Decode Base64 to byte string\n",
    "    array_bytes = base64.b64decode(base64_encoded)\n",
    "    # Convert byte string back to NumPy array and reshape\n",
    "    array = np.frombuffer(array_bytes, dtype=dtype).reshape(shape)\n",
    "    return array\n",
    "\n",
    "\n",
    "def parse_labels(s):\n",
    "    return json.loads(s.replace(\"'\", '\"'))\n",
    "\n",
    "\n",
    "def convert_to_rgba(image_np):\n",
    "    # Convert the image to 4 channels by adding an alpha channel\n",
    "    alpha_channel = (\n",
    "        np.ones((image_np.shape[0], image_np.shape[1], 1), dtype=image_np.dtype) * 255\n",
    "    )\n",
    "    image_rgba_np = np.concatenate((image_np, alpha_channel), axis=2)\n",
    "    return image_rgba_np\n",
    "\n",
    "\n",
    "def plot_segmentation_masks(original_image, segmentation_masks, labels):\n",
    "    \"\"\"Plot a list of segmentation mask over an image.\"\"\"\n",
    "    fig, ax = plt.subplots(1, len(segmentation_masks) + 1, figsize=(10, 5))\n",
    "    ax[0].imshow(original_image)\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "\n",
    "    for i, mask in enumerate(segmentation_masks):\n",
    "        ax[i + 1].imshow(original_image)\n",
    "        ax[i + 1].set_title(labels[i])\n",
    "        mask_temp = original_image.copy()\n",
    "        mask_temp[mask > 128] = [255, 0, 0, 255]\n",
    "        mask_temp[mask <= 128] = [0, 0, 0, 0]\n",
    "        ax[i + 1].imshow(mask_temp, alpha=0.9)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740785713161
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for index in range(len(df_input)):\n",
    "    orig_image = convert_to_rgba(plt.imread(png_files[index]))\n",
    "    result = df_result.iloc[index]\n",
    "\n",
    "    image_features = parse_image(result.iloc[1])\n",
    "    labels = parse_labels(result.iloc[2].replace(\"'\", '\"'))\n",
    "\n",
    "    # # Plot feature over image\n",
    "    print(f\"Image {index}\")\n",
    "    plot_segmentation_masks(orig_image, image_features, labels)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740785751168
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Clean up resources - delete the batch endpoint"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ml_workspace.batch_endpoints.begin_delete(endpoint_name).result()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python310-sdkv2",
   "language": "python",
   "display_name": "Python 3.10 - SDK v2"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   },
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "kernel_info": {
   "name": "python310-sdkv2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}