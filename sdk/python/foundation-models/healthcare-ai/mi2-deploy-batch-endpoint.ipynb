{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MedImageInsight for Image and Text Embeddings Deployment and Inference using Batch Endpoints\n",
    "\n",
    "This sample shows how to deploy MedImageInsight embedding type models to an batch endpoint for image and text embeddings inference. For this notebook, we use Python 3.10 - SDK v2. \n",
    "\n",
    "### Task\n",
    "MedImageInsight takes in images and/or text samples. For each image and text sample, feature embeddings are returned from the model.\n",
    " \n",
    "### Model\n",
    "The models that can perform the `embeddings` task are tagged with `embeddings`. We will use the `MedImageInsight` model in this notebook. \n",
    "\n",
    "### Inference data\n",
    "We will use a chest X-ray image and text as a sample input. \n",
    "\n",
    "### Outline\n",
    "1. Setup pre-requisites\n",
    "2. Pick a model to deploy\n",
    "3. Deploy the model to an online endpoint\n",
    "4. Test the endpoint\n",
    "5. Clean up resources - delete the endpoint"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup pre-requisites\n",
    "* Install [Azure ML Client library for Python](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-ml-readme?view=azure-python)\n",
    "* Connect to AzureML Workspace and authenticate."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.entities import (\n",
    "    BatchEndpoint,\n",
    "    ModelBatchDeployment,\n",
    "    ModelBatchDeploymentSettings,\n",
    "    Model,\n",
    "    AmlCompute,\n",
    "    Data,\n",
    "    BatchRetrySettings,\n",
    "    CodeConfiguration,\n",
    "    Environment,\n",
    ")\n",
    "from azure.ai.ml.constants import AssetTypes, BatchDeploymentOutputAction\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import pandas as pd\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_workspace = MLClient.from_config(credential)\n",
    "print(\"Workspace:\", ml_workspace)\n",
    "ml_registry = MLClient(credential, registry_name=\"azureml\")\n",
    "print(\"Registry:\", ml_registry)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715020627
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Pick a model to deploy\n",
    "\n",
    "Browse models in the Model Catalog in the AzureML Studio, filtering by the `embeddings` task. In this example, we use the `MedImageInsight` model. If you have opened this notebook for a different model, replace the model name accordingly."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = ml_registry.models.get(name=\"MedImageInsight\", label=\"latest\")\n",
    "model"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715021120
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create compute cluster\n"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "compute_name = \"mii-batch-cluster\"\n",
    "if not any(filter(lambda m: m.name == compute_name, ml_workspace.compute.list())):\n",
    "    compute_cluster = AmlCompute(\n",
    "        name=compute_name,\n",
    "        description=\"GPU cluster compute for MedImageInsight inference\",\n",
    "        min_instances=0,\n",
    "        max_instances=1,\n",
    "        size=\"Standard_NC6s_v3\",\n",
    "    )\n",
    "    ml_workspace.compute.begin_create_or_update(compute_cluster).result()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715024446
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Deploy the model to an batch endpoint for inference\n",
    "Batch endpoints give a durable REST API that can be used to integrate with applications that need to use the model."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create batch endpoint"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "endpoint_prefix = \"mii-batch\"\n",
    "endpoint_list = list(\n",
    "    filter(\n",
    "        lambda m: m.name.startswith(endpoint_prefix),\n",
    "        ml_workspace.batch_endpoints.list(),\n",
    "    )\n",
    ")\n",
    "\n",
    "if endpoint_list:\n",
    "    endpoint = endpoint_list and endpoint_list[0]\n",
    "    print(\"Found existing endpoint:\", endpoint.name)\n",
    "else:\n",
    "    # Creating a unique endpoint name by including a random suffix\n",
    "    allowed_chars = string.ascii_lowercase + string.digits\n",
    "    endpoint_suffix = \"\".join(random.choice(allowed_chars) for x in range(5))\n",
    "    endpoint_name = f\"{endpoint_prefix}-{endpoint_suffix}\"\n",
    "    endpoint = BatchEndpoint(\n",
    "        name=endpoint_name,\n",
    "        description=\"A batch endpoint for scoring images from MedImageInsigt.\",\n",
    "        tags={\"type\": \"medimageinsight\"},\n",
    "    )\n",
    "    ml_workspace.begin_create_or_update(endpoint).result()\n",
    "    print(f\"Created new endpoint: {endpoint_name}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715027444
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deploy MedImageInsight to batch endpoint\n",
    "\n",
    "- **max_concurrency_per_instance**: Determines the number of worker process to spawn. Each worker process loads the model into GPU. We want to use multiple worker process to maximize GPU utilization, but not exceed available GPU memory.\n",
    "- **retry_settings**: Timeout may need to be adjusted based on batch size. Larger batch size requires longer timeout; otherwise, worker process may end prematurely."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "deployment = ModelBatchDeployment(\n",
    "    name=\"mii-dpl\",\n",
    "    description=\"A deployment for model MedImageInsight\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=model,\n",
    "    compute=compute_name,\n",
    "    settings=ModelBatchDeploymentSettings(\n",
    "        max_concurrency_per_instance=4,\n",
    "        mini_batch_size=1,\n",
    "        instance_count=1,\n",
    "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "        output_file_name=\"predictions.csv\",\n",
    "        retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "        logging_level=\"info\",\n",
    "    ),\n",
    ")\n",
    "ml_workspace.begin_create_or_update(deployment).result()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715068852
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "endpoint = ml_workspace.batch_endpoints.get(endpoint.name)\n",
    "endpoint.defaults.deployment_name = deployment.name\n",
    "ml_workspace.batch_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(f\"The default deployment is {endpoint.defaults.deployment_name}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715070955
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4 Test the endpoint - base64 encoded image and text\n",
    "\n",
    "We will test the batch endpoint using the sample dataset."
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load sample dataset\n",
    "\n",
    "Download the sample dataset using command `azcopy copy --recursive https://azuremlexampledata.blob.core.windows.net/data/healthcare-ai/ /home/azureuser/data/`\n"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import glob\n",
    "\n",
    "root_dir = \"/home/azureuser/data/healthcare-ai/medimageinsight-examparameter/pngs\"\n",
    "\n",
    "png_files = glob.glob(f\"{root_dir}/**/*.png\", recursive=True)\n",
    "print(f\"Found {len(png_files)} PNG files\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715071052
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the input CSV file\n"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import base64\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "csv_folder = \"batch_inputs\"\n",
    "sample_dataset_size = len(png_files)\n",
    "target_dataset_size = 10000\n",
    "batch_max_size = 100\n",
    "batch_count = 0\n",
    "batch = []\n",
    "\n",
    "# read and encode image to base64\n",
    "def read_base64_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# write batch to a CSV file\n",
    "def write_to_csv():\n",
    "    csv_path = os.path.join(os.getcwd(), csv_folder, f\"batch_input{batch_count}.csv\")\n",
    "    df_input = pd.DataFrame(batch, columns=[\"image\", \"text\"])\n",
    "    df_input.to_csv(csv_path)\n",
    "\n",
    "\n",
    "# remove and create folder for CSV files\n",
    "shutil.rmtree(csv_folder)\n",
    "os.makedirs(csv_folder)\n",
    "\n",
    "# create test dataset by repeating images from the sample dataset\n",
    "for i in range(target_dataset_size):\n",
    "    png_index = i % sample_dataset_size\n",
    "    png_file = png_files[png_index]\n",
    "    base64_image = read_base64_image(png_file)\n",
    "    batch.append([base64_image, \"x-ray chest anteroposterior Pneumonia\"])\n",
    "\n",
    "    if len(batch) >= batch_max_size:\n",
    "        write_to_csv()\n",
    "        batch_count += 1\n",
    "        batch = []\n",
    "\n",
    "if batch:\n",
    "    write_to_csv()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741716507682
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the test dataset into AzureML\n"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_name = \"mii-png-dataset\"\n",
    "\n",
    "png_dataset = Data(\n",
    "    path=csv_folder,\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=f\"Sample dataset consist of {target_dataset_size} PNG images with batch size of {batch_max_size}\",\n",
    "    name=dataset_name,\n",
    ")\n",
    "\n",
    "ml_workspace.data.create_or_update(png_dataset)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741716613658
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verify the test dataset is uploaded successfully"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ml_workspace.data.get(name=dataset_name, label=\"latest\")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715979673
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Submit a job to the batch endpoint"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "input = Input(type=AssetTypes.URI_FILE, path=png_dataset.path)\n",
    "input"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1741715996816
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "job = ml_workspace.batch_endpoints.invoke(endpoint_name=endpoint.name, input=input)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Monitor job progress\n",
    "ml_workspace.jobs.stream(job.name)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download the job output\n",
    "\n",
    "MedImageInsight embeddings can be found in file `named-outputs/score/predictions.csv`\n"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scoring_job = list(ml_workspace.jobs.list(parent_job_name=job.name))[0]\n",
    "scoring_job"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "ml_workspace.jobs.download(\n",
    "    name=scoring_job.name, download_path=\".\", output_name=\"score\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load job result\n"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pred_csv_path = os.path.join(os.getcwd(), \"named-outputs\", \"score\", \"predictions.csv\")\n",
    "df_result = pd.read_csv(pred_csv_path, header=None)\n",
    "df_result.iloc[0]  # print first row"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1740429162012
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Clean up resources - delete the online endpoint"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ml_workspace.batch_endpoints.begin_delete(endpoint_name).result()"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {}
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "name": "python310-sdkv2",
   "language": "python",
   "display_name": "Python 3.10 - SDK v2"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}