{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline with Azure OpenAI CommandComponents from registry\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription - [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace with computer cluster - [Configure workspace](../../configuration.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](../../../README.md) - check the getting started section\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Connect to your AML workspace from the Python SDKv2\n",
    "- Define and load Azure OpenAI `CommandComponent` from the registry\n",
    "- Create `Pipeline` using loaded component.\n",
    "\n",
    "**Motivations** - This notebook covers the scenario where a user can load OpenAI components from the registry to create a pipeline and submit the job using sdkv2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Registry\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1 Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "from azure.ai.ml import MLClient, Input, load_component\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.dsl import pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configure credential\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. \n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "\n",
    "Reference for more available credentials if it does not work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Get a handle to the registry\n",
    "\n",
    "We need to initialize a MlClient pointed to the registry where the OpenAI components are available. [Check this api documentation for more details](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.mlclient?view=azure-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a handle to registry\n",
    "ml_client = MLClient(\n",
    "    credential=credential, registry_name=\"azureml\", region=\"northcentralus\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define and create components into workspace\n",
    "## 2.1 Load components from registry\n",
    "You need to modify the required params in the yaml files like version, compute uri, etc according to your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_pipeline = load_component(\n",
    "    client=ml_client, name=\"openai_completions_finetune_pipeline\", version=\"0.1.2\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Inspect loaded components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline component loaded successfully. Component spec:\")\n",
    "print(finetune_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sample pipeline job\n",
    "## 3.1 Build pipeline\n",
    "\n",
    "There are two types of tasks :\n",
    "\n",
    "1. completion : input dataset should have rows with \"prompt\" and \"completion\" keys\n",
    "2. chat : each row in the input dataset is a conversation represented as a list of json objects where each json object has \"role\" as one of the two values - user, assistant and \"content\" with the utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_TYPE = \"chat\"  # Change this to completion for completion dataset\n",
    "\n",
    "\n",
    "# Construct pipeline\n",
    "@pipeline(name=\"test-run\", compute=\"serverless\")\n",
    "def pipeline_with_registered_component(\n",
    "    train_dataset,\n",
    "    validation_dataset,\n",
    "    training_max_epochs=20,\n",
    "    model=\"gpt-35-turbo\",\n",
    "    registered_model_name=\"sdk-test-turbo-chat-1\",\n",
    "    learning_rate_multiplier=1,\n",
    "    batch_size=-1,\n",
    "    task_type=\"chat\",\n",
    "):\n",
    "    openai_completions_finetune_component_results = finetune_pipeline(\n",
    "        train_dataset=train_dataset,\n",
    "        validation_dataset=validation_dataset,\n",
    "        n_epochs=training_max_epochs,\n",
    "        model=model,\n",
    "        task_type=task_type,\n",
    "        registered_model_name=registered_model_name,\n",
    "        learning_rate_multiplier=learning_rate_multiplier,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    return openai_completions_finetune_component_results\n",
    "\n",
    "\n",
    "pipeline_job = pipeline_with_registered_component(\n",
    "    train_dataset=Input(type=AssetTypes.URI_FOLDER, path=\"./data/\"),\n",
    "    validation_dataset=Input(type=AssetTypes.URI_FOLDER, path=\"./data/\"),\n",
    "    training_max_epochs=1,\n",
    "    model=\"gpt-35-turbo\",  # Select any model from [\"babbage-002\", \"davinci-002\", \"gpt-35-turbo\"]\n",
    "    task_type=TASK_TYPE,\n",
    "    registered_model_name=\"sdk-test-turbo-chat-1\",\n",
    "    learning_rate_multiplier=1,\n",
    "    batch_size=-1,\n",
    ")\n",
    "\n",
    "# set pipeline level compute\n",
    "pipeline_job.settings.default_compute = \"serverless\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](https://github.com/Azure/azureml-examples/blob/6142c51451561447befa665e8dd6fb3ff80bdb62/sdk/python/jobs/configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a handle to workspace\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace_name = \"<AML_WORKSPACE_NAME>\"\n",
    "\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Submit pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit pipeline job to workspace\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"chat_pipeline_test\"\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
