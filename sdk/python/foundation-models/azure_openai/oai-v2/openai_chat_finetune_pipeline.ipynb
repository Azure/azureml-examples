{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline with Azure OpenAI CommandComponents from registry\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription - [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace with computer cluster - [Configure workspace](../../configuration.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](../../../README.md) - check the getting started section\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Connect to your AML workspace from the Python SDKv2\n",
    "- Define and load Azure OpenAI `CommandComponent` from the registry\n",
    "- Create `Pipeline` using loaded component.\n",
    "\n",
    "**Motivations** - This notebook covers the scenario where a user can load OpenAI components from the registry to create a pipeline and submit the job using sdkv2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Registry\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1 Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "from azure.ai.ml import MLClient, Input, load_component\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.dsl import pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configure credential\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. \n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "\n",
    "Reference for more available credentials if it does not work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DefaultAzureCredential failed to retrieve a token from the included credentials.\n",
      "Attempted credentials:\n",
      "\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
      "Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n",
      "\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint.\n",
      "\tSharedTokenCacheCredential: Azure Active Directory error '(invalid_grant) AADSTS700082: The refresh token has expired due to inactivity. The token was issued on 2023-06-27T07:40:26.0877328Z and was inactive for 90.00:00:00.\n",
      "Trace ID: 7a600205-ecad-486d-b5e0-d50447570300\n",
      "Correlation ID: 93f473f0-d206-47f2-a03b-d98520624425\n",
      "Timestamp: 2023-10-05 06:54:01Z'\n",
      "Content: {\"error\":\"invalid_grant\",\"error_description\":\"AADSTS700082: The refresh token has expired due to inactivity. The token was issued on 2023-06-27T07:40:26.0877328Z and was inactive for 90.00:00:00.\\r\\nTrace ID: 7a600205-ecad-486d-b5e0-d50447570300\\r\\nCorrelation ID: 93f473f0-d206-47f2-a03b-d98520624425\\r\\nTimestamp: 2023-10-05 06:54:01Z\",\"error_codes\":[700082],\"timestamp\":\"2023-10-05 06:54:01Z\",\"trace_id\":\"7a600205-ecad-486d-b5e0-d50447570300\",\"correlation_id\":\"93f473f0-d206-47f2-a03b-d98520624425\",\"error_uri\":\"https://login.microsoftonline.com/error?code=700082\"}\n",
      "To mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Get a handle to the registry\n",
    "\n",
    "We need to initialize a MlClient pointed to the registry where the OpenAI components are available. [Check this api documentation for more details](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.mlclient?view=azure-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a handle to registry\n",
    "ml_client = MLClient(credential=credential,\n",
    "                    registry_name=\"azureml\",\n",
    "                    registry_location=\"eastus\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define and create components into workspace\n",
    "## 2.1 Load components from registry\n",
    "You need to modify the required params in the yaml files like version, compute uri, etc according to your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_pipeline = load_component(\n",
    "    client=ml_client, name=\"openai_completions_finetune_pipeline\", version=\"0.0.9\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Inspect loaded components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline component loaded successfully. Component spec:\n",
      "$schema: http://azureml/sdk-2-0/PipelineComponent.json\n",
      "name: openai_completions_finetune_pipeline\n",
      "version: 0.0.9\n",
      "display_name: OpenAI Completions Finetune Pipeline\n",
      "description: Finetune your own OAI model. Visit https://learn.microsoft.com/en-us/azure/cognitive-services/openai/\n",
      "  for more info.\n",
      "type: pipeline\n",
      "inputs:\n",
      "  train_dataset:\n",
      "    type: uri_folder\n",
      "    description: Input dataset (file or folder). If a folder dataset is passed, includes\n",
      "      all nested files.\n",
      "    optional: false\n",
      "  validation_dataset:\n",
      "    type: uri_folder\n",
      "    description: Input dataset (file or folder). If a folder dataset is passed, includes\n",
      "      all nested files.\n",
      "    optional: true\n",
      "  model:\n",
      "    type: string\n",
      "    optional: false\n",
      "    default: gpt-35-turbo\n",
      "    description: GPT model engine\n",
      "    enum:\n",
      "    - babbage-002\n",
      "    - davinci-002\n",
      "    - gpt-35-turbo\n",
      "  task_type:\n",
      "    type: string\n",
      "    optional: false\n",
      "    description: Dataset type - chat or completion\n",
      "    enum:\n",
      "    - chat\n",
      "    - completion\n",
      "  registered_model_name:\n",
      "    type: string\n",
      "    optional: false\n",
      "    description: User-defined registered model name\n",
      "  n_epochs:\n",
      "    type: integer\n",
      "    optional: false\n",
      "    default: '-1'\n",
      "    description: Number of training epochs. If set to -1, number of epochs will be\n",
      "      determined dynamically based on the input data.\n",
      "  learning_rate_multiplier:\n",
      "    type: number\n",
      "    optional: false\n",
      "    default: '1.0'\n",
      "    description: The learning rate multiplier to use for training.\n",
      "  batch_size:\n",
      "    type: integer\n",
      "    optional: false\n",
      "    default: '-1'\n",
      "    description: Global batch size. If set to -1, batch size will be determined dynamically\n",
      "      based on the input data.\n",
      "outputs:\n",
      "  output_model:\n",
      "    type: uri_folder\n",
      "    description: Dataset with the output model weights (LoRA weights)\n",
      "  output_merged_model:\n",
      "    type: uri_folder\n",
      "    description: Dataset with the output (merged) model weights\n",
      "creation_context:\n",
      "  created_at: '2023-10-04T15:37:29.377685+00:00'\n",
      "  created_by: Microsoft\n",
      "  created_by_type: User\n",
      "  last_modified_at: '2023-10-04T15:37:29.377686+00:00'\n",
      "  last_modified_by: Microsoft\n",
      "  last_modified_by_type: User\n",
      "is_deterministic: false\n",
      "tags:\n",
      "  contact: gpt3finetuning@microsoft.com\n",
      "id: azureml://registries/azureml/components/openai_completions_finetune_pipeline/versions/0.0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Pipeline component loaded successfully. Component spec:\")\n",
    "print(finetune_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sample pipeline job\n",
    "## 3.1 Build pipeline\n",
    "\n",
    "There are two types of tasks :\n",
    "\n",
    "1. completion : input dataset should have rows with \"prompt\" and \"completion\" keys\n",
    "2. chat : each row in the input dataset is a conversation represented as a list of json objects where each json object has \"role\" as one of the two values - user, assistant and \"content\" with the utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TASK_TYPE = \"chat\" # Change this to completion for completion dataset\n",
    "\n",
    "# Construct pipeline\n",
    "@pipeline()\n",
    "def pipeline_with_registered_component(\n",
    "    train_dataset,\n",
    "    validation_dataset,\n",
    "    training_max_epochs=20,\n",
    "    model=\"gpt-35-turbo\",\n",
    "    registered_model_name=\"sdk-test-turbo-chat-1\",\n",
    "    learning_rate_multiplier=1,\n",
    "    batch_size=-1,\n",
    "    task_type=\"chat\"\n",
    "):\n",
    "    openai_completions_finetune_component_results = (\n",
    "        finetune_pipeline(\n",
    "            train_dataset=train_dataset,\n",
    "            validation_dataset=validation_dataset,\n",
    "            n_epochs=training_max_epochs,\n",
    "            model=model,\n",
    "            task_type=task_type,\n",
    "            registered_model_name=registered_model_name,\n",
    "            learning_rate_multiplier=learning_rate_multiplier,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return openai_completions_finetune_component_results\n",
    "\n",
    "pipeline_job = pipeline_with_registered_component(\n",
    "    train_dataset=Input(type=AssetTypes.URI_FOLDER, path=\"./data/\"),\n",
    "    validation_dataset=Input(type=AssetTypes.URI_FOLDER, path=\"./data/\"),\n",
    "    training_max_epochs=1,\n",
    "    model=\"gpt-35-turbo\",   # Select any model from [\"babbage-002\", \"davinci-002\", \"gpt-35-turbo\", \"gpt-4\"]\n",
    "    task_type=TASK_TYPE,\n",
    "    registered_model_name=\"sdk-test-turbo-chat-1\",\n",
    "    learning_rate_multiplier=1,\n",
    "    batch_size=-1\n",
    ")\n",
    "\n",
    "# set pipeline level compute\n",
    "pipeline_job.settings.default_compute = \"serverless\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](https://github.com/Azure/azureml-examples/blob/6142c51451561447befa665e8dd6fb3ff80bdb62/sdk/python/jobs/configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We could not find config.json in: . or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n"
     ]
    }
   ],
   "source": [
    "# Get a handle to workspace\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace_name = \"<AML_WORKSPACE_NAME>\"\n",
    "    subscription_id = \"ed2cab61-14cc-4fb3-ac23-d72609214cfd\"\n",
    "    resource_group = \"daholsterg\"\n",
    "    workspace_name = \"daholstewsncus-0923-aipgpu\"\n",
    "\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Submit pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'azure.core.exceptions.ServiceRequestError'>:\n<urllib3.connection.HTTPSConnection object at 0x00000184A84ABB20>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServiceRequestError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:1061\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_input\u001b[1;34m(self, entry, base_path)\u001b[0m\n\u001b[0;32m   1060\u001b[0m local_path \u001b[39m=\u001b[39m Path(base_path \u001b[39mor\u001b[39;00m Path\u001b[39m.\u001b[39mcwd(), entry\u001b[39m.\u001b[39mpath)\u001b[39m.\u001b[39mresolve()\n\u001b[1;32m-> 1061\u001b[0m entry\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m _upload_and_generate_remote_uri(\n\u001b[0;32m   1062\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_scope,\n\u001b[0;32m   1063\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datastore_operations,\n\u001b[0;32m   1064\u001b[0m     local_path,\n\u001b[0;32m   1065\u001b[0m     datastore_name\u001b[39m=\u001b[39;49mdatastore_name,\n\u001b[0;32m   1066\u001b[0m     show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress,\n\u001b[0;32m   1067\u001b[0m )\n\u001b[0;32m   1068\u001b[0m \u001b[39m# TODO : Move this part to a common place\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\_artifacts\\_artifact_utilities.py:328\u001b[0m, in \u001b[0;36m_upload_and_generate_remote_uri\u001b[1;34m(operation_scope, datastore_operation, path, artifact_type, datastore_name, show_progress)\u001b[0m\n\u001b[0;32m    327\u001b[0m asset_name \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39muuid4())\n\u001b[1;32m--> 328\u001b[0m artifact_info \u001b[39m=\u001b[39m _upload_to_datastore(\n\u001b[0;32m    329\u001b[0m     operation_scope\u001b[39m=\u001b[39;49moperation_scope,\n\u001b[0;32m    330\u001b[0m     datastore_operation\u001b[39m=\u001b[39;49mdatastore_operation,\n\u001b[0;32m    331\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[0;32m    332\u001b[0m     datastore_name\u001b[39m=\u001b[39;49mdatastore_name,\n\u001b[0;32m    333\u001b[0m     asset_name\u001b[39m=\u001b[39;49masset_name,\n\u001b[0;32m    334\u001b[0m     artifact_type\u001b[39m=\u001b[39;49martifact_type,\n\u001b[0;32m    335\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m    336\u001b[0m )\n\u001b[0;32m    338\u001b[0m path \u001b[39m=\u001b[39m artifact_info\u001b[39m.\u001b[39mrelative_path\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\_artifacts\\_artifact_utilities.py:300\u001b[0m, in \u001b[0;36m_upload_to_datastore\u001b[1;34m(operation_scope, datastore_operation, path, artifact_type, datastore_name, show_progress, asset_name, asset_version, asset_hash, ignore_file, sas_uri, blob_uri)\u001b[0m\n\u001b[0;32m    299\u001b[0m     asset_hash \u001b[39m=\u001b[39m get_object_hash(path, ignore_file)\n\u001b[1;32m--> 300\u001b[0m artifact \u001b[39m=\u001b[39m upload_artifact(\n\u001b[0;32m    301\u001b[0m     \u001b[39mstr\u001b[39;49m(path),\n\u001b[0;32m    302\u001b[0m     datastore_operation,\n\u001b[0;32m    303\u001b[0m     operation_scope,\n\u001b[0;32m    304\u001b[0m     datastore_name,\n\u001b[0;32m    305\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m    306\u001b[0m     asset_hash\u001b[39m=\u001b[39;49masset_hash,\n\u001b[0;32m    307\u001b[0m     asset_name\u001b[39m=\u001b[39;49masset_name,\n\u001b[0;32m    308\u001b[0m     asset_version\u001b[39m=\u001b[39;49masset_version,\n\u001b[0;32m    309\u001b[0m     ignore_file\u001b[39m=\u001b[39;49mignore_file,\n\u001b[0;32m    310\u001b[0m     sas_uri\u001b[39m=\u001b[39;49msas_uri,\n\u001b[0;32m    311\u001b[0m )\n\u001b[0;32m    312\u001b[0m \u001b[39mif\u001b[39;00m blob_uri:\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\_artifacts\\_artifact_utilities.py:180\u001b[0m, in \u001b[0;36mupload_artifact\u001b[1;34m(local_path, datastore_operation, operation_scope, datastore_name, asset_hash, show_progress, asset_name, asset_version, ignore_file, sas_uri)\u001b[0m\n\u001b[0;32m    178\u001b[0m     storage_client \u001b[39m=\u001b[39m get_storage_client(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdatastore_info)\n\u001b[1;32m--> 180\u001b[0m artifact_info \u001b[39m=\u001b[39m storage_client\u001b[39m.\u001b[39;49mupload(\n\u001b[0;32m    181\u001b[0m     local_path,\n\u001b[0;32m    182\u001b[0m     asset_hash\u001b[39m=\u001b[39;49masset_hash,\n\u001b[0;32m    183\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m    184\u001b[0m     name\u001b[39m=\u001b[39;49masset_name,\n\u001b[0;32m    185\u001b[0m     version\u001b[39m=\u001b[39;49masset_version,\n\u001b[0;32m    186\u001b[0m     ignore_file\u001b[39m=\u001b[39;49mignore_file,\n\u001b[0;32m    187\u001b[0m )\n\u001b[0;32m    189\u001b[0m artifact \u001b[39m=\u001b[39m ArtifactStorageInfo(\n\u001b[0;32m    190\u001b[0m     name\u001b[39m=\u001b[39martifact_info[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    191\u001b[0m     version\u001b[39m=\u001b[39martifact_info[\u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m     is_file\u001b[39m=\u001b[39mPath(local_path)\u001b[39m.\u001b[39mis_file(),\n\u001b[0;32m    200\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\_artifacts\\_blob_storage_helper.py:103\u001b[0m, in \u001b[0;36mBlobStorageClient.upload\u001b[1;34m(self, source, name, version, ignore_file, asset_hash, show_progress)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(source):\n\u001b[1;32m--> 103\u001b[0m     upload_directory(\n\u001b[0;32m    104\u001b[0m         storage_client\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    105\u001b[0m         source\u001b[39m=\u001b[39;49msource,\n\u001b[0;32m    106\u001b[0m         dest\u001b[39m=\u001b[39;49masset_id,\n\u001b[0;32m    107\u001b[0m         msg\u001b[39m=\u001b[39;49mmsg,\n\u001b[0;32m    108\u001b[0m         show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m    109\u001b[0m         ignore_file\u001b[39m=\u001b[39;49mignore_file,\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\_utils\\_asset_utils.py:622\u001b[0m, in \u001b[0;36mupload_directory\u001b[1;34m(storage_client, source, dest, msg, show_progress, ignore_file)\u001b[0m\n\u001b[0;32m    621\u001b[0m     storage_client\u001b[39m.\u001b[39mindicator_file \u001b[39m=\u001b[39m upload_paths[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 622\u001b[0m     storage_client\u001b[39m.\u001b[39;49mcheck_blob_exists()\n\u001b[0;32m    624\u001b[0m \u001b[39m# Submit paths to workers for upload\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\_artifacts\\_blob_storage_helper.py:196\u001b[0m, in \u001b[0;36mBlobStorageClient.check_blob_exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[0;32m    191\u001b[0m         message\u001b[39m=\u001b[39mmsg,\n\u001b[0;32m    192\u001b[0m         no_personal_data_message\u001b[39m=\u001b[39mmsg,\n\u001b[0;32m    193\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mARTIFACT,\n\u001b[0;32m    194\u001b[0m         error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mUSER_ERROR,\n\u001b[0;32m    195\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\_artifacts\\_blob_storage_helper.py:155\u001b[0m, in \u001b[0;36mBlobStorageClient.check_blob_exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    153\u001b[0m legacy_blob_client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer_client\u001b[39m.\u001b[39mget_blob_client(blob\u001b[39m=\u001b[39mlegacy_indicator_file)\n\u001b[1;32m--> 155\u001b[0m properties \u001b[39m=\u001b[39m blob_client\u001b[39m.\u001b[39;49mget_blob_properties()\n\u001b[0;32m    156\u001b[0m metadata \u001b[39m=\u001b[39m properties\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\storage\\blob\\_blob_client.py:1313\u001b[0m, in \u001b[0;36mBlobClient.get_blob_properties\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1312\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m partial(deserialize_pipeline_response_into_cls, cls_method)\n\u001b[1;32m-> 1313\u001b[0m     blob_props \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mblob\u001b[39m.\u001b[39mget_properties(\n\u001b[0;32m   1314\u001b[0m         timeout\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1315\u001b[0m         version_id\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mversion_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1316\u001b[0m         snapshot\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msnapshot,\n\u001b[0;32m   1317\u001b[0m         lease_access_conditions\u001b[39m=\u001b[39maccess_conditions,\n\u001b[0;32m   1318\u001b[0m         modified_access_conditions\u001b[39m=\u001b[39mmod_conditions,\n\u001b[0;32m   1319\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m deserialize_blob_properties,\n\u001b[0;32m   1320\u001b[0m         cpk_info\u001b[39m=\u001b[39mcpk_info,\n\u001b[0;32m   1321\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1322\u001b[0m \u001b[39mexcept\u001b[39;00m HttpResponseError \u001b[39mas\u001b[39;00m error:\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\storage\\blob\\_generated\\operations\\_blob_operations.py:1874\u001b[0m, in \u001b[0;36mBlobOperations.get_properties\u001b[1;34m(self, snapshot, version_id, timeout, request_id_parameter, lease_access_conditions, cpk_info, modified_access_conditions, **kwargs)\u001b[0m\n\u001b[0;32m   1872\u001b[0m request\u001b[39m.\u001b[39murl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mformat_url(request\u001b[39m.\u001b[39murl)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m-> 1874\u001b[0m pipeline_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39m_pipeline\u001b[39m.\u001b[39mrun(  \u001b[39m# type: ignore # pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1875\u001b[0m     request, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   1876\u001b[0m )\n\u001b[0;32m   1878\u001b[0m response \u001b[39m=\u001b[39m pipeline_response\u001b[39m.\u001b[39mhttp_response\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:213\u001b[0m, in \u001b[0;36mPipeline.run\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m first_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies \u001b[39melse\u001b[39;00m _TransportRunner(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport)\n\u001b[1;32m--> 213\u001b[0m \u001b[39mreturn\u001b[39;00m first_node\u001b[39m.\u001b[39;49msend(pipeline_request)\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 70 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py:181\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mwhile\u001b[39;00m retryable:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m    182\u001b[0m     redirect_location \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_redirect_location(response)\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\storage\\blob\\_shared\\policies.py:546\u001b[0m, in \u001b[0;36mStorageRetryPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    547\u001b[0m \u001b[39mif\u001b[39;00m retry_settings[\u001b[39m'\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\storage\\blob\\_shared\\policies.py:520\u001b[0m, in \u001b[0;36mStorageRetryPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m    521\u001b[0m     \u001b[39mif\u001b[39;00m is_retry(response, retry_settings[\u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 70 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\storage\\blob\\_shared\\policies.py:313\u001b[0m, in \u001b[0;36mStorageResponseHook.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    310\u001b[0m response_callback \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mresponse_callback\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \\\n\u001b[0;32m    311\u001b[0m     request\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mraw_response_hook\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_callback)\n\u001b[1;32m--> 313\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m    315\u001b[0m will_retry \u001b[39m=\u001b[39m is_retry(response, request\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:70\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\_base.py:108\u001b[0m, in \u001b[0;36m_TransportRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    105\u001b[0m request\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39minsecure_domain_change\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m PipelineResponse(\n\u001b[0;32m    107\u001b[0m     request\u001b[39m.\u001b[39mhttp_request,\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sender\u001b[39m.\u001b[39msend(request\u001b[39m.\u001b[39mhttp_request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrequest\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39moptions),\n\u001b[0;32m    109\u001b[0m     context\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mcontext,\n\u001b[0;32m    110\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\storage\\blob\\_shared\\base_client.py:329\u001b[0m, in \u001b[0;36mTransportWrapper.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\u001b[39mself\u001b[39m, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\storage\\blob\\_shared\\base_client.py:329\u001b[0m, in \u001b[0;36mTransportWrapper.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\u001b[39mself\u001b[39m, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py:376\u001b[0m, in \u001b[0;36mRequestsTransport.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39mif\u001b[39;00m error:\n\u001b[1;32m--> 376\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[0;32m    377\u001b[0m \u001b[39mif\u001b[39;00m _is_rest(request):\n",
      "\u001b[1;31mServiceRequestError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x00000184A84ABB20>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:542\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[1;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[1;32m--> 542\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[0;32m    544\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:898\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[1;34m(self, job)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, PipelineJob):\n\u001b[0;32m    897\u001b[0m     \u001b[39m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m--> 898\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_job_inputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flatten_group_inputs(job\u001b[39m.\u001b[39;49minputs), job\u001b[39m.\u001b[39;49m_base_path)\n\u001b[0;32m    899\u001b[0m     \u001b[39m# inputs in sub-pipelines has been resolved in\u001b[39;00m\n\u001b[0;32m    900\u001b[0m     \u001b[39m# self._resolve_arm_id_or_azureml_id(job, self._orchestrators.get_asset_arm_id)\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[39m# as they are part of the pipeline component\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:976\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_inputs\u001b[1;34m(self, entries, base_path)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m entries:\n\u001b[1;32m--> 976\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_job_input(entry, base_path)\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:1074\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_input\u001b[1;34m(self, entry, base_path)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1074\u001b[0m     \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[0;32m   1075\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSupported input path value are ARM id, AzureML id, remote uri or local path.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1076\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMet \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1077\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[0;32m   1078\u001b[0m         no_personal_data_message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSupported input path value are ARM id, AzureML id, remote uri or local path.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1079\u001b[0m         error\u001b[39m=\u001b[39me,\n\u001b[0;32m   1080\u001b[0m         error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mUSER_ERROR,\n\u001b[0;32m   1081\u001b[0m         error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mINVALID_VALUE,\n\u001b[0;32m   1082\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mValidationException\u001b[0m: Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'azure.core.exceptions.ServiceRequestError'>:\n<urllib3.connection.HTTPSConnection object at 0x00000184A84ABB20>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anagarajan\\Documents\\azureml-examples\\sdk\\python\\foundation-models\\azure_openai\\oai-v2\\openai_chat_finetune_pipeline.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anagarajan/Documents/azureml-examples/sdk/python/foundation-models/azure_openai/oai-v2/openai_chat_finetune_pipeline.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Submit pipeline job to workspace\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anagarajan/Documents/azureml-examples/sdk/python/foundation-models/azure_openai/oai-v2/openai_chat_finetune_pipeline.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pipeline_job \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49mjobs\u001b[39m.\u001b[39;49mcreate_or_update(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anagarajan/Documents/azureml-examples/sdk/python/foundation-models/azure_openai/oai-v2/openai_chat_finetune_pipeline.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     pipeline_job, experiment_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mchat_pipeline_test\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anagarajan/Documents/azureml-examples/sdk/python/foundation-models/azure_openai/oai-v2/openai_chat_finetune_pipeline.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anagarajan/Documents/azureml-examples/sdk/python/foundation-models/azure_openai/oai-v2/openai_chat_finetune_pipeline.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pipeline_job\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[0;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[1;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[0;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[0;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:608\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[1;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmarshmallow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m SchemaValidationError\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n\u001b[1;32m--> 608\u001b[0m     log_and_raise_error(ex)\n\u001b[0;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[1;32mc:\\Users\\anagarajan\\.conda\\envs\\sdkv2\\lib\\site-packages\\azure\\ai\\ml\\_exception_helper.py:295\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[1;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    293\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m--> 295\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(formatted_error)\n",
      "\u001b[1;31mException\u001b[0m: \n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'azure.core.exceptions.ServiceRequestError'>:\n<urllib3.connection.HTTPSConnection object at 0x00000184A84ABB20>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Submit pipeline job to workspace\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"chat_pipeline_test\"\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
