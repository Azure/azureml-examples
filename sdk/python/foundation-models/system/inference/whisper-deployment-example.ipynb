{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Notebook to deploy a Whisper MLFlow Huggingface model to an AML workspace using Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define required parameters\n",
    "\n",
    "Update these parameters to test deployments in your own workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "subscription_id=\"\" # Replace with your subscription ID\n",
    "resource_group=\"\" # Replace with your resource group name\n",
    "workspace_name=\"\" # Replace with your workspace name\n",
    "registry_name=\"\" # Replace with your registry name\n",
    "endpoint_name=\"\" # Replace with your endpoint name\n",
    "deployment_name=\"\" # Replace with your deployment name\n",
    "model_name=\"openai-whisper-large\" # Name of the whisper-model in the registry\n",
    "sku_name=\"Standard_DS4_v2\" # Name of the sku(instance type) Check the model-list(can be found in the parent folder(inference)) to get the most optimal sku for your model (Default: Standard_DS4_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell if all libraries are already installed\n",
    "# The required libraries can be installed in the local environment using the following command:\n",
    "%pip install azure-ai-ml==1.2.0 azure-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import CodeConfiguration, Environment, Model, ManagedOnlineDeployment, ManagedOnlineEndpoint, OnlineRequestSettings\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the ML Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ML Client to interact with your workspace\n",
    "ws_client = MLClient(DefaultAzureCredential(), subscription_id=subscription_id, resource_group_name=resource_group, workspace_name=workspace_name)\n",
    "\n",
    "# Create an ML Client to interact with the registry\n",
    "reg_client = MLClient(DefaultAzureCredential(), subscription_id=subscription_id, resource_group_name=resource_group, registry_name=registry_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the model in the registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell validates the existence of the model in the registry\n",
    "try:\n",
    "    model_list = reg_client.models.list(name=model_name)\n",
    "    version=list(model_list)[0].version\n",
    "    model = reg_client.models.get(model_name, version)\n",
    "    model.tags.update({\"registry\":registry_name})\n",
    "    print(f\"Model validated successfully. Using model {model_name}, version {version}\")\n",
    "except:\n",
    "    print(\"Model not found in the registry. Check the registry for the list of supported models\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model locally\n",
    "reg_client.models.download(name=model_name, version=version)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model to the workspace\n",
    "mlflow_model=Model(\n",
    "        path=f\"./{model_name}/mlflow_model_folder\", # replace with pointer to local download\n",
    "        type=AssetTypes.MLFLOW_MODEL,\n",
    "        name=model_name,\n",
    "        tags=model.tags,\n",
    "        description=\"MLflow model created from local path\")\n",
    "\n",
    "ws_model = ws_client.create_or_update(mlflow_model)\n",
    "print(f\"{ws_model}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environment to support the whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the whisper environment from ACR\n",
    "whisper_environment = Environment(name=\"whisper-env\", image=\"docker.io/whisperlarge/mlflow-huggingface:pyfunc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an online endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the endpoint already exists in the workspace\n",
    "try:\n",
    "    endpoint = ws_client.online_endpoints.get(endpoint_name)\n",
    "    print(\"---Endpoint already exists---\")\n",
    "except:\n",
    "    # Create an online endpoint if it doesn't exist\n",
    "\n",
    "    # Define the endpoint\n",
    "    endpoint = ManagedOnlineEndpoint(name=endpoint_name, description=\"Test endpoint for model\")\n",
    "\n",
    "    # Trigger the endpoint creation\n",
    "    try:\n",
    "        ws_client.begin_create_or_update(endpoint).wait()\n",
    "        print(\"\\n---Endpoint created successfully---\\n\")\n",
    "    except Exception as err:\n",
    "        raise RuntimeError(f\"Endpoint creation failed. Detailed Response:\\n{err}\") from err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an online endpoint-deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deployment\n",
    "# Update the model version as necessary\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"default\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=f\"azureml:{ws_model.name}:{ws_model.version}\",\n",
    "    environment=whisper_environment,\n",
    "    code_configuration= CodeConfiguration( code = \"./whisper_deployment_resources/\", scoring_script=\"whisper_score.py\"),\n",
    "    instance_type=sku_name,\n",
    "    instance_count=1,\n",
    "    request_settings=OnlineRequestSettings(request_timeout_ms=60000) # extended request_timeout to 60sec\n",
    ")\n",
    "\n",
    "# Trigger the deployment creation\n",
    "try:\n",
    "    ws_client.begin_create_or_update(deployment).wait()\n",
    "    print(\"\\n---Deployment created successfully---\\n\")\n",
    "except Exception as err:\n",
    "    raise RuntimeError(f\"Deployment creation failed. Detailed Response:\\n{err}\") from err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Audio File to Base64 encoded string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# languages supported are:\n",
    "# \"en\",\"zh\",\"de\",\"es\",\"ru\",\"ko\",\"fr\",\"ja\",\"pt\",\"tr\",\"pl\",\"ca\",\"nl\",\"ar\",\"sv\",\"it\",\n",
    "# \"id\",\"hi\",\"fi\",\"vi\",\"he\",\"uk\",\"el\",\"ms\",\"cs\",\"ro\",\"da\",\"hu\",\"ta\",\"'no'\",\"th\",\"ur\",\"hr\",\n",
    "# \"bg\",\"lt\",\"la\",\"mi\",\"ml\",\"cy\",\"sk\",\"te\",\"fa\",\"lv\",\"bn\",\"sr\",\"az\",\"sl\",\"kn\",\"et\",\"mk\",\n",
    "# \"br\",\"eu\",\"is\",\"hy\",\"ne\",\"mn\",\"bs\",\"kk\",\"sq\",\"sw\",\"gl\",\"mr\",\"pa\",\"si\",\"km\",\"sn\",\"yo\",\n",
    "# \"so\",\"af\",\"oc\",\"ka\",\"be\",\"tg\",\"sd\",\"gu\",\"am\",\"yi\",\"lo\",\"uz\",\"fo\",\"ht\",\"ps\",\"tk\",\n",
    "# \"nn\",\"mt\",\"sa\",\"lb\",\"my\",\"bo\",\"tl\",\"mg\",\"as\",\"tt\",\"haw\",\"ln\",\"ha\",\"ba\",\"jw\",\"su\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert audio file into base64 encoded string\n",
    "\n",
    "audio_file = \"<LOCAL_AUDIO_FILE_PATH>\" # Provide the audio file for inference\n",
    "with open(audio_file,'rb') as f:\n",
    "    audio = f.read()\n",
    "base64encodedstr = base64.b64encode(audio).decode(\"ascii\")\n",
    "\n",
    "# Create sample-request.json file for the audio file\n",
    "\n",
    "sample_file = os.path.join(os.getcwd(), \"sample-request.json\")\n",
    "sample_request = {\n",
    "    \"audio\": [base64encodedstr],\n",
    "    \"language\": [\"en\"] # Language to be transcribed to.\n",
    "}\n",
    "\n",
    "with open(sample_file, 'w') as f:\n",
    "    f.write(json.dumps(sample_request))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remote Audio File Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inferencing a remote audio file pass the audio file uri as \"audio\"\n",
    "audio_file_uri = \"<REMOTE_AUDIO_FILE_URI>\" # Provide the audio file URI\n",
    "sample_file = os.path.join(os.getcwd(), \"sample-request.json\")\n",
    "sample_request = {\n",
    "    \"audio\": [audio_file_uri],\n",
    "    \"language\": [\"en\"] # Language to be transcribed to.\n",
    "}\n",
    "\n",
    "with open(sample_file, 'w') as f:\n",
    "    f.write(json.dumps(sample_request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing the inference of the deployment, create a *sample-request.json* file in the same folder as the notebook. \n",
    "# Sample inputs for automatic-speech-recognition task can be found in the *sample-inputs* folder under *inference*.\n",
    "\n",
    "# Invoke the deployment using the given input\n",
    "try:\n",
    "    with open(\"./sample-request.json\", \"r\") as f:\n",
    "        print(f\"Input: \\n{f.read()}\")\n",
    "    output = ws_client.online_endpoints.invoke(\n",
    "        endpoint_name=endpoint_name,\n",
    "        deployment_name=deployment_name,\n",
    "        request_file=\"./sample-request.json\",\n",
    "    )\n",
    "    print(f\"Output: \\n{output}\\n\")\n",
    "except Exception as err:\n",
    "    raise RuntimeError(f\"Inference to endpoint: {endpoint_name} and deployment: {deployment_name} failed. Detailed Response:\\n{err}\") from err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all resources (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to delete all resources created as part of this notebook\n",
    "try:\n",
    "    ws_client.online_deployments.begin_delete(name=deployment_name, endpoint_name=endpoint_name)\n",
    "    print(\"\\n---Deployment deletion triggered successfully---\\n\")\n",
    "except Exception as err:\n",
    "    raise RuntimeError(f\"Deployment {deployment_name} deletion failed. Detailed Response:\\n{err}\") from err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml-whisper-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd4c7802ca2d7f02aa63e53786c03d4273e96360cf73bb9005ffc3fe1c1785ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
