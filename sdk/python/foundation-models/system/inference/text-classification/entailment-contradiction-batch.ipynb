{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Text Classification Inference using Batch Endpoints\n",
    "\n",
    "This sample shows how to run inference in batch model for `text-classification` task.\n",
    "\n",
    "### Task\n",
    "`text-classification` is generic task type that can be used for scenarios such as sentiment analysis, emotion detection, grammar checking, spam filtering, etc. In this example, we will test for entailment v/s contradiction, meaning given a premise sentence and a hypothesis sentence, the task is to predict whether the premise entails the hypothesis (entailment), contradicts the hypothesis (contradiction), or neither (neutral). \n",
    "\n",
    "### Inference data\n",
    "The Multi-Genre Natural Language Inference Corpus, or MNLI is a crowd sourced collection of sentence pairs with textual entailment annotations.The [MNLI](https://huggingface.co/datasets/glue) dataset is a subset of the larger [General Language Understanding Evaluation](https://gluebenchmark.com/) dataset. A copy of this dataset is available in the [glue-mnli](./glue-mnli/) folder.\n",
    "\n",
    "### Model\n",
    "Look for models tagged with `text-classification` in the system registry. Just looking for `text-classification` is not sufficient, you need to check if the model is specifically finetuned for  entailment v/s contradiction by studying the model card and looking at the input/output samples or signatures of the model. In this notebook, we use the `microsoft-deberta-base-mnli` model.\n",
    "\n",
    "  \n",
    "### Outline\n",
    "* Setup pre-requisites.\n",
    "* Pick a model to deploy.\n",
    "* Prepare data for inference. \n",
    "* Deploy the model for batch inference.\n",
    "* Run a batch inference job.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup pre-requisites\n",
    "* Install dependencies\n",
    "* Connect to AzureML Workspace. Learn more at [set up SDK authentication](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk). Replace  `<WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` below.\n",
    "* Check or create compute.\n",
    "* Connect to `azureml` system registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, ClientSecretCredential\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "import time\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        subscription_id =  \"21d8f407-c4c4-452e-87a4-e609bfb86248\", #\"<SUBSCRIPTION_ID>\"\n",
    "        resource_group_name =  \"rg-contoso-819prod\", #\"<RESOURCE_GROUP>\",\n",
    "        workspace_name =  \"mlw-contoso-819prod\", #\"WORKSPACE_NAME>\",\n",
    "    )\n",
    "# the models, fine tuning pipelines and environments are available in the AzureML system registry, \"azureml-preview\"\n",
    "registry_ml_client = MLClient(credential, registry_name=\"azureml-preview-test1\")\n",
    "\n",
    "compute_cluster = \"gpu-cluster-big\"\n",
    "try:\n",
    "    compute = workspace_ml_client.compute.get(compute_cluster)\n",
    "except Exception as ex:\n",
    "    compute = AmlCompute(\n",
    "        name=compute_cluster,\n",
    "        size=\"Standard_ND40rs_v2\",\n",
    "        max_instances=2,  # For multi node training set this to an integer value more than 1\n",
    "    )\n",
    "    workspace_ml_client.compute.begin_create_or_update(compute).wait()\n",
    "\n",
    "# genrating a unique timestamp that can be used for names and versions that need to be unique\n",
    "timestamp = str(int(time.time())) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2. Pick a model to deploy\n",
    "\n",
    "Browse models in the Model Catalog in the AzureML Studio, filtering by the `text-classification` task. In this example, we use the `microsoft-deberta-base-mnli` model. If you have opened this notebook for a different model, replace the model name and version accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Using model name: microsoft-deberta-base-mnli, version: 6, id: azureml://registries/azureml-preview-test1/models/microsoft-deberta-base-mnli/versions/6 for fine tuning\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft-deberta-base-mnli\"\n",
    "model_version = \"6\"\n",
    "foundation_model=registry_ml_client.models.get(model_name, model_version)\n",
    "print (\"\\n\\nUsing model name: {0}, version: {1}, id: {2} for fine tuning\".format(foundation_model.name, foundation_model.version, foundation_model.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare data for inference.\n",
    "\n",
    "A copy of the MNLI is available in the [ glue-mnli](./glue-mnli/) folder. The next few cells show basic data preparation:\n",
    "* Visualize some data rows\n",
    "* Replace numerical categories in data with the actual string labels. This mapping is available in the [./glue-mnli/label.json](./glue-mnli/label.json). This step is needed because the selected models will return labels such `CONTRADICTION`, `CONTRADICTION`, etc. when running prediction. If the labels in your ground truth data are left as `0`, `1`, `2`, etc., then they would not match with prediction labels returned by the models.\n",
    "* The dataset contains `premise` and `hypothesis` as two different columns. However, the models expect a single string for prediction in the format `[CLS] <premise text> [SEP] <hypothesis text> [SEP]`. Hence we merge the columns and drop the original columns.\n",
    "* We want this sample to run quickly, so save smaller dataset containing 10% of the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_dir = \"./glue-mnli-dataset\"\n",
    "data_file=\"train.jsonl\"\n",
    "\n",
    "# load the train.jsonl file into a pandas dataframe and show the first 5 rows\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0) # set the max column width to 0 to display the full text\n",
    "df = pd.read_json(os.path.join(dataset_dir,data_file), lines=True)\n",
    "df.head()\n",
    "\n",
    "# load the id2label json element of the label.json file into pandas table with keys as 'label' column of int64 type and values as 'label_string' column as string type\n",
    "import json\n",
    "label_file=\"label.json\"\n",
    "with open(os.path.join(dataset_dir,label_file)) as f:\n",
    "    id2label = json.load(f)\n",
    "    id2label = id2label['id2label']\n",
    "    label_df = pd.DataFrame.from_dict(id2label, orient='index', columns=['label_string'])\n",
    "    label_df['label'] = label_df.index.astype('int64')\n",
    "    label_df = label_df[['label', 'label_string']]\n",
    "\n",
    "# join the train, validation and test dataframes with the id2label dataframe to get the label_string column\n",
    "df =df.merge(label_df, on='label', how='left')\n",
    "# concat the premise and hypothesis columns to with \"[CLS]\" in the beginning and \"[SEP]\" in the middle and end to get the text column\n",
    "df['text'] = \"[CLS] \" + df['premise'] + \" [SEP] \" + df['hypothesis'] + \" [SEP]\"\n",
    "# drop the idx, premise and hypothesis columns as they are not needed\n",
    "df = df.drop(columns=['idx', 'premise', 'hypothesis', 'label'])\n",
    "# rename the label_string column to ground_truth_label\n",
    "df = df.rename(columns={'label_string': 'ground_truth_label'})\n",
    "# keep only the text column in batch_df dataframe\n",
    "batch_df = df[['text']]\n",
    "# rename text column to input_string\n",
    "batch_df = batch_df.rename(columns={'text': 'input_string'})\n",
    "# save 10 of the rows in batch_df dataframe to a csv file named small_batch_train.csv in the ./dataset_dir folder\n",
    "batch_df.sample(frac=0.1).to_csv(os.path.join(dataset_dir,\"small_batch_train.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Batch Endpoint\n",
    "\n",
    "Batch endpoints are endpoints that are used batch inferencing on large volumes of data over a period of time. Batch endpoints receive pointers to data and run jobs asynchronously to process the data in parallel on compute clusters. Batch endpoints store outputs to a data store for further analysis.\n",
    "\n",
    "To create an online endpoint we will use `BatchEndpoint`. This class allows user to configure the following key aspects:\n",
    "- `name` - Name of the endpoint. Needs to be unique at the Azure region level\n",
    "- `auth_mode` - The authentication method for the endpoint. Currently only Azure Active Directory (Azure AD) token-based (`aad_token`) authentication is supported. \n",
    "- `defaults` - Default settings for the endpoint.\n",
    "   - `deployment_name` - Name of the deployment that will serve as the default deployment for the endpoint.\n",
    "- `description`- Description of the endpoint.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import BatchEndpoint, BatchDeployment, Model, AmlCompute, Data\n",
    "batch_endpoint_name = \"entail-contra-\" + timestamp\n",
    "endpoint = BatchEndpoint(\n",
    "    name=batch_endpoint_name,\n",
    "    description=\"Batch endpoint for \" + foundation_model.name + \", to detect entailment v/s contradiction\",\n",
    ")\n",
    "\n",
    "endpoint=workspace_ml_client.batch_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a batch deployment\n",
    "\n",
    "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `BatchDeployment` class. MLflow models don't require an scoring script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "from azure.ai.ml.entities import BatchRetrySettings\n",
    "\n",
    "deployment = BatchDeployment(\n",
    "    name=\"demo\",\n",
    "    description=\"Batch deployment for \" + foundation_model.name + \", to detect entailment v/s contradiction\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=foundation_model,\n",
    "    compute=compute_cluster,\n",
    "    instance_count=2,\n",
    "    max_concurrency_per_instance=2,\n",
    "    mini_batch_size=10,\n",
    "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "    output_file_name=\"predictions.csv\",\n",
    "    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "    logging_level=\"info\",\n",
    ")\n",
    "deployment=workspace_ml_client.batch_deployments.begin_create_or_update(deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default deployment is demo\n"
     ]
    }
   ],
   "source": [
    "# set demo deployment as default\n",
    "endpoint = workspace_ml_client.batch_endpoints.get(batch_endpoint_name)\n",
    "endpoint.defaults.deployment_name = \"demo\"\n",
    "workspace_ml_client.batch_endpoints.begin_create_or_update(endpoint).result()\n",
    "\n",
    "endpoint = workspace_ml_client.batch_endpoints.get(batch_endpoint_name)\n",
    "print(f\"The default deployment is {endpoint.defaults.deployment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a reference of the new data asset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "input = Input(type=AssetTypes.URI_FOLDER, path=os.path.join(dataset_dir,\"small_batch_train.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.3 Invoke the deployment\n",
    "\n",
    "Using the `MLClient` created earlier, we will get a handle to the endpoint. The endpoint can be invoked using the `invoke` command with the following parameters:\n",
    "- `name` - Name of the endpoint\n",
    "- `input_path` - Path where input data is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading small_batch_train.csv\u001b[32m (< 1 MB): 100%|██████████| 756k/756k [00:00<00:00, 1.22MB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job = workspace_ml_client.batch_endpoints.invoke(endpoint_name=endpoint.name, input=input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Notice how we are not indicating the deployment name in the invoke operation. That's because the endpoint automatically routes the job to the default deployment. Since our endpoint only has one deployment, then that one is the default one. You can target an specific deployment by indicating the argument/parameter `deployment_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### 4.6.4 Get the details of the invoked job\n",
    "\n",
    "Let us get details and logs of the invoked job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: batchjob-87246ea0-1274-4349-b56b-8b14a3e3d28e\n",
      "Web View: https://ml.azure.com/runs/batchjob-87246ea0-1274-4349-b56b-8b14a3e3d28e?wsid=/subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/rg-contoso-819prod/workspaces/mlw-contoso-819prod\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2023-04-07 21:16:28Z] Submitting 1 runs, first five are: 1ce9ae60:b6faef50-968e-4fd6-a03c-0e35aeffa423\n",
      "[2023-04-07 21:41:10Z] Execution of experiment failed, update experiment status and cancel running nodes.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: batchjob-87246ea0-1274-4349-b56b-8b14a3e3d28e\n",
      "Web View: https://ml.azure.com/runs/batchjob-87246ea0-1274-4349-b56b-8b14a3e3d28e?wsid=/subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/rg-contoso-819prod/workspaces/mlw-contoso-819prod\n"
     ]
    },
    {
     "ename": "JobException",
     "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2023-04-07T21:41:10.154805Z\",\n    \"component_name\": \"\"\n} ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/CODE/REPOS/azureml-examples/sdk/python/foundation-models/system/inference/text-classification/entailment-contradiction-batch.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-examples/sdk/python/foundation-models/system/inference/text-classification/entailment-contradiction-batch.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m workspace_ml_client\u001b[39m.\u001b[39;49mjobs\u001b[39m.\u001b[39;49mstream(job\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:614\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[1;32m    612\u001b[0m     \u001b[39mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[39m=\u001b[39mjob_object\u001b[39m.\u001b[39mid)\n\u001b[0;32m--> 614\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream_logs_until_completion(\n\u001b[1;32m    615\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_runs_operations, job_object, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datastore_operations, requests_pipeline\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requests_pipeline\n\u001b[1;32m    616\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/ai/ml/operations/_job_ops_helper.py:297\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    295\u001b[0m         file_handle\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m         \u001b[39mraise\u001b[39;00m JobException(\n\u001b[1;32m    298\u001b[0m             message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException : \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(json\u001b[39m.\u001b[39mdumps(error, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)),\n\u001b[1;32m    299\u001b[0m             target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[1;32m    300\u001b[0m             no_personal_data_message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException raised on failed job.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    301\u001b[0m             error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    304\u001b[0m file_handle\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    305\u001b[0m file_handle\u001b[39m.\u001b[39mflush()\n",
      "\u001b[0;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2023-04-07T21:41:10.154805Z\",\n    \"component_name\": \"\"\n} "
     ]
    }
   ],
   "source": [
    "workspace_ml_client.jobs.stream(job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Exploring the results\n",
    "\n",
    "#### 4.7.1 Download the results\n",
    "\n",
    "The deployment creates a child job that executes the scoring. We can get the details of it using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "scoring_job = list(ml_client.jobs.list(parent_job_name=job.name))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs generated by the deployment job will be placed in an output named `score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.download(name=scoring_job.name, download_path=\".\", output_name=\"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read this data using pandas library:\n",
    "\n",
    "> Tip: Notice how the CSV is read as opposite to use directly `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "with open(\"named-outputs/score/predictions.csv\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "\n",
    "score = pd.DataFrame(\n",
    "    literal_eval(data.replace(\"\\n\", \",\")), columns=[\"file\", \"prediction\"]\n",
    ")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean up resources\n",
    "\n",
    "Clean-up the resources created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.batch_endpoints.begin_delete(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "amlv2"
  },
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "429d412e307b288f3a8cba821a3ba110e77b02cf5672d0d0b14db25cc0bc89f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
