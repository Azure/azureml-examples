{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae56335a",
   "metadata": {},
   "source": [
    "# Finetuning Llama-2 on Azure Machine Mearning\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Set up the environment](#Setup)\n",
    "1. [Download model from azureml-meta registry](#Download)\n",
    "1. [Data](#Data)\n",
    "1. [Establish baseline](#Baseline)\n",
    "1. [Finetune](#Finetune)\n",
    "1. [Evaluate](#Evaluate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "873a7cc4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates finetuning Llama-2 foundation model on a text classification dataset using AzureML.\n",
    "\n",
    "Llama-2 model is now available in AzureML Model Catalog. For details please see the [blog](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/introducing-llama-2-on-azure/ba-p/3881233).\n",
    "\n",
    "This functionality is in public preview in Azure Machine Learning. The preview version is provided without a service level agreement, and itâ€™s not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/en-us/support/legal/preview-supplemental-terms/)\n",
    "\n",
    "Notebook summary:\n",
    "\n",
    "1. Setting the environment\n",
    "2. Loading the model and data. In this example we use the [20 Newsgroups dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) from scikit-learn.\n",
    "3. Evaluate the pretrained model on the test set to establish baseline metrics\n",
    "4. Finetune the model\n",
    "5. Evaluating the finetuned model on a test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a7a966e",
   "metadata": {},
   "source": [
    "## Set up the environment <a class=\"anchor\" id=\"Setup\"></a>\n",
    "\n",
    "Install and load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44210d88",
   "metadata": {
    "gather": {
     "logged": 1690422784786
    }
   },
   "outputs": [],
   "source": [
    "%pip uninstall -y azure-identity\n",
    "%pip uninstall -y azure-ai-ml\n",
    "\n",
    "%pip install -U azure-identity\n",
    "%pip install azure-ai-ml==1.9.0a20230616001 --extra-index-url https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/\n",
    "%pip install torch==2.0.1\n",
    "%pip install bitsandbytes\n",
    "%pip install transformers==4.31.0\n",
    "%pip install peft\n",
    "%pip install azureml-evaluate-mlflow\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae5aa0",
   "metadata": {
    "gather": {
     "logged": 1690422788582
    }
   },
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from peft import prepare_model_for_int8_training, LoraConfig, get_peft_model\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "from azureml.metrics import compute_metrics, constants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6f5e85b",
   "metadata": {},
   "source": [
    "### Download model from azureml-meta registry <a class=\"anchor\" id=\"Download\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a21767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "# connect to a workspace\n",
    "workspace_ml_client = None\n",
    "try:\n",
    "    workspace_ml_client = MLClient.from_config(credential)\n",
    "    subscription_id = workspace_ml_client.subscription_id\n",
    "    workspace = workspace_ml_client.workspace_name\n",
    "    resource_group = workspace_ml_client.resource_group_name\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCS_GROUP>\"\n",
    "    workspace = \"<WORKSPACE_NAME>\"\n",
    "    workspace_ml_client = MLClient(\n",
    "        credential, subscription_id, resource_group, workspace\n",
    "    )\n",
    "# Connect to the meta  registry\n",
    "registry_mlclient = MLClient(credential=credential, registry_name=\"azureml-meta\")\n",
    "model_name = \"Llama-2-70b\"\n",
    "version = list(registry_mlclient.models.list(model_name))[0].version\n",
    "registry_mlclient.models.download(model_name, version=version)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "576c2f6f",
   "metadata": {},
   "source": [
    "### Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = f'{model_name}/mlflow_model_folder/data/tokenizer'\n",
    "if not os.path.exists(tokenizer_path):\n",
    "    # mlflow flavor where model and tokenizer in same folder\n",
    "    tokenizer_path = f'{model_name}/mlflow_model_folder/data/model'\n",
    "tokenizer = LlamaTokenizer.from_pretrained(tokenizer_path)\n",
    "tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2f500",
   "metadata": {
    "gather": {
     "logged": 1690424906644
    }
   },
   "outputs": [],
   "source": [
    "model_path = f'{model_name}/mlflow_model_folder/data/model'\n",
    "model = LlamaForSequenceClassification.from_pretrained(model_path, device_map='auto', load_in_8bit=True, torch_dtype=torch.float16, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d424f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please ensure all the shards of the model are loaded into GPUs and do not overflow into CPUs.\n",
    "model.hf_device_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6cf1f5e5",
   "metadata": {},
   "source": [
    "### Load and prepare data <a class=\"anchor\" id=\"Data\"></a>\n",
    "We use the [20 Newsgroups dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) from scikit-learn. We subsample the dataset to select only 4 categories (classes), and sample a 200-row training set, and a 100-row test set which will be held out for model evaluation. (Note that after removing some missing label rows, the exact number of rows are slightly smaller.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34469c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "target_column_name = \"label\"\n",
    "feature_column_name = \"sentence\"\n",
    "\n",
    "\n",
    "def get_20newsgroups_data():\n",
    "    \"\"\"Fetches 20 Newsgroups data from scikit-learn\n",
    "    Returns them in form of pandas dataframes\n",
    "    \"\"\"\n",
    "    remove = (\"headers\", \"footers\", \"quotes\")\n",
    "    categories = [\n",
    "        \"rec.sport.baseball\",\n",
    "        \"rec.sport.hockey\",\n",
    "        \"comp.graphics\",\n",
    "        \"sci.space\",\n",
    "    ]\n",
    "\n",
    "    data = fetch_20newsgroups(\n",
    "        subset=\"train\",\n",
    "        categories=categories,\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        remove=remove,\n",
    "    )\n",
    "    data = pd.DataFrame(\n",
    "        {feature_column_name: data.data, target_column_name: data.target}\n",
    "    )\n",
    "\n",
    "    data_train = data[:200]\n",
    "    data_test = data[200:300]\n",
    "\n",
    "    data_train = remove_blanks_20news(\n",
    "        data_train, feature_column_name\n",
    "    )\n",
    "    data_test = remove_blanks_20news(data_test, feature_column_name)\n",
    "    return Dataset.from_pandas(data_train), Dataset.from_pandas(data_test)\n",
    "\n",
    "\n",
    "def remove_blanks_20news(data, feature_column_name):\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        data.at[index, feature_column_name] = (\n",
    "            row[feature_column_name].replace(\"\\n\", \" \").strip()\n",
    "        )\n",
    "\n",
    "    data = data[data[feature_column_name] != \"\"]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9701254",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = get_20newsgroups_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2678209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    outputs = tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_train.map(\n",
    "    lambda samples: tokenize(samples), remove_columns=[\"__index_level_0__\", \"sentence\"], load_from_cache_file=False)\n",
    "\n",
    "test_dataset = data_test.map(\n",
    "    lambda samples: tokenize(samples), remove_columns=[\"__index_level_0__\", \"sentence\"], load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2be09247",
   "metadata": {},
   "source": [
    "### Compute metrics on test data to establish baseline<a class=\"anchor\" id=\"Baseline\"></a>\n",
    "Here we evaluate the pretrained model and compute metrics using azureml-metrics package, which is in preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885174ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test dataset\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = ['accuracy', 'AUC_weighted', 'average_precision_score_weighted', 'norm_macro_recall', 'precision_score_weighted']\n",
    "\n",
    "# compute the metrics on the test dataset with the predictions from target model\n",
    "def compute_model_metrics(target_model):\n",
    "    # Get predictions.\n",
    "    device = \"cuda\"\n",
    "    l = len(test_dataset)\n",
    "    batch_size = 1\n",
    "\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for i in range(0, l, batch_size):\n",
    "        data_batch = test_dataset[i:i + batch_size]\n",
    "        # NOTE: Before passing data_batch['input_ids] to the model, cast them using torch.LongTensor()\n",
    "        # Same for data_batch['attention_mask']. So that .to(device) call can work.\n",
    "        with torch.no_grad():\n",
    "            outputs = target_model(input_ids=torch.LongTensor(data_batch['input_ids']).to(device), \n",
    "                            attention_mask=torch.LongTensor(data_batch['attention_mask']).to(device))\n",
    "        batch_predictions = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        batch_predictions, batch_references = batch_predictions.detach().cpu().numpy().tolist(), data_batch[\"label\"]\n",
    "        predictions.extend(batch_predictions)\n",
    "        references.extend(batch_references)\n",
    "    references = np.asarray(references, dtype=int)\n",
    "    #Compute metrics\n",
    "    return compute_metrics(task_type=constants.Tasks.CLASSIFICATION,\n",
    "                           y_pred_proba =predictions,\n",
    "                           metrics=metric_names,\n",
    "                           y_test=references)[\"metrics\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a22df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_metrics = compute_model_metrics(model)\n",
    "pprint(pretrained_metrics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d7a85a3",
   "metadata": {},
   "source": [
    "## Finetune the model <a class=\"anchor\" id=\"Finetune\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f1740",
   "metadata": {
    "gather": {
     "logged": 1690424936083
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "   r=4,\n",
    "   lora_alpha=16,\n",
    "   target_modules= [\n",
    "       \"q_proj\",\n",
    "       \"v_proj\",\n",
    "   ],\n",
    "   lora_dropout=.05,\n",
    "   bias=\"none\",\n",
    "   task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccc08c",
   "metadata": {
    "gather": {
     "logged": 1690424937704
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    warmup_steps=0,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=3e-4,\n",
    "    fp16=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    output_dir='.',\n",
    "    ddp_find_unused_parameters=None,\n",
    "    remove_unused_columns=False,\n",
    "    logging_steps=8)\n",
    "\n",
    "trainer = Trainer(\n",
    "                  model=peft_model,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset=test_dataset,\n",
    "                  args=training_args,\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b837e5",
   "metadata": {
    "gather": {
     "logged": 1690419249413
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e05e944",
   "metadata": {},
   "source": [
    "## Evaluate the finetuned model <a class=\"anchor\" id=\"Evaluate\"></a>\n",
    "Now that the finetuned model is ready, we compute metrics with it on the same test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ac2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test dataset\n",
    "peft_model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26dd3a0a",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07788b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_metrics = compute_model_metrics(peft_model)\n",
    "pprint(finetuned_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f8adb56",
   "metadata": {},
   "source": [
    "## Comparison of metrics\n",
    "Here we see accuracy and other metrics improved before and after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ee955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metric_name = []\n",
    "pretrained = []\n",
    "finetuned = []\n",
    "for name in metric_names:\n",
    "        pretrained.append(pretrained_metrics[name])\n",
    "        finetuned.append(finetuned_metrics[name])\n",
    "result = pd.DataFrame({'metric': metric_names, 'pretrained': pretrained, 'finetuned': finetuned})\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
