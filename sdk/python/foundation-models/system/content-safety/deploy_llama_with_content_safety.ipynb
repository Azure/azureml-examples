{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# How to create an Azure AI Content safety enabled LLaMA online endpoint\n",
       "### This notebook will walk you through the steps to create an __Azure AI Content Safety__ enabled __LLaMA__ online endpoint.\n",
       "### The steps are:\n",
       "1. Create an __Azure AI Content Safety__ resource for moderating the request from user and response from the __LLaMA__ online endpoint.\n",
       "2. Create a new __LLaMA__ online endpoint.\n",
       "3. Create a new __Azure AI Content Safety__ enabled __LLaMA__ online endpoint with a custom score.py which will integrate with the __Azure AI Content Safety__ resource to moderate the response from the __LLaMA__ model and the request from the user, but to make the custom score.py to sucessfully autheticated to the __Azure AI Content Safety__ resource, we have 2 options:\n",
       "    1. __UAI__, recommended but more complex approach, is to create a __User Assigned Identity (UAI)__ and assign appropriate roles to the __UAI__. Then, the custom score.py can obtain the access token of the __UAI__ from the AAD server to access the Azure AI Content Safety resource.\n",
       "    2. __Environment variable__, simpler but less secure approach, is to just pass the access key of the __Azure AI Content Safety__ resource to the custom score.py via environment variable, then the custom score.py can use the key directly to access the Azure AI Content Safety resource, this option is less secure than the first option, if someone in your org has access to the endpoint, he/she can get the access key from the environment variable and use it to access the Azure AI Content Safety resource.\n",
       "  "
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 1. Prerequisites\n",
       "#### 1.1 Check List:\n",
       "- [x] You have created an new Python virtual environment for this notebook.\n",
       "- [x] The identity you are using to execute this notebook(yourself or your VM) need to have the __Contributor__ role on the resource group where the AML Workspace your specified is located, because this notebook will create an Azure AI Content Safety resource using that identity.\n",
       "- [x] Required If you choose to use the UAI approach, the identity executing this notebook (either yourself or your virtual machine) needs to have the owner role on the resource group that contains the specified AML Workspace. This is because the notebook will create a new UAI and assign the UAI some required roles to successfully create the Azure AI Content Safety enabled LLaMA endpoint."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 1.2 Install Dependencies"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "%pip install azure-identity==1.13.0\n",
       "%pip install azure-mgmt-cognitiveservices==13.4.0\n",
       "%pip install azure-ai-ml==1.8.0\n",
       "%pip install azure-mgmt-msi==7.0.0\n",
       "%pip install azure-mgmt-authorization==3.0.0"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 1.3 Assign variables for the workspace and deployment"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# NOTE: Update following workspace information to contain\n",
       "#       your subscription ID, resource group name, and workspace name\n",
       "subscription_id = \"c830bb7a-83f5-45e3-81fc-3c2053e7d16f\"\n",
       "resource_group = \"bowgong-test\"\n",
       "workspace_name = \"bowgong-aml-test\""
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 1.3 Decide on a name for your Content Safety enabled LLaMA online endpoint"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import random\n",
       "rand = random.randint(0, 10000)\n",
       "\n",
       "endpoint_name = f\"safetyllama{rand}\" # the final endpoint name of the safety enabled llama endpoint\n",
       "# with the given name, there will be 4 resources created in the resource group of your AML workspace:\n",
       "# 1. an Azure AI Content Safety resource: {endpoint_name}-aacs\n",
       "# 2. a LLaMA online endpoint: {endpoint_name}-llama\n",
       "# 3. a UAI(User Assigned Identity): {endpoint_name}-uia\n",
       "# 4. an Azure AI Content Safety enabled LLaMA online endpoint, which you will be using it to do your AI work: {endpoint_name}\n",
       "aacs_name = f\"{endpoint_name}-aacs\"\n",
       "uai_name = f\"{endpoint_name}-uai\"\n",
       "llama_endpoint_name = f\"{endpoint_name}-llama\"\n",
       "print(f\"going to create the following resources:\")\n",
       "print(f\"-  Azure AI Content Safety resource: {aacs_name}\")\n",
       "print(f\"-  LLaMA online endpoint: {llama_endpoint_name}\")\n",
       "print(f\"-  UAI: {uai_name}\")\n",
       "print(f\"-  Azure AI Content Safety enabled LLaMA online endpoint: {uai_name}\")\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2. Connect to your AML Workspace"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os, json\n",
       "from azure.ai.ml import MLClient\n",
       "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
       "\n",
       "try:\n",
       "    credential = DefaultAzureCredential()\n",
       "    # Check if given credential can get token successfully.\n",
       "    credential.get_token(\"https://management.azure.com/.default\")\n",
       "except Exception as ex:\n",
       "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
       "    credential = InteractiveBrowserCredential()\n",
       "\n",
       "try:\n",
       "    ml_client = MLClient(credentials=credential, subscription_id=subscription_id, resource_group=resource_group, workspace_name=workspace_name)\n",
       "except Exception as ex:\n",
       "    client_config = {\n",
       "        \"subscription_id\": subscription_id,\n",
       "        \"resource_group\": resource_group,\n",
       "        \"workspace_name\": workspace_name,\n",
       "    }\n",
       "    # write and reload from config file\n",
       "    config_path = \"./config.json\"\n",
       "    os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
       "    with open(config_path, \"w\") as fo:\n",
       "        fo.write(json.dumps(client_config))\n",
       "    ml_client = MLClient.from_config(credential=credential, path=config_path)\n",
       "    \n",
       "workspace_location = ml_client.workspaces.get(ml_client.workspace_name).location\n",
       "workspace_resource_id = ml_client.workspaces.get(ml_client.workspace_name).id\n",
       "subscription_id = ml_client.subscription_id\n",
       "resource_group_name = ml_client.resource_group_name\n",
       "workspace_name = ml_client.workspace_name\n",
       "print(f\"Connected to workspace {workspace_resource_id}\")\n",
       "print(f\"Workspace location is {workspace_location}\") "
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 4. Create Azure AI Content Safety"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 4.1 Choose a region for your Azure AI Content Safety\n",
       "Currently, Azure AI Content Safety only available in the following regions:\n",
       "- East US\n",
       "- West Europe\n",
       "\n",
       "__NOTE__: before you choose the region to deploy the Azure AI Content Safety, please aware of that your data will be transferred to the region you choose and by selecting a region outside your current location, you may be allowing the transmission of your data to regions outside your jurisdiction. It is important to note that data protection and privacy laws may vary between jurisdictions. Before proceeding, we strongly advise you to familiarize yourself with the local laws and regulations governing data transfer and ensure that you are legally permitted to transmit your data to an overseas location for processing. By continuing with the selection of a different region, you acknowledge that you have understood and accepted any potential risks associated with such data transmission. Please proceed with caution."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# location for the Azure AI Content Safety resource\n",
       "available_acs_locations = ['east us', 'west europe']\n",
       "aacs_location = available_acs_locations[0] \n",
       "\n",
       "print(f\"will create Azure AI Content Safety `{aacs_name}` in {aacs_location}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from azure.mgmt.cognitiveservices import CognitiveServicesManagementClient\n",
       "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
       "from azure.mgmt.cognitiveservices.models import Account, Sku, AccountProperties\n",
       "import time\n",
       "\n",
       "try:\n",
       "    credential = DefaultAzureCredential()\n",
       "    # Check if given credential can get token successfully.\n",
       "    credential.get_token(\"https://management.azure.com/.default\")\n",
       "except Exception as ex:\n",
       "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
       "    credential = InteractiveBrowserCredential()\n",
       "\n",
       "client = CognitiveServicesManagementClient(credential, subscription_id)\n",
       "\n",
       "# create a new Cognitive Services Account\n",
       "kind = \"ContentSafety\"\n",
       "sku_name = \"S0\"\n",
       "parameters = Account(sku=Sku(name=sku_name), kind=kind, location=aacs_location, properties= AccountProperties(custom_sub_domain_name=aacs_name, public_network_access=\"Enabled\"))\n",
       "# How many seconds to wait between checking the status of an async operation.\n",
       "wait_time = 10\n",
       "\n",
       "poller = client.accounts.begin_create(resource_group_name, aacs_name, parameters)\n",
       "while (not poller.done()) :\n",
       "    print(\"Waiting {wait_time} seconds for operation to finish.\".format(wait_time=wait_time))\n",
       "    time.sleep (wait_time)\n",
       "    # This will raise an exception if the server responded with an error.\n",
       "    result = poller.result()\n",
       "\n",
       "\n",
       "print(\"Resource created.\")\n",
       "\n",
       "aacs=client.accounts.get(resource_group_name, aacs_name)\n",
       "aacs_endpoint = aacs.properties.endpoint\n",
       "aacs_resource_id = aacs.id\n",
       "print(f\"AACS endpoint is {aacs_endpoint}\")\n",
       "print(f\"AACS ResourceId is {aacs_resource_id}\")\n",
       "\n",
       "aacs_access_key = client.accounts.list_keys(resource_group_name=resource_group_name, account_name=aacs_name).key1\n",
       "print(f\"AACS access key is {aacs_access_key}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 5. Create LLaMA online endpoint"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 5.1 Decide on SKU and instance count for the LLaMA online endpoint."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "compute_sku_for_llama=\"Standard_DS5_v2\" # the sku of the compute instance for LLaMA endpoint\n",
       "compute_instance_count_for_llama=1 # the number of compute instance\n",
       "llama_endpoint_name=f\"{endpoint_name}-llama\"\n",
       "print(f\"Will create LLaMA endpoint {llama_endpoint_name} using {compute_instance_count_for_llama} {compute_sku_for_llama} compute instance(s)\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 5.2 Check if LLaMA model is available in the AML registry."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "available_llama_models_pre_trained = [\"Llama-2-7b\", \"Llama-2-13b\"]\n",
       "available_llama_models_fine_tuned = [\"Llama-2-7b-chat\", \"Llama-2-13b-chat\"]\n",
       "\n",
       "model_name = \"gpt2\" # TODO(mingtwan) change to LLaMA\n",
       "\n",
       "registry_ml_client = MLClient(credential, registry_name=\"azureml\")\n",
       "version_list = list(registry_ml_client.models.list(model_name)) # list available versions of the model\n",
       "foundation_model = None\n",
       "if len(version_list) == 0:\n",
       "    print(\"Model not found in registry\")\n",
       "else:\n",
       "    model_version = version_list[0].version\n",
       "    foundation_model = registry_ml_client.models.get(model_name, model_version)\n",
       "    print(\n",
       "        f\"Using model name: {foundation_model.name}, version: {foundation_model.version}, id: {foundation_model.id} for inferencing\"\n",
       "    )"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 5.3 Create LLaMA online endpoint\n",
       "This step may take a few minutes."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, OnlineRequestSettings\n",
       "\n",
       "auth_mode_for_llama = \"key\" # please DO NOT change this. \n",
       "# create an online endpoint\n",
       "llama_endpoint = ManagedOnlineEndpoint(\n",
       "        name=llama_endpoint_name,\n",
       "        description=\"Online endpoint for LLaMA\",\n",
       "        auth_mode=auth_mode_for_llama,\n",
       "    )\n",
       "ml_client.begin_create_or_update(llama_endpoint).result()\n",
       "\n",
       "llama_deployment_name=\"demo\"\n",
       "llama_deployment = ManagedOnlineDeployment(\n",
       "    name=llama_deployment_name,\n",
       "    endpoint_name=llama_endpoint_name,\n",
       "    model=foundation_model.id,\n",
       "    instance_type=compute_sku_for_llama,\n",
       "    instance_count=compute_instance_count_for_llama,\n",
       "    request_settings=OnlineRequestSettings(\n",
       "        request_timeout_ms=60000,\n",
       "    )\n",
       ")\n",
       "ml_client.online_deployments.begin_create_or_update(llama_deployment).wait()\n",
       "# deployment takes 100 traffic\n",
       "llama_endpoint.traffic = {llama_deployment_name: 100}\n",
       "ml_client.online_endpoints.begin_create_or_update(llama_endpoint)\n",
       "\n",
       "llama_endpoint = ml_client.online_endpoints.get(name=llama_endpoint_name)\n",
       "llama_endpoint_id = llama_endpoint.id\n",
       "llama_score_uri = llama_endpoint.scoring_uri\n",
       "print(f\"LLaMA endpoint scoring uri is {llama_score_uri}\")\n",
       "llama_access_key = ml_client.online_endpoints.get_keys(name=llama_endpoint_name).primary_key\n",
       "print(f\"LLaMA endpoint access key is {llama_access_key}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 6. Create `score.py` for the Azure AI Content Safety enabled LLaMA endpoint\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 6.1 Create a folder to save the score.py and conda dependencies file.\n",
       "First create a source folder for the score.py file and conda dependencies file:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "\n",
       "scoring_src_dir = \"./safety-llama\"\n",
       "os.makedirs(scoring_src_dir, exist_ok=True)\n",
       "print(f\"Scoring script directory: {scoring_src_dir}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 6.2 Create the score.py"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "%%writefile {scoring_src_dir}/score.py\n",
       "import logging\n",
       "import json\n",
       "from azure.identity import ManagedIdentityCredential\n",
       "from azure.ai.ml import MLClient\n",
       "import os\n",
       "\n",
       "# environment variable names\n",
       "env_key_of_aacs_endpoint = \"AACS_ENDPOINT\"\n",
       "env_key_of_uai_id = \"UAI_CLIENT_ID\" # if provided, the script will use the UAI's AAD token to obtain the access key of the LLaMA online endpoint, and use the token to authenticate to the AACS resource directly.\n",
       "env_key_of_aacs_key = \"AACS_ACCESS_KEY\" # if the UAI_CLIENT_ID not provided, the the script will fallback to use the access of the AACS resource.\n",
       "env_key_of_llama_score_uri = \"LLAMA_SCORE_URI\"\n",
       "env_key_of_subscription_id = \"SUBSCRIPTION_ID\"\n",
       "env_key_of_resource_group_name = \"RESOURCE_GROUP_NAME\"\n",
       "env_key_of_workspace_name = \"WORKSPACE_NAME\"\n",
       "env_key_of_llama_endpoint_name = \"LLAMA_ENDPOINT_NAME\"\n",
       "\n",
       "\n",
       "def init():\n",
       "    \"\"\"\n",
       "    This function is called when the container is initialized/started, typically after create/update of the deployment.\n",
       "    You can write the logic here to perform init operations like caching the model in memory\n",
       "    \"\"\"\n",
       "    aacs_endpoint = os.environ.get(env_key_of_aacs_endpoint)\n",
       "    llama_score_uri = os.environ.get(env_key_of_llama_score_uri)\n",
       "    uai_id = os.environ.get(env_key_of_uai_id) \n",
       "    \n",
       "    logging.info(\"AACS endpoint: \", aacs_endpoint)\n",
       "    logging.info(\"LLaMA score uri: \", llama_score_uri)\n",
       "    logging.info(\"UAI ID: \", uai_id)\n",
       "    logging.info(\"Init complete\")\n",
       "\n",
       "def run(raw_data):\n",
       "    \"\"\"\n",
       "    This function is called for every invocation of the endpoint to perform the actual scoring/prediction.\n",
       "    In the example we extract the data from the json input and call the scikit-learn model's predict()\n",
       "    method and return the result back\n",
       "    \"\"\"\n",
       "    data = json.loads(raw_data)[\"data\"]\n",
       "    logging.info(\"Request processed\")\n",
       "    return '{\"text\":\"Hello World\"}'\n",
       "\n",
       "def _get_aad_token_for_aacs():\n",
       "    \"\"\"\n",
       "    Get access key for Azure AI Content Safety\n",
       "    \"\"\"\n",
       "    credential = ManagedIdentityCredential(client_id=os.environ.get(env_key_of_uai_id))\n",
       "    aacs_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\") # get token for AACS\n",
       "\n",
       "def _get_llama_access_key():\n",
       "    \"\"\"\n",
       "    Helper function to get the access key for LLaMA endpoint\n",
       "    \"\"\"\n",
       "    credential = ManagedIdentityCredential(client_id=os.environ.get(env_key_of_uai_id))\n",
       "    subscription_id = os.environ.get(env_key_of_subscription_id)\n",
       "    resource_group =  os.environ.get(env_key_of_resource_group_name)\n",
       "    workspace_name = os.environ.get(env_key_of_workspace_name)\n",
       "\n",
       "    ml_client = MLClient(\n",
       "        credential,\n",
       "        subscription_id=subscription_id,\n",
       "        resource_group_name=resource_group,\n",
       "        workspace_name=workspace_name,\n",
       "    )\n",
       "    llama_endpoint_name = os.environ.get(env_key_of_llama_endpoint_name)\n",
       "    if not llama_endpoint_name:\n",
       "        raise ValueError(\"LLaMA endpoint name is not provided\")\n",
       "    \n",
       "    llama_access_key = ml_client.online_endpoints.get_keys(name=llama_endpoint_name).primary_key\n",
       "    return llama_access_key"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 6.3 Create the conda.yaml"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "%%writefile {scoring_src_dir}/conda.yaml\n",
       "name: aacs-conda\n",
       "channels:\n",
       "  - defaults\n",
       "dependencies:\n",
       "  - python=3.9\n",
       "  - pip:\n",
       "    - azure-identity==1.13.0\n",
       "    - azure-ai-ml==1.8.0\n",
       "    - azureml-inference-server-http==0.8.4"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 7. Create the Azure AI Content Safety enabled LLaMA online endpoint\n",
       "Before we get started to create the Azure AI Contenet Safety enabled LLaMA online endpoint, you need to make the decision on which approach you want to use for the custome score.py to authenticate to the Azure AI Content Safety resource, if you choose the UAI approach you need to the steps 7.1 and 7.2, if you choose the environment variable approach then you can skip to step 7.3 to get started."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 7.1 Create a Managed Identity for the Azure AI Content Safety enabled LLaMA endpoint\n",
       "NOTE: Azure Content Safey is support AAD token based authentication by default, which means we need to create a new UAI for the Azure AI Content Safety enabled LLaMA endpoint, so that it can access the Azure AI Content Safety using AAD token."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.1.1 Get a handle to the ManagedServiceIdentityClient"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from azure.mgmt.msi import ManagedServiceIdentityClient\n",
       "from azure.mgmt.msi.models import Identity\n",
       "\n",
       "msi_client = ManagedServiceIdentityClient(\n",
       "    subscription_id=subscription_id,\n",
       "    credential=credential,\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.1.2 Create the User Assigned Identity:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "uai_name = f\"{endpoint_name}-uai\"\n",
       "print(f\"Will create UAI(User Assigned Identity) {uai_name} for the Azure AI Content Safety enabled LLaMA endpoint.\")\n",
       "\n",
       "msi_client.user_assigned_identities.create_or_update(\n",
       "    resource_group_name=resource_group_name,\n",
       "    resource_name=uai_name,\n",
       "    parameters=Identity(location=workspace_location),\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.1.3 Retrieve the identity object\n",
       "we need to retrieve the identity object so that we can use it to deploy the Azure AI Content Safety enabled LLaMA online endpoint."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "uai_identity = msi_client.user_assigned_identities.get(\n",
       "    resource_group_name=resource_group_name,\n",
       "    resource_name=uai_name,\n",
       ")\n",
       "uai_principal_id = uai_identity.principal_id\n",
       "uai_client_id = uai_identity.client_id\n",
       "uai_id = uai_identity.id\n",
       "print(f\"UAI principal id: {uai_principal_id}\")\n",
       "print(f\"UAI client id: {uai_client_id}\")\n",
       "print(f\"UAI id: {uai_id}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 7.2 Grant appropriate roles to the UAI we created above.\n",
       "Note: In order to successfully run scripts in current step, your must have owner permission on the AACS resource and the LLaMA endpoint, which we created in the previous steps."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.2.1 Get an AuthorizationManagementClient to list Role Definitions"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from azure.mgmt.authorization import AuthorizationManagementClient\n",
       "from azure.mgmt.authorization.v2020_10_01_preview.models import RoleAssignmentCreateParameters\n",
       "import uuid\n",
       "\n",
       "role_definition_client = AuthorizationManagementClient(\n",
       "    credential=credential,\n",
       "    subscription_id=subscription_id,\n",
       "    api_version=\"2018-01-01-preview\",\n",
       ")\n",
       "\n",
       "role_assignment_client = AuthorizationManagementClient(\n",
       "    credential=credential,\n",
       "    subscription_id=subscription_id,\n",
       "    api_version=\"2020-10-01-preview\",\n",
       ")\n",
       "\n",
       "uai_role_check_list = {\n",
       "    \"Cognitive Services User\": {\"step\": \"7.2.2\", \"description\":\"assigne the role Cognitive Services User to the UAI on the Azure AI Content Safety resource.\"},\n",
       "    \"AzureML Data Scientist\": {\"step\": \"7.2.3\", \"description\":\"assigne the role AzureML Data Scientist to the UAI on the workspace.\"},\n",
       "    \"AcrPull\": {\"step\": \"7.2.4\", \"description\":\"assigne the role AcrPull to the UAI on the Azure Container Registry.\"},\n",
       "    \"Storage Blob Data Reader\": {\"step\": \"7.2.5\", \"description\":\"assigne the role Storage Blob Data Reader to the UAI on the Azure Storage account.\"},\n",
       "}"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.2.2 Grant the user identity access to the Azure Content Safety resource\n",
       "Cognitive Services User role is required to access the Azure Content Safety resource."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "role_name = \"Cognitive Services User\" # minimum role required for accessing AACS\n",
       "scope = aacs_resource_id\n",
       "\n",
       "role_defs = role_definition_client.role_definitions.list(scope=scope)\n",
       "role_def = next((r for r in role_defs if r.role_name == role_name))\n",
       "\n",
       "from azure.core.exceptions import ResourceExistsError\n",
       "try:\n",
       "    role_assignment_client.role_assignments.create(\n",
       "        scope=scope,\n",
       "        role_assignment_name=str(uuid.uuid4()),\n",
       "        parameters=RoleAssignmentCreateParameters(\n",
       "            role_definition_id=role_def.id,\n",
       "            principal_id=uai_principal_id,\n",
       "            principal_type=\"ServicePrincipal\",\n",
       "        ),\n",
       "    )\n",
       "except ResourceExistsError as ex:\n",
       "    pass\n",
       "except Exception as ex:\n",
       "    print(ex)\n",
       "    raise ex\n",
       "\n",
       "if role_name in uai_role_check_list:\n",
       "    del uai_role_check_list[role_name] \n",
       "print(f\"Role assignment for {role_name} at the Azure AI Content Safety resource level completed.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.2.3 Grant the user identity access to the LLaMA online endpoint.\n",
       "In order to retrieve the key of the LLaMA online endpoint, the MI must have `AzureML Data Scientist` role on the workspace level."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "role_name = \"AzureML Data Scientist\"\n",
       "scope = workspace_resource_id\n",
       "\n",
       "role_defs = role_definition_client.role_definitions.list(scope=scope)\n",
       "role_def = next((r for r in role_defs if r.role_name == role_name))\n",
       "from azure.core.exceptions import ResourceExistsError\n",
       "try:\n",
       "    role_assignment_client.role_assignments.create(\n",
       "        scope=scope,\n",
       "        role_assignment_name=str(uuid.uuid4()),\n",
       "        parameters=RoleAssignmentCreateParameters(\n",
       "            role_definition_id=role_def.id,\n",
       "            principal_id=uai_principal_id,\n",
       "            principal_type=\"ServicePrincipal\",\n",
       "        ),\n",
       "    )\n",
       "except ResourceExistsError as ex:\n",
       "    pass\n",
       "except Exception as ex:\n",
       "    print(ex)\n",
       "    raise ex\n",
       "\n",
       "if role_name in uai_role_check_list:\n",
       "    del uai_role_check_list[role_name] \n",
       "print(f\"Role assignment for {role_name} at the workspace level completed.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.2.4 Assign AcrPull at the workspace container registry scope\n",
       "Since we will create the content safety enabled LlaMa endpoint with User Assigned Identity, the user managed identity must have Storage Blob Data Reader permission on the storage account for the workspace, and AcrPull permission on the Azure Container Registry (ACR) for the workspace. Make sure your User Assigned Identity has the right permission."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "workspace = ml_client.workspaces.get(workspace_name)\n",
       "container_registry = workspace.container_registry\n",
       "\n",
       "role_name = \"AcrPull\"\n",
       "\n",
       "role_defs = role_definition_client.role_definitions.list(scope=container_registry)\n",
       "role_def = next((r for r in role_defs if r.role_name == role_name))\n",
       "\n",
       "from azure.core.exceptions import ResourceExistsError\n",
       "try:\n",
       "    role_assignment_client.role_assignments.create(\n",
       "        scope=container_registry,\n",
       "        role_assignment_name=str(uuid.uuid4()),\n",
       "        parameters=RoleAssignmentCreateParameters(\n",
       "            role_definition_id=role_def.id,\n",
       "            principal_id=uai_principal_id,\n",
       "            principal_type=\"ServicePrincipal\",\n",
       "        ),\n",
       "    ) \n",
       "except ResourceExistsError as ex:\n",
       "    pass\n",
       "except Exception as ex:\n",
       "    print(ex)\n",
       "    raise ex\n",
       "\n",
       "if role_name in uai_role_check_list:\n",
       "    del uai_role_check_list[role_name] \n",
       "print(\"Role assignment for AcrPull at the workspace container registry completed.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.2.5 Assign Storage Blob Data Reader at the workspace storage account scope"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "role_name = \"Storage Blob Data Reader\"\n",
       "blob_scope = workspace.storage_account\n",
       "\n",
       "role_defs = role_definition_client.role_definitions.list(scope=blob_scope)\n",
       "role_def = next((r for r in role_defs if r.role_name == role_name))\n",
       "\n",
       "from azure.core.exceptions import ResourceExistsError\n",
       "try:\n",
       "    role_assignment_client.role_assignments.create(\n",
       "        scope=blob_scope,\n",
       "        role_assignment_name=str(uuid.uuid4()),\n",
       "        parameters=RoleAssignmentCreateParameters(\n",
       "            role_definition_id=role_def.id,\n",
       "            principal_id=uai_principal_id,\n",
       "            principal_type=\"ServicePrincipal\",\n",
       "        ),\n",
       "    )\n",
       "except ResourceExistsError as ex:\n",
       "    pass\n",
       "except Exception as ex:\n",
       "    print(ex)\n",
       "    raise ex\n",
       "\n",
       "if role_name in uai_role_check_list:\n",
       "    del uai_role_check_list[role_name]  \n",
       "print(\"Role assignment for `Storage Blob Data Reader` at the workspace storage account completed.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 7.3 Create Content Safety enabled LLaMA online endpoint using above score.py"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.3.1 Decide on SKU and instance count for the Content Safety enabled LLaMA online endpoint.\n",
       "TODO: Add more details about SKU and instance count recommandation."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "compute_sku_for_safety_proxy = \"Standard_DS5_v2\"\n",
       "compute_count = 1\n",
       "\n",
       "safety_llama_auth_mode = \"key\" # currently, \"key\" and \"aml_token\" are supported\n",
       "aacs_authentication_mode = \"UAI\" # UAI or EnvVar, if EnvVar is used, the access keys of AACS and LLaMA online endpoint will be set to environment variables."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "##### 7.3.2 Create the Safety-Enabled LLaMA Online Endpoint\n",
       "This step may take a few minutes."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "__Before we proceed to the next step, let's make sure we didn't miss anything in the previous steps, please execute the following script to check on that:__"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Check everything is properly done before creating the Azure AI Content Safety Enabled LLaMA online endpoint\n",
       "missing_steps = []\n",
       "if aacs_authentication_mode == \"UAI\":\n",
       "    print(\"You selected UAI to deploy the Azure AI Content Safety Enabled LLaMA online endpoint, checking if the UAI has the required roles assigned...\")\n",
       "    if uai_role_check_list:\n",
       "        for key, value in uai_role_check_list.items():\n",
       "            missing_steps.append(f'Please go to step {value[\"step\"]} to {value[\"description\"]}')\n",
       "\n",
       "if missing_steps:\n",
       "    print(\"Seems you missed some step above.\")\n",
       "    steps = \"\\n\".join(missing_steps)\n",
       "    raise Exception(f\"Please complete the missing steps before proceeding:\\n{steps}\")\n",
       "else:\n",
       "    print(\"All steps are completed, proceeding to create the Azure AI Content Safety Enabled LLaMA online endpoint...\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# environment variables that will be used in the scoring script\n",
       "# environment variable names\n",
       "env_key_of_aacs_endpoint = \"AACS_ENDPOINT\"\n",
       "env_key_of_uai_id = \"UAI_CLIENT_ID\" # if provided, the script will use the UAI's AAD token to obtain the access key of the LLaMA online endpoint, and use the token to authenticate to the AACS resource directly.\n",
       "env_key_of_aacs_key = \"AACS_ACCESS_KEY\" # if the UAI_CLIENT_ID is not provided, the the script will fallback to use the access key of the AACS resource.\n",
       "env_key_of_llama_key = \"LLAMA_ACCESS_KEY\" # if the UAI_CLIENT_ID is not provided, the the script will fallback to use the access key of the LLaMA online endpoint.\n",
       "env_key_of_llama_score_uri = \"LLAMA_SCORE_URI\"\n",
       "env_key_of_subscription_id = \"SUBSCRIPTION_ID\"\n",
       "env_key_of_resource_group_name = \"RESOURCE_GROUP_NAME\"\n",
       "env_key_of_workspace_name = \"WORKSPACE_NAME\"\n",
       "env_key_of_llama_endpoint_name = \"LLAMA_ENDPOINT_NAME\"\n",
       "\n",
       "from azure.ai.ml.entities import (\n",
       "    ManagedOnlineDeployment,\n",
       "    ManagedOnlineEndpoint,\n",
       "    CodeConfiguration,\n",
       "    Environment,\n",
       "    ManagedIdentityConfiguration,\n",
       "    IdentityConfiguration\n",
       ")\n",
       "\n",
       "if not aacs_endpoint:\n",
       "    raise Exception(\"AACS Endpoint is not valid.\")\n",
       "else:\n",
       "    print(f\"AACS Endpoint: {aacs_endpoint}\")\n",
       "\n",
       "environment_variables = { \n",
       "    env_key_of_aacs_endpoint: aacs_endpoint,\n",
       "    env_key_of_llama_score_uri: llama_score_uri,\n",
       "    env_key_of_subscription_id: subscription_id,\n",
       "    env_key_of_resource_group_name: resource_group_name,\n",
       "    env_key_of_workspace_name: workspace_name,\n",
       "    env_key_of_llama_endpoint_name: llama_endpoint_name\n",
       "}\n",
       "\n",
       "uai_identity_config = None\n",
       "if uai_client_id:\n",
       "    environment_variables[env_key_of_uai_id] = uai_client_id\n",
       "else:\n",
       "    print(\"UAI_CLIENT_ID is not provided. The script will fallback to use the access key of the AACS resource and the LLaMA online endpoint.\")\n",
       "    # use environment varibale to pass access keys\n",
       "    environment_variables[env_key_of_aacs_key] = aacs_access_key\n",
       "    environment_variables[env_key_of_llama_key] = llama_access_key\n",
       "    uai_identity_config = IdentityConfiguration(\n",
       "            type=\"user_assigned\",\n",
       "            user_assigned_identities=[\n",
       "                ManagedIdentityConfiguration(resource_id=uai_id)\n",
       "            ],\n",
       "        )\n",
       "\n",
       "deployment = ManagedOnlineDeployment(\n",
       "        name=\"blue\",\n",
       "        endpoint_name=endpoint_name,\n",
       "        code_configuration=CodeConfiguration(\n",
       "            code=f\"{scoring_src_dir}\", scoring_script=\"score.py\"\n",
       "        ),\n",
       "        environment=Environment(\n",
       "            conda_file=f\"{scoring_src_dir}/conda.yaml\",\n",
       "            image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
       "        ),\n",
       "        instance_type=compute_sku_for_safety_proxy,\n",
       "        instance_count=compute_count,\n",
       "        environment_variables=environment_variables,\n",
       "    )\n",
       "\n",
       "\n",
       "endpoint = ManagedOnlineEndpoint(\n",
       "        name=endpoint_name,\n",
       "        description=\"Azure AI Content Safety enabled LLaMA online endpoint\",\n",
       "        auth_mode=safety_llama_auth_mode,\n",
       "        identity=uai_identity_config,\n",
       "    )\n",
       "# create online endpoint\n",
       "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
       "\n",
       "endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
       "print(endpoint.identity.type)\n",
       "print(endpoint.identity.user_assigned_identities)\n",
       "\n",
       "# create deployment\n",
       "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
       "# check status\n",
       "deployment = ml_client.online_deployments.get(\n",
       "        endpoint_name=endpoint_name, name=deployment.name\n",
       "    )\n",
       "print(deployment)\n",
       "# Set traffic to 100% for deployment\n",
       "endpoint.traffic = {str(deployment.name): 100}\n",
       "ml_client.begin_create_or_update(endpoint).result()\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 8. Test the Safety Enabled LLaMA online endpoint."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 8.1 Test endpoint with normal sample request"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "\n",
       "test_src_dir = \"./safety-llama-test\"\n",
       "os.makedirs(test_src_dir, exist_ok=True)\n",
       "print(f\"test script directory: {test_src_dir}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "%%writefile {test_src_dir}/sample-request.json\n",
       "{\"data\": \"Hello World\"}"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "sample_data = f\"{test_src_dir}/sample-request.json\"\n",
       "ml_client.online_endpoints.invoke(endpoint_name=endpoint_name, request_file=sample_data)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### 8.2 Test endpoint with harmful sample request"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "%%writefile {test_src_dir}/sample-harmful-request.json\n",
       "{\"data\": \"I wanna kill you!\"}"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "sample_data = f\"{test_src_dir}/sample-harmful-request.json\"\n",
       "ml_client.online_endpoints.invoke(endpoint_name=endpoint_name, request_file=sample_data)"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 1
   }