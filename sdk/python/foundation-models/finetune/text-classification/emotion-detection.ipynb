{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification - Emotion Detection \n",
    "\n",
    "This sample shows how to fine tune a model to detect emotions using emotion dataset and deploy it to an endpoint for real time inference.\n",
    "\n",
    "### Training data\n",
    "We will use the [emotion](https://huggingface.co/datasets/dair-ai/emotion) dataset a copy of which is available in the `azureml` system registry for easy access.\n",
    "\n",
    "### Model\n",
    "Models that can perform the `fill-mask` task are generally good candidates to fine tune for `text-classification`. We will list all models of the `fill-mask` type, from which you can pick one. If you opened this notebook from a specific model card, copy past the model `Asset ID`. Optionally, if you need to fine tune a model that is available on HuggingFace, but not available in `azureml` system registry, you can either [import](https://github.com/Azure/azureml-examples) the model or use the `huggingface_id` parameter to use a model directly from HuggingFace. [Learn more]().\n",
    "\n",
    "### Outline\n",
    "* Setup pre-requisites such as compute.\n",
    "* Pick a model to fine tune.\n",
    "* Pick and explore training data.\n",
    "* Configure the fine tuning job.\n",
    "* Run the fine tuning job.\n",
    "* Register the fine tuned model. \n",
    "* Deploy the fine tuned model for real time inference.\n",
    "* Clean up resources. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup pre-requisites\n",
    "* Install dependencies\n",
    "* Connect to AzureML Workspace. Learn more at [set up SDK authentication](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk). Replace  `<WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` below.\n",
    "* Connect to `azureml` system registry\n",
    "* Set an optional experiment name\n",
    "* Check or create compute. A single GPU node can have multiple GPU cards. For example, in one node of `Standard_ND40rs_v2` there are 8 NVIDIA V100 GPUs while in `Standard_NC12s_v3`, there are 2 NVIDIA V100 GPUs. Refer to the [docs](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu) for this information. The number of GPU cards per node is set in the param `gpus_per_node` below. Setting this value correctly will ensure utilization of all GPUs in the node. The recommended GPU compute SKUs can be found [here](https://learn.microsoft.com/en-us/azure/virtual-machines/ncv3-series) and [here](https://learn.microsoft.com/en-us/azure/virtual-machines/ndv2-series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, ClientSecretCredential\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        subscription_id =  \"21d8f407-c4c4-452e-87a4-e609bfb86248\", #\"<SUBSCRIPTION_ID>\"\n",
    "        resource_group_name =  \"rg-contoso-819prod\", #\"<RESOURCE_GROUP>\",\n",
    "        workspace_name =  \"mlw-contoso-819prod\", #\"WORKSPACE_NAME>\",\n",
    ")\n",
    " \n",
    "registry_ml_client = MLClient(\n",
    "    credential,\n",
    "    registry_name=\"azureml-preview\",\n",
    ")\n",
    "\n",
    "experiment_name = \"text-classification-emotion-detection\"\n",
    "\n",
    "compute_cluster = \"gpu-cluster-big\"\n",
    "try:\n",
    "    workspace_ml_client.compute.get(compute_cluster)\n",
    "except Exception as ex:\n",
    "    compute = AmlCompute(\n",
    "        name = compute_cluster, # If you already have a gpu cluster, mention it here.\n",
    "        size= \"Standard_ND40rs_v2\",\n",
    "        max_instances= 2 # For multi node training set this to an integer value more than 1\n",
    "    )\n",
    "    workspace_ml_client.compute.begin_create_or_update(compute).wait()\n",
    "\n",
    "gpus_per_node = 2 # This is the number of GPUs in a single node of the selected 'vm_size' compute\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pick a model to fine tune\n",
    "\n",
    "We will query the `azureml` system registry and list all models of the type `fill-mask`. Any of these models will work for `text-classification`, but in this example, we use `bert-base-uncased`. If you have opened this notebook for a specific mode, replace the model name and version accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: distilbert-base-uncased, version: 3\n",
      "Model name: distilroberta-base, version: 3\n",
      "Model name: roberta-large, version: 3\n",
      "Model name: camembert-base, version: 3\n",
      "Model name: microsoft-deberta-base, version: 3\n",
      "Model name: bert-large-uncased, version: 3\n",
      "Model name: microsoft-deberta-xlarge, version: 3\n",
      "Model name: distilbert-base-cased, version: 3\n",
      "Model name: bert-large-cased, version: 3\n",
      "Model name: bert-base-cased, version: 3\n",
      "Model name: microsoft-deberta-large, version: 3\n",
      "Model name: bert-base-uncased, version: 3\n",
      "Model name: roberta-base, version: 3\n"
     ]
    }
   ],
   "source": [
    "models = registry_ml_client.models.list()\n",
    "for model in models:\n",
    "    versions=registry_ml_client.models.list(model.name) # replace this with get the latest version?\n",
    "    for version in versions:\n",
    "        if (version.tags['task'] == 'fill-mask'):\n",
    "            print (\"Model name: {0}, version: {1}\".format(version.name, version.version))\n",
    "        break       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Using model name: bert-base-uncased, version: 3 for fine tuning\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "model_version = \"3\"\n",
    "print (\"\\n\\nUsing model name: {0}, version: {1} for fine tuning\".format(model_name, model_version))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare the dataset for to fine tune\n",
    "> This notebook pulls from HuggingFace datasets but we will change this to point to system registry after we onboard sample data to system registry and fine tune component supports data splitting\n",
    "\n",
    "Start by fetching dataset label names. The actual data contains label numeric categories so we will use this metadata to add a column that contains actual label names when we download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_context:\n",
      "  created_at: '2023-03-15T23:54:19.132158+00:00'\n",
      "  created_by: Manoj Bableshwar\n",
      "  created_by_type: User\n",
      "  last_modified_at: '2023-03-15T23:54:19.147819+00:00'\n",
      "id: /subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourceGroups/rg-contoso-819prod/providers/Microsoft.MachineLearningServices/workspaces/mlw-contoso-819prod/data/emotion/versions/1\n",
      "name: emotion\n",
      "path: azureml://subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/rg-contoso-819prod/workspaces/mlw-contoso-819prod/datastores/workspaceblobstore/paths/LocalUpload/d4561647b85625a246688ae8f566c7fa/emotion-unsplit.json\n",
      "properties: {}\n",
      "tags: {}\n",
      "type: uri_file\n",
      "version: '1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "import pandas as pd\n",
    "# toto - this data asset should be loaded from the system registry\n",
    "data_asset = workspace_ml_client.data.get(name=\"emotion\", version=1)\n",
    "print(data_asset)\n",
    "\n",
    "# todo - show some sample data from the data asset\n",
    "# df = pd.read_json(data_asset.path, lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Submit the fine tuning job using the the model and data as inputs\n",
    " \n",
    "Create the job that uses the `text-classification` pipeline component. [Learn more]() about all the parameters supported for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import CommandComponent, PipelineComponent, Job, Component\n",
    "from azure.ai.ml import PyTorchDistribution, Input\n",
    "\n",
    "# fetch the pipeline component\n",
    "pipeline_component_func = registry_ml_client.components.get(name=\"textclassificationsinglelabel_pipelinecomponent\", version=\"0.0.13\")\n",
    "\n",
    "# temporary registry until split_dataset is available in fine tune component\n",
    "registry_data_ml_client = MLClient(\n",
    "    credential,\n",
    "    registry_name=\"sample-data\",\n",
    ")\n",
    "split_dataset_func = registry_data_ml_client.components.get(name=\"split_dataset\", version=\"0.0.11\")\n",
    "\n",
    "# define the pipeline job\n",
    "@pipeline()\n",
    "def create_pipeline():\n",
    "    split_data_job = split_dataset_func(\n",
    "        data_file = Input(type=\"uri_file\", path=data_asset.path),\n",
    "        train_split = 0.05, # dataset has 50k+ rows, so picking a small number for sample pipeline\n",
    "        validation_split = 0.005, # 10% of train split\n",
    "        test_split = 0.005, # 10% of train split\n",
    "    )\n",
    "    split_data_job.compute = compute_cluster\n",
    "\n",
    "    finetuning_job = pipeline_component_func( \n",
    "        huggingface_id = model_name, # this needs to change to use model from system registry\n",
    "        compute_model_selector = compute_cluster,\n",
    "        compute_preprocess = compute_cluster,\n",
    "        compute_finetune = compute_cluster,\n",
    "        compute_model_evaluation = compute_cluster,\n",
    "        train_file_path = split_data_job.outputs.train_file, \n",
    "        valid_file_path = split_data_job.outputs.validation_file,\n",
    "        test_file_path = split_data_job.outputs.test_file,\n",
    "        sentence1_key = \"text\", # picked up by visualizing the sample data in step 3\n",
    "        label_key = \"label_string\", # picked up by visualizing the sample data in step 3\n",
    "        test_data_input_column_names = \"text\", # picked up by visualizing the sample data in step 3\n",
    "        process_count_per_instance_finetune = gpus_per_node, # set to the number of GPUs available in the compute\n",
    "        epochs = 2,\n",
    "        learning_rate = 2e-5, \n",
    "    )\n",
    "    return {\n",
    "        \"trained_model\": finetuning_job.outputs.mlflow_model_folder_finetune\n",
    "    }\n",
    "\n",
    "pipeline_object = create_pipeline()\n",
    "pipeline_object.display_name =  \"text-classification-using-\" + model_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: gray_basket_ldlxr7bjlx\n",
      "Web View: https://ml.azure.com/runs/gray_basket_ldlxr7bjlx?wsid=/subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/rg-contoso-819prod/workspaces/mlw-contoso-819prod\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2023-03-16 05:28:50Z] Submitting 2 runs, first five are: 4a45a41a:d29a1872-cc6d-40f5-9794-518301334583,5a7a9693:fd4b32b7-045c-4101-b25e-fc927f8a63a7\n"
     ]
    }
   ],
   "source": [
    "pipeline_job = workspace_ml_client.jobs.create_or_update(pipeline_object, experiment_name=experiment_name)\n",
    "workspace_ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Register the fine tuned model with the workspace\n",
    "\n",
    "We will register the model from the output of the fine tuning job. This will track lineage between the fine tuned model and the fine tuning job. The fine tuning job, further, tracks lineage to the foundation model, data and training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline job outputs:  {'trained_model': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x7f62988e60a0>}\n",
      "path to register model:  azureml://jobs/4765c75a-871a-476f-ac5b-5fba7cd01263/outputs/mlflow_model_folder\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "# check if the `trained_model` output is available\n",
    "print (\"pipeline job outputs: \", workspace_ml_client.jobs.get(pipeline_job.name).outputs)\n",
    "\n",
    "# fetch the model from pipeline job output - not working, hence fetching from fine tune child job\n",
    "# model_path_from_job = (\"azureml://jobs/{0}/outputs/{1}\".format(pipeline_job.name, \"trained_model\"))\n",
    "\n",
    "for level1_job in workspace_ml_client.jobs.list(parent_job_name=pipeline_job.name): # pipeline component job\n",
    "    for level2_job in workspace_ml_client.jobs.list(parent_job_name=level1_job.name): # pipeline component subgraph job (not shown in UI)\n",
    "        for level3_job in workspace_ml_client.jobs.list(parent_job_name=level2_job.name): # child jobs\n",
    "            if (level3_job.display_name == \"finetune\"):\n",
    "                model_path_from_job = (\"azureml://jobs/{0}/outputs/{1}\".format(level3_job.name, \"mlflow_model_folder\"))\n",
    "\n",
    "finetuned_model_name = model_name + \"-emotion-detection\"\n",
    "print(\"path to register model: \", model_path_from_job)\n",
    "#prepare_to_register_model = Model(\n",
    "#    path=model_path_from_job,\n",
    "#    type=AssetTypes.MLFLOW_MODEL,\n",
    "#    name=finetuned_model_name\n",
    "#    version=1,\n",
    "#    description=model_name + \" fine tuned model for emotion detection\"\n",
    "#)\n",
    "#print(prepare_to_register_model)\n",
    "# register the model from pipeline job output \n",
    "# registered_model = workspace_ml_client.models.create_or_update(prepare_to_register_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class FeatureStoreOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class FeaturesetOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class FeaturestoreEntityOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "{\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2023-03-15T05:48:59.688470+00:00\",\n",
      "    \"created_by\": \"Manoj Bableshwar\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2023-03-15T05:48:59.688470+00:00\",\n",
      "    \"last_modified_by\": \"Manoj Bableshwar\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"flavors\": {\n",
      "    \"hftransformers\": {\n",
      "      \"code\": \"\",\n",
      "      \"hf_pretrained_class\": \"BertForSequenceClassification\",\n",
      "      \"huggingface_id\": \"bert-base-uncased\",\n",
      "      \"model_data\": \"data\",\n",
      "      \"pytorch_version\": \"1.11.0\",\n",
      "      \"task_type\": \"text-classification\",\n",
      "      \"tokenizer_config\": \"{\\n  \\\"padding\\\": \\\"max_length\\\",\\n  \\\"truncation\\\": \\\"true\\\"\\n}\",\n",
      "      \"train_label_list\": \"{\\n  \\\"path_list\\\": \\\"train_label_list.npy\\\"\\n}\",\n",
      "      \"transformers_version\": \"4.21.1\"\n",
      "    },\n",
      "    \"python_function\": {\n",
      "      \"data\": \"data\",\n",
      "      \"env\": \"conda.yaml\",\n",
      "      \"loader_module\": \"azureml.evaluate.mlflow.hftransformers\",\n",
      "      \"python_version\": \"3.8.15\"\n",
      "    }\n",
      "  },\n",
      "  \"id\": \"azureml:/subscriptions/ed2cab61-14cc-4fb3-ac23-d72609214cfd/resourceGroups/training_rg/providers/Microsoft.MachineLearningServices/workspaces/swatig_ws/models/bert-base-uncased-emotion-detection/versions/1\",\n",
      "  \"job_name\": \"4765c75a-871a-476f-ac5b-5fba7cd01263\",\n",
      "  \"name\": \"bert-base-uncased-emotion-detection\",\n",
      "  \"path\": \"azureml://subscriptions/ed2cab61-14cc-4fb3-ac23-d72609214cfd/resourceGroups/training_rg/workspaces/swatig_ws/datastores/workspaceblobstore/paths/azureml/f9d009a0-1830-43b0-984c-1b9829ebd6b5/mlflow_model_folder/\",\n",
      "  \"properties\": {},\n",
      "  \"resourceGroup\": \"training_rg\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"mlflow_model\",\n",
      "  \"version\": \"1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Use cli to register model, with path from the above output until \n",
    "! az ml model create --path azureml://jobs/4765c75a-871a-476f-ac5b-5fba7cd01263/outputs/mlflow_model_folder --name bert-base-uncased-emotion-detection --version 1 --type mlflow_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deploy the fine tuned model to an online endpoint\n",
    "Online endpoints give a durable REST API that can be used to integrate with applications that need to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "\n",
    "finetuned_model_name = \"bert-base-uncased\" + \"-emotion-detection\"\n",
    "\n",
    "registered_model = workspace_ml_client.models.get(name=finetuned_model_name, version=1)\n",
    "\n",
    "timestamp = str(int(time.time())) # endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
    "# Create online endpoint\n",
    "online_endpoint_name = \"emotion-\" + timestamp\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"Online endpoint for \" + registered_model.name + \", fine tuned model for emotion detection\",\n",
    "    auth_mode=\"key\"\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint emotion-1678894711 exists\n",
      "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(BadRequest) The request is invalid.\nCode: BadRequest\nMessage: The request is invalid.\nException Details:\t(InferencingClientCreateDeploymentFailed) InferencingClient HttpRequest error, error detail: {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_DS2_v2 in SubscriptionId ed2cab61-14cc-4fb3-ac23-d72609214cfd. Current usage/limit: 98/100. Additional needed: 4 Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-outofquota\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-ab61d316fbbc35369a98123cfda92535-0d1503e90d490258-01\"}\n\tCode: InferencingClientCreateDeploymentFailed\n\tMessage: InferencingClient HttpRequest error, error detail: {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_DS2_v2 in SubscriptionId ed2cab61-14cc-4fb3-ac23-d72609214cfd. Current usage/limit: 98/100. Additional needed: 4 Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-outofquota\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-ab61d316fbbc35369a98123cfda92535-0d1503e90d490258-01\"}\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"ab61d316fbbc35369a98123cfda92535\",\n        \"request\": \"46308321247dabec\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"eastus\"\n}Type: Location\nInfo: {\n    \"value\": \"eastus\"\n}Type: Time\nInfo: {\n    \"value\": \"2023-03-15T15:42:17.5945741+00:00\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# create a deployment\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m demo_deployment \u001b[39m=\u001b[39m ManagedOnlineDeployment(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdemo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     endpoint_name\u001b[39m=\u001b[39monline_endpoint_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     instance_count\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m workspace_ml_client\u001b[39m.\u001b[39;49monline_deployments\u001b[39m.\u001b[39;49mbegin_create_or_update(demo_deployment)\u001b[39m.\u001b[39mwait()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m endpoint\u001b[39m.\u001b[39mtraffic \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdemo\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m100\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bmanojubuntu/mnt/c/CODE/REPOS/azureml-foundation-models/finetune/sample_pipelines/single_label_classification/emotion/emotion-finetune.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m workspace_ml_client\u001b[39m.\u001b[39mbegin_create_or_update(endpoint)\u001b[39m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/ai/ml/operations/_online_deployment_operations.py:184\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, local, vscode_debug, skip_script_validation)\u001b[0m\n\u001b[1;32m    182\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    183\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/ai/ml/operations/_online_deployment_operations.py:179\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, local, vscode_debug, skip_script_validation)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[39mreturn\u001b[39;00m poller\n\u001b[1;32m    178\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m--> 179\u001b[0m         \u001b[39mraise\u001b[39;00m ex\n\u001b[1;32m    180\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/ai/ml/operations/_online_deployment_operations.py:162\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, local, vscode_debug, skip_script_validation)\u001b[0m\n\u001b[1;32m    159\u001b[0m     location \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_workspace_location()\n\u001b[1;32m    160\u001b[0m     deployment_rest \u001b[39m=\u001b[39m deployment\u001b[39m.\u001b[39m_to_rest_object(location\u001b[39m=\u001b[39mlocation)\n\u001b[0;32m--> 162\u001b[0m     poller \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_online_deployment\u001b[39m.\u001b[39;49mbegin_create_or_update(\n\u001b[1;32m    163\u001b[0m         resource_group_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resource_group_name,\n\u001b[1;32m    164\u001b[0m         workspace_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_workspace_name,\n\u001b[1;32m    165\u001b[0m         endpoint_name\u001b[39m=\u001b[39;49mdeployment\u001b[39m.\u001b[39;49mendpoint_name,\n\u001b[1;32m    166\u001b[0m         deployment_name\u001b[39m=\u001b[39;49mdeployment\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    167\u001b[0m         body\u001b[39m=\u001b[39;49mdeployment_rest,\n\u001b[1;32m    168\u001b[0m         polling\u001b[39m=\u001b[39;49mAzureMLPolling(\n\u001b[1;32m    169\u001b[0m             LROConfigurations\u001b[39m.\u001b[39;49mPOLL_INTERVAL,\n\u001b[1;32m    170\u001b[0m             path_format_arguments\u001b[39m=\u001b[39;49mpath_format_arguments,\n\u001b[1;32m    171\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_kwargs,\n\u001b[1;32m    172\u001b[0m         ),\n\u001b[1;32m    173\u001b[0m         polling_interval\u001b[39m=\u001b[39;49mLROConfigurations\u001b[39m.\u001b[39;49mPOLL_INTERVAL,\n\u001b[1;32m    174\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_kwargs,\n\u001b[1;32m    175\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m response, deserialized, headers: OnlineDeployment\u001b[39m.\u001b[39;49m_from_rest_object(deserialized),\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m poller\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_deployments_operations.py:895\u001b[0m, in \u001b[0;36mOnlineDeploymentsOperations.begin_create_or_update\u001b[0;34m(self, resource_group_name, workspace_name, endpoint_name, deployment_name, body, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m cont_token \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mcontinuation_token\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# type: Optional[str]\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m cont_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     raw_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_or_update_initial(\n\u001b[1;32m    896\u001b[0m         resource_group_name\u001b[39m=\u001b[39;49mresource_group_name,\n\u001b[1;32m    897\u001b[0m         workspace_name\u001b[39m=\u001b[39;49mworkspace_name,\n\u001b[1;32m    898\u001b[0m         endpoint_name\u001b[39m=\u001b[39;49mendpoint_name,\n\u001b[1;32m    899\u001b[0m         deployment_name\u001b[39m=\u001b[39;49mdeployment_name,\n\u001b[1;32m    900\u001b[0m         body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    901\u001b[0m         content_type\u001b[39m=\u001b[39;49mcontent_type,\n\u001b[1;32m    902\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x,y,z: x,\n\u001b[1;32m    903\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    904\u001b[0m     )\n\u001b[1;32m    905\u001b[0m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39merror_map\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    907\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_long_running_output\u001b[39m(pipeline_response):\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_deployments_operations.py:827\u001b[0m, in \u001b[0;36mOnlineDeploymentsOperations._create_or_update_initial\u001b[0;34m(self, resource_group_name, workspace_name, endpoint_name, deployment_name, body, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m, \u001b[39m201\u001b[39m]:\n\u001b[1;32m    826\u001b[0m     map_error(status_code\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code, response\u001b[39m=\u001b[39mresponse, error_map\u001b[39m=\u001b[39merror_map)\n\u001b[0;32m--> 827\u001b[0m     \u001b[39mraise\u001b[39;00m HttpResponseError(response\u001b[39m=\u001b[39mresponse, error_format\u001b[39m=\u001b[39mARMErrorFormat)\n\u001b[1;32m    829\u001b[0m response_headers \u001b[39m=\u001b[39m {}\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: (BadRequest) The request is invalid.\nCode: BadRequest\nMessage: The request is invalid.\nException Details:\t(InferencingClientCreateDeploymentFailed) InferencingClient HttpRequest error, error detail: {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_DS2_v2 in SubscriptionId ed2cab61-14cc-4fb3-ac23-d72609214cfd. Current usage/limit: 98/100. Additional needed: 4 Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-outofquota\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-ab61d316fbbc35369a98123cfda92535-0d1503e90d490258-01\"}\n\tCode: InferencingClientCreateDeploymentFailed\n\tMessage: InferencingClient HttpRequest error, error detail: {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_DS2_v2 in SubscriptionId ed2cab61-14cc-4fb3-ac23-d72609214cfd. Current usage/limit: 98/100. Additional needed: 4 Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-outofquota\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-ab61d316fbbc35369a98123cfda92535-0d1503e90d490258-01\"}\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"ab61d316fbbc35369a98123cfda92535\",\n        \"request\": \"46308321247dabec\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"eastus\"\n}Type: Location\nInfo: {\n    \"value\": \"eastus\"\n}Type: Time\nInfo: {\n    \"value\": \"2023-03-15T15:42:17.5945741+00:00\"\n}"
     ]
    }
   ],
   "source": [
    "# create a deployment\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=\"demo\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {\"demo\": 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test the endpoint with sample data\n",
    "\n",
    "We will fetch some sample data from the test data and submit to online endpoint for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "429d412e307b288f3a8cba821a3ba110e77b02cf5672d0d0b14db25cc0bc89f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
