## Cohere model samples

### Basic samples

Sample | Description | SDKs
--|--|--
[webrequests.ipynb](./webrequests.ipynb)|Use Command R family of LLMs with the native Python packages.|`urllib.request`, `json`
[cohere-cmdR.ipynb](./cohere-cmdR.ipynb)|Use Command R family of LLMs with the Cohere python SDK.|`cohere`
[cohere-embed.ipynb](./cohere-embed.ipynb)| Use Embedding models with the Cohere python SDK.|`cohere`
[langchain.ipynb](./langchain.ipynb)|Use Command R family of LLMs with the LangChain SDK and Cohere's LangChain integration.|`langchain`, `langchain_cohere` 
[litellm.ipynb](./litellm.ipynb)|Use Command R family of LLMs with the LiteLLM SDK |`litellm` 
[openaisdk.ipynb](./openaisdk.ipynb)|Use Command R family of LLMs with the Open AI SDK. Note that this is exprimental and can break if there is breaking change with the OpenAI APIs. |`openai`
todo| Coming soon: Use Command R family of LLMs with the LLM tool in Prompt Flow|todo
todo|Command R+ tool/function calling using LangChain| todo


### Retrieval Augmented Generation (RAG) samples
Sample | Description | SDKs
--|--|--
todo|Create a local (FAISS) vector index using Cohere embeddings - Langchain| todo
todo|Use Cohere Command R/R+ to answer questions from data in local (FAISS) vector index - Langchain|todo
todo|Use Cohere Command R/R+ to answer questions from data in AI search vector index - Langchain|tpdp 
todo|Use Cohere Command R/R+ to answer questions from data in AI search vector index - Cohere SDK| todo



