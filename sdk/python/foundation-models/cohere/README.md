## Cohere model samples

### Basic samples

Sample | Description | SDKs
--|--|--
[webrequests.ipynb](./webrequests.ipynb)|Use Command R family of LLMs with the native Python packages.|`urllib.request`, `json`
[cohere-cmdR.ipynb](./cohere-cmdR.ipynb)|Use Command R family of LLMs with the Cohere python SDK.|`cohere`
[cohere-embed.ipynb](./cohere-embed.ipynb)| Use Embedding models with the Cohere python SDK.|`cohere`
[langchain.ipynb](./langchain.ipynb)|Use Command R family of LLMs with the LangChain SDK and Cohere's LangChain integration.|`langchain`, `langchain_cohere` 
[litellm.ipynb](./litellm.ipynb)|Use Command R family of LLMs with the LiteLLM SDK |`litellm` 
[openaisdk.ipynb](./openaisdk.ipynb)|Use Command R family of LLMs with the Open AI SDK. Note that this is exprimental and can break if there is breaking change with the OpenAI APIs. |`openai`
todo| Coming soon: Use Command R family of LLMs with the LLM tool in Prompt Flow|todo
todo|Command R+ tool/function calling using LangChain| todo


### Retrieval Augmented Generation (RAG) samples
Sample | Description | SDKs
--|--|--
todo|Create and retrive embeddings using Embedding models with LangChain and save them to a local vector store (FAISS) | todo
todo|Create embeddings using Embedding models with LangChain, save them to a local vector store, and retrive them when applicable using Command R+ function calling (FAISS)|todo
todo|RAG with LangChain using Cohere Embed, Cohere Command R+  and Azure AI Search vector - Advanced example using Command R+ function calling and cloud vector store (Azure AI Search)|tpdp 
todo|RAG with Promptflow using Cohere Embed, Cohere Command R+  and Azure AI Search - Promptflow SDK| todo



