{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Cohere Command R or Cohere Command R+ in Azure AI and Azure ML\n",
    "\n",
    "Use `cohere` client to consume Cohere Command R or Cohere Command R+ deployments in Azure AI and Azure ML..\n",
    "\n",
    "> Review the [documentation](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deploy-models-cohere) for the Cohere family of models at for AI Studio and for ML Studio for details on how to provision inference endpoints, regional availability, pricing and inference schema reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before we start, there are certain steps we need to take to deploy the models:\n",
    "\n",
    "* Register for a valid Azure account with subscription \n",
    "* Make sure you have access to [Azure AI Studio](https://learn.microsoft.com/en-us/azure/ai-studio/what-is-ai-studio?tabs=home)\n",
    "* Create a project and resource group\n",
    "* Select `Cohere Command R` or `Cohere Command R+`.\n",
    "\n",
    "    > Notice that some models may not be available in all the regions in Azure AI and Azure Machine Learning. On those cases, you can create a workspace or project in the region where the models are available and then consume it with a connection from a different one. To learn more about using connections see [Consume models with connections](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deployments-connections)\n",
    "\n",
    "* Deploy with \"Pay-as-you-go\"\n",
    "\n",
    "Once deployed successfully, you should be assigned for an API endpoint and a security key for inference.\n",
    "\n",
    "For more information, you should consult Azure's official documentation [here](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deploy-models-cohere) for model deployment and inference.\n",
    "\n",
    "To complete this tutorial, you will need to:\n",
    "\n",
    "* Install `cohere`:\n",
    "\n",
    "    ```bash\n",
    "    pip install cohere\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "The following is an example about how to use `cohere` with a Cohere Command R or Cohere Command R+ model deployed in Azure AI and Azure ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "name": "imports"
   },
   "outputs": [],
   "source": [
    "import cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `cohere`, create a client and configure it as follows:\n",
    "\n",
    "- `endpoint`: Use the endpoint URL from your deployment. Include `/v1` at the end of the endpoint.\n",
    "- `api_key`: Use your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "chat_client"
   },
   "outputs": [],
   "source": [
    "co = cohere.Client(\n",
    "    base_url=\"https://<endpoint>.<region>.inference.ai.azure.com/v1\", api_key=\"<key>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(\n",
    "    base_url=\"https://cohere-cmdr-plus-nydav-serverless.eastus2.inference.ai.azure.com/v1\",\n",
    "    api_key=\"IhBJ96WuhRfRbidJotB1aYXFPTmxN395\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the client to create chat completions requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "name": "chat_invoke"
   },
   "outputs": [],
   "source": [
    "chat_response = co.chat(\n",
    "    message=\"Who is the most renowned French painter? Provide a short answer.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated text can be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "name": "chat_response"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Monet.\n"
     ]
    }
   ],
   "source": [
    "print(chat_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\",\n",
    "        content=\"You are a helpful assistant that help users to find information about traveling, how to get to places and the different transportations options. You care about the environment and you always have that in mind when answering inqueries.\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=\"When is the next flight from Miami to Seattle?\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "chat_response = client.chat(\n",
    "    model=\"azureai\", messages=messages, tools=tools, tool_choice=ToolChoice.auto\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aditional resources\n",
    "\n",
    "Here are some additional reference:  \n",
    "\n",
    "* [Plan and manage costs (marketplace)](https://learn.microsoft.com/azure/ai-studio/how-to/costs-plan-manage#monitor-costs-for-models-offered-through-the-azure-marketplace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
