name: python-sdk-train-amlarc
on:
  schedule:
    - cron: "0 6,18 * * *"
  pull_request:
    branches:
      - main
      - releases/current
    paths:
      - python-sdk/workflows/train/**
      - .github/workflows/python-sdk-train-amlarc.yml
      - cli/amlarc-compute.sh
      - python-sdk/requirements.txt
  workflow_dispatch:
    inputs:
      AMLARC_RELEASE_TRAIN:
        description: 'Release version: experimental, staging or stable'
        required: true
        default: 'experimental'
jobs:
  cpu-test:
    runs-on: ubuntu-latest
    env:
      INPUT_AMLARC_RELEASE_TRAIN: ${{ github.event.inputs.AMLARC_RELEASE_TRAIN }}
      ARC_CLUSTER_PREFIX: amlarc-cluster-arc-py
      AKS_CLUSTER_PREFIX: amlarc-cluster-aks-py
      WORKSPACE: main-python-sdk-amlarc
    steps:
    - name: check out repo
      uses: actions/checkout@v2
    - name: setup python
      uses: actions/setup-python@v2
      with:
        python-version: "3.8"
    - name: pip install
      run: pip install -r python-sdk/requirements.txt
    - name: azure login
      uses: azure/login@v1
      with:
        creds: ${{secrets.AZ_AE_CREDS}}
    - name: init env
      run: |
        bash cli/amlarc-compute.sh install_tools
        bash cli/amlarc-compute.sh prepare_attach_compute_py
    - name: setup STANDARD_DS3_V2 cluster # cpu-cluster
      run: bash cli/amlarc-compute.sh setup_cluster STANDARD_DS3_V2 5 10
    - name: setup cpu-cluster compute
      run: bash cli/amlarc-compute.sh setup_compute STANDARD_DS3_V2 cpu-cluster
    - name: install azmlcli
      run: az extension add -n azure-cli-ml -y
    - name: attach to workspace
      run: az ml folder attach -w main-python-sdk-amlarc -g azureml-examples-rg
    - name: run python-sdk/workflows/train/fastai/mnist/job.py # cpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/fastai/mnist/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/fastai/mnist-mlproject/job.py # cpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/fastai/mnist-mlproject/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/lightgbm/iris/job.py # cpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/lightgbm/iris/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/scikit-learn/diabetes/job.py # cpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/scikit-learn/diabetes/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/scikit-learn/diabetes-mlproject/job.py # cpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/scikit-learn/diabetes-mlproject/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/xgboost/iris/job.py # cpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/xgboost/iris/job.py
      continue-on-error: true
    - name: uninstall azmlcli
      if: ${{ always() }}
      run: az extension remove -n azure-cli-ml
    - name: clean up STANDARD_DS3_V2 cluster
      if: ${{ always() }}
      run: bash cli/amlarc-compute.sh clean_up_cluster STANDARD_DS3_V2
    - name: count result
      if: ${{ always() }}
      run: bash cli/amlarc-compute.sh count_result
      
  gpu-test:
    runs-on: ubuntu-latest
    env:
      INPUT_AMLARC_RELEASE_TRAIN: ${{ github.event.inputs.AMLARC_RELEASE_TRAIN }}
      ARC_CLUSTER_PREFIX: amlarc-cluster-arc-py
      AKS_CLUSTER_PREFIX: amlarc-cluster-aks-py
      WORKSPACE: main-python-sdk-amlarc
    steps:
    - name: check out repo
      uses: actions/checkout@v2
    - name: setup python
      uses: actions/setup-python@v2
      with:
        python-version: "3.8"
    - name: pip install
      run: pip install -r python-sdk/requirements.txt
    - name: azure login
      uses: azure/login@v1
      with:
        creds: ${{secrets.AZ_AE_CREDS}}
    - name: init env
      run: |
        bash cli/amlarc-compute.sh install_tools
        bash cli/amlarc-compute.sh prepare_attach_compute_py
    #- name: setup STANDARD_NC6 cluster # gpu-cluster
    #  run: bash cli/amlarc-compute.sh setup_cluster STANDARD_NC6 4 4
    - name: setup STANDARD_NC12 cluster # gpu-K80-2
      run: bash cli/amlarc-compute.sh setup_cluster STANDARD_NC12 4 4
    - name: setup gpu-cluster compute
      run: bash cli/amlarc-compute.sh setup_compute STANDARD_NC12 gpu-cluster
    - name: setup gpu-K80-2 compute
      run: bash cli/amlarc-compute.sh setup_compute STANDARD_NC12 gpu-K80-2
    - name: install azmlcli
      run: az extension add -n azure-cli-ml -y
    - name: attach to workspace
      run: az ml folder attach -w main-python-sdk-amlarc -g azureml-examples-rg
    # Skipping v100 test cases because of lacking of quota
    # - name: run train/deepspeed/cifar job # gpu-V100-2
    #   run: python python-sdk/workflows/train/deepspeed/cifar/job.py
    # - name: run train/deepspeed/cifar job # gpu-V100-4
    #   run: python python-sdk/workflows/train/deepspeed/transformers/job.py
    - name: run python-sdk/workflows/train/fastai/pets/job.py # gpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/fastai/pets/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/pytorch/cifar-distributed/job.py # gpu-K80-2
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/pytorch/cifar-distributed/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/pytorch/mnist/job.py # gpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/pytorch/mnist/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/pytorch/mnist-mlproject/job.py # gpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/pytorch/mnist-mlproject/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/tensorflow/mnist-distributed-horovod/job.py # gpu-K80-2
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/tensorflow/mnist-distributed-horovod/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/tensorflow/mnist-distributed/job.py # gpu-K80-2
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/tensorflow/mnist-distributed/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/tensorflow/mnist/job.py # gpu-cluster
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/tensorflow/mnist/job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/transformers/glue/1-aml-finetune-job.py # gpu-K80-2
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/transformers/glue/1-aml-finetune-job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/transformers/glue/2-aml-comparison-of-sku-job.py # gpu-cluster gpu-K80-2
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/transformers/glue/2-aml-comparison-of-sku-job.py
      continue-on-error: true
    - name: run python-sdk/workflows/train/transformers/glue/3-aml-hyperdrive-job.py # gpu-K80-2
      run: bash cli/amlarc-compute.sh run_py_test python-sdk/workflows/train/transformers/glue/3-aml-hyperdrive-job.py
      continue-on-error: true
    - name: uninstall azmlcli
      if: ${{ always() }}
      run: az extension remove -n azure-cli-ml
    #- name: clean up STANDARD_NC6 cluster
    # if: ${{ always() }}
    # run: bash cli/amlarc-compute.sh clean_up_cluster STANDARD_NC6
    - name: clean up STANDARD_NC12 cluster
      if: ${{ always() }}
      run: bash cli/amlarc-compute.sh clean_up_cluster STANDARD_NC12
    - name: count result
      if: ${{ always() }}
      run: bash cli/amlarc-compute.sh count_result

