# This code is autogenerated.
# Code is generated by running custom script: python3 readme.py
# Any manual changes to this file may cause incorrect behavior.
# Any manual changes will be overwritten if the code is regenerated.

name: cli-jobs-spark-serverless-spark-pipeline-managed-identity
on:
  workflow_dispatch:
  schedule:
    - cron: "57 5/12 * * *"
  pull_request:
    branches:
      - main
    paths:
      - cli/jobs/spark/**
      - infra/bootstrapping/**
      - .github/workflows/cli-jobs-spark-serverless-spark-pipeline-managed-identity.yml
      - cli/jobs/spark/data/titanic.csv
      - cli/setup.sh
permissions:
  id-token: write
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - name: check out repo
      uses: actions/checkout@v2
    - name: azure login
      uses: azure/login@v1
      with:
        client-id: ${{ secrets.OIDC_AZURE_CLIENT_ID }}
        tenant-id: ${{ secrets.OIDC_AZURE_TENANT_ID }}
        subscription-id: ${{ secrets.OIDC_AZURE_SUBSCRIPTION_ID }}
    - name: bootstrap resources
      run: |
          echo '${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}';
          bash bootstrap.sh
      working-directory: infra/bootstrapping
      continue-on-error: false
    - name: setup-cli
      run: |
          source "${{ github.workspace }}/infra/bootstrapping/sdk_helpers.sh";
          source "${{ github.workspace }}/infra/bootstrapping/init_environment.sh";
          bash setup.sh
      working-directory: cli
      continue-on-error: true
    - name: upload data
      run: |
          bash -x upload-data-to-blob.sh jobs/spark/
      working-directory: cli
      continue-on-error: true
    - name: setup identities
      run: |
          bash -x setup-identities.sh
      working-directory: cli/jobs/spark
      continue-on-error: true
    - name: run job
      run: |
          source "${{ github.workspace }}/infra/bootstrapping/sdk_helpers.sh";
          source "${{ github.workspace }}/infra/bootstrapping/init_environment.sh";
          bash -x ../../run-job.sh serverless-spark-pipeline-managed-identity.yml
      working-directory: cli/jobs/spark
    - name: validate readme
      run: |
          python check-readme.py "${{ github.workspace }}/cli/jobs/spark"
      working-directory: infra/bootstrapping
      continue-on-error: false
